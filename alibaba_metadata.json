{
    "0": {
        "title": "Elastic Compute Service:What is ECS?",
        "url": "https://www.alibabacloud.com/help/en/ecs/what-is-ecs",
        "content": "This Product\nElastic Compute Service:What is ECS?\nElastic Compute Service (ECS) is a high-performance, stable, reliable, and scalable IaaS-level service provided by Alibaba Cloud. ECS eliminates your need to invest in hardware up front. You can create as many or as few instances as you need in response to changes in requirements or popularity of your workloads. ECS provides a variety of instance types that suit various business needs and helps boost business growth.\nDiversified computing capabilities: Alibaba Cloud ECS supports the mainstream x86 and Arm architectures and provides various types of instances, including compute-optimized, GPU-accelerated, ECS Bare Metal, and Super Computing Cluster (SCC) instances, from hundreds of instance families to meet the business requirements of customers of different scales and types.\nEase of use: You do not need to build self-managed data centers. Alibaba Cloud can deliver ECS instances in minutes. ECS provides standard APIs, a performance monitoring framework, and a proactive O&M system. ECS supports various O&M capabilities, such as Terraform, CloudOps Orchestration Service (OOS), and Resource Orchestration Service (ROS), to improve usability and applicability.\nCost optimization: ECS provides multiple billing methods such as pay-as-you-go, subscription, and preemptible instances to meet the requirements of different application scenarios. You can also use discount policies such as savings plans and reserved instances, as well as Auto Scaling and Auto Provisioning capabilities to ensure stable computing power and maximize resource cost-efficiency.\nElasticity and flexibility: You can scale up or down ECS instances in compute capacity, storage capacity, or network bandwidth as your requirements change. You can also use Alibaba Cloud Auto Scaling to scale resources as scheduled or against business loads.\nStability and reliability: A single instance reaches an availability of 99.975%, and multiple instances across zones reach an availability of 99.995%. Storage attached to ECS instances makes use of a multi-replica mechanism to provide a data durability of 99.9999999% (nine 9's). ECS provides various availability and reliability features such as snapshots and automatic alerting.\nSecurity: ECS is secured by high-standard data center security and physical infrastructure protection measures. To enhance the operating system security, access security, network security, and application security, ECS provides multiple guarantees such as hardware encryption, virtual firewalls, Resource Access Management (RAM), Anti-DDoS, vulnerability scanning, and data encryption. This comprehensively protects user business in the cloud.\nFor more information about the benefits and supported scenarios of ECS, see Benefits and Common scenarios.\nECS provides various features and components, including instances, images, block storage devices, snapshots, and security groups, for use in different networks. The following figure shows the service architecture of ECS. For information about the features and components shown in the following figure, see Terms.\nIn ECS, compute resources (vCPUs and memory), images, block storage devices, public bandwidth, and snapshots are the resources that you need to pay for.\nECS supports multiple billing methods for resources:\nSubscription: Subscription instances are resources that you secure for an extended period of time for an upfront payment.\nPay-as-you-go: Pay-as-you-go instances allow you to pay only for the resources that you use without making prior commitments or upfront payments.\nPreemptible Instance: Preemptible instances are unused ECS capacity in Alibaba Cloud. You can purchase preemptible instances at steep discounts, but these instances may be reclaimed by Alibaba Cloud with a short notice.\nReserved Instance: Reserved instances are capacity reservations that are offered at a discounted rate. The discounted rate is applied when the attributes of the ECS instance (including instance type, region, and zone) match those of your reserved instances.\nSavings Plan: Savings plans are a flexible pricing model that offers lower prices for pay-as-you-go instances. Savings plans can be applied to ECS resources such as compute resources and disks, and offer savings on the pay-as-you-go rate on these resources in exchange for a commitment to use a specific amount (measured in USD/hour) within a specific timeframe.\nStorage Capacity Unit (SCU): SCUs are resource plans that offer lower prices for pay-as-you-go storage resources. When you purchase SCUs, you make a commitment to use storage resources of a specific type and capacity in exchange for a lower price. SCUs can be applied to Elastic Block Storage (EBS) devices, File Storage NAS file systems, and Object Storage Service (OSS) buckets.\nFor more information about the billing of ECS resources, see Billing overview and visit the Pricing tab of the Elastic Compute Service product page.\nAfter you create an Alibaba Cloud account, you can log on to Alibaba Cloud and create, use, or release ECS resources by using one of the following methods:\nECS console: a web service page used to manage ECS resources. For information about the operations that you can perform in the ECS console, see Quick reference.\nECS API: A Remote Procedure Call (RPC) API that supports GET and POST requests. For more information, see API overview. You can use the following developer tools or services to call ECS API operations:\nAlibaba Cloud CLI\nOpenAPI Explorer: an Alibaba Cloud service that facilitates API lookup, simplifies the creation of requests, and dynamically generates SDK sample code.\nAlibaba Cloud SDK: provides SDKs for a variety of programming languages such as Java, Python, and PHP.\nROS: an Alibaba Cloud service that you can use to automatically create and configure all Alibaba Cloud resources based on templates that you create.\nOOS: an Alibaba Cloud automated O&M service that you can use to automatically manage and execute O&M tasks. You can define items such as tasks, task steps, inputs, and outputs in execution templates and use the templates to automate O&M tasks.\nTerraform references: an open source tool that can help you version control configuration files or use them to call compute resources of Alibaba Cloud and other platforms that support Terraform.\nAlibaba Cloud Client: a client provided by Alibaba Cloud that can be used to query, view, and connect to ECS instances, elastic container instances, simple application servers, and managed instances.\nTo maximize the benefits of ECS, we recommend that you follow the best practices described in this section.\nRegion and zone\nAlibaba Cloud ECS is available in multiple locations across the world. These locations are classified into regions and zones. Regions are geographical areas in which Alibaba Cloud data centers reside and provide services. Zones are discrete locations within a region with independent power and networking capacities. After an ECS instance is created, its metadata is created, and its region cannot be changed. Metadata is supported only by ECS instances of the Virtual Private Cloud (VPC) type. You can select a region and zone based on your geographical location, the availability of Alibaba Cloud services, application availability requirements, and whether internal network communication is required. For example, if you want to create an ApsaraDB for RDS instance over an internal network, the RDS instance and the ECS instance must reside in the same region. For more information, see Regions and zones.\nHigh availability\nTo ensure business consistency and continuity, create snapshots to back up data, deploy critical components of applications across multiple zones, and use deployment sets and Server Load Balancer (SLB) for disaster recovery.\nNetworking\nAlibaba Cloud VPC allows you to deploy ECS instances in a logically isolated virtual networking environment exclusive to your account. You have full control over the network topology of your VPCs, and can assign private IP addresses to your ECS instances in the VPCs. Alibaba Cloud VPC is compatible with all ECS instance types and features, and is useful for isolating applications or interconnecting services that span multiple regions. For more information, see What is a VPC?\nSecurity\nSecurity groups serve as virtual firewalls for your ECS instances, and allow you to control inbound and outbound traffic and configure port listening settings. Security groups are provided at no extra cost to you. For more information about security groups, see Overview.\nAlibaba Cloud provides free basic security and attack mitigation services in the form of Anti-DDoS Origin Basic and Alibaba Cloud Security Center Basic. The basic security and attack mitigation services secure applications deployed on your ECS instances. For more information, see Anti-DDoS Origin Basic and Basic security services.\nAnti-DDoS Origin Basic provides a DDoS mitigation capacity of up to 5 Gbit/s and is enabled by default. For more advanced DDoS mitigation capabilities, you can opt to purchase an Anti-DDoS Pro or Anti-DDoS Premium instance. For more information, see What is Anti-DDoS Proxy?\nSecurity Center Basic provides ECS instances with basic security services free of charge, such as suspicious logon detection, vulnerability scan, and baseline check. You can upgrade your Security Center to the Anti-virus, Advanced, or Enterprise edition to obtain additional security features and further enhance the security of your ECS instances. For more information, see What is Security Center?"
    },
    "1": {
        "title": "Elastic Compute Service:Benefits",
        "url": "https://www.alibabacloud.com/help/en/ecs/benefits",
        "content": "This Product\nElastic Compute Service:Benefits\nElastic Compute Service (ECS) offers a wide range of instance options, providing convenient, scalable, and reliable compute capacity in the cloud. With ECS, you no longer have to invest precious time and money to purchase, set up, and manage your IT infrastructure, so you can focus on developing and deploying your applications.\nECS provides a broad and deep selection of instances to fit different use cases.\nState-of-the-art computing architecture\nECS instances run on the x86 and ARM architectures, which are sufficient to cover almost all types of workloads.\nDiversified instance types\nECS provides a wide selection of instance types and gives you the flexibility to size your compute resources to match capacity needs at the lowest cost. Instance types comprise varying combinations of compute, memory, and storage capacity, allowing you to choose an appropriate mix of resources for your applications. General-purpose, network-enhanced, storage-enhanced, memory-optimized, security-enhanced, big data, high clock speed, GPU-accelerated, and FPGA-accelerated instance types are available with different options for CPU, memory, and network resources to provide exceptional cost performance for general-purpose computing, heterogeneous computing, and high performance computing scenarios.\nMultiple deployment models\nAside from the typical virtual machine deployment model, ECS also offers dedicated physical resources in the form of ECS bare metal instances and dedicated hosts. ECS bare metal instances provide direct access to the processor and memory resources without virtualization overheads. You can deploy containerized applications on top of ECS bare metal instances in cases where performance is key. Dedicated hosts are physical servers that are entirely dedicated to you. You can create and run ECS instances on dedicated hosts on demand, gaining additional visibility and control over how instances are placed on physical servers.\nAlibaba Cloud's global network allows you to deploy ECS instances in multiple locations all around the world. Equipped with abundant state-of-the-art resources, 10,000 ECS instances can be provisioned securely and reliably within a few minutes. You can use ECS to create as many or as few instances as you need and scale in or out in response to changes in requirements or popularity of your workloads.\nVertical scaling\nYou can scale up or down ECS instances in compute capacity, storage capacity, or network bandwidth as your requirements change.\nHorizontal scaling\nMost business sees different volumes of traffic at different times of the day. In cases such as these, you can use ECS with Auto Scaling to scale in or out resources based on a predetermined schedule or in response to traffic fluctuations to maintain steady, predictable performance at the lowest possible cost.\nService reliability\nECS operates with a single-instance availability of 99.975% and a cross-zone multi-instance availability of 99.995%.\nData durability\nStorage attached to ECS instances makes use of a multi-replica mechanism to provide a data durability of 99.9999999% (nine 9's).\nAvailability and disaster tolerance\nECS provides a host of availability and reliability features such as failover, snapshots, and automatic alerting to ensure service availability and data recovery even when one or more instances fail.\nIntuitive interface\nECS provides a user-friendly, web-based console, which you can use to start, stop, configure, and modify ECS instances in the same way you would with a physical machine.\nPush-button deployment\nECS images are preconfigured with an ever-growing list of operating systems and software. Images allow you to deploy multiple instances with the same configurations quickly and easily.\nRich management and migration tools\nAlibaba Cloud provides rich management and governance tools such as Terraform, CloudOps Orchestration Service, and Resource Orchestration Service (ROS). ECS can also work with Server Migration Center (SMC) to facilitate migration of your business to the cloud.\nDiversified security features\nAlibaba Cloud provides a host of security services and features that meet international standards and requirements for data security. These services include Anti-DDoS Origin Basic, port intrusion detection, vulnerability scanning, and trojan scanning to protect your applications hosted in ECS.\nHardware encryption\nECS supports Virtual Trusted Platform Module (vTPM), confidential computing based on Intel Software Guard Extensions (SGX), and vSGX and provides comprehensive hardware encryption capabilities.\nMultiple billing methods\nECS provides the following purchasing options for instances to help you optimize costs at every stage of your business: subscription instances, pay-as-you-go instances, and preemptible instances.\nFlexible pricing models\nECS also provides modular pricing models in the form of savings plans and reserved instances to help you further reduce costs on ECS resources. Savings plans are a flexible pricing model that offers lower prices than pay-as-you-go pricing, in exchange for a commitment to a consistent amount of usage (measured in USD per hour) for a one- or three-year period. After you purchase savings plans, the lower prices are applied for resources that match the configurations of the savings plans. Reserved instances give you the option to reserve capacity for a period of time and in return receive significant discounts compared to pay-as-you-go Instance pricing. Reserved instances can be applied to pay-as-you-go instances that match the attributes of the reserved instances.\nMix-and-match billing methods\nYou can mix and match billing methods of different ECS resources to achieve the perfect blend of performance and costs tailored towards your use case."
    },
    "2": {
        "title": "Elastic Compute Service:Common scenarios",
        "url": "https://www.alibabacloud.com/help/en/ecs/common-scenarios",
        "content": "This Product\nElastic Compute Service:Common scenarios\nElastic Compute Service (ECS) is compatible with a wide range of Alibaba Cloud services. You can build applications by using only ECS instances, or pair ECS instances with other Alibaba Cloud services to extend your application capabilities.\nThis topic describes some typical use scenarios of ECS.\nNew websites usually have low or sporadic traffic. In cases such as these, you can host your websites on low-configuration instances that can provide sufficient performance for basic website components. As your business grows, you can scale up your instance or scale out to more instances at any time to handle traffic spikes.\nSome e-commerce applications, especially applications used in flash sales or promotions, may experience brief, sharp fluctuations in traffic. In cases such as these, you can use Auto Scaling feature to automatically scale your ECS instances based on business forecasts to maintain steady, predictable performance at the lowest possible cost. You can also leverage Server Load Balancer (SLB) to the mix to improve service availability and ensure consistent user experience. For more information, see What is Auto Scaling? and What is SLB?\nECS caters to data analytics scenarios with its big data instance families. Instances in these instance families are ideal for distributed computing workloads based on the Hadoop framework, log processing jobs, and massive-scale data warehouses. These instance families leverage locally attached storage and interconnected internal networking capabilities to provide immense storage capabilities and minimize network latency for Hadoop and Spark clusters. For more information, see Big data instance families.\nGPU-accelerated instances leverage GPUs to deliver accelerated computing capabilities through hardware acceleration. These instances are capable of near-real-time rendering and are ideal for graphics-intensive workloads, such as rendering, cloud graphics workstation, and video transcoding workloads.\nvgn6i and gn6i instances are powered by Turing-based NVIDIA Tesla T4 GPUs and are designed to deliver top-of-the-line graphics processing capabilities. vgn6i instances also support virtual GPUs (vGPUs), which allows you to virtualize the equipped GPU into multiple GPUs. This way, you can effectively dedicate portions (1/2, 1/4, or 1/8) of the GPU's computing capabilities towards different tasks.\nGPU-accelerated instances provide great price performance balance for time-consuming, compute-intensive deep learning workloads. These instances are ideal for performing floating point computing, data pattern matching, and training deep learning models for machine learning applications. For more information, see GPU-accelerated compute-optimized and vGPU-accelerated instance.\nECS offers instances that are ideal for high-performance computing applications in which you want to run parallel and compute-intensive workloads, such as highly complex simulations. These applications include weather forecasting, biopharmaceutical manufacturing, gene sequencing, and graphics processing.\nFor highly compute-intensive applications such as these, we recommend that you use Elastic High Performance Computing (E-HPC) to manage ECS with other computing resources. E-HPC helps you aggregate and scale computing capabilities with ease, allowing you to build powerful applications that help solve major challenges across multiple fields, including science, engineering, and commerce.\nFor more information about the use scenarios of ECS, see Alibaba Cloud solutions."
    },
    "3": {
        "title": "Elastic Compute Service:Terms",
        "url": "https://www.alibabacloud.com/help/en/ecs/terms",
        "content": "This Product\nElastic Compute Service:Terms\nThis topic describes the terms used in Elastic Compute Service (ECS).\nTerm\nDescription\nECS instance\nAn ECS instance is a virtual server that includes basic components such as vCPUs, memory, an operating system (OS), network, and disks.\nECS instance type\nInstance types define the basic attributes such as computing capacity, storage capacity, and networking performance of ECS instances. Instance types must be used together with images, Elastic Block Storage (EBS) devices, and network resources to create ECS instances that serve different purposes.\nimage\nAn ECS image is a basic template for creating an ECS instance. An image contains the OS and provisioned data that are required to start and run an instance.\npublic image\nPublic images are base images provided by Alibaba Cloud. Public images are licensed and include Windows Server OS images and mainstream Linux OS images.\nAlibaba Cloud Linux\nAlibaba Cloud Linux is a Linux OS distribution developed by Alibaba Cloud. It offers a safe, stable, and high-performance customized environment for applications on ECS instances and are optimized for the infrastructure of Alibaba Cloud.\ncustom image\nYou can create or import custom images. Custom images contain the initial system environment, application environment, and related software configurations. This eliminates the need for repeated manual configurations.\nElastic Block Storage device\nEBS devices offer high performance and reduce latency. You can partition and format EBS devices and create file systems on the devices to meet the data storage requirements of your business.\ndisk\nDisks are block-level EBS devices that use a triplicate mechanism to ensure 99.9999999% data durability for ECS instances.\nlocal disk\nLocal disks are located on the same physical server as the ECS instance to which the disks are attached. Local disks are cost-effective and provide high storage I/O. However, the durability of data stored on local disks is determined by the reliability of the associated physical server, which increases the risks of single points of failure (SPOFs).\nsnapshot\nA snapshot is a point-in-time backup of a disk and is used to back up or restore the disk.\nsecurity group\nA security group is a virtual firewall that is used to control the inbound and outbound traffic of ECS instances in the security group.\nSSH key pair\nAn SSH key pair is a secure and convenient authentication method provided by Alibaba Cloud for instance logons. An SSH key pair consists of a public key and a private key. You can use SSH key pairs to log on to only Linux instances.\nInstance RAM role\nInstance Resource Access Management (RAM) roles enable ECS instances to assume roles with specific access permissions. An instance can access the APIs of specified Alibaba Cloud services and manage specified Alibaba Cloud resources based on a Security Token Service (STS) temporary credential to ensure high security.\nvirtual private cloud (VPC)\nA VPC is a private network established on Alibaba Cloud. VPCs are logically isolated from each other based on tunnels. You have full control over your VPCs. For example, you can specify CIDR blocks and configure route tables and gateways for your VPCs.\nelastic network interface (ENI)\nAn ENI is an independent virtual network interface that can be bound to or unbound from an ECS instance to implement the flexible scaling and migration of services.\nlaunch template\nA launch template contains configuration information that you can use to create ECS instances and eliminates repeated manual configurations.\ndeployment set\nDeployment sets support the high availability strategy. After you apply a high availability strategy to a deployment set, all the instances within the deployment set are distributed across different physical servers to ensure business availability and disaster recovery capabilities at the underlying layer.\ndedicated host\nA dedicated host is a cloud host whose physical resources are exclusively reserved for a single tenant. Dedicated hosts meet strict security and compliance requirements and support Bring Your Own License (BYOL) when you migrate services to the cloud.\nauto provisioning group\nAuto provisioning groups support quick deployment of instance clusters across instance types and zones. Auto provisioning groups can create preemptible instances and pay-as-you-go instances by using a combination of provisioning policies to provide high stability at low cost.\ntag\nEach tag consists of a key and a value. You can add tags to resources that have identical characteristics, such as resources that belong to the same organization and resources that serve the same purpose. You can use tags to search for and manage resources in an efficient manner.\nresource group\nResource groups allow you to manage resources across services and regions based on your business requirements and manage the permissions of resource groups.\nCloud Assistant\nCloud Assistant is an automated O&M tool provided by Alibaba Cloud. Cloud Assistant allows you to perform operations such as running commands in ECS instances and sending files to ECS instances without logging on to the ECS instances.\nsystem event\nSystem events are scheduled or unexpected O&M events that affect the running status of ECS instances and require the restart, stop, or release of ECS instances. For system events, ECS sends you notifications that contain information such as solutions and event cycles so that you can back up data and make preparations in a timely manner.\nTerm\nDescription\nsubscription\nIn this billing method, you pay for resources upfront and use them over a specified period of time.\npay-as-you-go\nIn this billing method, you pay for resources after you use them. Resources can be purchased and released as needed.\npreemptible instance\nIn this billing method, you can bid for available computing resources to create preemptible instances. Preemptible instances are discounted compared with pay-as-you-go instances. However, preemptible instances can be reclaimed.\nreserved instance\nReserved instances are discounted coupons that are used together with pay-as-you-go instances. When you purchase a reserved instance, you make a commitment to use instances that have specified configurations such as instance type, region, and zone to receive discounted billing. Reserved instances are applied to offset the bills of computing resources.\nsavings plan\nSavings plans are discounted plans that are used together with pay-as-you-go instances. When you purchase a savings plan, you make a commitment to use a consistent amount (measured in USD/hour) of resources to receive discounted billing. Savings plans are applied to offset the bills of computing resources and system disks.\nResource Assurance\nAfter an elasticity assurance or a capacity reservation is created, the system generates a private pool to reserve resources for a specific number of instances that have specific attributes. During the validity period of the elasticity assurance or capacity reservation, you always have access to the resources reserved in the private pool when you want to create instances.\nstorage capacity unit (SCU)\nSCUs are storage resource plans that are used together with pay-as-you-go storage resources. When you purchase an SCU, you make a commitment to use storage resources of specific capacity to receive discounted billing. SCUs are applied to offset the bills of various storage resources such as EBS devices, File Storage NAS file systems, and Object Storage Service (OSS) buckets.\npay-by-bandwidth\nPay-by-bandwidth is a billing method for network usage. You are charged based on the specified bandwidth.\npay-by-traffic\nPay-by-traffic is a billing method for network usage. You are charged for the actual amount of traffic that you use. You must configure a maximum bandwidth value to prevent unexpected fees caused by traffic bursts."
    },
    "4": {
        "title": "Elastic Compute Service:ECS usage limits and quotas",
        "url": "https://www.alibabacloud.com/help/en/ecs/limitations",
        "content": "This Product\nElastic Compute Service:ECS usage limits and quotas\nThe Elastic Compute Service (ECS) may impose certain limitations on product features, service performance, and associated quotas. Some limitations can be addressed by requesting quota increases. It is advisable to understand these limitations before actual deployment, to plan accordingly, and to either apply for quota increases or pre-emptively manage unavoidable limitations to ensure ECS meets your business requirements. This topic describes ECS limitations and how to request quota increases for some of them.\nThe tables in each module of this topic provide details on specific limitations. The dimensions explained in the tables are as follows:\nLimitation item: Refers to product features, service performance, or related quotas that are subject to limitations.\n'Quota' denotes the maximum value of cloud resources or the maximum number of operations that a single Alibaba Cloud account (primary account) can utilize.\nLimitation: Specifies the particular limitations for the current limitation item.\nFor ECS-related quotas, a corresponding quota ID is provided. You can check the quota for the limitation item using this ID, which represents the current maximum limit.\nQuota increase method: Indicates whether the limitation for the current item can be addressed.\nIf the limitation cannot be addressed, it should be managed in advance. If it can be addressed, you can apply for an increase using the specified method.\nLimitation item\nLimitation\nQuota increase method\nvCPU quota item\n\nThe maximum number of vCPUs for a specific instance family that a single Alibaba Cloud account can hold in a specific region and billing method (subscription, pay-as-you-go, preemptible). For specific limitations, see vCPU quota item.\nView or increase ECS instance type quota\nGPU card and vGPU quota item\nThe maximum number of GPU cards or vGPU instances for a specific instance family that a single Alibaba Cloud account can hold in a specific region and billing method (subscription, pay-as-you-go, preemptible). For specific limitations, see GPU card and vGPU quota item.\nView or increase ECS instance type quota\nThe maximum number of subscription instances that a single Alibaba Cloud account can purchase in a specific region at one time\nPlease refer to the quota ID q_prepaid-instance-count-per-once-purchase to view the corresponding quota. For specific operations, see View or increase ECS quota.\nNone\nChange from pay-as-you-go to subscription\nNo quantity or amount limit.\nDiscontinued instance types do not support changing from pay-as-you-go to subscription. For more information, see Change from pay-as-you-go to subscription.\nNone\nChange from subscription to pay-as-you-go\nChanging from subscription to pay-as-you-go will generate a refund, and the refund will consume the refund quota. Therefore, if the refund quota for the month is exceeded, you cannot perform the refund operation, that is, you cannot change from subscription to pay-as-you-go. For more information, see Change from subscription to pay-as-you-go.\nThe refund quota is based on the display on the conversion page, and the quota is automatically reset to zero on the 1st of the next month.\nNone\nInstance families that support secondary virtualization\nOnly ECS Bare Metal Instance and Super Computing Cluster support secondary virtualization. Other instance families do not support the installation of virtualization software and secondary virtualization.\nNone\nSound card applications\nSound card applications are not supported.\nNone\nLoading external hardware devices\nDirect loading of external hardware devices (such as hardware dongles, USB flash drives, external hard disks, bank U keys, etc.) is not supported. You can try software dongles or two-factor authentication based on dynamic passwords.\nNone\nMulticast protocol\nMulticast protocol is not supported. If you need to use multicast, it is recommended to use unicast point-to-point instead.\nNone\nWebsite filing\nIf you need to file a website or app, you must purchase a subscription ECS instance for 3 months or more, and each ECS instance can file up to 5 websites or apps. For details, see Filing server check.\nNone\nLicense\nSome software or application licenses need to be bound to the hardware information of ECS. The migration operation of ECS may cause changes in hardware information, which may lead to license invalidation.\nNone\n\nWhen viewing quotas, the corresponding number of quotas represents the maximum number of vCPUs for a single Alibaba Cloud account in the current region, not the total maximum number of vCPUs across all regions.\nQuota ID\nQuota Item Description\nCorresponding Instance Family (click the instance family link in this column to view specific specifications)\nQuota\nQuota Increase Method\nq_ecs_restrict_prepay_c\nMaximum vCPU count for subscription instances with purchase restrictions\nLegacy shared instance families xn4, n4, mn4, e4\nPhased-out instance types\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_local_storage_prepay_c\nMaximum number of vCPUs for subscription instances within instance families featuring local SSDs, such as the d and i series.\nBig data type (d series)\nLocal SSD type (i series)\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_share_prepay_c\nMaximum number of vCPUs for subscription instances within shared instance families, such as the e and t series.\nEconomy instance family e\nBurstable instance family t6\nBurstable instance family t5\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_ebm_prepay_c\nMaximum vCPU count for subscription-based ECS Bare Metal Instance families\nFor ECS Bare Metal Instance specifications (excluding GPU-accelerated types), see ECS Bare Metal Instance specifications.\nRefer to the quota ID for the corresponding quota details. For instructions on viewing or increasing quotas, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_hpc_prepay_c\nMaximum vCPU count for subscription instances within compute-optimized high-performance instance families, such as High Performance Computing (HPC) and Super Computing Cluster (SCC).\nSpecifications for Super Computing Cluster instances (excluding GPU-accelerated SCC instances)\nRefer to the quota ID to view the corresponding quota. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_high_mem_prepay_c\nMaximum number of vCPUs for subscription instances within memory-optimized instance families, such as the re and se series.\nMemory-optimized instance family re7p\nPersistent memory-optimized instance family re6p\nPersistent memory-optimized instance family re6p\nMemory-optimized instance family re4\nMemory-optimized instance family re4e\nMemory network-enhanced instance family se1ne\nMemory-optimized instance family se1\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_enterprise_prepay_c\nMaximum number of vCPUs for subscription instances within enterprise-level instance families, including g, c, r, u, hf, and sn series\nGeneral-Purpose (G Series)\nCompute-Optimized (C Series)\nEnhanced features (excluding )\nMemory-optimized (r series), excluding se1ne and se1\nGeneral-Purpose Compute (U Instances)\nHigh-Frequency (HF Series)\nPlease refer to the quota ID to view the corresponding quota. For detailed instructions, see View or Increase ECS Instance Type Quota.\nView or Increase Your ECS Instance Type Quota\nq_ecs_restrict_postpay_c\nMaximum vCPU limit for pay-as-you-go instances under restricted purchase conditions\nLegacy shared instance families xn4, n4, mn4, e4\nPhased-out instance types\nPlease consult the quota ID for the corresponding limits. For detailed instructions, see View or Increase ECS Instance Type Quota.\nView or Increase ECS Instance Type Quota\nq_ecs_local_storage_postpay_c\nMaximum number of vCPUs for pay-as-you-go instances within instance families featuring local SSDs, such as the d and i series instance families\nBig data type (d series)\nLocal SSD type (i series)\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_share_postpay_c\nMaximum vCPU count for pay-as-you-go instances within shared instance families, such as the e and t series\nEconomy instance family e\nBurstable instance family t6\nBurstable instance family t5\nPlease refer to the quota ID for the corresponding quota details. For specific instructions, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_ebm_postpay_c\nMaximum vCPU count for pay-as-you-go ECS Bare Metal Instance families\nFor ECS Bare Metal Instance specifications, excluding those with GPU acceleration, see ECS Bare Metal Instance specifications.\nRefer to the quota ID for the corresponding quota details. For instructions on viewing or increasing quotas, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_hpc_postpay_c\nMaximum vCPU count for pay-as-you-go instances within compute-optimized high-performance families, such as HPC and SCC\nSuper Computing Cluster instance specifications (excluding GPU-accelerated SCC instances)\nPlease refer to the quota ID for the corresponding quota details. For specific instructions, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_high_mem_postpay_c\nMaximum vCPU count for pay-as-you-go instances within memory-optimized instance families, such as the re and se series.\nMemory-optimized instance family re7p\nPersistent memory-optimized instance family re6p\nPersistent memory-optimized instance family re6p\nMemory-optimized instance family re4\nMemory-optimized instance family re4e\nMemory network-enhanced instance family se1ne\nMemory-optimized instance family se1\nPlease refer to the quota ID for the corresponding quota details. For specific instructions, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_enterprise_postpay_c\nMaximum vCPU count for pay-as-you-go instances within enterprise-level instance families, including g, c, r, u, hf, and sn series\nGeneral-purpose (g series)\nCompute-optimized (c series)\nEnhanced (excluding  re6p, re6, re4)\nMemory-optimized (r series) (excluding se1ne, se1)\nGeneral-purpose compute (U instances)\nHigh-frequency (hf series)\nPlease refer to the quota ID for the corresponding quota details. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_restrict_spot_c\nMaximum vCPU limit for preemptible instances available for limited purchase\nLegacy shared instance families xn4, n4, mn4, e4\nPhased-out instance types\nPlease refer to the quota ID to view the corresponding quota. For detailed instructions, see View or Increase ECS Instance Type Quota.\nView or Increase ECS Instance Type Quota\nq_ecs_local_storage_spot_c\nMaximum number of vCPUs for preemptible instances within instance families featuring local SSDs, such as the d and i series\nBig data type (d series)\nLocal SSD type (i series)\nPlease refer to the quota ID for the corresponding quota details. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_share_spot_c\nMaximum number of vCPUs for preemptible instances within shared instance families, such as the e and t series.\nEconomy instance family e\nBurstable instance family t6\nBurstable instance family t5\nPlease refer to the quota ID to view the corresponding quota. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_ebm_spot_c\nMaximum vCPU count for preemptible instances within ECS Bare Metal Instance families\nRefer to ECS Bare Metal Instance specifications, excluding those for GPU-accelerated ECS Bare Metal Instances.\nConsult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_hpc_spot_c\nMaximum number of vCPUs for preemptible instances within compute-optimized high-performance instance families, such as HPC and SCC.\nSuper Computing Cluster instance specifications (excluding GPU-accelerated instances)\nPlease refer to the quota ID to view the corresponding quota. For specific instructions, see how to view or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_high_mem_spot_c\nMaximum number of vCPUs for preemptible instances within memory-optimized instance families, such as the re and se series\nMemory-optimized instance family re7p\nPersistent memory-optimized instance family re6p\nPersistent memory-optimized instance family re6p\nMemory-optimized instance family re4\nMemory-optimized instance family re4e\nMemory network-enhanced instance family se1ne\nMemory-optimized instance family se1\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_restrict_prepay_c\nMaximum number of vCPUs for subscription instances with limited purchase options\nGeneral-Purpose (G Series)\nCompute-Optimized (C Series)\nEnhanced versions (excluding  re6p, re6, re4)\nMemory-optimized (r series), excluding se1ne and se1.\nGeneral-Purpose Compute (U Instances)\nHigh-Frequency (HF Series)\nPlease consult the quota ID to view the corresponding quota. For detailed instructions, see View or Increase ECS Instance Type Quota.\nView or Increase Your ECS Instance Type Quota\nWhen viewing quotas, the corresponding number of quotas is the maximum number of GPU cards or vGPU instances for a single Alibaba Cloud account in the current region, not the total maximum number of GPU cards or vGPU instances in all regions.\nQuota ID\nQuota Item Description\nCorresponding Instance Family (click the instance family link in this column to view specific specifications)\nQuota\nQuota Increase Method\nq_ecs_ag_prepay_g\nMaximum GPU count for subscription-based Arm instances within GPU-accelerated instance families\nGPU-accelerated ECS Bare Metal Instance family ebmgn6ia\nPlease refer to the quota ID to view the corresponding quota. For detailed instructions, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_vgpu_prepay_g\nMaximum number of subscription instances for GPU- and vGPU-accelerated instance families\nvGPU-accelerated instance family sgn8ia\nvGPU-accelerated instance family sgn7i-vws (shared CPU)\nvGPU-accelerated instance family vgn7i-vws\nvGPU-accelerated instance family vgn6i-vws\nvGPU-accelerated instance family vgn6i\nvGPU-accelerated instance family vgn5i\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7i_prepay_g\nMaximum number of GPU cards available for subscription in GN7i/GN7s GPU-accelerated instances\nGPU-accelerated compute-optimized instance family GN7i\nGPU-accelerated compute-optimized instance family GN7s\nGPU-accelerated ECS Bare Metal Instance family EBMGN7i\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn5_prepay_g\nMaximum GPU count for subscription-based instances within GPU-accelerated instance families, such as the gn5 and gn5i.\nGPU-accelerated compute-optimized gn5 instance family\nGPU-accelerated compute-optimized gn5i instance family\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see how to view or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6i_prepay_g\nMaximum GPU count for subscription-based instances within GPU-accelerated families such as gn6i and ebmgn6i\nGPU-accelerated compute-optimized gn6i instance family\nGPU-accelerated ECS Bare Metal ebmgn6i instance family\nPlease consult the quota ID for the relevant quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6v_prepay_g\nMaximum number of GPUs for subscription instances within GPU-accelerated instance families, such as the gn6v and ebmgn6v\nGPU-accelerated compute-optimized gn6v instance family\nGPU-accelerated ECS Bare Metal ebmgn6v instance family\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6e_prepay_g\nMaximum GPU count for subscription-based GPU-accelerated instances in families such as gn6e and ebmgn6e\ngn6e GPU-accelerated compute-optimized instance family\nebmgn6e GPU-accelerated ECS Bare Metal Instance family\nRefer to the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn8i_prepay_g\nMaximum GPU count for subscription-based instances within GPU-accelerated instance families, such as the gn8i and gn8is families\nGPU-accelerated compute-optimized gn8is instance family\nGPU-accelerated ECS Bare Metal ebmgn8is instance family\n\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7v_prepay_g\nMaximum GPU count for subscription-based instances within GPU-accelerated instance families, such as the gn7 and gn7v.\nGPU-accelerated compute-optimized gn7 instance family\nGPU-accelerated ECS Bare Metal Instance family ebmgn7\n\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7e_prepay_g\nQuota limit for GPU-accelerated instances in the (ebm)gn7e edition on a subscription basis\nGPU-accelerated compute-optimized instance family gn7e\nGPU-accelerated ECS Bare Metal Instance family ebmgn7e\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see how to view or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn8v_prepay_g\nMaximum GPU count for subscription-based instances within GPU-accelerated instance families, such as the gn8v series\nGPU-accelerated compute-optimized gn8v/gn8v-tee instance family\nGPU-accelerated ECS Bare Metal Instance family ebmgn8v\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_ag_postpay_g\nMaximum GPU count for pay-as-you-go Arm instances within GPU-accelerated instance families\nGPU-accelerated ECS Bare Metal Instance family ebmgn6ia\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_vgpu_postpay_g\nMaximum number of pay-as-you-go instances for GPU- and vGPU-accelerated instance families\nvGPU-accelerated instance family sgn8ia\nvGPU-accelerated instance family sgn7i-vws (shared CPU)\nvGPU-accelerated instance family vgn7i-vws\nvGPU-accelerated instance family vgn6i-vws\nvGPU-accelerated instance family vgn6i\nvGPU-accelerated instance family vgn5i\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7i_postpay_g\nThe maximum number of GPU cards for pay-as-you-go gn7i/gn7s GPU-accelerated instances\nGPU-accelerated compute-optimized instance family gn7i\nGPU-accelerated compute-optimized instance family gn7s\nGPU-accelerated ECS Bare Metal Instance family ebmgn7i\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn5_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families such as gn5 and gn5i\nGPU-accelerated compute-optimized gn5 instance family\nGPU-accelerated compute-optimized gn5i instance family\nRefer to the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6i_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families, such as the gn6i and ebmgn6i\ngn6i GPU-accelerated compute-optimized instance family\nebmgn6i GPU-accelerated ECS Bare Metal Instance family\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6v_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families, such as the gn6v and ebmgn6v families\nGPU-accelerated compute-optimized gn6v instance family\nGPU-accelerated ECS Bare Metal ebmgn6v instance family\nPlease refer to the quota ID for the corresponding quota details. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6e_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families, such as the gn6e and ebmgn6e\nGPU-accelerated compute-optimized gn6e instance family\nGPU-accelerated ECS Bare Metal ebmgn6e instance family\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn8i_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families, such as the gn8i and gn8is families\nGPU-accelerated compute-optimized instance family gn8is\nGPU-accelerated ECS Bare Metal Instance family ebmgn8is\n\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7v_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families, such as the gn7 and gn7v.\nGPU-accelerated compute-optimized gn7 instance family\nGPU-accelerated ECS Bare Metal Instance family ebmgn7\n\nRefer to the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7e_postpay_g\nMaximum GPU card limit for pay-as-you-go gn7e edition GPU-accelerated instances\nCompute-optimized GPU-accelerated instance family gn7e\nECS Bare Metal GPU-accelerated instance family ebmgn7e\nPlease refer to the quota ID to view the corresponding quota. For specific operations, refer to View or Increase ECS Instance Type Quota.\nView or Increase ECS Instance Type Quota\nq_ecs_gn8v_postpay_g\nMaximum GPU count for pay-as-you-go instances within GPU-accelerated instance families, such as the gn8v family\nGPU-accelerated compute-optimized gn8v/gn8v-tee instance family\nGPU-accelerated ECS Bare Metal ebmgn8v instance family\nRefer to the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_ag_spot_g\nMaximum number of GPUs for preemptible Arm instances within GPU-accelerated instance families\nGPU-accelerated ECS Bare Metal Instance family ebmgn6ia\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_vgpu_spot_g\nMaximum number of preemptible instances for GPU- and vGPU-accelerated instance families\nvGPU-accelerated instance family sgn8ia\nvGPU-accelerated instance family sgn7i-vws (shared CPU)\nvGPU-accelerated instance family vgn7i-vws\nvGPU-accelerated instance family vgn6i-vws\nvGPU-accelerated instance family vgn6i\nvGPU-accelerated instance family vgn5i\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7i_spot_g\nThe maximum number of GPU cards for preemptible GN7i/GN7s GPU-accelerated instances and for EBM GN7ix/GN7s GPU-accelerated instances\nGPU-accelerated compute-optimized instance family gn7i\nGPU-accelerated compute-optimized instance family gn7s\nGPU-accelerated ECS Bare Metal Instance family ebmgn7i\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn5_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families, such as the gn5 and gn5i.\nGPU-accelerated compute-optimized gn5 instance family\nGPU-accelerated compute-optimized gn5i instance family\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see how to view or increase ECS instance type quotas.\nView or increase ECS instance type quota\nq_ecs_gn6i_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families, such as the gn6i and ebmgn6i.\nGPU-accelerated compute-optimized gn6i instance family\nGPU-accelerated ECS Bare Metal ebmgn6i instance family\nPlease refer to the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6v_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families, such as the gn6v and ebmgn6v families\nGPU-accelerated compute-optimized gn6v instance family\nGPU-accelerated ECS Bare Metal ebmgn6v instance family\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn6e_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families, such as the gn6e and ebmgn6e.\nGPU-accelerated compute-optimized gn6e instance family\nGPU-accelerated ECS Bare Metal ebmgn6e instance family\nPlease consult the quota ID for the corresponding quota details. For specific procedures, see how to view or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn8i_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families, such as the gn8i and gn8is families\nGPU-accelerated compute-optimized instance family gn8is\nGPU-accelerated ECS Bare Metal Instance family ebmgn8is\n\nPlease refer to the quota ID for the corresponding quota details. For specific procedures, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7v_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families such as gn7 and gn7v\nGPU-accelerated compute-optimized gn7 instance family\nGPU-accelerated ECS Bare Metal Instance family ebmgn7\n\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn7e_spot_g\nMaximum GPU card count for preemptible GN7e edition GPU-accelerated instances\nCompute-optimized GPU-accelerated instance family gn7e\nECS Bare Metal Instance family ebmgn7e\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see how to view or increase ECS instance type quota.\nView or increase ECS instance type quota\nq_ecs_gn8v_spot_g\nMaximum GPU count for preemptible instances within GPU-accelerated instance families, such as the gn8v family\nGPU-accelerated compute-optimized gn8v/gn8v-tee instance family\nGPU-accelerated ECS Bare Metal ebmgn8v instance family\nPlease refer to the quota ID to view the corresponding quota. For specific operations, see View or increase ECS instance type quota.\nView or increase ECS instance type quota\nLimitation item\nLimitation\nQuota increase method\nMaximum number of custom images that a single Alibaba Cloud account can retain in a specific region\nPlease refer to the quota ID q_user-image-count to view the corresponding quota. For specific operations, see View or increase ECS quota.\nView or increase ECS quota\nMaximum number of users that a single custom image can be shared with\nPlease refer to the quota ID q_user-per-image-shared-user-count to view the corresponding quota. For specific operations, see View or increase ECS quota.\nView or increase ECS quota\nLimitations of images and instance types\nInstance types with 4 GiB or more memory do not support 32-bit images.\nNone\nFor more information on images, see the Image Overview.\nLimitation item\nLimitation\nQuota increase method\nNumber of system disks on a single instance\n1\nNone\nNumber of data disks on a single instance\nThe maximum number of cloud disks supported by different instance types varies. For more information, see Instance family.\nWhen creating an instance, you can attach up to 1 system disk and 16 data disks. If the instance requires more data disks, you need to attach them after creating the instance. The maximum number of cloud disks supported by different instance types can be queried through the DescribeInstanceTypes interface.\nNone\nCloud disk capacity quota for a single Alibaba Cloud account in a specific region and zone\nThe capacity quota of different types of cloud disks varies. You can view the corresponding quota for each type of cloud disk. For specific operations, see View or increase block storage quota.\nView or increase block storage quota\nCapacity of a single basic disk\n5 GiB to 2,000 GiB\nNone\nCapacity of a single standard SSD\n20 GiB to 32,768 GiB\nNone\nCapacity of a single ultra disk\n20 GiB to 32,768 GiB\nNone\nCapacity of a single ESSD\nPL0: 1 GiB to 65,536 GiB\nPL1: 20 GiB to 65,536 GiB\nPL2: 461 GiB to 65,536 GiB\nPL3: 1,261 GiB to 65,536 GiB\nNone\nCapacity of a single ESSD AutoPL disk\n1 GiB to 65,536 GiB\nNone\nSingle ESSD Entry disk\n10 GiB to 32,768 GiB\nNone\nCapacity of a single zone-redundant ESSD\n1 GiB to 65,536 GiB\nNone\nCapacity of a single local standard SSD\n5 GiB to 800 GiB\nNone\nTotal capacity of all local standard SSDs on an instance\n1,024 GiB\nNone\nCapacity of a single ephemeral disk\n64 GiB to 8,192 GiB\nNone\nCapacity of a single system disk\nWindows Server: 40 GiB to 2,048 GiB\nFreeBSD: 30 GiB to 2,048 GiB\nLinux distributions excluding CoreOS: 20 GiB to 2,048 GiB\nBasic disks (previous generation of disks, gradually discontinued) have a capacity upper limit of 500 GiB when used as system disks.\nNone\nPermissions to attach new local disks to instances that are equipped with local disks\nNot allowed.\nNone\nPermissions to change the configurations of instances that are equipped with local disks\nOnly bandwidth configurations can be changed.\nNone\nMount point of the system disk on a Linux instance\n/dev/vda\nNone\nMount points of data disks on a Linux instance\nThe naming of mount points varies based on the number of data disks:\n1 to 25 data disks: /dev/xvd[b-z].\nMore than 25 data disks: /dev/xvd[aa-zz]. For example, the 26th data disk will be named /dev/xvdaa, the 27th data disk will be /dev/xvdab, and so on.\nNone\nBlock storage is quantified using binary units, which denote data sizes based on a base of 1024. For instance, 1 GiB is equivalent to 1,024 MiB.\nFor more information about block storage, see Block Storage Overview.\nLimitation item\nLimitation\nQuota increase method\nNumber of manual snapshots that can be retained for a single cloud disk\n256\nNone\nNumber of automatic snapshots that can be retained for a single cloud disk\n1,000\nNone\nNumber of automatic snapshot policies that can be retained for a single Alibaba Cloud account in a single region\n100\nNone\nNumber of automatic snapshot policies that can be set for a single cloud disk\n1\nNone\nNumber of concurrent snapshot creations for a single cloud disk\n1\nNone\nBlock storage type\nlocal disks, and ephemeral disks do not support snapshot creation.\nCurrently, only ESSD series disks (ESSD, ESSD AutoPL, and ESSD Entry) support the snapshot consistency group feature, and the disks must not have the multi-attach feature enabled.\nOnly ESSD series disks (ESSD, ESSD AutoPL, ESSD Entry, and zone-redundant ESSD) support the snapshot rapid availability capability. For more information, see Snapshot rapid availability capability.\nNone\nDownload or export snapshots\nDownloading or exporting created snapshots is not supported.\nYou can first create a custom image from a snapshot, and then export the custom image to your local device.\nNone\nConstraints on the process of creating manual and automatic snapshots\nIf a snapshot is being manually or automatically created for a cloud disk when the point in time specified in the associated automatic snapshot policy is reached, the automatic snapshot cannot be created based on the policy at the point in time. An automatic snapshot is created for the disk at the next point in time specified in the automatic snapshot policy.\nIf an automatic snapshot is being created for a cloud disk, you cannot create a manual snapshot for the disk. Wait until the automatic snapshot is created.\nNone\nFor more information on snapshots, see the Snapshot Overview.\nLimitation item\nLimitation\nQuota increase method\nSSH key pair quota for a single Alibaba Cloud account in a single region\n500\nNone\nImage types that support SSH key pairs\nOnly Linux operating systems are supported.\nNone\nFor more information on SSH key pairs, see Managing SSH Key Pairs.\nThe combined peak public bandwidth limit for all pay-as-you-go and preemptible instances billed by fixed bandwidth under a single Alibaba Cloud account in one region is:\nIf you require higher bandwidth, you can check and request a quota increase by referencing quota ID q_internet-bandwidth-pay-by-bandwidth-of-postpaid-instance. For detailed instructions, see View or increase ECS quota.\nRegion name\nLimitation\nChina (Beijing), China (Shanghai), China (Hangzhou), China (Shenzhen)\n50 Gbps\nHong Kong (China), Singapore\n20 Gbps\nOthers\n10 Gbps\nAs of November 27, 2020, the peak bandwidth is subject to the account throttling policy when creating or modifying ECS instances:\n\nIf you require increased peak bandwidth, you can , submit a ticket, or .\nWithin a single region, the total actual peak bandwidth for all pay-by-traffic billed ECS instances under a single Alibaba Cloud account must not exceed 5 Gbps.\nIn one region, the actual peak bandwidth in operation for all ECS instances billed by fixed bandwidth under a single Alibaba Cloud account must not exceed 50 Gbps.\nLimits on single instance bandwidth peak and public IP replacement:\nThe inbound and outbound bandwidth peaks in the Pay-by-traffic billing mode represent upper limits and are not guaranteed service levels. Bandwidth peaks may be restricted during times of resource contention. For guaranteed bandwidth, please opt for the Fixed Bandwidth billing mode.\nLimitation item\nLimitation\nQuota increase method\nSingle instance inbound bandwidth peak\nWhen the purchased outbound bandwidth peak is less than or equal to 10 Mbit/s, Alibaba Cloud will allocate 10 Mbit/s inbound bandwidth.\nWhen the purchased outbound bandwidth peak is greater than 10 Mbit/s, Alibaba Cloud will allocate inbound bandwidth equal to the purchased outbound bandwidth peak.\nNone\nSingle instance outbound bandwidth peak\nPay-by-traffic:\nSubscription instance: 200 Mbit/s\nPay-as-you-go instance: 100 Mbit/s\nFixed bandwidth billing: 200 Mbit/s\nThe outbound bandwidth peak of a single instance is also limited by the Network Bandwidth Base/burst (gbit/s) indicator data of the ECS instance type. For more information, see Instance family.\nNone\nLimit on changing the assigned public IP address of a single instance\nThe public IP address of a newly created instance can be changed within 6 hours, and an instance can be changed up to three times.\nNone\nFor more information about public bandwidth, see Public bandwidth.\nLimitation item\nLimitation\nQuota increase method\nMaximum number of elastic network interfaces (secondary network interfaces) that can be created by a single Alibaba Cloud account in a specific region\nPlease refer to the quota ID q_elastic-network-interfaces to view the corresponding quota. For specific operations, see View or increase ECS quota.\nView or increase ECS quota\nVPC and zone restrictions for binding elastic network interfaces to instances\nInstances and the bound elastic network interfaces must belong to the same VPC and zone.\nMultiple elastic network interfaces bound to an instance can belong to different subnets (vSwitches) within the same VPC and zone.\nIf two or more network interfaces from the same subnet are attached to an instance, network issues such as asymmetric routing may occur. You can assign one or more secondary private IP addresses to a primary or secondary elastic network interface to optimize the usage of ECS instances deployed in VPCs and divert traffic during a failover. For more information, see Secondary private IP.\nNone\nMaximum number of elastic network interfaces that can be bound to a single instance\nThe number of network interfaces that can be bound to an instance is determined by the instance type. For more information, see Instance family under Elastic network interfaces.\nNone\nFor more information on elastic network interfaces, see the Elastic Network Interface Overview.\n\nLimitation item\nLimitation\nQuota increase method\nMaximum number of prefix lists for a single Alibaba Cloud account in a single region\n100\nNone\nMaximum number of entries in a single prefix list\n200\nNone\nMaximum number of associated resources for a single prefix list\n1,000\nNone\nFor more information on prefix lists, see the Prefix List Overview.\nLimitation item\nBasic security group limitation\nEnterprise security group limitation\nMaximum number of security groups for a single Alibaba Cloud account in a specific region\nPlease refer to the quota ID q_security-groups to view or apply for an increase in the corresponding quota. For specific operations, see View or increase ECS quota.\nSame as basic security group\nMaximum number of ECS instances of the classic network type that a single classic network type security group can contain\n1,000\nIf more than 1,000 instances of the classic network type require mutual access over the internal network, you can assign the instances to multiple security groups and allow mutual access among the security groups.\nClassic network is not supported\nMaximum number of ECS instances of the VPC type that a single VPC type security group can contain\nNot fixed, depends on the number of private IP addresses that the security group can contain.\nUnlimited\nMaximum number of security groups that a single instance can be associated with\n10\nSame as basic security group\nMaximum number of security groups that each elastic network interface of a single instance can be associated with\nMaximum number of rules (including inbound and outbound rules) for all security groups associated with a single elastic network interface\n1,000\nSame as basic security group\nMaximum number of authorized security group rules that can be added to a single security group\n20\n0 rules. In enterprise security groups, you cannot add rules with security groups as authorization objects, nor can you use enterprise security groups as authorization objects in other security group rules.\nMaximum number of private IP addresses that a single VPC type security group can contain for a single Alibaba Cloud account in a specific region\n6,000\nYou can also view the maximum number of private IP addresses in a VPC basic security group by referring to the quota ID q_vpc-normal-security-group-ip-count. For specific operations, see View or increase ECS quota.\nIf more than 6,000 private IP addresses require mutual access over the internal network, you can assign the ECS instances with these private IP addresses to multiple security groups and allow mutual access among the security groups.\n65,536\nPublic access port\nFor security reasons, port 25 of ECS instances is restricted by default. It is recommended to use the SSL encrypted port (usually port 465) to send emails externally.\nSame as basic security group\nFor more information on security groups, see the overview of security groups.\nLimitation item\nLimitation\nQuota increase method\nTotal number of regional reserved instances for a single Alibaba Cloud account across all regions\n20\nSubmit a ticket\nNumber of zone-level reserved instances for a single Alibaba Cloud account in a single zone\n20\nSubmit a ticket\nInstance type of reserved instances\ngn6i and t5 instance families do not support regional reserved instances and cannot be split or merged.\nThe instance types that you can select when purchasing reserved instances are displayed on the actual interface.\nNone\nEligible resources\nOnly pay-as-you-go instances (excluding preemptible instances) are eligible for deduction.\nOnly the fees of computing resources (vCPUs and memory) can be offset. The fees of resources such as network and storage resources cannot be offset. For more information about ECS instance billing, see Billing overview.\nWindows reserved instances can also offset the image fees.\nWindows reserved instances already include Windows images at no additional cost and can offset the image portion of the bill for pay-as-you-go instances running Windows operating systems.\nNone\nFor more information on reserved instances, see Reserved Instances.\nLimitation item\nLimitation\nQuota increase method\nNumber of savings plans that a single Alibaba Cloud account can purchase\n200\nNone\nEligible resources\nOnly ECS and ECI pay-as-you-go instances (excluding preemptible instances) are eligible for deduction. For detailed deduction items and rules, see Savings plan deduction items and rules.\nFor ECS instances, savings plans can be used to offset the fees for computing resources (vCPUs and memory), images, system disks, and public bandwidth. Savings plans can also be used to offset capacity fees, performance provision fees, and performance burst fees for data disks on the ECS instances. For more information about ECS instance billing, see Billing overview.\nFor ECI instances (non-specified instance types), savings plans can be used to offset the fees for computing resources (vCPUs and memory). For more information about ECI instance billing, see ECI instance billing.\nNone\nFor more information on savings plans, see Savings Plans.\nLimitation item\nLimitation\nQuota increase method\nMaximum capacity of a single storage capacity unit package that can be purchased at one time\n50 TiB\nSubmit a ticket\nMaximum number of SCUs that can be purchased in a single region\n100\nNone\nResource types that support SCUs\nESSD, standard SSD, ultra disk, and basic disk.\nCapacity NAS file system and Performance NAS file system.\nStandard snapshot.\nStandard OSS, infrequent access OSS, and archive OSS.\nCloud Backup storage capacity.\nPhoto and cloud disk services.\nNone\nDeduction type\nOnly pay-as-you-go bills are eligible for deduction. Bills of pay-as-you-go disks attached to preemptible instances are not eligible for deduction.\nNone\nEffective time\nYou can configure an effective time for each SCU. The configured time must fall within six months of the SCU creation.\nNone\nCreate and manage SCUs through API\nNot supported yet.\nNone\nFor more information on storage capacity unit packages, see Storage Capacity Unit Package (SCU).\nLimitation item\nLimitation\nQuota increase method\nMaximum number of launch templates that a single Alibaba Cloud account can have in a specific region\nPlease refer to the quota ID q_launch-template-count to view the corresponding quota. For specific operations, see View or increase ECS quota.\n\nView or increase ECS quota\nMaximum number of versions for a single launch template that a single Alibaba Cloud account can have in a specific region\nPlease refer to the quota ID q_launch-template-version-count to view the corresponding quota. For specific operations, see View or increase ECS quota.\n\nView or increase ECS quota\nLaunch template parameters\nWhen you create a launch template, all parameters are optional. However, if a launch template does not include required parameters such as the instance type and image, you must specify these parameters when you use the launch template to create ECS instances.\nNone\nModify an existing launch template\nAfter a launch template is successfully created, it cannot be modified. You can create a new version of the launch template to change configuration parameters. For specific operations, see Manage launch template versions.\nNone\nFor more information on launch templates, see the launch template overview.\nLimitation item\nLimitation\nQuota increase method\nMaximum number of deployment sets that a single Alibaba Cloud account can have in a specific region\nPlease refer to the quota ID q_deployment-set-count to view the corresponding quota. For specific operations, see View or increase ECS quota.\nView or increase ECS quota\nMaximum number of instances that can be contained in a single deployment set\nThe number of instances that can be contained in a deployment set depends on the deployment strategy you choose. For more information, see Deployment strategy.\nNone\nCreate dedicated hosts in deployment sets\nDeployment sets do not support creating dedicated hosts.\nNone\nRegion and zone restrictions\nInstances and deployment sets must be in the same region. Instances in a deployment set with a low network latency strategy must all be in the same zone.\nNone\nInstance types that support deployment sets\nDifferent deployment strategies support creating specific instance families. You can call the DescribeDeploymentSetSupportedInstanceTypeFamily API to specify a deployment strategy and obtain the instance families supported by each deployment strategy.\nNone\nMerge deployment sets\nDeployment sets cannot be merged with each other.\nNone\nFor more information on deployment sets, see Deployment Sets.\nLimitation item\nLimitation\nQuota increase method\nProvisioning instances across regions\nAuto provisioning groups do not support provisioning instances across regions.\nNone\nMaximum number of configuration sources that can be specified for a single auto provisioning group\nA single auto provisioning group can specify only one specific version of a launch template as the basic configuration for instances. However, you can extend the instance types in the template to form multiple resource pools.\nNone\nMaximum number of resource pools that can be set for a single auto provisioning group\nA single auto provisioning group supports setting up to 20 resource pools (combinations of zones and instance types).\nNone\nMaximum number of instances that can be created under a single auto provisioning group\n1,000\nNone\nFor more information on auto provisioning groups, see the Auto Provisioning Overview.\nLimitation item\nLimitation\nQuota increase method\nMaximum number of Cloud Assistant commands for a single Alibaba Cloud account in a specific region\nRefer to quota ID q_axt-command-count for the corresponding quota. For specific operations, see View or increase ECS quota.\nView or increase ECS quota\nCloud Assistant task output size limit for a single Alibaba Cloud account in a specific region\nRefer to quota ID q_axt-task-output-size for the corresponding quota. For specific operations, see View or increase ECS quota.\nNone\nCloud Assistant task output retention period for a single Alibaba Cloud account in a specific region\nRefer to quota ID q_axt-task-output-life for the corresponding quota. For specific operations, see View or increase ECS quota.\nNone\nMaximum number of Cloud Assistant activation codes for managed instances for a single Alibaba Cloud account in a specific region\nRefer to quota ID q_cloud-assistant-activation-count for the corresponding quota. For specific operations, see View or increase ECS quota.\nNone\nMaximum number of instances that support command execution for a single Alibaba Cloud account in a specific region\nRefer to quota ID q_task-instance-count for the corresponding quota. For specific operations, see View or increase ECS quota.\nView or increase ECS quota\nFile size limits for created Bat, PowerShell, or Shell scripts and custom parameters after Base64 encoding\nCreate command: File size (after Base64 encoding) cannot exceed 18 KB.\nExecute and save command immediately: File size cannot exceed 18 KB.\nExecute but do not save command immediately: File size cannot exceed 24 KB.\nUpload file: File size cannot exceed 32 KB.\nNone\nMaximum number of custom parameters in a single command\n20\nNone\nOperating systems\nCloud Assistant commands can only be run on instances with the following operating systems:\nAlibaba Cloud Linux\nCentOS 6, CentOS 7, CentOS 8, and later\nCoreOS\nDebian 8, Debian 9, Debian 10, and later\nOpenSUSE\nRed Hat 5, Red Hat 6, Red Hat 7, and later\nIn Red Hat, you must manually download the RPM package to install the Cloud Assistant Agent. For specific operations, see Install Cloud Assistant Agent.\nSUSE Linux Enterprise Server (SLES) 11, SLES 12, SLES 15, and later\nUbuntu 12, Ubuntu 14, Ubuntu 16, Ubuntu 18, and later\nFreeBSD 11, FreeBSD 12, FreeBSD 13, FreeBSD 14, and later\nWindows Server 2012, Windows Server 2016, Windows Server 2019, and later\nBy default, the Cloud Assistant Agent is installed on ECS instances created from public images.\nFor ECS instances created from custom images or Alibaba Cloud Marketplace images, verify that the operating systems support Cloud Assistant before installing the Cloud Assistant Agent. For specific steps, see Install Cloud Assistant Agent.\nNone\nFor more information, see the Cloud Assistant overview.\nLimitation item\nLimitation\nQuota increase method\nAPI rate quota\nThe API rate quota refers to the constraint limit on the frequency of OpenAPI calls. Based on the API version and resource type, it is roughly divided into two categories:\nECS API rate quota: The rate limit for APIs such as images, security groups, and block storage with the API version 2014-05-26.\nFor specific operations to view the ECS API rate quota, see View ECS API rate quota.\nBlock Storage API rate quota: The rate limit for advanced feature APIs of block storage with the API version 2021-07-30.\nFor specific operations to view the block storage API rate quota, see View or increase block storage API rate quota.\nECS API rate quota: This type of API rate quota does not support quota increase applications.\nBlock Storage API rate quota: You can apply for a quota increase. For specific operations, see View or increase block storage API rate quota.\nFor more information on ECS APIs, see Integration Overview."
    },
    "5": {
        "title": "Elastic Compute Service:Services that work with ECS",
        "url": "https://www.alibabacloud.com/help/en/ecs/services-that-work-with-ecs",
        "content": "This Product\nElastic Compute Service:Services that work with ECS\nThis topic describes the relationships between Elastic Compute Service (ECS) and other Alibaba Cloud services.\nThe following figure shows the relationships between ECS and other Alibaba Cloud services.\nThe following table describes the relationships between ECS and other Alibaba Cloud services.\nService\nRelationship\nReferences\nVPC\nVirtual Private Cloud (VPC) provides an isolated, stable, secure, fast-deliverable, and controllable network environment for ECS. You have complete control over IP addresses and network topology within a VPC. VPCs are suitable for users who have high network security requirements.\nOverview\nEIP\nElastic IP addresses (EIPs) are NAT IP addresses that are located in the public gateway of Alibaba Cloud. By means of NAT gateways, EIPs are mapped to the primary elastic network interfaces (ENIs) of the ECS instances that are associated with the EIPs. You can associate EIPs with ECS instances that are located in VPCs to enable the instances to communicate over the Internet.\nElastic IP addresses\nAssociate or disassociate an EIP\nSLB\nServer Load Balancer (SLB) distributes traffic across multiple ECS instances.\nService architecture\nCloudMonitor\nCloudMonitor develops monitoring solutions for ECS instances, system disks, and public bandwidth.\nView the monitoring information of an instance\nView monitoring data\nRAM\nResource Access Management (RAM) allows you to manage the identities and permissions of Alibaba Cloud services and users to implement access control over ECS resources.\nRAM overview\nAnti-DDoS\nAnti-DDoS Origin Basic is a service that protects ECS instances from DDoS attacks to ensure system stability. If inbound traffic to an instance exceeds the maximum traffic rate allowed by the instance type, Alibaba Cloud Security throttles the traffic.\nAnti-DDoS Origin Basic\nSecurity Center\nAlibaba Cloud Security Center provides ECS with basic security services such as unusual logon detection, vulnerability scan, and baseline check. You can check the security status of your ECS instances in the ECS console or in the Security Center console.\nBasic security services\nKMS\nThe ECS disk encryption feature uses Key Management Service (KMS) to encrypt data stored in ECS instances.\nOverview\nESS\nAuto Scaling (ESS) adjusts the number of ECS instances based on business and policy changes.\nESS adds ECS instances to ensure computing capabilities as business requirements increase.\nESS removes ECS instances to reduce costs as business requirements decrease.\nCreate a scaling group based on an existing ECS instance\nCreate a scaling configuration of the ECS type\nROS\nYou can create a stack template by using the Resource Orchestration Service (ROS) console or by calling ROS API operations. Then, you can use the template to quickly create and manage ECS resources.\nROS\nOOS\nYou can use CloudOps Orchestration Service (OOS) to execute automatic O&M tasks on ECS resources.\nUse OOS to manage ECS\nApsaraDB RDS\nECS instances work with ApsaraDB RDS instances that reside within the same region as the ECS instances to build a typical service access architecture. This reduces network latency and Internet traffic fees and ensures the optimal performance of ApsaraDB RDS instances.\nHow do I connect an ECS instance to an ApsaraDB RDS instance over an internal network?\nACK\nContainer Service for Kubernetes (ACK) uses Docker containers to manage application lifecycles on groups of ECS instances.\nWhat is Container Service for Kubernetes?\nCreate an elastic container instance from a specified ECS instance type\nDedicated Host\nYou can deploy ECS instances on a dedicated host and gain exclusive access to its physical resources. Dedicated Host allows you to redeploy your business or migrate your business to the cloud at minimal costs. ECS instances deployed on dedicated hosts meet strict regulatory compliance requirements.\nDedicated hosts\nCreate ECS instances on a dedicated host\nSMC\nYou can use Server Migration Center (SMC) to migrate ECS instances within an Alibaba Cloud account or across Alibaba Cloud accounts.\nServer migration guide\nAlibaba Cloud Marketplace\nAlibaba Cloud Marketplace is a platform where third-party partners provide various software and services such as software infrastructure, business software, website construction, hosted O&M, cloud security, data, API operations, and solutions for ECS.\nUse Alibaba Cloud Marketplace images"
    },
    "6": {
        "title": "Elastic Compute Service:Regions and zones",
        "url": "https://www.alibabacloud.com/help/en/ecs/regions-and-zones",
        "content": "This Product\nElastic Compute Service:Regions and zones\nThis topic describes the regions and zones supported by Elastic Compute Service.\nFor the concepts about Alibaba Cloud regions and zones, see Regions and zones.\nFor information about the global deployment of Alibaba Cloud services, go to the Alibaba Cloud's Global Infrastructure page and use a map for assistance.\nWhen you create an ECS instance, select a region based on the factors that are described in the following table. If you select an improper region, you can re-create the instance in a proper region and release the instance in the improper region, or migrate data as described in Migrate data between ECS instances that belong to the same Alibaba Cloud account or different Alibaba Cloud accounts.\nFactor\nDescription\nGeographical locations of an ECS instance and the users who access the instance\nIf you want to provide a good experience for users who access an ECS instance, you must consider the network latency between the users and the instance. Geographical distance and the quality of communication links affect the network latency.\nA region that is closer to the geographical location of users provides lower latency and higher access speed.\nWe recommend that you select a region based on your business requirements for network latency.\nRequirements for communication between cloud services over the internal network\nIf ECS and other cloud services reside in the same region, other cloud services can access ECS by using Virtual Private Cloud (VPC) endpoints over the internal network. This does not generate data transfer fees and provides faster access speed than access over the Internet.\nIf you purchased a cloud network service to connect cloud services, ignore this factor.\nIf you do not want cloud services to communicate with each other over the internal network, deploy the services in different regions or in the same region.\nIf you want cloud services to communicate with each other over the internal network, deploy the services in the same region.\nAccess from ECS instances that are located in the Chinese mainland, Hong Kong (China), and Macao (China) to ECS instances that are located in other countries and regions\nECS instances that are located in the Chinese mainland, Hong Kong (China), and Macao (China) may experience high network latency and even packet loss when the instances use public IP addresses to access ECS instances that are located in other countries and regions. We recommend that you deploy ECS instances that require mutual access in the same region.\nResource prices\nThe prices of resource plans vary based on regions. You can select a region that offers resource plans that are more cost-effective.\nThe prices of resources may vary based on regions. You can view the prices on the ECS product page or instance buy page. For more information, see the Instance buy page and the Pricing tab of the ECS product page.\nFeatures\nWhen a new ECS feature is released, public previews of the feature are launched in specific regions. If you want to try out the new feature, you must create an ECS instance in one of the regions. For information about the release notes for ECS features, see Release notes.\nWhen you create or purchase an Alibaba Cloud resource, select a zone in which you want to deploy the resource. The resource is zone-specific, and you cannot directly change the zone of the resource after the resource is created or purchased. To change the zone of an ECS instance, you can migrate the instance across zones. For more information, see Change instance types across zones.\nZones within the same region are interconnected over an internal network. Zones are independent of each other, which provides effective fault isolation. Incidents in one zone do not affect operations in another zone. We recommend that you appropriately distribute your services across multiple zones based on your requirements for disaster recovery and network latency.\nIf your application requires high disaster recovery capabilities, we recommend that you deploy instances in different zones within the same region.\nIf your application requires low latency, we recommend that you deploy instances within the same zone.\nThe following figure shows the architecture of a common cross-zone disaster recovery solution. ECS and File Storage NAS (NAS) use a multi-zone primary/secondary solution to ensure the high availability of services.\nThe following tables describe all regions and zones supported by Elastic Compute Service. The regions and zones supported by each cloud service may vary. For information about the regions and zones supported by a specific cloud service, see the documentation of the cloud service.\nRegions and zones in China\nRegion name\nRegion ID\nNumber of zones\nZone name\nZone ID\nChina (Qingdao)\ncn-qingdao\n2\nQingdao Zone B\ncn-qingdao-b\nQingdao Zone C\ncn-qingdao-c\nChina (Beijing)\ncn-beijing\n12\nBeijing Zone A\ncn-beijing-a\nBeijing Zone B\ncn-beijing-b\nBeijing Zone C\ncn-beijing-c\nBeijing Zone D\ncn-beijing-d\nBeijing Zone E\ncn-beijing-e\nBeijing Zone F\ncn-beijing-f\nBeijing Zone G\ncn-beijing-g\nBeijing Zone H\ncn-beijing-h\nBeijing Zone I\ncn-beijing-i\nBeijing Zone J\ncn-beijing-j\nBeijing Zone K\ncn-beijing-k\nBeijing Zone L\ncn-beijing-l\nChina (Zhangjiakou)\ncn-zhangjiakou\n3\nZhangjiakou Zone A\ncn-zhangjiakou-a\nZhangjiakou Zone B\ncn-zhangjiakou-b\nZhangjiakou Zone C\ncn-zhangjiakou-c\nChina (Hohhot)\ncn-huhehaote\n2\nHohhot Zone A\ncn-huhehaote-a\nHohhot Zone B\ncn-huhehaote-b\nChina (Ulanqab)\ncn-wulanchabu\n3\nUlanqab Zone A\ncn-wulanchabu-a\nUlanqab Zone B\ncn-wulanchabu-b\nUlanqab Zone C\ncn-wulanchabu-c\nChina (Hangzhou)\ncn-hangzhou\n8\nHangzhou Zone B\ncn-hangzhou-b\nHangzhou Zone E\ncn-hangzhou-e\nHangzhou Zone F\ncn-hangzhou-f\nHangzhou Zone G\ncn-hangzhou-g\nHangzhou Zone H\ncn-hangzhou-h\nHangzhou Zone I\ncn-hangzhou-i\nHangzhou Zone J\ncn-hangzhou-j\nHangzhou Zone K\ncn-hangzhou-k\nChina (Shanghai)\ncn-shanghai\n11\nShanghai Zone A\ncn-shanghai-a\nShanghai Zone B\ncn-shanghai-b\nShanghai Zone C\ncn-shanghai-c\nShanghai Zone D\ncn-shanghai-d\nShanghai Zone E\ncn-shanghai-e\nShanghai Zone F\ncn-shanghai-f\nShanghai Zone G\ncn-shanghai-g\nShanghai Zone K\ncn-shanghai-k\nShanghai Zone L\ncn-shanghai-l\nShanghai Zone M\ncn-shanghai-m\nShanghai Zone N\ncn-shanghai-n\nChina (Nanjing - Local Region)\ncn-nanjing\n1\nNanjing - Local Region Zone A\ncn-nanjing-a\nChina (Fuzhou - Local Region)\ncn-fuzhou\n1\nFuzhou - Local Region Zone A\ncn-fuzhou-a\nChina (Wuhan - Local Region)\ncn-wuhan-lr\n1\nWuhan - Local Region Zone A\ncn-wuhan-lr-a\nChina (Shenzhen)\ncn-shenzhen\n6\nShenzhen Zone A\ncn-shenzhen-a\nShenzhen Zone B\ncn-shenzhen-b\nShenzhen Zone C\ncn-shenzhen-c\nShenzhen Zone D\ncn-shenzhen-d\nShenzhen Zone E\ncn-shenzhen-e\nShenzhen Zone F\ncn-shenzhen-f\nChina (Heyuan)\ncn-heyuan\n2\nHeyuan Zone A\ncn-heyuan-a\nHeyuan Zone B\ncn-heyuan-b\nChina (Guangzhou)\ncn-guangzhou\n2\nGuangzhou Zone A\ncn-guangzhou-a\nGuangzhou Zone B\ncn-guangzhou-b\nChina (Chengdu)\ncn-chengdu\n2\nChengdu Zone A\ncn-chengdu-a\nChengdu Zone B\ncn-chengdu-b\nChina (Hong Kong)\ncn-hongkong\n3\nHong Kong Zone B\ncn-hongkong-b\nHong Kong Zone C\ncn-hongkong-c\nHong Kong Zone D\ncn-hongkong-d\nRegions and zones outside China\nRegion name\nRegion ID\nNumber of zones\nZone name\nZone ID\nSingapore\nap-southeast-1\n3\nSingapore Zone A\nap-southeast-1a\nSingapore Zone B\nap-southeast-1b\nSingapore Zone C\nap-southeast-1c\nMalaysia (Kuala Lumpur)\nap-southeast-3\n2\nKuala Lumpur Zone A\nap-southeast-3a\nKuala Lumpur Zone B\nap-southeast-3b\nIndonesia (Jakarta)\nap-southeast-5\n3\nJakarta Zone A\nap-southeast-5a\nJakarta Zone B\nap-southeast-5b\nJakarta Zone C\nap-southeast-5c\nPhilippines (Manila)\nap-southeast-6\n1\nManila Zone A\nap-southeast-6a\nThailand (Bangkok)\nap-southeast-7\n2\nBangkok Zone A\nap-southeast-7a\nBangkok Zone B\nap-southeast-7b\nJapan (Tokyo)\nap-northeast-1\n3\nTokyo Zone A\nap-northeast-1a\nTokyo Zone B\nap-northeast-1b\nTokyo Zone C\nap-northeast-1c\nSouth Korea (Seoul)\nap-northeast-2\n1\nSeoul Zone A\nap-northeast-2a\nUS (Silicon Valley)\nus-west-1\n2\nSilicon Valley Zone A\nus-west-1a\nSilicon Valley Zone B\nus-west-1b\nUS (Virginia)\nus-east-1\n2\nVirginia Zone A\nus-east-1a\nVirginia Zone B\nus-east-1b\nGermany (Frankfurt)\neu-central-1\n3\nFrankfurt Zone A\neu-central-1a\nFrankfurt Zone B\neu-central-1b\nFrankfurt Zone C\neu-central-1c\nUK (London)\neu-west-1\n2\nLondon Zone A\neu-west-1a\nLondon Zone B\neu-west-1b\nUAE (Dubai)\nme-east-1\n1\nDubai Zone A\nme-east-1a\nSAU (Riyadh - Partner Region)\nThe SAU (Riyadh - Partner Region) region is operated by a partner.\nme-central-1\n2\nRiyadh Zone A\nme-central-1a\n\nRiyadh Zone B\nme-central-1b\nMexico\nna-south-1\n1\nMexico Zone A\nna-south-1a\nCall the DescribeRegions operation to query the regions in which Elastic Compute Service are available for purchase.\nRun the following command to query the regions supported by ECS. Replace {RegionId} with a region ID in the preceding tables.\nCall the DescribeZones operation to query the zones supported by Elastic Compute Service in a specific region and the ECS resources that are available for purchase in the zones.\nRun the following command to query the preceding information. Replace {RegionId} with a region ID in the preceding tables.\nFor different regions, the available instance types for purchase are different. You can go to the Instance types available for each region page to check the details for a specific instance type.\nAn endpoint is a domain name that is used by Elastic Compute Service to provide external services. ECS supports public endpoints and VPC endpoints. When you integrate Elastic Compute Service into your business system, you must specify ECS endpoints in the code of your programming tool, such as an SDK, CLI, or API, to communicate with the Alibaba Cloud ECS service. For information about the endpoints supported by ECS, see the following topics:\nFor information about the endpoints used to manage ECS resources, such as instances, images, and block storage devices, see Endpoints of ECS API.\nFor information about the endpoints used to configure the advanced features of block storage, see Endpoints of advanced block storage features.\n\n"
    },
    "7": {
        "title": "Elastic Compute Service:Usage notes",
        "url": "https://www.alibabacloud.com/help/en/ecs/usage-notes",
        "content": "This Product\nElastic Compute Service:Usage notes\nTo ensure that Elastic Compute Service (ECS) instances can run as expected, take note of the following items before you use the instances.\nAlibaba Cloud and customers share responsibilities for the security of ECS in the cloud. For information about the security responsibilities of Alibaba Cloud and customers for ECS, see Shared security responsibility model of ECS.\nAfter you create an ECS instance, only you have the administrator permissions on the instance and can log on to the instance.\nDo not resell or sublicense the bandwidth that is assigned to your ECS instances without authorization. Failure to comply with the note causes your instances to be stopped, locked, and released.\nDo not use your ECS instances for malicious, fraudulent, or illegal activities, such as click farming or fraudulent transactions on e-commerce websites such as Taobao. Failure to comply with the note results in the suspension or termination of your account.\nDo not uninstall relevant hardware drivers.\nDo not modify the media access control (MAC) addresses of network interface controllers (NICs) unless necessary.\nDo not enable SELinux.\nECS instances whose memory size is greater than or equal to 4 GiB must use 64-bit operating systems. A 32-bit operating system can address up to 4 GiB of memory. Alibaba Cloud allows you to create instances that run 64-bit operating systems. The operating system versions that are displayed on the instance buy page prevail. The following 64-bit operating systems are supported:\nAlibaba Cloud Linux 64-bit\nCoreOS 64-bit\nCentOS 64-bit\nDebian 64-bit\nFreeBSD 64-bit\nopenSUSE 64-bit\nSUSE Linux 64-bit\nUbuntu 64-bit\nRed Hat 64-bit\nWindows 64-bit\nTo ensure service continuity and prevent failover-induced service unavailability, we recommend that you configure relevant service software to automatically start on instance startup. If service applications are connected to databases, we recommend that you enable auto-reconnection for the service applications.\nWe recommend that you do not upgrade the kernel or operating system of an instance.\nSpecific software or application licenses must be bound to the hardware of ECS instances. After data is migrated from one instance to another, hardware information may change and invalidate the licenses.\nDo not stop the built-in Aliyun Assist Service or shutdownmon.exe process. If you stop the service or process, your ECS instances may fail to be stopped or restarted in the ECS console.\nDo not modify the hostname of the domain controller.\nWe recommend that you do not create custom images by using a virtual machine that acts as a domain controller.\nDo not rename, delete, or disable the administrator account on an ECS instance. Such operations may affect the use of the instance.\nIf your instances use basic disks, we recommend that you do not use the virtual memory. If your instances use ultra disks, standard SSDs, or enhanced SSDs (ESSDs), you can use the virtual memory based on your business requirements.\nProceed with caution when you use the administrator account to resize disks, manage spanned volumes or the registry, and update the system. Failure to comply with the note may result in data loss.\nA 32-bit Windows operating system supports up to 4 vCPUs.\nMake sure that at least 2 GiB memory is available when you build a website or deploy a web environment on a Windows instance. Instance types that have only one vCPU and 1 GiB of memory do not support MySQL databases.\nFor information about the usage notes on images and operating systems, see Select an image.\nDo not modify the content of the default /etc/issue file on Linux instances. If you modify the /etc/issue file on a Linux instance and then use the instance to create a custom image, the operating system distribution of the image cannot be recognized. As a result, instances that are created from the image fail to start.\nDo not modify the permissions of the directories in the root partition, especially /etc, /sbin, /bin, /boot, /dev, /usr, and /lib. Improper modifications of permissions may cause errors.\nDo not rename, delete, or disable the root account.\nDo not compile or perform operations on the Linux kernel.\nIf your instances use basic disks, we recommend that you do not use swap partitions. If your instances use ultra disks, standard SSDs, or ESSDs, you can use swap partitions based on your business requirements.\nProceed with caution when you use the root account to run the fio, mkfs, or fsck command or resize disks. Failure to comply with the note may result in data loss.\nFor information about the usage notes on images and operating systems, see Select an image.\nFor information about the limits on ECS, see Limits."
    },
    "8": {
        "title": "Elastic Compute Service:Release notes",
        "url": "https://www.alibabacloud.com/help/en/ecs/release-notes",
        "content": "This Product\nElastic Compute Service:Release notes\nThis topic describes the release notes for Elastic Compute Service (ECS) features and provides links to the relevant references.\nFor information about the release notes for images, see Release notes for public images, Release notes for Alibaba Cloud Linux 2, and Release notes for Alibaba Cloud Linux 3.\nFor information about the release notes for Server Migration Center (SMC), see Release notes for SMC.\nDecember 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe sgn8ia vGPU-accelerated instance family is released.\n2024-12-27\nSpecific regions\nOverview of instance families\nNovember 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe gn8v GPU-accelerated compute-optimized instance family is released.\n2024-11-20\nSpecific regions\ngn8v, GPU-accelerated compute-optimized instance family\nInstance family\nThe ebmgn8v GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2024-11-20\nSpecific regions\nebmgn8v, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nOctober 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nSnapshot type\nThe name of a snapshot type is changed from normal snapshot to standard snapshot.\n2024-10-21\nAll regions\nSnapshot overview\nCreateSnapshot\nOperating system replacement\nThe precheck feature is added.\n2024-10-18\nAll regions\nReplace the operating system (system disk) of an instance\nSeptember 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe gn8is GPU-accelerated compute-optimized instance family is released.\n2024-09-13\nSpecific regions\nOverview of instance families\nInstance family\nThe ebmgn8is GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2024-09-12\nSpecific regions\nebmgn8is, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nMigration and upgrade of operating systems\nThe migration check feature is added.\n2024-09-11\nAll regions\nMigrate and upgrade the operating system of an ECS instance\nAugust 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nESSD AutoPL disks\nThe performance burst fee cap feature is added for Enterprise SSD (ESSD) AutoPL disks.\n2024-08-22\nAll regions\nESSD AutoPL disks\nJuly 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nRegional ESSD\nRegional ESSD is a new cloud disk category that belongs to the ESSD series. Data written to a Regional ESSD can be automatically stored in multiple zones within the same region. Regional ESSDs are physically isolated from data centers, racks, and power supplies.\n2024-07-25\nAll regions\nRegional ESSDs (public preview)\nApplication Management\nThe Application Management feature provided by CloudLens for Elastic Block Storage (EBS) can generate reports on the monitoring data of disks and periodically send the reports to you by email or internal message. This way, you can comprehensively analyze the monitoring data of disks, including the disk quantity, disk capacity, disk distribution by region, and disk distribution by category, properly plan resource allocation, and optimize costs.\n2024-07-17\nAll regions\nApplication Management\nVminit installation\nVminit can be installed when you create a Windows custom image. Vminit is a component that performs configuration tasks, such as performing network configurations, specifying hostnames, and executing custom scripts, to initialize the configurations of a Windows ECS instance.\n2024-07-03\nAll regions\nInstall Vminit\nvirtio driver installation\nAn installation package of the virtio driver can be installed when you create a Windows custom image.\n2024-07-03\nAll regions\nInstall the virtio driver\nDisk event\nCloudLens for EBS reports risk events when the disk performance data reaches a specific upper limit or snapshots are not created for data backup. You are prompted to handle the events at the earliest opportunity to ensure stable disk operation and data security.\n2024-07-03\nAll regions\nDisk events\nJune 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nProhibit a RAM user from creating high-risk security group rules\nOne or more custom Resource Access Management (RAM) policies that contain RAM condition keywords can be attached to a RAM user to restrict the operation permissions of the RAM user on creating security groups or adding security group rules. For example, you can use custom RAM policies to prohibit the RAM user from creating security group rules that contain specific IP addresses and protocols, allow the RAM user to create only security group rules that contain specific authorization objects (sources or destinations of traffic), or prohibit the RAM user from using default security groups when the RAM user creates ECS instances. This way, you can improve the security of your Alibaba Cloud account.\n2024-06-25\nAll regions\nProhibit a RAM user from creating high-risk security group rules\nOperating system EOL guidance\nAfter an operating system reaches the end of life (EOL), software updates or security patches are no longer provided by Alibaba Cloud. Alibaba Cloud provides a full range of EOL guidance for CentOS, Red Hat Enterprise Linux, Windows Server, and Alibaba Cloud Linux versions.\n2024-06-18\nAll regions\nImage maintenance cycle and EOL guidance\nUpgrade savings plans\nAs your business grows, your ECS usage may significantly exceed your spend commitment amount. As a result, existing savings plan may not reduce the costs. In this case, savings plans can be upgraded to increase the hourly commitment amount and reduce Savings Plan rates.\n2024-06-06\nAll regions\nUpgrade savings plans\nRenew a savings plan or enable auto-renewal for a savings plan\nA savings plan can be manually or automatically renewed before it expires. This extends the duration of the savings plan for ECS instances.\n2024-06-06\nAll regions\nRenew a savings plan or enable auto-renewal for a savings plan\n\nMay 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nVminit component\nThe first time an instance is started or every time an instance is started, a series of configuration tasks are automatically executed by the Vminit component to initialize an instance or perform other configurations.\n2024-05-23\nAll regions\nInitialization tools\n\nApril 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nECS instance boot mode\nThe Unified Extensible Firmware Interface (UEFI) Preferred mode is supported by ECS instances and images. If the boot mode of an image is UEFI-Preferred, the image can be started in Legacy BIOS or UEFI boot mode.\n2024-04-11\nAll regions\nECS instance boot modes\n\nMarch 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nPrivate pool sharing\nA private pool can be shared with other Alibaba Cloud accounts or within a resource directory of an organization. Other Alibaba Cloud accounts can use your shared private pool to create ECS instances. This improves resource utilization and reduces costs.\n2024-03-28\nAll regions\nShare a private pool\nFebruary 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nBuilding of a TDX confidential computing environment\nIntel\u00ae Trust Domain Extensions (TDX) is a CPU hardware-based technology that provides hardware-assisted isolation and encryption for ECS instances to protect runtime data, such as CPU registers, memory data, and interrupt injections. TDX helps achieve higher levels of data privacy and mitigate risks that are associated with unauthorized access to running processes or sensitive data that is being processed.\n2024-02-08\nBeijing Zone I\nBuild a TDX confidential computing environment\nModification of the execution information of a task by using Cloud Assistant\nIf a task that you created for a command does not meet your business requirements, you can modify the execution information of the task, such as modifying the command content and scheduled execution mode and adding ECS or managed instances to the task.\n2024-02-02\nAll regions\nModify the execution information of a task\nJanuary 2024\nFeature\nDescription\nRelease date\nRegion\nReferences\nTask status event and first heartbeat event\nCloud Assistant events include task status events and first heartbeat events. You can subscribe to the events to manage and monitor cloud resources in an efficient manner.\n2024-01-19\nAll regions\nSubscribe to Cloud Assistant events\nDecember 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nOperating system upgrade\nWindows Server 2008 instances can be upgraded to Windows Server 2012 in the same language.\nWindows Server 2012 instances can be upgraded to Windows Server 2016 in the same language.\n2023-12-28\nAll regions\nMigrate and upgrade the operating system of an ECS instance\neRDMA monitoring and checking\nThe diagnostics tool and CloudMonitor can be used to monitor and check Elastic Remote Direct Memory Access (eRDMA).\n2023-12-21\nAll regions\nMonitor and check eRDMA\n\nNovember 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nBurst bandwidth\nSpecific instance types in 6th-generation or later instance families support network burst bandwidths. ECS instances of the instance types can burst their network bandwidths beyond the baseline level to handle traffic spikes.\n2023-11-06\nAll regions\nNetwork bandwidth\nOctober 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nDisk\nThe minimum capacity of ESSDs at performance level 0 and ESSD AutoPL disks in the China (Hohhot), China (Guangzhou), and South Korea (Seoul) regions is 1 GB.\n2023-10-30\nAll regions\nDisks\nInstant access\nStarting 11:00 on October 12, 2023, canary release is performed by region to upgrade the instant access feature, and new snapshots of ESSDs at performance levels 0, 1, 2, and 3 and ESSD AutoPL disks are immediately available after creation without the need for additional configurations.\n2023-10-12\nAll regions\nUse the instant access feature\nExtended retention period of snapshots\nThe retention period of existing snapshots, including manual and automatic snapshots, can be extended to meet your requirements for data backup or audit compliance.\n2023-10-09\nAll regions\nCreate a snapshot\nCreate an automatic snapshot policy\n\nSeptember 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nOperating system migration\nECS instances can be migrated from Alibaba Cloud Linux 2 to Alibaba Cloud Linux 3.\n2023-09-20\nAll regions\nMigrate and upgrade the operating system of an ECS instance\nSharing of encrypted snapshots\nEncrypted snapshots can be shared.\n2023-09-01\nAll regions\nShare a snapshot\nAugust 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nWorkbench\nThe AliyunServiceRoleForECSWorkbench role can be assumed by Workbench to gain access to ECS and Elastic Container Instance.\n2023-08-28\nAll regions\nWorkbench service-linked role\nMay 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nCopy and Encrypt Snapshot\nThe Copy and Encrypt Snapshot feature can be used to create an encrypted copy of a snapshot within the same region or across regions to back up data or enhance security.\n2023-05-25\nAll regions\nCopy a snapshot\nSnapshot sharing\nSystem disk snapshots and data disk snapshots can be shared with other Alibaba Cloud accounts or within an organization based on resource directories or folders. The sharees can create disks by using shared snapshots to meet daily O&M requirements.\n2023-05-25\nAll regions\nShare a snapshot\nApril 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g8a general-purpose instance family is released.\n2023-04-21\nSpecific regions\ng8a, general-purpose instance family\nInstance family\nThe c8a compute-optimized instance family is released.\n2023-04-21\nSpecific regions\nc8a, compute-optimized instance family\nInstance family\nThe r8a memory-optimized instance family is released.\n2023-04-21\nSpecific regions\nOverview of instance families\nBoot mode change of images\nThe boot mode of an image can be changed in the ECS console. The boot mode is the mode in which the system disk is booted during instance creation. The following boot modes are supported: UEFI and BIOS.\n2023-04-09\nAll regions\nModify the attributes and tags of an image\nMarch 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nMaximum transmission unit (MTU) management\nJumbo Frames can be enabled or disabled for ECS instances.\n2023-03-25\nAll regions\nJumbo Frames\nInstance family\nThe g8i general-purpose instance family is released.\n2023-03-21\nSpecific regions\ng8i, general-purpose instance family\nInstance family\nThe c8i compute-optimized instance family is released.\n2023-03-21\nSpecific regions\nc8i, compute-optimized instance family\nInstance family\nThe r8i memory-optimized instance family is released.\n2023-03-21\nSpecific regions\nOverview of instance families\nInstance family\nThe g8ae general-purpose instance family with enhanced performance is released.\n2023-03-15\nSpecific regions\ng8ae, performance-enhanced general-purpose instance family\nInstance family\nThe c8ae compute-optimized instance family with enhanced performance is released.\n2023-03-15\nSpecific regions\nc8ae, performance-enhanced compute-optimized instance family\nInstance family\nThe r8ae memory-optimized instance family with enhanced performance is released.\n2023-03-15\nSpecific regions\nr8ae, performance-enhanced memory-optimized instance family\nFebruary 2023\nFeature\nDescription\nRelease date\nRegion\nReferences\nDisk resizing\nThe partitions and file systems of disks can be extended for instances that run specific operating systems by using Cloud Assistant in the ECS console.\n2023-02-22\nAll regions\nStep 1: Resize a disk to extend the capacity of the disk\nOperating system migration\nInstances can be migrated from CentOS 7 to Alibaba Cloud Linux 3.\n2023-02-14\nAll regions\nMigrate and upgrade the operating system of an ECS instance\nOperating system migration\nECS instances can be migrated from CentOS 7 or CentOS 8 to operating systems of the same version or a different version.\n2023-02-02\nAll regions\nMigrate and upgrade the operating system of an ECS instance\nNovember 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g6r general-purpose instance family is released.\n2022-11-17\nSpecific regions\ng6r, general-purpose instance family\nInstance family\nThe c8y compute-optimized instance family is released.\n2022-11-15\nSpecific regions\nc8y, compute-optimized instance family\nInstance family\nThe r8y memory-optimized instance family is released.\n2022-11-15\nSpecific regions\nr8y, memory-optimized instance family\nSeptember 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nESSD AutoPL disk\nThe ESSD AutoPL disk category is released. ESSD AutoPL disks are provided by Alibaba Cloud based on ESSDs. ESSD AutoPL disks inherit the features and performance of ESSDs and decouple disk capacity from disk performance.\n2022-09-28\nSpecific regions\nESSD AutoPL disks\nCross-zone instance type change\nYou can change the instance types of ECS instances across zones. This way, you can migrate ECS instances to different zones and change their instance types based on your business requirements.\n2022-09-22\nAll regions\nChange instance types across zones\nAugust 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nAnti-DDoS Basic\nThe basic DDoS mitigation policy for ECS instances is adjusted and enforces new protection thresholds against DDoS attacks.\n2022-08-31\nAll regions\nAnti-DDoS Basic\nInstance family\nThe gn7e GPU-accelerated compute-optimized instance family is released.\n2022-08-25\nSpecific regions\nOverview of instance families\nWorkbench\nThe file management and multi-terminal features are added to Workbench.\n2022-08-09\nAll regions\nManage files\nUse the multi-terminal feature\nJuly 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nENI modification\nThe attributes of a primary elastic network interface (ENI) can be modified.\n2022-07-28\nAll regions\nModify the attributes of an ENI\nInstance family\nSpecific general-purpose instance families, compute-optimized instance families, memory-optimized instance families, Super Computing Cluster (SCC) instance families, and instance families with high clock speeds support a specific number of IPv6 addresses per ENI.\n2022-07-28\nAll regions\nOverview of instance families\nWorkbench\nThe system management feature is added to Workbench.\n2022-07-22\nAll regions\nPerform system management\nImage replication\nAn encrypted image copy task can be canceled.\n2022-07-19\nAll regions\nCopy a custom image\nAlibaba Cloud Client\nAlibaba Cloud Client can be used to view, query, and connect to ECS instances, elastic container instances, simple application servers, and Alibaba Cloud managed instances.\n2022-07-08\nAll regions\nOverview of Alibaba Cloud Client\nJune 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nOperating system migration\nOperating system migration reduces service downtime by retaining data stored on system disks. The following migrations are supported:\nCentOS 7 to Alibaba Cloud Linux 2 or Anolis OS 7\nCentOS 8 to Alibaba Cloud Linux 3 or Anolis OS 8\n2022-06-17\nAll regions\nMigrate a Linux operating system\nScheduled execution of commands\nCloud Assistant can be used to create and run commands on schedule. You can use this feature for recurring tasks, routine maintenance, and one-time tasks that need to be completed at a specific point in time.\n2022-06-02\nAll regions\nCreate and run a command\nCreate a command\nRun a command\nCheck execution results and troubleshoot common issues\nMay 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nReplication pair-consistent group\nReplication pair-consistent groups can be used to batch manage multiple cloud disks in disaster recovery scenarios. The data of cloud disks in the same replication pair-consistent group can be restored to the same point in time to perform disaster recovery of one or more instances.\n2022-05-27\nAll regions\nOverview of replication pair-consistent groups\nManaged ENI\nManaged ENIs are managed by Alibaba Cloud services. When ENIs are created for specific Alibaba Cloud services such as Container Service for Kubernetes (ACK) and NAT Gateway, the ENIs can be configured to allow the services to manage the ENIs.\n2022-05-20\nAll regions\nManaged ENIs\nApril 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nMarch 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nCommunity image\nCommunity images are publicly available. Custom images can be published as community images for other users to obtain and use.\n2022-03-25\nAll regions\nCommunity images\nSession Manager\nSession Manager is provided by Cloud Assistant. Compared with SSH and Virtual Network Computing (VNC), Session Manager makes your connections to ECS instances more convenient and secure.\n2022-03-22\nSpecific regions\nSession Manager\nConnect to an instance by using Session Manager\nConnect to an instance over SSH by using ali-instance-cli\nFebruary 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nInstance types are added to the gn7i GPU-accelerated compute-optimized instance family.\n2022-02-09\nSpecific regions\nOverview of instance families\nJanuary 2022\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe d3c compute-intensive big data instance family is released.\n2022-01-27\nSpecific regions\nd3c, compute-intensive big data instance family\nDecember 2021\nNovember 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nSnapshot\nThe instance snapshot feature is upgraded to the snapshot-consistent group feature.\n2021-11-30\nAll regions\nCreate a snapshot-consistent group\nInstance family\nThe ebmgn6ia GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2021-11-24\nAll regions\nebmgn6ia, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nInstance family\nThe ebmg7a general-purpose ECS Bare Metal Instance family, ebmc7a compute-optimized ECS Bare Metal Instance family, and ebmr7a memory-optimized ECS Bare Metal Instance family are released.\n2021-11-16\nAll regions\nOverview of instance families\nInstance family\nThe ebmg7 general-purpose ECS Bare Metal Instance family, ebmc7 compute-optimized ECS Bare Metal Instance family, and ebmr7 memory-optimized ECS Bare Metal Instance family are released.\n2021-11-16\nAll regions\nOverview of instance families\nInstance family\nThe ebmgn7e GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2021-11-15\nAll regions\nebmgn7e, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nInstance family\nThe sgn7i-vws vGPU-accelerated instance family with shared CPUs is released.\n2021-11-15\nAll regions\nsgn7i-vws, vGPU-accelerated instance family with shared CPUs\nOctober 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g7se storage-enhanced general-purpose instance family, c7se storage-enhanced compute-optimized instance family, and r7se storage-enhanced memory-optimized instance family are released.\n2021-11-02\nSpecific regions\nOverview of instance families\nSeptember 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nCloud Assistant\nThe Operation Content and Result Delivery feature can be used to deliver O&M task execution records to Object Storage Service (OSS) and Simple Log Service for persistent storage.\n2021-09-28\nAll regions\nUse the Operation Content and Result Delivery feature\nInstance family\nThe vgn7i-vws vGPU-accelerated instance family is released. This instance family comes with an NVIDIA GRID vWS license.\n2021-09-15\nAll regions\nvgn7i-vws, vGPU-accelerated instance family\nAugust 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nCommunity image\nCommunity images are publicly available. Custom images can be published as community images and used by other users in the Alibaba Cloud community.\n2021-08-11\nSpecific regions\nCommunity images\nImage\nThe Kernel Live Patching feature is supported by Alibaba Cloud Linux 3. The feature allows Alibaba Cloud Linux 3 to update its kernel with new patches without the need to restart ECS instances.\n2021-08-10\nAll regions\nOverview of the Kernel Live Patching feature\nEconomical mode\nThe feature name is changed from No Fees for Stopped Instances (VPC-Connected) to economical mode.\n2021-08-09\nAll regions\nEconomical mode\nJuly 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nDeployment set\nThe maximum number of ECS instances that can be created in a deployment set is increased from 7 to 20.\n2021-07-29\nAll regions\nDeployment set\nResource Assurance\nThe tag matching feature provided by Resource Assurance is used to match ECS instances with open private pools based on tags.\n2021-07-19\nAll regions\nOverview of Resource Advisor\nInstance family\nThe gn7i GPU-accelerated compute-optimized instance family is released.\n2021-07-01\nAll regions\nOverview of instance families\nJune 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nImage\nThe Kernel Live Patching feature is supported by Alibaba Cloud Linux 2. The feature allows Alibaba Cloud Linux 2 to update its kernel with new patches without the need to restart ECS instances.\n2021-06-30\nAll regions\nOverview of the Kernel Live Patching feature\nAutomatic reactivation\nAfter you complete the overdue payments in your account, the ECS instances that were stopped due to the overdue payments are automatically reactivated. If the ECS instances cannot be automatically reactivated, manually reactivate them at the earliest opportunity.\n2021-06-22\nAll regions\nStart an instance\nInstance family\nThe ebmgn7i GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2021-06-08\nAll regions\nebmgn7i, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nMay 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe ebmc6me compute-optimized ECS Bare Metal Instance family is released.\n2021-05-28\nSpecific regions\nebmc6me, compute-optimized ECS Bare Metal Instance family\nInstance family\nThe g7a general-purpose instance family, c7a compute-optimized instance family, and r7a memory-optimized instance family are released.\n2021-05-28\nSpecific regions\nOverview of instance families\nApril 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g7 general-purpose instance family, c7 compute-optimized instance family, and r7 memory-optimized instance family are released.\n2021-04-19\nSpecific regions\nOverview of instance families\nImage\nThe Alibaba Cloud Linux 3 public image is released.\n2021-04-16\nAll regions\nWhat is Alibaba Cloud Linux?\nReserved instance\nReserved instances can be applied to more instance families.\n2021-04-15\nAll regions\nOverview of reserved instances\nInstance hibernation\nThe instance hibernation feature is released. When hibernated ECS instances are restarted, the instances automatically restore their applications to the states that the applications were in before hibernation.\n2021-04-06\nSpecific regions\nHibernate instances\nSnapshot\nThe instance snapshot feature is released. You can simultaneously create snapshots for multiple cloud disks on an ECS instance by creating a snapshot for the instance. This ensures the point-in-time write consistency of data.\n2021-04-06\nSpecific regions\nCreate a snapshot-consistent group\nSnapshot\nThe application-consistent snapshot feature is released. You can use application-consistent snapshots to roll back applications to ensure that the applications start in a consistent state.\n2021-04-06\nSpecific regions\nCreate application-consistent snapshots\nMarch 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g7t security-enhanced general-purpose instance family, c7t security-enhanced compute-optimized instance family, and r7t security-enhanced memory-optimized instance family are released.\n2021-03-31\nSpecific regions\nOverview of instance families\nOverview of security capabilities\nInstance family\nThe ebmhfg7 general-purpose ECS Bare Metal Instance family with high clock speeds, ebmhfc7 compute-optimized ECS Bare Metal Instance family with high clock speeds, and ebmhfr7 memory-optimized ECS Bare Metal Instance family with high clock speeds are released.\n2021-03-03\nSpecific regions\nOverview of instance families\nFebruary 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe i3g instance family with local SSDs is released.\n2021-02-26\nAll regions\ni3g, instance family with local SSDs\nInstance family\nThe g7ne network-enhanced general-purpose instance family is released.\n2021-02-09\nSpecific regions\ng7ne, network-enhanced general-purpose instance family\nJanuary 2021\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe gn7 GPU-accelerated compute-optimized instance family is released.\n2021-01-12\nSpecific regions\ngn7, GPU-accelerated compute-optimized instance family\nImage Builder\nImage Builder is an all-in-one image customization service provided by ECS that allows you to create custom images for ECS instances across regions and Alibaba Cloud accounts.\n2021-01-11\nAll regions\nImage Builder\nTable 1. December 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nResource Assurance\nResource Assurance is a comprehensive service that guarantees the provision of resources to meet your business needs. It can be used to quantify the amount of available resources, reserve resources, and plan private pools.\n2020-12-14\nSome\nOverview\nfaasutil\nfaasutil is released. faasutil is a next-generation command line tool provided by Alibaba Cloud FPGA as a Service (FaaS). This tool simplifies the management of FPGA-accelerated instances and helps improve their stability, security, and scalability.\n2020-12-08\nSome\nObtain faasutil\nUse faasutil\nInstant access\nThe instant access feature is available for public preview in the China (Hohhot) region.\n2020-12-03\nSome\nUse the instant access feature\nTable 2. November 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe re6p persistent memory-optimized instance family is released.\n2020-11-04\nSome\nOverview of instance families\nInstance family\nThe i3 instance family with local SSDs is released.\n2020-11-03\nSome\nOverview of instance families\nTable 3. October 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g6se storage-enhanced instance family is released.\n2020-10-23\nSome\nOverview of instance families\nTable 4. September 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nPreemptible instance\nA preemptible instance can be configured to have no protection period when it is created by calling an API operation.\n2020-09-25\nAll\nWhat are preemptible instances?\nRunInstances\nSavings plan\nSavings plans are provided as discount plans that can be applied to offset the bills of pay-as-you-go instances, excluding preemptible instances.\n2020-09-18\nAll\nOverview\nSavings plans\nPurchase and apply savings plans\nInstance family\nThe g6t security-enhanced general-purpose instance family and c6t security-enhanced compute-optimized instance family are released.\n2020-09-08\nSome\nOverview of instance families\nOverview of security capabilities\nInstance family\nThe g6a general-purpose instance family, c6a compute-optimized instance family, and r6a memory-optimized instance family are released.\n2020-09-07\nSome\nOverview of instance families\nInstance family\nThe ebmg6a general-purpose ECS Bare Metal Instance family, ebmc6a compute-optimized ECS Bare Metal Instance family, and ebmr6a memory-optimized ECS Bare Metal Instance family are released.\n2020-09-07\nSome\nOverview of instance families\nTable 5. August 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nTag\nTags can be added to more resources, including reserved instances.\n2020-08-18\nAll\nTags\nSnapshot\nSnapshots can be replicated across regions to improve service reliability and availability.\n2020-08-14\nSome\nCopy a snapshot\nTable 6. July 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nImage family\nThe image family feature is released to facilitate smooth upgrade and rollback of images.\n2020-07-02\nAll\nOverview\nTable 7. June 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe d2c compute-intensive big data instance family is released.\n2020-06-23\nSome\nOverview of instance families\nInstance family\nThe scchfc6 compute-optimized Super Computing Cluster (SCC) instance family with high clock speeds, scchfg6 general-purpose SCC instance family with high clock speeds, and scchfr6 memory-optimized SCC instance family with high clock speeds are released.\n2020-06-23\nAll\nOverview of instance families\nInstance family\nThe ebmc6e compute-optimized ECS Bare Metal Instance family with enhanced performance, ebmg6e general-purpose ECS Bare Metal Instance family with enhanced performance, and ebmr6e memory-optimized ECS Bare Metal Instance family with enhanced performance are released.\n2020-06-23\nAll\nOverview of instance families\nStorage capacity unit (SCU)\nSCUs can be used to offset the pay-as-you-go bills of different storage resources, such as disks, Object Storage Service (OSS) buckets, Apsara File Storage NAS file systems, and snapshots.\n2020-06-23\nAll\nOverview\nSCUs\nUsage rules\nElastic Block Storage (EBS)\nThe sequence numbers of disks attached to ECS instances can be queried.\n2020-06-16\nAll\nQuery the serial numbers of block storage devices\nNetwork\nVirtual private clouds (VPCs) of ECS instances can be changed in the ECS console. This feature is in invitational preview.\n2020-06-10\nSome\nChange the VPC of an ECS instance\nEnhanced SSD (ESSD)\nESSDs at the performance level 0 (PL0 ESSDs) are in public preview in the China (Hangzhou) and China (Beijing) regions.\n2020-06-10\nSome\nESSDs\nBlock storage performance\nLocal disk-related system event\nSystem events about local disk damages can be queried and damaged local disks can be isolated in the ECS console.\n2020-06-09\nAll\nIsolate damaged local disks\nInstance family\nThe hfg7 general-purpose instance family with high clock speeds, hfc7 compute-optimized instance family with high clock speeds, and hfr7 memory-optimized instance family with high clock speeds are released.\n2020-06-09\nSome\nOverview of instance families\nInstance family\nThe g6e general-purpose instance family with enhanced performance, c6e compute-optimized instance family with enhanced performance, and r6e memory-optimized instance family with enhanced performance are released.\n2020-06-09\nAll\nOverview of instance families\nInstance family\nThe ebmre6p non-volatile memory-optimized ECS Bare Metal Instance family with enhanced performance is released.\n2020-06-09\nSome\nOverview of instance families\nTable 8. May 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nImage\nTechnical support for the CoreOS Container Linux public images is discontinued. CoreOS Container Linux has reached its end of life, and no more security patches are provided. For security concerns, we recommend that you no longer use CoreOS Container Linux images. Alibaba Cloud will soon release Fedora CoreOS public images as a replacement.\n2020-05-26\nAll\nRelease notes\nReserved instance\nThe normalization factors of instance types can be queried to help understand the computing power requirements in the splitting and merging of reserved instances and the size flexibility of regional reserved instances.\n2020-05-14\nAll\nOverview\nView normalization factors\nTable 9. April 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe ebmre6-6t memory-optimized ECS Bare Metal Instance family with enhanced performance is released.\n2020-04-28\nAll\nOverview of instance families\nInstance family\nThe re6 memory-optimized instance family with enhanced performance is released.\n2020-04-20\nSome\nOverview of instance families\nTable 10. March 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe i2ne and i2gne instance families with local SSDs are released.\n2020-03-11\nAll\nOverview of instance families\nTable 11. February 2020\nTable 12. January 2020\nFeature\nDescription\nRelease date\nRegion\nReferences\nTag\nA wide range of tag features are provided. Tags can be used to control permissions of Resource Access Management (RAM) users. Tags can be added and modified by using Operation Orchestration Service (OOS).\n2020-01-03\nAll\nControl access to resources by using tags\nCreate a resource with a specific tag\nUse OOS to add tags to multiple ECS resources at a time\nUse OOS to modify a tag value of multiple resources\nInstance family\nThe d2s storage-intensive big data instance family is released.\n2020-01-17\nSome\nOverview of instance families\nInstance family\nThe vgn6i lightweight GPU-accelerated compute-optimized instance family is released.\n2020-01-16\nSome\nOverview of instance families\nInstance family\nThe s6 shared standard instance family is released.\n2020-01-16\nSome\nOverview of instance families\nImage\nTechnical support for the Windows Server 2008 and Windows Server 2008 R2 public images is discontinued. We recommend that you upgrade to Windows Server 2012 or later at your earliest convenience.\n2020-01-14\nAll\nOverview\nTable 13. December 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nSCU\n40 GiB, 100 GiB, and 500 GiB are added as capacity options for SCUs.\n2019-12-05\nSome\nOverview\nTable 14. November 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nTag\nThe tag editor feature is released. Up to 5,000 resource data entries across services and regions can be queried. The tags of resources can be edited, and resource information can be exported.\n2019-11-28\nAll\nUse the tag editor to manage resource tags\nSnapshot\nThe quota for automatic snapshots is increased to 1,000.\n2019-11-15\nAll\nOverview\nInstance family\nThe gn6e GPU-accelerated compute-optimized instance family is released.\n2019-11-14\nSome\nOverview of instance families\nInstance family\nThe ebmgn6e GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2019-11-14\nSome\nOverview of instance families\nTable 15. October 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe hfc6, hfg6, and hfr6 instance families with high clock speeds are released.\n2019-10-15\nSome\nOverview of instance families\nInstance family\nThe ebmhfc6, ebmhfg6, and ebmhfr6 ECS Bare Metal Instance families are released.\n2019-10-10\nAll\nOverview of instance families\nTable 16. September 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nDisk resizing\nStandard SSDs and ultra disks can be resized to up to 32 TiB.\nESSDs can be resized online.\n2019-09-26\nAll\nOverview\nStep 1: Resize a disk to extend the capacity of the disk\nInstance family\nThe ebmc6, ebmg6, and ebmr6 ECS Bare Metal Instance families are released.\n2019-09-24\nAll\nOverview of instance families\nInstance family\nThe t6 burstable instance family is released.\n2019-09-12\nSome\nOverview of instance families\nSecurity group\nThe maximum number of security group rules that a security group can contain is increased to 200.\n2019-09-03\nAll\nLimits\nSnapshot\nThe individual quotas for manual snapshots and automatic snapshots are increased to 256.\n2019-09-02\nAll\nOverview\nTable 17. August 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe ebmgn6v GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2019-08-26\nSome\nOverview of instance families\nInstance family\nThe ebmgn6i GPU-accelerated compute-optimized ECS Bare Metal Instance family is released.\n2019-08-26\nSome\nOverview of instance families\nImage\nThe image export feature is available in all Alibaba Cloud regions.\n2019-08-21\nAll\nExport a custom image\nSnapshot\nThe snapshot service is available for commercial use. All existing and new snapshots are billed on a pay-as-you-go basis.\n2019-08-21\nAll\nSnapshots\nTable 18. July 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe g6 general-purpose instance family is released.\n2019-07-30\nSome\nOverview of instance families\nInstance family\nThe c6 compute-optimized instance family is released.\n2019-07-30\nSome\nOverview of instance families\nInstance family\nThe r6 memory-optimized instance family is released.\n2019-07-30\nSome\nOverview of instance families\nInstance family\nThe ebmc5s network-enhanced compute-optimized ECS Bare Metal Instance family is released.\n2019-07-30\nSome\nOverview of instance families\nInstance family\nThe ebmg5s network-enhanced general-purpose ECS Bare Metal Instance family is released.\n2019-07-30\nSome\nOverview of instance families\nInstance family\nThe ebmr5s network-enhanced memory-optimized ECS Bare Metal Instance family is released.\n2019-07-30\nSome\nOverview of instance families\nTable 19. June 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nAuto Provisioning\nAuto Provisioning uses auto provisioning groups to schedule and maintain computing resources. This makes it easy to deploy clusters of instances across billing methods, instance types, and zones.\n2019-06-28\nAll\nOverview\nESSD\nThe ESSD service is available for commercial use after the public preview is complete. Three performance levels of ESSDs are released.\n2019-06-28\nSome. For more information about the supported regions, see FAQ.\nESSDs\nvgn5i, lightweight GPU-accelerated compute-optimized instance family\nGRID drivers are provided for vgn5i instances.\n2019-06-19\nAll\nInstall a GRID driver on a Linux vGPU-accelerated instance\nTable 20. May 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nEBS\nSubscription disks can be created by calling API operations.\n2019-05-15\nAll\nCreateDisk\nTable 21. April 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nElastic network interface (ENI)\nA single ENI can be assigned multiple private IP addresses.\n2019-04-28\nAll\nSecondary private IP addresses\nEBS\nData disks of an ECS instance can be resized online to meet storage requirements without restarting the instance.\n2019-04-24\nAll\nStep 1: Resize a disk to extend the capacity of the disk\nEBS\nSystem disks can be resized.\n2019-04-24\nAll\nResize disks offline for Linux and Windows instances\nSnapshot\nSnapshots can be created for expired disks.\n2019-04-20\nAll\nCreate a snapshot\nCreateSnapshot\nTable 22. March 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nPublic image\nAliyun Linux 2 public images are released.\n2019-03-27\nAll\nOverview\nInstance family\nThe gn6i GPU-accelerated compute-optimized instance family is released.\n2019-03-21\nAll\nOverview of instance families\nInstance family\nThe sccgn6 GPU-accelerated compute-optimized SCC instance family is released.\n2019-03-20\nAll\nOverview of instance families\nInstance family\nThe vgn5i lightweight GPU-accelerated compute-optimized instance family is released.\n2019-03-19\nAll\nOverview of instance families\nReserved instance\nThe reserved instance feature is in invitational preview.\n2019-03-18\nAll\nOverview\nCloud Assistant\nCloud Assistant is available for ECS instances in the classic network.\n2019-03-01\nAll\nInstall Cloud Assistant Agent\nTable 23. January 2019\nFeature\nDescription\nRelease date\nRegion\nReferences\nEvent notification\nStatus change events and alert events for the recycling of preemptible instances are supported.\n2019-01-29\nAll\nOverview\nTable 24. December 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nCloud Assistant\nCloud Assistant is available in the UK (London) region.\n2018-12-31\nAll\nOverview\nPreemptible instance\nPreemptible instances are billed by second.\n2018-12-17\nAll\nPreemptible instances\nInstance\nThe release protection feature is supported.\n2018-12-14\nAll\nEnable or disable release protection for ECS instances\nENI\nThe DescribeNetworkInterfaces operation can be called to query the public IP address associated with an ENI.\n2018-12-04\nAll\nDescribeNetworkInterfaces\nTable 25. November 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nCustom image\nPacker can be used to create custom images.\n2018-11-30\nAll\nUse Packer to create a custom image\nInstance family\nThe re4e high memory instance family is released.\n2018-11-30\nAll\nOverview of instance families\nEBS\nSubscription disks can be separately created and attached to subscription instances.\n2018-11-29\nAll\nCreate a subscription disk\nDeployment set\nThe deployment set feature is released.\n2018-11-16\nAll\nDeployment set\nTable 26. October 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe f3 FPGA-accelerated compute-optimized instance family is released.\n2018-10-31\nAll\nOverview of instance families\nAPI best practices\nAPI best practices are released in the ECS console.\n2018-10-19\nAll\nCreate an instance on the Custom Launch tab\nTable 27. September 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nt5, burstable instance family\nUnlimited mode is available for the t5 burstable instance family.\n2018-09-30\nAll\nUnlimited mode\nInstance metadata\nInformation of O&M system events is included in instance metadata.\n2018-09-14\nAll\nOverview of ECS instance metadata\nInstance health status\nThe health status of each ECS instance is displayed on the instance details page.\n2018-09-14\nAll\nView the health status of ECS instances\nInstance family\nThe gn6v new-generation GPU-accelerated instance family (V100 model) is released.\n2018-09-12\nAll\nOverview of instance families\nInstance purchase\nMultiple instances can be renewed at a time, and historical instances can be purchased.\n2018-09-07\nAll\nRenew a subscription instance\nSystem event\nAPI operations used to create or cancel simulated events are released.\n2018-09-03\nAll\nCreateSimulatedSystemEvents\nCancelSimulatedSystemEvents\nBilling method\nSubscription instances can be changed into pay-as-you-go instances.\n2018-09-01\nAll\nChange the billing method of an instance from subscription to pay-as-you-go\nTable 28. August 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nLocal disk\nThe O&M of instances that have local disks attached is optimized.\n2018-08-31\nAll\nLocal disks\nCloud Assistant\nCloud Assistant is supported in the ECS console.\n2018-08-17\nAll\nOverview\nInstance family\nSCC instance families are released.\n2018-08-16\nAll\nOverview of instance families\nTable 29. July 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nCustom image\nImages in the qcow2 format can be imported.\n2018-07-30\nAll\nImport custom images\nImportImage\nSecurity group\nSecurity group rules can be modified.\n2018-07-25\nAll\nModify security group rules\nTag\nTags can be added to resources when the resources are created.\n2018-07-20\nAll\nCreate or add a tag\nInstance family\nThe ebmc4 compute-optimized ECS Bare Metal Instance family is released.\n2018-07-18\nAll\nOverview of instance families\nSnapshot\nThe estimated remaining time required to create snapshots is displayed.\n2018-07-17\nAll\nCreate a snapshot\nAccount and user privileges\nQuota management is supported.\n2018-07-15\nAll\nView quotas (old version)\nESSD\nThe ESSD service is in public preview in Beijing Zone G.\n2018-07-14\nBeijing Zone G\nDisks\nInstance troubleshooting\nSystem logs and screenshots can be viewed.\n2018-07-13\nAll\nView system logs and screenshots\nSecurity group\nA ticket can be submitted to modify the maximum numbers of instances and security group rules that can be added to a security group.\n2018-07-10\nAll\nLimits\nInstance family\nThe ic5 compute-intensive instance family is released.\n2018-07-09\nAll\nOverview of instance families\nTable 30. June 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nPublic image\nOperating systems including Red Hat can be selected from public images to create ECS instances.\n2018-06-29\nAll\nCreate an instance on the Custom Launch tab\nInstance configuration upgrade\nThe configurations of pay-as-you-go instances can be upgraded or downgraded across instance families.\n2018-06-15\nAll\nInstance types and families that support instance type changes\nBilling method\nSubscription instances can be renewed on a weekly basis.\n2018-06-12\nAll\nRenew a subscription instance\nSecurity group\nSecurity groups in the classic network can be cloned to a VPC.\n2018-06-06\nAll\nClone a security group\nActive O&M\nPhase 2 of active O&M is brought online.\n2018-06-01\nAll\nOverview\nTable 31. May 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nCustom image\nThe image compliance tool is released.\n2018-05-28\nAll\nCheck and repair an image\nSystem event\nECS system events are updated to CloudMonitor and can be queried.\n2018-05-25\nAll\nOverview\nLaunch template\nThe launch template feature is released.\n2018-05-11\nAll\nCreate a launch template\nTable 32. April 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nBilling method\nPay-as-you-go instances can be changed into subscription instances.\n2018-04-23\nAll\nChange the billing method of an instance from pay-as-you-go to subscription\nInstance configuration downgrade\nThe configurations of expired subscription instances can be downgraded while the instances are being renewed.\n2018-04-13\nAll\nRenew an instance and downgrade its configurations\nTable 33. March 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nGPU-accelerated instance\nNVIDIA GPU Cloud (NGC) GPU-accelerated containers are supported.\n2018-03-28\nAll\nDeploy an NGC environment on gn5 instances\nSystem event\nThe system event feature is released.\n2018-03-26\nAll\nOverview\nECS Bare Metal Instance\nECS Bare Metal Instance is released.\n2018-03-14\nAll\nOverview\nInstance identity\nThe ECS instance identity feature is released.\n2018-03-01\nAll\nUse instance identities\nTable 34. February 2018\nFeature\nDescription\nRelease date\nRegion\nReferences\nECS API\nThe API operation used to check whether the configurations of ECS instances can be upgraded or downgraded is released.\n2018-02-10\nAll\nDescribeResourcesModification\nSubscription instance\nThe number of days during which an instance stays expired before it is released is extended from 7 to 15.\n2018-02-07\nAll\nSubscription\nECS API\nAPI operations used to create and query resources are released.\n2018-02-02\nAll\nDescribeAvailableResource\nTable 35. January 2018\nTable 36. December 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nNo Fees for Stopped Instances (VPC-Connected)\nThe No Fees for Stopped Instances (VPC-Connected) feature is supported for pay-as-you-go instances.\n2017-12-14\nAll\nEconomical mode\nENI\nThe ENI feature is released.\n2017-12-08\nAll\nOverview\nFPGA-accelerated instance family\nThe f1 FPGA-accelerated compute-optimized instance family is released.\n2017-12-02\nAll\nOverview of instance families\nECS API\nThe API operation used to batch create instances is released.\n2017-12-01\nAll\nRunInstances\nInstance troubleshooting\nThe real-time diagnostics feature is supported in the ECS console.\n2017-12-01\nAll\nAutomatic diagnostics system\nTable 37. November 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nCloud Migration tool\nThe Cloud Migration tool is released.\n2017-11-27\nAll\nWhat is SMC?\nSecurity group rule\nSecurity group rules can be imported and exported.\n2017-11-23\nAll\nManage security group rules\nSubscription instance\nThe auto-renewal feature can be disabled for subscription instances.\n2017-11-23\nAll\nModifyInstanceAutoRenewAttribute\nBilling method\nAPI operations used to create and renew weekly subscription instances are released.\n2017-11-03\nAll\nCreateInstance\nInstance RAM role\nRAM roles can be assigned to ECS instances.\n2017-11-01\nAll\nOverview\nTable 38. October 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nElastic IP Address (EIP)\nThe public IP addresses of instances in VPCs can be converted into EIPs.\n2017-10-31\nAll\nConvert the static public IP address of an instance in a VPC to an EIP\nPreemptible instance\nThe preemptible instance feature is released.\n2017-10-18\nAll\nWhat are preemptible instances?\nt5, burstable instance family\nThe t5 burstable instance family is released.\n2017-10-09\nAll\nOverview\nTable 39. September 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nBilling method\nBills of pay-as-you-go instances and disks are accurate to the second and generated by hour.\n2017-09-29\nAll\nPay-as-you-go\ngn5i instance family\nThe gn5i GPU-accelerated compute-optimized instance family is released. It is applicable to deep learning and online inference scenarios.\n2017-09-23\nAll\nOverview of instance families\nDisk encryption\nDisks can be encrypted.\n2017-09-05\nAll\nEncryption overview\nTable 40. August 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nSecurity group rule\nSecurity group rules can be configured based on 5-tuples.\n2017-08-31\nAll\nSecurity group quintuple rules\nClassicLink\nClassicLink allows instances in the classic network to be connected to instances in VPCs.\n2017-08-25\nAll\nNetwork types\nInstance family\nThe new-generation instance families with high clock speeds and instance families with local SSDs are released. They are powered by Skylake processors and support 25 Gigabit Ethernet.\n2017-08-22\nAll\nOverview of instance families\nECS API\nThe API operation used to change the bandwidth configurations of instances is released.\n2017-08-17\nAll\nModifyInstanceNetworkSpec\nCustom image\nCustom images can be imported.\n2017-08-10\nAll\nImport custom images\nTable 41. July 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nImage\nTechnical support for the Windows Server 2003 public images is discontinued. We recommend that you upgrade to Windows Server 2012 or later at your earliest convenience.\n2017-07-20\nAll\nOverview\nSecurity group\nSecurity group rules can be configured to isolate the instances in a security group from each other.\n2017-07-07\nAll\nNetwork isolation within a basic security group\nTable 42. June 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nClassic network\nThe classic network is unavailable for users who create ECS instances at or after 12:00:00 on June 16, 2017 (UTC+8) for the first time. We recommend that you use VPC.\n2017-06-16\nAll\nWhat is a VPC?\nTable 43. May 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance RAM role\nThe API operation used to manage instance RAM roles is released.\n2017-05-26\nAll\nUse an instance RAM role by calling API operations\nInstance family\nThe network-enhanced instance family is released.\n2017-05-23\nAll\nOverview of instance families\nInstance family\nThe d1 storage-intensive instance family is released.\n2017-05-12\nAll\nOverview of instance families\nSecurity group\nThe default security group rule is modified to expose only Internet Control Message Protocol (ICMP) ports, Transmission Control Protocol (TCP) port 22, and TCP port 3389.\n2017-05-11\nAll\nSecurity groups\nSecurity group\nSecurity groups can be backed up, overwritten, and restored.\n2017-05-10\nAll\nRestore security group rules\nTable 44. April 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nSSH key pair\nThe SSH key pair feature is released.\n2017-04-25\nAll\nOverview\nTable 45. February 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nCustom image\ncloud-init supports some custom images.\n2017-02-24\nAll\nInstall cloud-init\nInstance family\nThe i1 I/O optimized instance family with local SSDs is released.\n2017-02-17\nAll\nOverview of instance families\nSnapshot\nSystem disk snapshots can be used to create data disks.\n2017-02-15\nAll\nCreate a disk from a snapshot\nInstance family\nThe gn4 GPU-accelerated compute-optimized instance family is released.\n2017-02-14\nAll\nOverview of instance families\nTable 46. January 2017\nFeature\nDescription\nRelease date\nRegion\nReferences\nInstance family\nThe ga1 GPU-accelerated visualization and compute-optimized instance family is released.\n2017-01-24\nAll\nOverview of instance families\nInstance family\nThe se1 dedicated instance family is released.\n2017-01-21\nAll\nOverview of instance families\nTable 47. 2016\nFeature\nDescription\nRelease date\nRegion\nReferences\nSnapshot\nSnapshot 2.0 is released.\n2016-03-15\nAll\nOverview\nDisk resizing\nSystem disks can be resized.\n2016-01-15\nAll\nResize disks offline for Linux and Windows instances\nTable 48. 2015\nFeature\nDescription\nRelease date\nRegion\nReferences\nCustom image\nCustom images can be imported.\n2015-12-15\nAll\nInstructions for importing images\nSecurity group\nSecurity groups are supported in the ECS console.\n2015-11-02\nAll\nCreate a security group\nAlibaba Cloud market mirror image\nAlibaba Cloud market mirror images are available for commercial use.\n2015-09-02\nAll\nAlibaba Cloud Marketplace images\nTag\nThe tag feature is released.\n2015-08-20\nAll\nTags\nSystem disk\nThe operating systems of pay-as-you-go instances can be replaced.\n2015-08-13\nAll\nReplace the operating system of an instance\nCustom image\nCustom images can be shared.\n2015-05-15\nAll\nShare or unshare a custom image\nDisk resizing\nDisks can be resized offline.\n2015-04-20\nAll\nOverview\nCustom image\nThe image replication feature is released.\n2015-01-26\nAll\nCopy a custom image\nTable 49. 2014\nFeature\nDescription\nRelease date\nRegion\nReferences\nEBS\nThe independent disk feature is released.\n2014-08-22\nAll\nElastic Block Storage devices"
    },
    "9": {
        "title": "Elastic Compute Service:Service notices",
        "url": "https://www.alibabacloud.com/help/en/ecs/service-notices/",
        "content": "This Product\nElastic Compute Service:Service notices"
    },
    "10": {
        "title": "Elastic Compute Service:Security announcement",
        "url": "https://www.alibabacloud.com/help/en/ecs/security-announcement/",
        "content": "This Product\nElastic Compute Service:Security announcement"
    },
    "11": {
        "title": "Elastic Compute Service:Billing overview",
        "url": "https://www.alibabacloud.com/help/en/ecs/billing-overview",
        "content": "This Product\nElastic Compute Service:Billing overview\nThis topic walks you through Elastic Compute Service (ECS) billable items, billing methods, usage fees, and instance pricing.\nAn ECS instance is a virtual server in the cloud that consists of computing resources (such as vCPUs and memory), an operating system (provided by an image), block storage devices, and networking resources. The following table describes how each individual component is billed.\nResource\nDescription\nBilling method\nReferences\nComputing resources (vCPUs and system disk memory)\nThe computing resources you can obtain are determined by the instance type. Each instance type offers a unique combination of vCPUs, memory, and related capabilities, which determine the price of the instance.\nWhen you create an instance, you occupy computing resources in the cloud. As long as you occupy these resources, you are billed for these resources even if they are idle. This is particularly true for pay-as-you-go instances. To avoid paying for idle resources, we recommend that you stop such instances in economical mode. For more information about the economical mode, see Economical mode.\nSubscription\nPay-as-you-go\nPreemptible Instance\nPay-as-you-go + Reserved Instance\nPay-as-you-go + Savings Plan\nInstance types\nImages\nImage fees are determined based on the types and usage of images.\nSubscription\nPay-as-you-go\nPay-as-you-go + Reserved Instance (for public images)\nImages can be used only with ECS instances. Reserved instances for Windows instances include the costs for the instance and the public image.\nImages\nBlock storage device (cloud disk or local disk)\nBilling for cloud disks is determined by their size and usage duration.\nLocal disks only come with specific instance types and cannot be separately purchased. The prices of the instances include the costs of their local disks.\nSubscription\nPay-as-you-go\nStorage Capacity Unit (SCU)\nPay-as-you-go + Savings Plan\nBlock storage devices\nPublic bandwidth\nIf your instance uses a system-assigned public IP address to access the Internet, you are charged only for outbound data transfers to the Internet.\nAn instance can also use an elastic IP address (EIP) or a NAT gateway to access the Internet. For information about how EIPs are billed and how NAT gateways are billed , see Overview and Billing of Internet NAT gateways respectively.\nPay-by-bandwidth\nPay-by-traffic\nPublic bandwidth\nSnapshots\nWhen you create snapshots, you are charged for them based on their size and storage duration. Fees are region-specific and vary from region to region.\nWhen you copy snapshots, you are charged data transfer fees in addition to the storage fees generated for the snapshot copies.\nPay-as-you-go\nSCU\nSnapshots\nECS resources support the subscription and pay-as-you-go billing methods. You can mix and match different billing methods for different resources to reduce costs. For more information, see Overview.\nThe following figure shows the fees charged for your ECS usage and illustrates how individual resources are billed.\nFor information about the instance price schedule, visit the Instance tab on the Pricing tab of the Elastic Compute Service product page.\nYou can switch between billing methods for ECS instances as your business requirements change and evolve. The following table describes the resources whose billing methods can be changed.\nResource\nDescription\nReferences\nInstance\nWhen you change the billing method of ECS instances, the billing methods of their computing resources and system disks are changed to match the billing method of the instance.\nIf your workloads become intermittent or you no longer need the instance, you can change the billing method of an instance from subscription to pay-as-you-go. Then, you need to pay only for what you use and can release the instance at any time. This lets you recover a portion of the subscription costs.\nAlibaba Cloud determines whether you can switch the billing method of an instance based on usage metrics of the instance. Go to the ECS console and check for the button or menu item that is used to change the billing method of an instance. If the button or menu item does not exist, the billing method of the instance cannot be changed.\nIf your workloads shift towards long-term, sustained business, you can change the billing method of an instance from pay-as-you-go to subscription to save on costs in the long run.\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nCloud disks\nYou can freely change the billing method of data disks that are attached to subscription instances.\nHowever, the billing methods of system disks and data disks on pay-as-you-go instances change together with the billing methods of the instances.\nChange the billing method of a disk\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nPublic bandwidth\nYou can change the billing method for network usage by upgrading or downgrading instance configurations for instances that have system-assigned public IP addresses.\nChange the billing method for network usage of an ECS instance that uses an auto-assigned IP address\nYou can view your bills and their details in the Expenses and Costs. For more information, see View billing details.\nSubscription instances stop providing services when they expire. You can renew an expired instance to continue using it. However, if you do not renew it within the grace period, the instance is released, and all data stored on the instance is lost and cannot be recovered. For more information, see Renewal overview.\nPayments become overdue if you do not have sufficient funds in your account when a bill is due. The total usable funds are calculated as the sum of your balance and applicable vouchers in your account. Overdue payments may result in service interruptions. We recommend that you regularly check your account balance and ensure that you have enough funds to ensure business continuity.\nSubscription resources: Subscription resources are not affected by overdue payments because you have already paid for the resources. You can use these instances up until they expire. However, you will be unable to perform payment-related activities, including purchasing new instances, upgrading instance configurations, or renewing resources.\nPay-as-you-go resources: Pay-as-you-go instances are automatically stopped when you have overdue payments. In this state, billing is stopped for some resources. You are required to settle the overdue payments before you can continue using your instances. If payment is not completed within the grace period, your instances are released and all data stored on the instances is lost and cannot be recovered.\nECS supports the following payment methods:\nBank card\nPayPal\nAlibaba Cloud performs a pre-authorization hold on your PayPal account when you create pay-as-you-go resources.\nYou can use coupons to obtain discounts and savings on your purchases.\nIf you want to purchase ECS resources in the Chinese mainland, you must first complete real-name verification for your Alibaba Cloud account. For more information, see the \"Why do I need to complete real-name registration when purchasing cloud products in Chinese mainland?\" section of Real-name registration FAQs.\nAlibaba Cloud provides multiple methods to view the detailed information about your bills. For more information, see View billing details.\nECS usage costs can be broken into ownership costs and O&M costs. We have prepared a selection of best practices for maximizing cost performance, including actions such as optimizing resources, upgrading resources, taking cost savings measures, and implementing automated O&M. For more information, see Best practices for cost optimization.\nFor answers to the questions that you may encounter when you purchase or use ECS resources, see Billing FAQ."
    },
    "12": {
        "title": "Elastic Compute Service:Billable items",
        "url": "https://www.alibabacloud.com/help/en/ecs/billable-items/",
        "content": "This Product\nElastic Compute Service:Billable items"
    },
    "13": {
        "title": "Elastic Compute Service:Billing methods",
        "url": "https://www.alibabacloud.com/help/en/ecs/billing-methods/",
        "content": "This Product\nElastic Compute Service:Billing methods"
    },
    "14": {
        "title": "Elastic Compute Service:Change the billing method",
        "url": "https://www.alibabacloud.com/help/en/ecs/change-the-billing-method/",
        "content": "This Product\nElastic Compute Service:Change the billing method"
    },
    "15": {
        "title": "Elastic Compute Service:Renew subscription instances",
        "url": "https://www.alibabacloud.com/help/en/ecs/renew-instances/",
        "content": "This Product\nElastic Compute Service:Renew subscription instances"
    },
    "16": {
        "title": "Elastic Compute Service:View billing details",
        "url": "https://www.alibabacloud.com/help/en/ecs/view-billing-details",
        "content": "This Product\nElastic Compute Service:View billing details\nYou can view the bills and consumption details related to ECS instances in the Billing And Cost console to understand the consumption situation.\nAlibaba Cloud currently provides three versions of Bill Details (Old Version), Bill Details (New Version), and Bill Details (Upgraded Version) for different users. The upgraded version of the bill is currently in grayscale for customers. This document provides a corresponding usage introduction for the Bill Details (New Version). For operation guides for other versions of bill details, see Bill Details.\nThe public network fees related to Elastic Compute Service (ECS) only include the fees for static public IP addresses billed with the instance. If you use other products to access the public network, see How to View the Fees for ECS Public Network Traffic for fee queries.\nLog on to the Billing and Cost Console.\nIn the left navigation bar, select Bill Management > Bill Details.\nClick the corresponding tab as needed to view consumption information.\nThe following table describes the tabs.\nTab\nDescription\nConsumption By Bill\nThe Consumption by Bill tab includes each order and the bill for each billing cycle.\nWhen querying ECS bills, you can filter the product as Elastic Compute Service.\nDetailed Bill\nYou can filter billing details by statistical item and statistical period. The billing details include the product details, subscription types, prices, and deducted fees of services.\nWhen querying ECS bills, you can filter the product as Elastic Compute Service or specify an instance for a term query. The subscription type descriptions are as follows:\nSubscription: applies to subscription ECS instances.\nPay-As-You-Go: applies to pay-as-you-go or preemptible ECS instances.\nUsage Details\nUsage details must be exported as a CSV file to be viewed. When configuring, select Elastic Compute Service as the product. You can select the measurement specification, usage time, and measurement granularity as needed. After clicking Export CSV, the export record page will automatically open. When the status changes from File Generating to Export Successful, click Download in the Operation column to export the usage details file to your local computer.\nFor more detailed billing information, see Bill Management.\n\nYou can click Customize Columns in the upper right corner of the bill to select the bill content you want to display.\nIf you want to analyze your bill more conveniently, you can click Export Bill CSV to export your current bill to your local computer for viewing and analysis.\nPreemptible instances are offered at a discounted price compared to pay-as-you-go instances. You can view the bills of preemptible instances to calculate the invoice discounts and actual costs of the instances.\nAll created preemptible instances are attached with the system tag key:acs:ecs:payType value:spot. You can filter the ECS instances with the tag key:acs:ecs:payType value:spot in the exported bill to summarize the billing and discount amounts.\nEnable the acs:ecs:payType cost tag.\nLog on to the Billing and Cost Console.\nIn the left navigation bar, select Billing Management > Cost Tag.\nEnter acs:ecs:payType in the tag key text box and click Search.\n\nClick acs:ecs:payType tag Operation column Enable.\n\nSelect Bill Management > Bill Details.\nClick the Detailed Bill tab, to view the bills for preemptible instances.\nView the bills for a single preemptible instance.\nEnter the preemptible instance ID in the Instance ID text box and click Search to view the bill for the preemptible instance, including consumption time, official price, discount amount, and payable amount.\nView the bills for multiple preemptible instances.\nFilter by product: Elastic Compute Service.\nSelect Instance Tag in the Customize Columns.\nClick Export Bill CSV, select All Content in the pop-up window, then click OK.\nIn the exported bill, you can filter out preemptible instances based on the tag key:acs:ecs:payType value:spot.\nThe butler service and diagnostics service on the order details page are not charged and have no impact on ECS instance orders. You can ignore them.\n\n"
    },
    "17": {
        "title": "Elastic Compute Service:ECS overdue payments",
        "url": "https://www.alibabacloud.com/help/en/ecs/overdue-payments",
        "content": "This Product\nElastic Compute Service:ECS overdue payments\nIf you have insufficient funds in your Alibaba Cloud account, including the account balance and vouchers, to complete a payment, the payment becomes overdue. This topic describes the impacts of overdue payments on Elastic Compute Service (ECS) resources and how to prevent and complete overdue payments.\nYou are notified if your ECS resources are about to be out of service due to overdue payments. To ensure service continuity, complete the overdue payments at the earliest opportunity.\n\nEach subscription ECS resource has a validity period. For information about the impacts of ECS resource expiration, see the Impacts of resource expiration section of the \"Subscription\" topic.\nOverdue payments in your account do not affect the usage of existing subscription ECS resources, but the overdue payments have the following impacts:\nAfter a payment becomes overdue in your account, you cannot perform operations that generate fees, such as purchasing resources, upgrading instance configurations, or renewing instances.\nIf a pay-as-you-go cloud disk is attached to an unexpired subscription ECS instance or the subscription ECS instance uses the pay-by-traffic metering method for Internet data transfers, the public bandwidth service of the instance and the cloud disk become unavailable after a payment becomes overdue. For more information, see the Pay-as-you-go ECS resources section of this topic.\nThe cloud disk may fail to be detached. If the cloud disk fails to be detached, you are no longer charged for the disk, but data that is stored on the disk may be lost. We recommend that you no longer use the cloud disk.\nThe system attempts to deduct the fees for pay-as-you-go ECS resources on the following days: on the payment due date (day T), on the 7th day after the payment due date (day T+7), and on the 14th day after the payment due date (day T+14).\nWithin 15 days after the payment becomes overdue: The ECS instance runs as expected.\nIf the fees for a pay-as-you-go ECS instance fail to be deducted on day T, the payment for the instance becomes overdue. Within 15 days after the payment becomes overdue, the system does not stop the ECS instance. You can continue to use the existing resources of the ECS instance, but you cannot purchase resources, upgrade instance configurations, or renew resources. The system attempts to deduct the fees on day T+7 and day T+14.\nIf you stop the ECS instance in economical mode, the computing resources (vCPUs and memory) are recycled. After the payment becomes overdue, the ECS instance may fail to restart. For information about the economical mode, see Economical mode.\nMore than 15 days after the payment becomes overdue: The ECS instance is stopped.\nIf all attempts to deduct the fees for a pay-as-you-go ECS instance fail, the instance is stopped on day T+15 and billing for the instance also stops. If the payment remains overdue for more than 15 days after the ECS instance is stopped, the system releases, detaches, or disassociates the resources of the instance.\nThe following table describes whether the resources of a pay-as-you-go ECS instance are retained or released in different periods of time after the instance is stopped due to an overdue payment.\nResource type\nWithin 15 days after the ECS instance is stopped\nMore than 15 days after the ECS instance is stopped\nComputing resources (vCPUs and memory)\nThe computing resources (vCPUs and memory) of the ECS instance are retained, but the instance stops providing services.\nAfter the ECS instance stops providing services, you cannot connect to the instance or access the websites that are deployed on the instance. Service errors may also occur.\nThe computing resources (vCPUs and memory) of the ECS instance are released.\nIf computing resources (vCPUs and memory) are released due to overdue payments, the system notifies you by email.\nBlock storage devices\nCloud disks and data that is stored on the disks are retained, but the disks become unavailable.\nLocal disks and data that is stored on the disks are retained, but the disks become unavailable.\nAfter cloud disks or local disks become unavailable, the disks cannot process read/write requests as expected. As a result, the operation of the ECS instances to which the disks are attached is affected. For example, the read/write performance of applications may significantly decline, an extended period of time may be required to complete specific operations, or ECS instances that run specific operating system versions may unexpectedly shut down or fail to restart.\nCloud disks are released and data that is stored on the disks cannot be recovered.\nData disks that are created together with pay-as-you-go ECS instances and pay-as-you-go data disks that are separately created on the Block Storage page in the ECS console are released.\nLocal disks are released and data that is stored on the disks cannot be recovered.\nPublic IP addresses\nIf the ECS instance is deployed in the classic network, the static public IP address (also called system-assigned public IP address or auto-assigned public IP address) of the instance is retained.\nIf the ECS instance is deployed in a virtual private cloud (VPC), the following rules apply:\nThe static public IP address of the ECS instance is retained.\nThe lifecycle of an elastic IP address (EIP) and the lifecycle of an ECS instance with which the EIP is associated are independent of each other. If you use an EIP, overdue payments affect the EIP. For more information, see the \"Overdue payments of EIPs\" section of the Overdue payments topic.\nIf the instance is deployed in the classic network, the static public IP address of the instance is released.\nIf the ECS instance is deployed in a VPC, the following rules apply:\nThe static public IP address of the ECS instance is released.\nThe lifecycle of an EIP and the lifecycle of an ECS instance with which the EIP is associated are independent of each other. If you use an EIP, overdue payments affect the EIP. For more information, see the \"Overdue payments of EIPs\" section of the Overdue payments topic.\nSnapshots\nAll snapshots and custom images are retained. You cannot manually or automatically create snapshots for disks attached to the ECS instance. As a result, you cannot create custom images from the ECS instance.\nIf you add funds to your account to complete the overdue payment, automatic snapshot policies are automatically re-enabled for disks attached to the ECS instance.\nBilling for existing snapshots continues, and fees are added to the overdue amount.\nAll snapshot resources are deleted, including snapshots that are not associated with custom images, snapshot-consistent groups, and snapshots that are associated with custom images. The snapshot data cannot be recovered.\nIf a snapshot is associated with a custom image, the custom image is deleted when the snapshot is deleted and cannot be recovered.\nIf you add funds to your account to complete the overdue payment, automatic snapshot policies are automatically re-enabled for disks attached to the ECS instance.\nYou are charged for snapshots until the snapshots are deleted. Delete the snapshots that you no longer require.\nAfter a custom image is deleted, you can continue to use the subscription ECS instances that are created from the image, but you cannot re-initialize the system disks of the instances.\nIf you delete a custom image that is shared with other users, the other users can no longer view and use the image to create instances. The system disks of instances that use the image can no longer be re-initialized.\nIf you delete a custom image that is published as a community image, the community image is also deleted and cannot be used to create instances. The system disks of instances that use the community image can no longer be re-initialized.\nIf your account has overdue payments, pay-as-you-go ECS instances may be stopped. To prevent overdue payments from affecting your services, we recommend that you complete the overdue payments at the earliest opportunity. You can log on to the Expenses and Costs console, click Pay Now in the upper part of the Account Overview page, and then follow the on-screen instructions to complete the overdue payments.\nAfter you complete the overdue payments in your account, the ECS instances that were stopped due to the overdue payments are automatically restarted. If an ECS instance fails to automatically restart, you can manually restart the instance. For more information, see Start an instance.\nRelease resources that are no longer required\nIf you no longer require an ECS resource, we recommend that you back up data and release the resource at the earliest opportunity.\nSpecify an alert threshold\nYou can log on to the Expenses and Costs console and specify an alert threshold on the Account Overview page. If the credit balance in your account is lower than the alert threshold, you are notified by the system.\nSpecify an automatic release time\nSpecify an automatic release time for pay-as-you-go ECS instances to prevent unnecessary costs and overdue payments. For more information, see Release an instance.\n"
    },
    "18": {
        "title": "Elastic Compute Service:Refunds",
        "url": "https://www.alibabacloud.com/help/en/ecs/refund-instructions",
        "content": "This Product\nElastic Compute Service:Refunds\nYou can request refunds only for subscription resources, such as subscription Elastic Compute Service (ECS) instances and resource plans. If you no longer use a subscription resource, you can unsubscribe from the resource and request a refund for the resource. Then, Alibaba Cloud reclaims the resource based on the rules for unsubscribing from resources and refunds you the fees for the resource. If you no longer use a pay-as-you-go resource, you cannot request a refund for the resource. To stop billing for the resource, you can release or delete the resource in the Alibaba Cloud Management Console based on the billing documentation of the billable items related to the resource.\nYou can request refunds for Alibaba Cloud resources in the following scenarios: You unsubscribe from in-use resources, cancel resource renewal orders that have not taken effect, automatically unsubscribe from resources that fail to be created or updated, downgrade resource configurations, change the billing method of resources from subscription to pay-as-you-go, and return in-kind products. For more information, see the following topics:\nRules for unsubscribing from resources\nMethods for unsubscribing from resources\nRefund flow\nFAQ about unsubscribing from cloud resources on the international site\n"
    },
    "19": {
        "title": "Elastic Compute Service:ECS Billing FAQ",
        "url": "https://www.alibabacloud.com/help/en/ecs/billing-faq",
        "content": "This Product\nElastic Compute Service:ECS Billing FAQ\nThis section provides answers to frequently asked questions regarding Elastic Compute Service (ECS) billing.\nYou may be unable to purchase ECS instances for several reasons:\nReal-name Verification Not Completed: To purchase ECS instances in the Chinese mainland, you must first complete  or real-name verification.\nvCPU cores exceed quota: The total number of vCPU cores for the selected instance type may exceed your account's quota limit.\nRegion Sales Volume Limit Reached: The sales volume for ECS instances in the selected region may have hit its cap, resulting in a temporary suspension of transactions. Please try again later, or you can visit available ECS instance regions to check instance availability.\nInvoices are generated according to your monthly statement and cannot be divided. To apply for invoices, please visit the Billing Management section of the Alibaba Cloud Management Console.\nThe refund method for real-time configuration downgrade depends on the payment currency of the order:\nIf your order's payment currency is USD, the  Price Difference Refund Method  will be used to calculate the refund amount.\nIf the order's payment currency is a local currency, such as the Malaysian Ringgit (MYR), the  Proportional Refund Method  is utilized to determine the refund amount.\nRemaining value: The remaining value of an instance is the linearly distributed value over time. If you cancel a subscription after using it for a period, the remaining value is the total refundable amount. For example, for a 30-day ECS instance costing USD 30, the remaining value after 10 days is USD 20. If you cancel then, USD 20 is refunded.\nWhen you make a payment in local currency, the USD value of the order is converted to the local currency using the exchange rate at the time of payment. Consequently, when calculating the remaining value of an instance, the exchange rate is a factor to consider. Unlike the  Price Difference Refund Method, the  Proportional Refund Method guarantees that refunds are issued at the exchange rate valid at the time of payment. This approach protects you from the effects of exchange rate fluctuations during a configuration downgrade and reduces exchange rate risks.\nReal-time configuration downgrade does not change the instance lifecycle.\nIf payment currency changes, instances with inconsistent new purchase and upgrade payment currencies do not support real-time downgrade.\nExamples of the price difference refund method:\nExample 1: A new instance A is purchased, used for a period, and then immediately downgraded.\nAssume you bought a 30-day subscription instance (Instance A) at USD 1 per day, paying USD 30. On the 11th day, you downgrade the configuration. The new configuration price is USD 0.5 per day. The refund is calculated as follows:\nCalculate the remaining value, M, of Instance A.\nCalculate remaining value M of Instance A: M = USD 30 \u00d7 (30 days - 10 days)/30 days = USD 20\nCalculate the value N for the new instance configurations.\nCalculate value N of new configurations: N = USD 0.5 per day \u00d7 20 days = USD 10\nCalculate the refund amount\nCalculate refundable amount: Refundable amount = M - N = USD 20 - USD 10 = USD 10\nIn this example, Alibaba Cloud will refund USD 10 for the instance configuration downgrade.\nExample 2: A new instance B is purchased, used for a period, upgraded, and then immediately downgraded.\nAssume you bought a 30-day subscription instance (Instance B) at USD 1 per day, paying USD 30. On the 11th day, you upgrade the configuration. The new configuration price is USD 2 per day. You pay the price difference P: P = (USD 2 per day - USD 1 per day) \u00d7 (30 days - 10 days) = USD 20. On the 21st day, you downgrade the configuration. The new configuration price is USD 0.5 per day. The refund is calculated as follows:\nCalculate the remaining value M of Instance B\nAfter the instance's configuration upgrade, the remaining value comprises the initial purchase's remaining value M1 and the upgrade's remaining value M2. Use the following formulas to calculate M1 and M2:\nRemaining value M1 from instance purchase = USD 30 \u00d7 (30 days - 20 days) / 30 days = USD 10\nRemaining value M2 from configuration upgrade = USD 20 \u00d7 (20 days - 10 days) / 20 days = USD 10\nThe current total remaining value M = M1 + M2 = USD 20\nCalculate the value N for the new instance configurations.\nThe lifecycle of the instance is unaffected by the downgrade. The new configurations can be utilized for the remaining 10 days of the subscription period. To calculate N, use the formula: N = USD 0.5 per day \u00d7 10 days = USD 5.\nCalculate the refundable amount:\nRefundable amount = M - N = USD 20 - USD 5 = USD 15.\nIn this example, Alibaba Cloud will refund USD 15 for the instance configuration downgrade.\nExamples of the proportional refund method (in MYR):\nExample 1: A new instance A is purchased, used for a period, and then immediately downgraded.\nAssume you bought a 30-day subscription instance (Instance A) at USD 1 per day. The MYR to USD exchange rate was 1:10 at purchase. You paid MYR 300. On the 11th day, you downgrade the configuration. The new configuration price is USD 0.5 per day. The refund is calculated as follows:\nCalculate the remaining value, M, of Instance A.\nCalculate remaining value M of Instance A: M = MYR 300 \u00d7 (30 days - 10 days)/30 days = MYR 200\nCalculate the refund ratio, R.\nCalculate refund ratio R: R = (USD 1 per day - USD 0.5 per day)/USD 1 per day = 1/2\nCalculate the amount eligible for refund\nCalculate refundable amount: Refundable amount = M \u00d7 R = MYR 200 \u00d7 1/2 = MYR 100\nIn this example, Alibaba Cloud will refund MYR 100 for the instance configuration downgrade.\nExample 2: A new instance B is purchased, used for a period, upgraded, and then immediately downgraded.\nAssume you bought a 30-day subscription instance (Instance B) at USD 1 per day. The MYR to USD exchange rate was 1:10 at purchase. You paid MYR 300. On the 11th day, you upgrade the configuration. The new configuration price is USD 2 per day. The MYR to USD exchange rate was 1:11 at upgrade. You pay the price difference P: P = (USD 2 per day - USD 1 per day) \u00d7 (30 days - 10 days) \u00d7 11 = MYR 220. On the 21st day, you downgrade the configuration. The new configuration price is USD 0.5 per day. The refund is calculated as follows:\nCalculate the residual value M of Instance B\nAfter the instance's configuration was upgraded, its residual value is composed of M1, the value remaining from the initial purchase, and M2, the value added by the upgrade. To determine M1 and M2, use the following calculations:\nResidual value M1 from initial purchase = USD 30 \u00d7 (30 days - 20 days) / 30 days \u00d7 10 = MYR 100\nResidual value M2 from upgrade = USD 20 \u00d7 (20 days - 10 days) / 20 days \u00d7 11 = MYR 110\nThe combined residual value M = M1 + M2 = MYR 210\nCalculate the refund ratio, R:\nR = (USD 2 per day - USD 0.5 per day) / USD 2 per day = 3/4\nCalculate the refundable amount\nRefundable amount = M \u00d7 R = (M1 \u00d7 R) + (M2 \u00d7 R) = (MYR 100 \u00d7 3/4) + (MYR 110 \u00d7 3/4) = MYR 157.5\nIn this example, Alibaba Cloud will refund MYR 157.5 for the instance configuration downgrade.\nThis could be due to a discount applied at the time of purchase, or an adjustment in the original price of the instance when downgrading.\nThis discrepancy may be due to a discount received at purchase or an adjustment in the original price of the instance at the time of downgrade. For example, if you purchased a 30-day subscription instance at USD 1 per day, and the MYR to USD exchange rate was 1:10, the refundable amount should be MYR 100 based on the original price. However, if a discount was applied or the original price was adjusted to USD 0.7 per day, the refundable amount would be:\nCalculate the remaining value, M, of Instance A.\nCalculate remaining value M of Instance A: M = MYR 300 \u00d7 (30 days - 10 days)/30 days = MYR 200\nCalculate the refund ratio, R.\nCalculate refund ratio R: R = (USD 0.7 per day - USD 0.5 per day)/USD 1 per day = 1/5\nCalculate the refund amount\nCalculate refundable amount: Refundable amount = M \u00d7 R = MYR 200 \u00d7 1/5 = MYR 40\nIn this example, the actual refundable amount is MYR 40 instead of MYR 100.\nA savings plan is a discount scheme that provides lower pay-as-you-go rates when you commit to a consistent usage of resources, billed in either  or USD/hour, for a duration of 1 or 3 years. Upon purchasing a savings plan, any part of your hourly usage that remains within the committed amount benefits from a discount, which the savings plan then applies. For more information, see What is a savings plan.\nFlexible purchase: Available for as little as one cent per hour, with no price limits. Supports installment payments, optimizing cash flow.\nCost-effective: Reduces the cost of using pay-as-you-go resources, with discounts up to 76% off.\nEasy to manage: A single plan can be applied to pay-as-you-go instances of products like ECS or ECI across different regions, instance families, and accounts.\nPurchasing a savings plan involves committing to a specified fee and duration. The hourly commitment, measured in /USD, represents the minimum usage. With a savings plan, you receive a discount on your hourly bill within this commitment range, and any excess can be covered by the plan. If you opt for the Partial Upfront or No Upfront payment option, you will be charged 50% of your hourly commitment if your hourly bill falls below the commitment for Partial Upfront, or 100% for No Upfront. For guidance on selecting the right hourly commitment value, see Purchase and use savings plans.\nThe hourly commitment is the upper limit of the pay-as-you-go bill exempted by the savings plan. For example:\nThe following prices are for reference only. Actual prices are displayed on the purchase page.\nThe pay-as-you-go rate for ecs.c5.large instances in the China (Hangzhou) region is USD 0.106 per instance per hour. For the ecs.c5 instance family, the savings plan offers a one-year, all upfront general-purpose discount of 42.2%. With an hourly commitment of USD 1, you can cover up to 22.35 instances per hour under the savings plan.\nIf your savings plan can be applied to 38.22 instances per hour and is not an integer, it means that if you have 39 instances running, 22% of the bill for one instance is offset, and the remaining 78% is paid at regular pay-as-you-go rates. If you have 38 instances running, the coverage for 0.22 instance per hour is wasted.\nAlibaba Cloud provides two types of savings plans:\nGeneral-purpose\nApplicable to pay-as-you-go instances of services like ECS and ECI. Automatically applied to eligible pay-as-you-go instances regardless of region, instance family, instance size, and operating system.\nECS compute\nApplicable to pay-as-you-go ECS instances. Applied only to a specific instance family in a single region regardless of instance size and operating system.\nGeneral-purpose savings plans offer greater flexibility, whereas ECS compute savings plans deliver more substantial discounts and cost savings. For more details, see What is a savings plan.\nSavings plans offer three payment options: All Upfront, Partial Upfront, and No Upfront. The level of discount you receive depends on the chosen duration and payment option of the savings plan. The highest discount is available with a three-year All Upfront savings plan. Discounts decrease in the following order: three-year Partial Upfront, three-year No Upfront, one-year All Upfront, one-year Partial Upfront, and finally, one-year No Upfront. For more information, see Savings plans.\nOption 1\nYou can visit the  or the international savings plan purchase page to make a purchase. Alternatively, for tailored recommendations, visit the  or the international savings plan purchase recommendation page. The system will recommend savings plans that best suit your consumption data, plan type, payment method, and other selected criteria.\nOption 2\nNavigate to the ECS console, and in the left-side navigation pane, click Deployment & Elasticity > Savings Plan.\nYou can check the  or the international savings plan price discount details page. There, you can configure the savings plan attributes to see the applicable pay-as-you-go discounts.\nYou can view the cost savings associated with a savings plan, such as cumulative, annual, and monthly savings amounts, by visiting the  or the international savings plan overview page.\nYes, you can purchase and use multiple savings plans simultaneously. The system automatically selects the optimal savings plan to apply.\nYes, you can purchase both reserved instances and savings plans at the same time. However, reserved instances take precedence over savings plans when applied to pay-as-you-go instances.\nYes, you can purchase both SCUs and savings plans at the same time. However, SCUs take precedence over savings plans when applied to pay-as-you-go instances.\nNo, you cannot upgrade the instance types of instances to which the savings plans you purchase are applied. You can purchase additional savings plans for the instance types you want to upgrade to.\nNo, savings plans do not provide reserved resources. You cannot specify resources to reserve when purchasing savings plans.\nNo, savings plans cannot be applied to preemptible instances.\nWhen your savings plans expire, the discounts provided by your savings plans are no longer available. Eligible pay-as-you-go instances are billed at their regular prices. The instances are not released, and your business operations are not affected.\nZonal reserved instances provide reserved resources. Regional reserved instances do not.\nReserved instances are compatible with both Windows and Linux operating systems. For instance, if you purchase a reserved Linux instance, you can use it to cover the costs of pay-as-you-go Linux instances with matching attributes, irrespective of the image type, including public images, custom images, shared images, or Alibaba Cloud Marketplace images.\nTo apply a reserved instance to pay-as-you-go instances created from Bring Your Own License (BYOL) images, please submit a ticket.\nThe instance families supported by reserved instances are listed on the reserved instance buy page in the ECS console.\nFor more information on purchasing reserved instances, see Purchase Reserved Instances.\nFor more information on instance families, see Instance Families.\nNo, they cannot.\nNo, you cannot.\nZonal reserved instances are recommended when you have specific requirements to reserve resources.\nRegional reserved instances are recommended if you require a higher degree of zone flexibility or instance size flexibility.\nOnly reserved instances at the regional level offer zone flexibility. The example below illustrates the application of zone flexibility:\nAssume you are operating a pay-as-you-go instance:\nOne ecs.c5.xlarge Linux instance located in Qingdao Zone B, named C5PAYG-b.\nAssume you have purchased the following reserved instance:\nOne ecs.c5.xlarge reserved instance in the China (Qingdao) region, named C5RI.\nC5RI corresponds with C5PAYG-b and is used to offset the billing charges of C5PAYG-b.\nOnly regional reserved instances provide zone flexibility. For example, if you have a regional reserved instance and release a pay-as-you-go instance in one zone, the reserved instance can be applied to another pay-as-you-go instance in a different zone within the same region.\nOnly reserved instances at the regional level offer instance size flexibility. The example below illustrates the application of this flexibility:\nAssume you possess a regional ecs.g5.4xlarge reserved instance. This reserved instance can be allocated to a single ecs.g5.4xlarge pay-as-you-go instance, two ecs.g5.2xlarge pay-as-you-go instances, or four ecs.g5.xlarge pay-as-you-go instances.\nOnly regional reserved instances provide instance size flexibility. For example, a regional reserved instance for a larger instance type can be applied to offset the hourly fees of smaller pay-as-you-go instances within the same instance family.\nNo, they do not. A zonal reserved instance can only be applied to pay-as-you-go instances of the same instance type.\nNo, they do not. A zonal reserved instance can only be applied to pay-as-you-go instances in the same zone.\nYes, you can modify the scope of a reserved instance once purchased. Supported changes include the following:\nFrom a zone to its encompassing region.\nFrom a region to one of its zones.\nFrom one zone to another within the same region, applicable to zonal reserved instances.\nNo, you cannot. For example, you cannot change the scope of a zonal reserved instance in Hangzhou Zone B to a zone in another region or to a regional reserved instance in another region.\nNo, you cannot.\nNo, they cannot. Reserved instances are applied to offset the fees for vCPUs and memory of pay-as-you-go instances. Windows reserved instances can also offset image fees.\nNo, you cannot. When multiple pay-as-you-go instances match a reserved instance's attributes, the reserved instance is applied based on an optimized matching scheme.\nReserved instances are billed independently and offer payment options such as All Upfront, Partial Upfront, and No Upfront.\nThe reserved instance term commences upon purchase, and charges apply according to the chosen payment option, irrespective of whether it is applied to pay-as-you-go instances. The All Upfront option offers the greatest cost savings. For more information, see Reserved instances.\nA reserved instance becomes active and billing commences from the hour of purchase. It expires at 00:00:00 on the day following the end of its term. For example:\nIf you purchase a reserved instance with a one-year term at 13:45:00 on February 26, 2019, it becomes active and billing commences from 13:00:00 on the same day. The reserved instance will expire at 00:00:00 on February 27, 2020. Should you have eligible pay-as-you-go instances at the time of purchase, the reserved instance will be applied to offset the costs of these instances from 13:00:00 to 14:00:00 on February 26, 2019, until the expiration of the reserved instance.\nIf you purchase a reserved instance with a one-year term at 13:45:00 on February 26, 2019, it will take effect and billing will start at 01:00:00 on March 1, 2019. This reserved instance will expire at 00:00:00 on March 1, 2020. If you have eligible pay-as-you-go instances at the time of your purchase, the reserved instance will be applied to offset the bills from these instances starting at 01:00:00 on March 1, 2019, until the reserved instance expires.\nWhen reserved instances are modified, split, or merged, new reserved instances are generated, and the original ones become invalid. The new reserved instances take effect, and the original ones become invalid on the hour of the operation. For example, if you split one ecs.g5.2xlarge zonal reserved instance into two ecs.g5.xlarge reserved instances at 13:45:00 on February 26, 2019, the original instance becomes invalid, and the new instances take effect at 13:00:00 on February 26, 2019. If the new instances are matched to pay-as-you-go instances immediately after taking effect, they offset the hourly fees starting from 13:00:00 on February 26, 2019.\nThe availability of the No Upfront option depends on your ECS usage.\nNo, you cannot.\nNo, they cannot.\nYes, they can. Windows reserved instances include Windows images at no additional cost and can offset image fees for pay-as-you-go Windows instances.\nNo, they cannot.\nYes, they are.\nYes, they can. Reserved instances check for eligible pay-as-you-go bills hourly and deduct fees based on their computing power.\nThe computing power and term of each reserved instance are fixed. You cannot increase the computing power of a reserved instance by shortening its term.\nFor example, if you have a reserved instance with the following attributes:\nInstance type: c5.large\nInstances: 1 (indicating that the reserved instance can match one pay-as-you-go instance of the specified instance type)\nTerm: 1 year\nThe following examples demonstrate how the reserved instance is applied based on the pay-as-you-go instances that exist:\nIf six c5.large pay-as-you-go instances exist for 1 hour each, the reserved instance is randomly applied to one of these instances. You cannot configure the reserved instance to be applied to all six instances by shortening the term to two months.\nIf six c5.large pay-as-you-go instances exist for 10 minutes each, the six instances consume the amount of computing power that the c5.large reserved instance can deliver every hour. The reserved instance is applied to all six instances.\nIf six c5.large pay-as-you-go instances exist for 15 minutes each, the six instances consume more computing power than a c5.large reserved instance can deliver every hour. The reserved instance is randomly applied to offset the fees for 1 hour of computing power.\nYou may be unable to change the billing method due to several reasons:\nThe current state of the instance does not support the change: For instance, an unpaid order exists for the instance.\nThe instance is expired: An expired instance cannot be changed.\nThe instance information has changed: If the instance configurations have changed, such as a temporary bandwidth upgrade, the change may not be allowed.\nTo resolve the issue, perform the following:\nCheck the instance state: Ensure no unpaid orders exist and the instance is not expired.\nReview the instance configurations: If you have made changes to the instance recently, you may need to undo these changes to restore the original configuration state before the change.\nIf the issue remains after you have made adjustments to the instance as suggested, or if you come across an error message that is not clear,  or submit a ticket  to reach out to Alibaba Cloud technical support.\nAfter purchasing subscription instances, you may incur additional charges for resources billed on a pay-as-you-go basis, such as snapshots and pay-by-traffic public bandwidth. These charges are separate from the subscription fees and are not included at the time of purchase. If your account balance is insufficient to cover the outstanding pay-as-you-go fees, the payment becomes overdue. You can review the consumption details to determine if there are any pay-as-you-go bills. For more information, see Bill query.\nPay-as-you-go instances are billed in 1-second increments with payments made every hour. The billable time is automatically calculated. In the given example, the billing cycle is from 01:00:00 to 02:00:00, and the billable time of 1,800 seconds is calculated as: 30 minutes \u00d7 60 = 1,800 seconds.\nStopped Due To Overdue Payments: This status means the instance has been automatically stopped because of overdue payments. While an instance in this state incurs no charges, it will not remain stopped due to overdue payments indefinitely. For more information, see Pay-as-you-go.\nManually Stopped: This status means that you have stopped the instance through the ECS console or by using the StopInstance operation while it was active. The instance then transitions to the Stopped state. Billing for the instance is contingent on its network type and the activation status of economical mode.\nVPC:\nEconomical Mode Enabled: Billing commences upon instance creation. While the instance is in the Stopped state, charges for certain resources are paused. Billing is reinstated once the instance is restarted. In economical mode, when a pay-as-you-go instance is stopped, charges for computing resources (vCPUs and memory) and the static public IP address are halted, whereas charges for additional resources, such as disks and EIP, persist. For more information, see Economical Mode.\nEconomical mode not enabled: The instance is billed even if stopped.\nClassic network: The instance is billed even if stopped, regardless of economical mode.\nBilling for pay-as-you-go instances ceases after instances are automatically stopped due to overdue payments. Billing for manually stopped instances depends on configurations and network type.\nFailure to place the order may be due to the following reasons:\nThe current state of the instance does not support the change: For instance, the instance has overdue payments or an automatic release time set.\nThe instance information has changed: The instance configurations have changed or an unpaid order to change the billing method exists.\nThe instance does not meet the change requirements: For example, the instance is of a retired type or is a preemptible instance, or the automatic release time is not canceled.\nTo resolve the issue, perform the following:\nComplete overdue payments and cancel the automatic release of the instance.\nCheck for configuration changes or unpaid orders. If configurations are being changed, wait for completion or undo the change. If an order exists, pay for or cancel it.\nEnsure the instance is not of a retired type and is not a preemptible instance.\nIf the issue persists after you adjust the instance based on the preceding suggestions, submit a ticket to contact Alibaba Cloud technical support.\nNo, it will not. Switching the billing method from pay-as-you-go to subscription affects only the billing for instances and disks. For details on changing the billing method for bandwidth, see Overview of Upgrade and Downgrade Methods.\nWhen you switch your instance's billing method from pay-as-you-go to subscription, an order is generated. To activate the change, you must finalize the payment. Should you upgrade the instance's configurations before settling the payment, the transaction will fail. This is because the instance components have changed, rendering the original order incompatible and thus invalid.\nIf you want to alter the billing method, you must first cancel any unpaid orders on the Order Management page. Then, you can proceed to switch from a pay-as-you-go to a subscription billing method, reflecting the upgraded configuration of your instance.\nThe instance must meet the following requirements to change from pay-as-you-go to subscription:\nThe instance type of the instance is not retired. For more information, see Retired instance types.\nThe instance is not a preemptible instance.\nYou do not have unpaid orders for the instance.\nIf you have unpaid orders for the instance, you must pay for the orders or cancel the orders before you can change the billing method of the instance.\nThe automatic release time is not set for the instance.\nIf the automatic release time is set for the instance, you must cancel the automatic release of the instance before you change its billing method. For more information, see Release an instance.\nThe instance is in the Running or Stopped state.\nIf you placed an order to change the billing method of an instance in the Running or Stopped state and then the instance entered a different state before the payment is completed, the payment fails and the billing method does not change. You can go to the Billing Management console and pay for the order when the instance is in the Running or Stopped state again.\nThe following ECS instances support economical mode:\nNetwork type is VPC.\nBilling method is pay-as-you-go, including preemptible instances.\nInstance family does not include local storage.\nInstance family does not include persistent memory.\nFor more information, see Economical Mode.\nAfter enabling economical mode, you can specify whether to trigger it when stopping a pay-as-you-go instance. If not triggered, the instance's computing and network resources are not released.\nIf you need to temporarily stop and then restart an ECS instance, it's advisable to choose StoppedMode as KeepCharging when executing the StopInstance operation, or select  Normal Stop Mode  in the console when stopping the instance.\nIf you halt an instance using its operating system, economical mode will not activate. Once enabled, economical mode only applies to pay-as-you-go or preemptible instances that are stopped because of the following reasons:\nThe ECS console. For more information, see Stopping Instances.\nAPI requests made through the Alibaba Cloud CLI or SDKs. For more information, see StopInstance.\nOverdue payments.\nNo, instances with local storage do not support economical mode.\nWhen an instance enters economical mode, its computing resources (CPUs and memory) along with its public IP address are reclaimed.\nIf you need to temporarily stop and then restart an ECS instance, it is advisable to set StoppedMode to KeepCharging when executing the StopInstance operation, or choose  Normal Stop Mode from the console when stopping the ECS instance.\nWhen economical mode is triggered, the instance's computing resources are recycled. If insufficient resources are available, an OperationDenied.NoStock error occurs when attempting to restart the instance. Try again later.\nWhen an instance is stopped in economical mode, its static public IP address is recycled. Upon restart, a new static public IP address is assigned, causing the change.\nTo maintain the original static public IP address, you can transform it into an elastic IP address (EIP) before stopping the instance. The EIP remains associated with the instance even when it's in economical mode, ensuring the public IP address does not change. For more information, see Convert a static public IP address to an EIP and ConvertNatPublicIpToEip.\nAfter converting a static public IP address to an EIP, you will incur charges for outbound bandwidth and EIP configuration and association, both of which may be free under certain conditions, when accessing the Internet using the EIP. For more information on pricing, see Overview of EIP billing.\nYou can manually release pay-as-you-go instances and set an automatic release time, but you cannot manually release subscription instances.\nIf the issue persists, you can  or submit a ticket.\nYou can copy the instance ID or name of the instance you want to query and consult View and export detailed bills for the billing details.\nWhether you can switch from a subscription to pay-as-you-go for your ECS depends on how you use the service. The ECS instance you want to change must be either  Running or  Stopped.\nAfter an ESSD disk is created, capacity fees are charged regardless of whether the disk is attached. ESSD disks support subscription and pay-as-you-go billing methods.\nSubscription: Disk capacity (GiB) \u00d7 Disk unit price \u00d7 Subscription duration.\nPay-as-you-go: Disk capacity (GiB) \u00d7 Disk unit price \u00d7 Billing duration.\nFor detailed billing information on ESSD disks (PL0-PL3), refer to Block storage billing. Prices for ESSD disks (PL0-PL3) differ by region. For pricing details, visit the  or the ECS pricing page.\nFor more information on instance families compatible with SSD disks, see Instance families. Prices differ by region. For details on pricing, visit the  for China or the Pricing details page for international regions.\nSSD disks represent a previous-generation disk product and are being phased out in certain regions and zones. When choosing disks, consider using ESSD AutoPL disks as a replacement for SSD disks. For more information on ESSD AutoPL disks, see ESSD AutoPL disks.\nAfter a data disk is created, capacity fees are charged regardless of whether the disk is attached.\nPay-as-you-go: Disk capacity (GiB) \u00d7 Disk unit price \u00d7 Billing duration.\nFor more information about the billing rules, see Block storage billing. Disk prices vary by region. For details on pricing, visit the  or the ECS pricing page.\nA Storage Capacity Unit (SCU) is a subscription-based resource plan designed to reduce the costs of storage resources on a pay-as-you-go basis, such as disks. SCUs offer a more cost-effective and flexible solution when used with pay-as-you-go disks compared to disks bundled with subscription-based Elastic Compute Service (ECS) instances. For more information, see the Overview of Storage Capacity Units.\nSCUs can offset the pay-as-you-go bills of eligible storage resources. Note the following:\nSCUs can be used to offset the bills of Enterprise SSDs (ESSDs), standard SSDs, ultra disks, and basic disks. SCUs cannot be used to offset the bills of local disks.\nSCUs can be used to offset the bills of Capacity NAS file systems and Performance NAS file systems in File Storage NAS. SCUs cannot be used to offset the bills of Extreme NAS file systems or Infrequent Access (IA) storage media.\nSCUs can be used to offset the bills of snapshots.\nSCUs can be used to offset bills of OSS Standard, Infrequent Access, and Archive storage classes.\nNo, they cannot. SCUs need to be paired with pay-as-you-go disks or snapshots to offset pay-as-you-go charges.\nSCUs apply discounts to the pay-as-you-go bills for disks or snapshots by using a specific discount coefficient. For more information, see Offset rules.\nSCUs are billed based on their capacity. SCU capacity prices vary with regions. For more information about the prices of SCUs in different regions, see Storage capacity unit pricing page.\nTo review the Internet traffic charges for an ECS instance, follow these steps:\nLog on to the ECS console.\nAt the top navigation bar, click Billing.\nIn the left-side navigation pane, select Bill Management > Bill Details.\nChoose the Usage Details tab.\nSet the Product to ECS and the Metering Specification to Internet Traffic. Then, select the desired usage time and query granularity.\nClick Export CSV.\nOn the Export Records page, wait for the file status to change to Exported Successfully. Then, click Download in the Actions column.\nOpen the downloaded CSV file to review the ECS instance's Internet traffic bills.\nTraffic within the same VPC, either between ECS instances or between ECS instances and other Alibaba Cloud services, incurs no charges. However, traffic to and from the Internet is subject to the following billing rules:\nIncoming Internet traffic is not charged. This includes traffic from the Internet to ECS instances, such as when downloading resources to your ECS instances or when users upload resources to your ECS instances using an FTP client.\nOutgoing Internet traffic is chargeable. This encompasses traffic from ECS instances to the Internet, for instance, when providing external access from your ECS instances or when users download resources from your ECS instances using an FTP client.\nFor more information on bandwidth billing, see the Billing of public bandwidth.\nWhen you opt for pay-by-bandwidth as your network usage billing method, charges are based on the bandwidth you specify. The actual outbound bandwidth will not exceed this predetermined limit.\nChoosing pay-by-traffic as your billing method means you are billed for the actual amount of data transferred. This method operates on a pay-as-you-go basis. To avoid unexpected charges due to traffic spikes, you can set a bandwidth cap for outbound Internet traffic.\nFor more information, see the referenced document.\nWhen you switch the billing method of a static public IP address associated with an instance from pay-by-bandwidth to pay-by-traffic, it adopts the pay-as-you-go billing method. If you then change the network type from public IP address to EIP and alter the EIP's billing method from pay-as-you-go to subscription, the EIP fees may not align with the previously adjusted fees for the static public IP address. This discrepancy can occur if you benefited from a discount on the ECS instance purchase, which is not available when switching the EIP from pay-as-you-go to subscription, resulting in a price difference.\nNo, the EIP will continue to incur charges after being disassociated from the ECS instance. To stop incurring charges, you must manually release the EIP. Once released, the EIP will no longer be billed. For more information, see Release pay-as-you-go EIP instances.\nYes, adjustments can be made. For more information, see an overview of bandwidth upgrade and downgrade methods.\nInbound Internet traffic to your ECS instance resulting from attacks is not billable; however, outbound Internet traffic is subject to charges.\nTo enhance the security of your ECS instances, we recommend utilizing Security Center.\nYes, you can. For more information, see Custom Purchase Instances.\nFor more information on the pay-by-traffic billing method, please see the Pricing section on the Elastic Compute Service product page.\nPay-by-traffic is a pay-as-you-go billing method where charges are based on the actual data transferred. Billing occurs hourly, on the hour. For uninterrupted service, ensure your account has adequate funds. To avoid unexpected charges due to traffic spikes, you can set a bandwidth cap.\nYes, you can. Utilize the bandwidth downgrade feature to alter the billing method from pay-by-bandwidth to pay-by-traffic. Note that there is a limit to how often you can make this change. For more information, see Modify the bandwidth of a subscription instance with a fixed public bandwidth.\nYou can also modify the billing method by renewing the subscription and downgrading the bandwidth. The updated billing method will be effective in the subsequent billing cycle. For more information, see Renew and downgrade.\nYou can adjust the bandwidth limit at any time using the bandwidth downgrade feature. The new bandwidth limit becomes effective immediately. Please note that a maximum of three refunds are allowed per instance. Be cautious when downgrading an instance's configurations.\nIf you have already downgraded the configurations of a subscription instance upon renewal, you will not be able to change the instance's configurations, either by upgrading or downgrading, until the start of the next billing cycle.\nWhile overdue payments will not impact the operation of subscription instances, they will result in the suspension of the pay-by-traffic public bandwidth service. Once suspended, the instances will be disconnected from the Internet. Access to the public bandwidth service can be restored only once the overdue payment is cleared. To avoid service interruptions, please ensure your account maintains a sufficient balance.\nYes, you will receive an SMS notification. Please ensure you top up your account promptly to prevent any disruption to your services.\nNo, you must settle any overdue payments before you can upgrade the instance type.\nIf the public bandwidth service is suspended because of overdue payment, it will automatically resume once the payment is settled, without the need for manual intervention.\nPay-by-traffic is a pay-as-you-go billing method where charges are based on the actual data transfer volume. Billing occurs hourly. For more information, see  or ECS pricing.\n"
    },
    "20": {
        "title": "Elastic Compute Service:Getting started with ECS",
        "url": "https://www.alibabacloud.com/help/en/ecs/getting-started/quick-start",
        "content": "This Product\nElastic Compute Service:Getting started with ECS\nWelcome to Elastic Compute Service (ECS). Follow this guide to begin exploring and using this service.\nECS offers resources and network architecture comparable to physical machines in a local data center.\nRegion: The physical location of the ECS deployment. Generally, the closer the location of your users is to the ECS instance, the lower the network latency and the faster the access speed. For more information, see Regions and zones.\nVirtual private cloud (VPC): A private network environment on the cloud for ECS. It ensures isolation between different VPCs and direct communication within the same VPC. For more information, see VPCs and vSwitches.\nvSwitch: An essential network device within a VPC. For more information, see VPCs and vSwitches.\nInstance type: Defines the ECS specifications, including CPU model, core count, and memory size, such as 2 vCPU and 4 GiB memory. To explore available instance families, see Overview of instance families.\nImage: The operating system and its version on an ECS instance. Examples include Alibaba Cloud Linux 3.2104 LTS 64-bit and Windows Server 2022 Datacenter 64-bit. For more information, see Image overview.\nStorage: Includes system and data disks for storing system images and business data. For more information, see Overview of Block Storage.\nPublic IP address: Allows ECS to communicate with the Internet.\nSecurity group: A virtual firewall that manages ECS instance traffic. For more information, see Security group overview.\nKey pair: Security credentials used for ECS instance authentication. For more information, see SSH key pair overview.\nSelect the billing method that best fits your needs. The main options are pay-as-you-go and subscription. You can also choose preemptible instances based on your business needs. For more information, see Billing overview.\nBilling method\nDescription\nPay-as-you-go\nThis billing method charges you for the actual ECS resources used, payable after use. To stop billing, you must manually release the ECS resources.\nPay-as-you-go is well-suited for services and applications with fluctuating traffic, such as interim\u00a0scaling\u00a0or\u00a0testing\u00a0needs.\nSubscription\nSubscription requires you to pay for resources before you use them. If an ECS instance is not renewed post-expiration, the instance and its data will be deleted after 15 days.\nSubscription is suitable for services that operate continuously, such as web services, which are active 24/7. Payment for subscription resources is required in advance of their use.\nPreemptible instance\nPreemptible instances are unused ECS capacity in Alibaba Cloud. Compared with pay-as-you-go instances, discounts are offered for preemptible instances. However, these instances may be reclaimed by Alibaba Cloud on short notice, meaning you will lose your access to them.\nPreemptible instances are suitable for stateless scenarios such as scalable web services, image rendering, big data analytics, and large-scale parallel computing.\nChoose the method that best suits your needs to create and start using ECS.\nMethod\nIntended user\nCreate an instance on the Custom Launch tab in the ECS console and manage the instance\nBest for users who prefer a web interface and want to select specific configurations when purchasing ECS instances.\nCreate and manage an ECS instance by using an SDK\nRecommended for users who want to create and manage ECS instances through programming.\nCreate and use an ECS instance by using Alibaba Cloud CLI\nIdeal for users who prefer command line tools for creating and managing ECS instances.\nCreate and use an ECS instance by using Terraform\nRecommended for users who want to create and manage ECS instances through Terraform.\nTerraform is a tool of Infrastructure as Code (IaC). Developers and O&M teams can use it to automatically create and manage ECS resources.\nEnhance your understanding of ECS with the following resources:\nTo select the right instance type, consider performance, cost, and workload requirements. For more information, see Instance type selection.\nLearn about the various methods and tools to connect to ECS instances. For details, see Connect to an instance.\nUnderstand the lifecycle of instances, including how to start, restart, and release them. For more information, see Instance lifecycle.\nWe recommend that you immediately back up data after creating ECS instances by taking snapshots of the disks to prevent data loss. For more information, see Snapshot overview."
    },
    "21": {
        "title": "Elastic Compute Service:Create a Linux instance on the Custom Launch tab in the ECS console and deploy Apache on the instance",
        "url": "https://www.alibabacloud.com/help/en/ecs/getting-started/use-the-ecs-instance-in-the-console",
        "content": "This Product\nElastic Compute Service:Create a Linux instance on the Custom Launch tab in the ECS console and deploy Apache on the instance\nThis topic describes the main steps to create a Linux Elastic Compute Service (ECS) instance on the Custom Launch tab of the instance buy page in the ECS console and set up a web service on the instance. You can use this topic to get started with ECS.\nAn Alibaba Cloud account is created and real-name verification is completed for the account. For information about how to create an Alibaba Cloud account and complete real-name verification, see Create an Alibaba Cloud account and FAQ about real-name verification of Alibaba Cloud accounts.\nThe following diagram shows the basic resources that are required to create an ECS instance.\nRegion: Multiple Alibaba Cloud regions are available where you can create and deploy ECS instances. In most cases, we recommend that you choose a region in close proximity to your users to achieve lower network latency and higher access speed. For more information, see Regions and Zones.\nVirtual private cloud (VPC): A VPC is a virtual network dedicated to your Alibaba Cloud account, in which you can deploy ECS instances. VPCs are mutually isolated and cannot directly access each other. All ECS instances that are deployed in the same VPC can communicate with each other. For more information, see VPCs and vSwitches.\nvSwitch: A vSwitch is a basic network device in a VPC. For more information, see VPCs and vSwitches.\nInstance type: Different instance types offer different compute, memory, and storage capabilities and vary in terms of specifications, such as the CPU models, number of vCPUs, and memory size. For example, some instance types have 2 vCPUs and 4 GiB of memory. For information about the ECS instance families available for purchase, see Overview of instance families.\nImage: An image is a basic template for creating an ECS instance, containing an operating system. For more information, see Overview of images.\nStorage: System disks and data disks are attached to ECS instances to store images and business data. For more information, see Overview of Block Storage.\nPublic IP address: In this topic, you need to access the ECS instance by using a public IP address. Therefore, associate a public IP address with the instance.\nSecurity group: A security group serves as a virtual firewall that can control inbound and outbound traffic for ECS instances. For more information, see Overview of security groups.\nKey pair: You can bind an SSH key pair to an ECS instance and use the key pair to authenticate when you log on to the instance for O&M purposes. For more information, see Overview of SSH key pairs.\nThis section describes how to create an ECS instance that runs a Linux operating system on the Custom Launch tab of the instance buy page in the ECS console. For information about other methods of creating ECS instances, see Create instances.\nEntry point for instance creation: Go to the Custom Launch tab of the instance buy page in the ECS console. Perform the following steps to create or select the basic resources required to create an ECS instance. Configure the other parameters based on your business requirements. For more information, see Create an instance on the Custom Launch tab.\nSelect a billing method based on your business requirements. In this example, the pay-as-you-go billing method is selected, which offers greater flexibility in terms of instance usage. For more information, see Billing overview.\nSelect a region based on the network latency requirements of your business. To achieve low network latency and high access speed, we recommend that you select a region in close proximity to your users. In this example, the China (Hangzhou) region is selected.\n\nWhen you create a VPC, select the region in which you want to create an ECS instance and specify a CIDR block to associate with the VPC based on your business requirements. When you create a VPC, you must create a vSwitch for the VPC. In this example, a VPC and a vSwitch are created in the China (Hangzhou) region. After you create a VPC, go back to the Custom Launch tab of the instance buy page in the ECS console, refresh the VPC and vSwitch drop-down lists, and then select the VPC and vSwitch that you created.\nWhen you create a VPC, you can create a vSwitch at the same time.\n\n\n\nSelect an instance type and an image. The operating system version included in the image is installed on the instance during instance creation. In this example, the cost-effective ecs.e-c1m1.large instance type and the Alibaba Cloud Linux 3.2104 LTS 64-bit public image are selected.\nYou can use ECS Purchase Assistant or the Add to Comparison feature in the lower part of the Instance > All Instance Types tab in the Instances & Images section to select an instance type that best fits your business requirements.\n\nConfigure a system disk and data disks for the ECS instance based on your business requirements. This topic describes how to set up a simple web service on the ECS instance, which requires only a system disk to store the operating system of the instance without the need for data disks.\nSystem Disk: System disks are the boot disks of ECS instances and are used to store system-related data, such as operating systems and program files.\nData Disk: Data disks are used to store data that is not related to the system, such as user data, logs, and applications.\nFor more information about storage, see Overview of Block Storage.\n\nTo provide Internet connectivity to the ECS instance, select Assign Public IPv4 Address to assign a public IP address to the instance. Alternatively, associate an elastic IP address (EIP) with the ECS instance after the instance is created. For more information, see Associate an EIP with an ECS instance.\nIf you do not assign a public IP address to or associate an EIP with the ECS instance, you cannot access the instance over SSH or Remote Desktop Protocol (RDP) or test the web service that is deployed on the instance over the Internet.\nAfter you select Assign Public IPv4 Address, set Bandwidth Billing Method to specify a billing method for network usage. In this example, the Bandwidth Billing Method parameter is set to Pay-by-traffic (CDT). In the pay-by-traffic billing method, you are charged based on the amount of data transferred over the Internet. For more information, see Public bandwidth.\n\nCreate a security group for the ECS instance. A security group serves as a virtual firewall that can control inbound and outbound traffic for ECS instances. When you create a security group, open the following ports to allow access to the ECS instance:\nOpen IPv4 Ports/Protocols: select SSH (TCP:22), RDP (TCP:3389), HTTP (TCP:80), and HTTPS (TCP:443).\nIn the Open IPv4 Ports/Protocols section, select the ports that must be open for the applications that will run on the ECS instance.\nBy default, a rule that references 0.0.0.0/0 as a source address is created in the new security group. 0.0.0.0/0 represents all IP addresses. The rule allows access to the ECS instance from all IP addresses on the specified ports. After you create the instance, we recommend that you modify the rule to allow access to the instance from only specific IP addresses. For more information, see Modify a security group rule.\n\nYou can bind key pairs to ECS instances and use the key pairs as security credentials to authenticate your identity when you log on to the instances. After you create a key pair, download the private key of the key pair in order to subsequently connect to an ECS instance. After you create a key pair, go back to the Custom Launch tab of the instance buy page, refresh the Key Pair drop-down list, and select the key pair that you created.\nroot is the highest-privileged account in the operating system. If you select root as the logon username, this can create security risks. We recommend that you select ecs-user as the logon username.\nWhen the key pair is created, the private key of the key pair is automatically downloaded. Pay attention to the download records of your browser and save the private key file that is in the .pem format.\n\nAfter you create or select the required basic resources, read and select ECS Terms of Service, Product Terms of Service, and CDT Terms of Service (which is available if you set Bandwidth Billing Method to Pay-by-traffic (CDT). Then, click Create Order. In the Success message, click Console to view the created ECS instance on the Instance page. Make note of the following data for later use:\nInstance ID: You can search for the ECS instance by instance ID.\nRegion: You can search for the ECS instance in the region.\nPublic IP address: You can use the public IP address of the ECS instance to check whether a web service is deployed on the instance.\n\nAfter you create an ECS instance, you can use a connection tool to log on to the instance. Before you can use the instance, you must log on to the instance.\nOn the Instance page in the ECS console, find the ECS instance that you created based on the region and instance ID. In the Actions column, click Connect.\nIn the Remote connection dialog box, click Sign in now in the Workbench section.\nThis topic demonstrates only how to connect to an instance by using the Workbench tool. For more information about different ways and tools to connect to instances, see Methods for connecting to an ECS instance.\nIn the Instance Login dialog box, set Authentication to SSH Key Authentication, set Username to ecs-user, enter or upload the private key file that you downloaded when you created the key pair, and then click OK.\nThe private key file was automatically downloaded to your on-premises computer when you created the key pair. Check the download records of your browser to find the private key file in the .pem format.\n\nThe page shown in the following figure indicates that you are logged on to the ECS instance.\nAfter you are logged on to the ECS instance, you can use the ECS instance based on your business requirements. This section describes how to deploy Apache on the ECS instance and use a browser to access Apache on the instance.\nInstall Apache.\nRun the following command on the ECS instance to install Apache:\nIf Apache is installed, Complete! appears in the command output, as shown in the following figure.\nStart Apache. Run the following command on the ECS instance to start Apache. The command does not return an output.\nCheck whether Apache is started.\nRun the following command on the ECS instance:\nIf Apache is running, active (running) appears in the command output, as shown in the following figure.\nVerify the result. In the address bar of a browser on your on-premises computer, enter http://<Public IP address of the ECS instance> and press the Enter key to access Apache on the ECS instance. The page shown in the following figure indicates that Apache is deployed on the ECS instance.\nReplace <Public IP address of the ECS instance> with the public IP address that you recorded in the 8. Create and view an ECS instance section. If you cannot find the public IP address of the ECS instance in your records, go to the Instance page in the ECS console, find the instance based on its region and instance ID, and then view the public IP address of the instance. If you did not assign a public IPv4 address to the instance during instance creation, you can associate an EIP with the instance. For more information, see EIPs.\n\nThis topic describes only how to deploy a web service on an ECS instance and does not go into the procedure of building a website. For information about how to build a website on an ECS instance, see Build a website.\nIf you no longer require the ECS instance that you created, you can release the instance. After the ECS instance is released, billing for the instance stops, and data of the instance is lost and cannot be restored. Perform the following operations:\nGo to the Instance page in the ECS console, find the ECS instance based on its region and instance ID, and then click the  icon in the Actions column.\nChoose Instance Status > Release.\nIn the Release dialog box, set Release Mode to Release Now and click Next.\nConfirm the associated resources that you want to release, read the notes about the data risks, select \"I am aware of the instances and their associated resources to be released and understand the data risks\", and then click OK.\nWhen the ECS instance is released, the system disk of the instance is released. If a public IP address was assigned to the instance, the IP address is also released.\nWhen the ECS instance is released, the associated security group, vSwitch, and VPC are not released. You are not charged for the security group, vSwitch, or VPC. You can retain or release them based on your business requirements.\nIf an EIP is associated with the ECS instance, the EIP is retained when the instance is released. You are charged for the EIP. You can retain or release the EIP based on your business requirements. For information about the billing for EIPs, see Billing overview.\nYou can view the billing details of the ECS instance for a certain period of time. Billing details are updated with a one-day delay. Perform the following operations:\nGo to the Expenses and Costs console, choose Bills > Bill Details in the left-side navigation pane, and then click the Billing Details tab.\nSpecify the ID of the ECS instance as a filter condition and click Search to view the billing details of the ECS instance.\nYou can refer to the following topics to learn more about ECS.\nFor information about common operations on ECS resources, see Quick reference.\nFor information about how to programmatically integrate ECS, see Integration overview."
    },
    "22": {
        "title": "Elastic Compute Service:Create and manage an ECS instance by using an SDK",
        "url": "https://www.alibabacloud.com/help/en/ecs/getting-started/use-an-sdk-to-create-ecs-instances",
        "content": "This Product\nElastic Compute Service:Create and manage an ECS instance by using an SDK\nAlibaba Cloud provides various APIs and SDKs that allow you to programmatically create and manage Elastic Compute Service (ECS) instances, improving business efficiency and implementing system automation. This topic describes how to use ECS SDK 2.0 for Java to create an ECS instance, run a command on the ECS instance by calling a Cloud Assistant API operation, and release resources.\nCreate an AccessKey pair for a Resource Access Management (RAM) user. An Alibaba Cloud account has all permissions on resources. If the AccessKey pair of your Alibaba Cloud account is leaked, your resources are exposed to great risks. We recommend that you use the AccessKey pair of a RAM user. For information about how to create an AccessKey pair for a RAM user, see Create an AccessKey pair.\nGrant the required permissions on ECS and Virtual Private Cloud (VPC) resources to the RAM user that you want to use. The sample code provided in this topic creates resources, such as an ECS instance, a VPC, and a vSwitch. To grant the permissions required to run the sample code, we recommend that you attach the policies described in the following table to the RAM user.\nAlibaba Cloud service\nPolicy\nVPC\nAliyunVPCFullAccess\nECS\nAliyunECSFullAccess\nConfigure the AccessKey pair of the RAM user that you want to use in environment variables. The sample code provided in this topic reads the AccessKey pair from the environment variables and uses the AccessKey pair as credentials to access Alibaba Cloud services. For information about how to configure an AccessKey pair in environment variables, see Configure environment variables in Linux, macOS, and Windows.\nObtain ECS SDK 2.0 for Java and VPC SDK 2.0 for Java. In this topic, ECS SDK 2.0 for Java and VPC SDK 2.0 for Java are installed by adding Maven dependencies. For information about other installation methods, see Install ECS SDK for Java and Install VPC SDK for Java.\nThe following sample code provides an example on how to add Maven dependencies:\nMultiple parameters, such as vSwitch ID, security group ID, and image ID, are required to create an ECS instance. You can pass in the IDs of existing resources or call API operations to create new resources.\nCreate a VPC\nA VPC is a dedicated private network in the cloud. You can configure and manage VPCs as logically isolated networks in the public cloud.\nAPI operation\nParameter\nDescription and example\nCreateVpc\nRegionId\nThe ID of the region in which to create the VPC. Example: cn-hangzhou.\nCidrBlock\nThe CIDR block of the VPC. Example: 192.168.0.0/16.\nQuery the details of the VPC.\nAfter you call the CreateVpc operation to create a VPC, you can call an API operation to query the status of the VPC. If the VPC is in the Available state, call API operations to perform subsequent steps.\nAPI operation\nParameter\nDescription and example\nDescribeVpcs\nRegionId\nThe region ID of the VPC. Example: cn-hangzhou.\nVpcId\nThe ID of the VPC. Example: vpc-bp1aag0sb9s4i92i3****.\nCreate a vSwitch\nA vSwitch is a network switching device in a VPC, which supports the functionality of a physical switch. It serves to enable communication between virtual machines (VMs) and between VMs and physical networks.\nAPI operation\nParameter\nDescription and example\n\nRegionId\nThe ID of the region in which to create the vSwitch. Example: cn-hangzhou.\nCreateVSwitch\nZoneId\nThe ID of the zone in which to create the vSwitch. Example: cn-hangzhou-i.\nVpcId\nThe ID of the VPC in which you want to create the vSwitch. Example: vpc-bp1aag0sb9s4i92i3****.\nCidrBlock\nThe CIDR block of the vSwitch. Example: 192.168.0.0/24.\nCreate a security group.\nA security group acts as a virtual firewall that controls inbound and outbound traffic for ECS instances.\nAPI operation\nParameter\nDescription and example\nCreateSecurityGroup\nRegionId\nThe ID of the region in which to create the security group. Example: cn-hangzhou.\nVpcId\nThe ID of the VPC in which to create the security group. Example: vpc-bp1aag0sb9s4i92i3****.\nCreate an inbound rule in the security group.\nAPI operation\nParameter\nDescription and example\nAuthorizeSecurityGroup\nRegionId\nThe region ID of the security group. Example: cn-hangzhou.\nSecurityGroupId\nThe ID of the security group. Example: sg-bp1esyhwfbqeyudt****.\nIpProtocol\nThe protocol. Example: tcp.\nSourceCidrIp\nThe source IPv4 CIDR block. Example: 0.0.0.0/0.\nPortRange\nThe port range. Examples:\nLinux instances: 22/22.\nWindows instances: 3389/3389.\nCreate an SSH key pair.\nAlibaba Cloud provides the secure and convenient SSH key pair-based authentication method for logon to ECS instances. The key pairs are used for authentication and encrypted communication over the SSH protocol. SSH key pairs allow you to remotely log on to ECS instances in a password-free manner.\nAPI operation\nParameter\nDescription and example\nCreateKeyPair\nRegionId\nThe region ID of the instance. Example: cn-hangzhou.\nKeyPairName\nThe name of the SSH key pair. Example: sdk-key-pair.\nCreate an ECS instance.\nECS provides high-performance, secure, and low-cost compute capacity and is suitable for various scenarios such as website hosting, application development, and data processing. With ECS, you can quickly deploy and run applications and flexibly adjust resources in response to business changes.\nAPI operation\nParameter\nDescription and example\nRunInstances\nRegionId\nThe ID of the region in which to create the ECS instance. Example: cn-hangzhou.\nImageId\nThe ID of the image. We recommend that you select the Alibaba Cloud Linux image whose ID is aliyun_3_x64_20G_scc_alibase_20220225.vhd.\nInstanceType\nThe instance type. Example: ecs.e-c1m2.xlarge.\nSecurityGroupId\nThe ID of the security group. Example: sg-bp1esyhwfbqeyudt****.\nVSwitchId\nThe ID of the vSwitch. Example: vsw-bp1nzprm8h7mmnl8t****.\nInstanceName\nThe ECS instance name. Example: sdk-test.\nInstanceChargeType\nThe billing method of the ECS instance. To create a pay-as-you-go instance, set this parameter to PostPaid.\nMake sure that your account balance is sufficient.\nKeyPairName\nThe name of the SSH key pair. Example: sdk-key-pair.\nSystemDisk.Category\nThe disk category of the system disk. Example: cloud_essd.\nQuery the status of the ECS instance.\nAfter you call the RunInstances operation to create an ECS instance, the ECS instance requires approximately 10 seconds to initialize. You can log on to the ECS instance by using a connection method to perform operations and deploy applications only when the instance is in the Running state. You can call the API operation that is described in the following table to query the status of the ECS instance.\nAPI operation\nParameter\nDescription and example\nDescribeInstanceStatus\nRegionId\nThe region ID of the ECS instance. Example: cn-hangzhou.\nInstanceId\nThe IDs of ECS instances. Example: [\"i-bp17f3kzgtzzj91r****\"].\nComplete sample code:\nCloud Assistant is a native automated O&M tool developed for ECS. Cloud Assistant allows you to batch run commands, such as shell, PowerShell, and batch commands, to execute various tasks on ECS instances in a password-free manner without the need to log on to the instances or use jump servers. You can use Cloud Assistant to run automated O&M scripts, poll processes, install or uninstall software, start or stop services, and install patches or security updates. For more information, see Overview.\nFor example, you can call the RunCommand operation to install Java and Tomcat on ECS instances by running a Cloud Assistant command.\nAPI operation\nParameter\nDescription and example\nRunCommand\nRegionId\nThe ID of the region. Example: cn-hangzhou.\nType\nThe language type of the command. Example: RunShellScript.\nCommandContent\nThe command content. Example:\nTimeout\nOptional. The timeout period for the command execution. Unit: seconds.   Example: 60.\nInstanceId\nThe IDs of ECS instances. Example: [\"i-bp17f3kzgtzzj91r****\"].\nComplete sample code:\nIf you no longer require the resources that you created, call API operations to release the resources.\nCall API operations to release resources based on your business requirements. In the following examples, all resources that are created in the preceding section are released.\nRelease an ECS instance.\nAPI operation\nParameter\nDescription and example\nDeleteInstances\nRegionId\nThe region ID of the ECS instance. Example: cn-hangzhou.\nInstanceId\nThe ID of the ECS instance. Example: i-bp17f3kzgtzzj91r****.\nDelete an SSH key pair.\nAPI operation\nParameter\nDescription and example\nDeleteKeyPairs\nRegionId\nThe region ID of the SSH key pair. Example: cn-hangzhou.\nKeyPairNames\nThe name of the SSH key pair. Example: [\"sdk-key-pair\"].\nDelete a security group.\nAPI operation\nParameter\nDescription and example\nDeleteSecurityGroup\nRegionId\nThe region ID of the security group. Example: cn-hangzhou.\nSecurityGroupId\nThe ID of the security group. Example: sg-bp1esyhwfbqeyudt****.\nDelete a vSwitch.\nAPI operation\nParameter\nDescription and example\nDeleteVSwitch\nRegionId\nThe region ID of the vSwitch. Example: cn-hangzhou.\nVSwitchId\nThe ID of the vSwitch. Example: vsw-bp1nzprm8h7mmnl8t****.\nDelete a VPC.\nAPI operation\nParameter\nDescription and example\nDeleteVpc\nRegionId\nThe region ID of the VPC. Example: cn-hangzhou.\nVpcId\nThe ID of the VPC. Example: vpc-bp1aag0sb9s4i92i3****.\nSample code:"
    },
    "23": {
        "title": "Elastic Compute Service:Create and use an ECS instance by using Alibaba Cloud CLI",
        "url": "https://www.alibabacloud.com/help/en/ecs/getting-started/cli-reference",
        "content": "This Product\nElastic Compute Service:Create and use an ECS instance by using Alibaba Cloud CLI\nAlibaba Cloud CLI is a command-line tool that allows you to call Alibaba Cloud API operations in a terminal or a command-line interface to create, configure, and manage Alibaba Cloud resources. This topic describes how to call Elastic Compute Service (ECS) API operations by using Alibaba Cloud CLI to create and manage ECS instances and provides examples.\nFor more information about Alibaba Cloud CLI, see What is Alibaba Cloud CLI?\nCreate an AccessKey pair for a Resource Access Management (RAM) user. An Alibaba Cloud account has all permissions on resources. If the AccessKey pair of your Alibaba Cloud account is leaked, your resources are exposed to great risks. We recommend that you use the AccessKey pair of a RAM user. For information about how to create an AccessKey pair, see Create an AccessKey pair.\nGrant the required permissions on ECS and Virtual Private Cloud (VPC) resources to the RAM user that you want to use. The sample code provided in this topic creates resources, such as an ECS instance, a VPC, and a vSwitch. To grant the permissions required to run the sample code, we recommend that you attach the policies described in the following table to the RAM user.\nCloud service\nPolicy\nVPC\nAliyunVPCFullAccess\nECS\nAliyunECSFullAccess\nInstall and configure Alibaba Cloud CLI. You must install Alibaba Cloud CLI before you can use Alibaba Cloud CLI. You can install Alibaba Cloud CLI on Windows, Linux, and macOS. Download an installation package that is suitable for the operating system that runs on your computer.\nInstall Alibaba Cloud CLI. For information about how to install Alibaba Cloud CLI in different operating systems, see the following topics:\nWindows\nLinux\nmacOS\nConfigure Alibaba Cloud CLI.\nConfigure parameters, such as credentials and regions, that are required to use Alibaba Cloud resources. For information about how to configure credentials, go to the AK tab of the Credential types section of the \"Configure profiles\" topic.\nIf you only need to perform temporary debugging operations, you do not need to install Alibaba Cloud CLI. You can use Cloud Shell provided by Alibaba Cloud to perform the debugging operations. For more information, see What is Cloud Shell?\nMultiple parameters, such as vSwitch ID, security group ID, and image ID, are required to create an ECS instance. You can pass in the IDs of existing resources or call API operations to create new resources.\nCreate a VPC.\nA VPC is a dedicated private network in the cloud. You can configure and manage VPCs as logically isolated networks in the public cloud.\nAPI operation\nParameter\nDescription and example\nCreateVpc\nRegionId\nThe ID of the region in which to create the VPC. Example: ap-northeast-1.\nCidrBlock\nThe CIDR block of the VPC. Example: 192.168.0.0/16.\nCreate a vSwitch.\nA vSwitch is a network switching device in a VPC, which supports the functionality of a physical switch. It serves to enable communication between virtual machines (VMs) and between VMs and physical networks.\nAPI operation\nParameter\nDescription and example\n\nRegionId\nThe ID of the region in which to create the vSwitch. Example: ap-northeast-1.\nCreateVSwitch\nZoneId\nThe ID of the zone in which to create the vSwitch. Example: ap-northeast-1a.\nVpcId\nThe ID of the VPC in which to create the vSwitch. Example: vpc-bp1aag0sb9s4i92i3****.\nCidrBlock\nThe CIDR block of the vSwitch. Example: 192.168.0.0/24.\nCreate a security group.\nA security group acts as a virtual firewall that controls inbound and outbound traffic for ECS instances.\nAPI operation\nParameter\nDescription and example\nCreateSecurityGroup\nRegionId\nThe ID of the region in which to create the security group. Example: ap-northeast-1.\nVpcId\nThe ID of the VPC in which to create the security group. Example: vpc-bp1aag0sb9s4i92i3****.\nCreate an inbound rule in the security group.\nAPI operation\nParameter\nDescription and example\nAuthorizeSecurityGroup\nRegionId\nThe region ID of the security group. Example: ap-northeast-1.\nSecurityGroupId\nThe ID of the security group. Example: sg-bp1esyhwfbqeyudt****.\nIpProtocol\nThe protocol. Example: tcp.\nSourceCidrIp\nThe source CIDR block. Example: 0.0.0.0/0.\nPortRange\nThe port range. Examples:\nLinux instances: 22/22.\nWindows instances: 3389/3389.\nCreate an ECS instance.\nECS provides high-performance, secure, and low-cost compute capacity and is suitable for various scenarios such as website hosting, application development, and data processing. With ECS, you can quickly deploy and run applications and flexibly adjust resources in response to business changes.\nAPI operation\nParameter\nDescription and example\nRunInstances\nRegionId\nThe ID of the region in which to create the ECS instance. Example: ap-northeast-1.\nImageId\nThe ID of the image from which to create the ECS instance. We recommend that you select the Alibaba Cloud Linux image whose ID is aliyun_3_x64_20G_alibase_20240819.vhd.\nInstanceType\nThe instance type of the ECS instance. Example: ecs.e-c1m1.large.\nSecurityGroupId\nThe ID of the security group in which to create the ECS instance. Example: sg-bp1esyhwfbqeyudt****.\nVSwitchId\nThe ID of the vSwitch to which to connect the ECS instance. Example: vsw-bp1nzprm8h7mmnl8t****.\nInstanceName\nThe name of the ECS instance. Example: ecs_cli_demo.\nInstanceChargeType\nThe billing method of the ECS instance. To create a pay-as-you-go instance, set this parameter to PostPaid.\nMake sure that your account balance is sufficient.\nPASSWORD\nThe logon password. Example: ******.\nInternetMaxBandwidthOut\nThe maximum outbound public bandwidth. If the value of this parameter is greater than 0, a public IP address is automatically assigned to the instance.\nSystemDisk.Category\nThe disk category of the system disk. Example: cloud_essd.\nSystemDisk.Size\nThe size of the system disk. Example: 40 GiB.\nThe following sample code provides a complete example on how to create an ECS instance.\nUse Alibaba Cloud CLI to run the sample code. If you repeatedly run the code, resources such as VPCs, vSwitches, and security groups are repeatedly created. This may cause resource wastes. Make sure that you carefully review the code and optimize the code based on your business logic.\nCreate and run a Shell script. The following figure shows the command output.\n\nYou can use SSH to log on to the ECS instance and then deploy services and build applications on the ECS instance.\nObtain the public IP address of the ECS instance.\nCall the DescribeInstances operation and specify <Instance ID> to query the public IP address of the instance.\nSample request\nSample response\nThe PublicIpAddresses parameter indicates the public IP address of the ECS instance.\n\nConnect to the ECS instance.\n\nIf you no longer require the resources that you created, you can call the following API operations to release the resources.\nSelect an API operation to release resources based on your business requirements. In the following examples, all resources that are created in the preceding section are released.\nRelease an ECS instance.\nAPI operation\nParameter\nDescription and example\nDeleteInstances\nRegionId\nThe region ID. Example: ap-northeast-1.\nInstanceId\nThe instance ID. Example: i-bp17f3kzgtzzj91r****.\nDelete a security group.\nAPI operation\nParameter\nDescription and example\nDeleteSecurityGroup\nRegionId\nThe region ID of the security group. Example: ap-northeast-1.\nSecurityGroupId\nThe security group ID. Example: sg-bp1esyhwfbqeyudt****.\nDelete a vSwitch.\nAPI operation\nParameter\nDescription and example\nDeleteVSwitch\nRegionId\nThe region ID. Example: ap-northeast-1.\nVSwitchId\nThe vSwitch ID. Example: vsw-bp1nzprm8h7mmnl8t****.\nDelete a VPC.\nAPI operation\nParameter\nDescription and example\nDeleteVpc\nRegionId\nThe region ID. Example: ap-northeast-1.\nVpcId\nThe VPC ID. Example: vpc-bp1aag0sb9s4i92i3****.\nSample code:\nYou can run the following command to query supported commands:\nYou can run commands by using the following syntax to call ECS API operations. For information about the request parameters, see the documentation of each API operation.\nAlibaba Cloud provides OpenAPI Explorer for developers to understand and use the API operations of various Alibaba Cloud services in a quick and efficient manner. OpenAPI Explorer integrates multiple features related to API operations, including intelligent search, documentation, online debugging, SDK download, sample code, error diagnosis, and call statistics. You can use OpenAPI Explorer to generate a CLI command for an API operation. For more information, see What is an API?\nLog on to the OpenAPI Portal.\nSelect the API operation for which you want to generate a CLI command and specify parameters.\nClick the CLI Example tab in the right-side pane to view the CLI command that is generated with the specified parameters.\n"
    },
    "24": {
        "title": "Elastic Compute Service:Create and use an ECS instance by using Terraform",
        "url": "https://www.alibabacloud.com/help/en/ecs/getting-started/create-and-use-an-ecs-instance-by-using-terraform",
        "content": "This Product\nElastic Compute Service:Create and use an ECS instance by using Terraform\nTerraform is an Infrastructure as Code (IaC) tool that is designed to help developers and O&M teams automate the creation, deployment, and management of cloud infrastructure. Terraform allows you to write simple code to define and configure cloud infrastructure without the need for manual operations or configurations. This topic describes how to use Terraform to create an Elastic Compute Service (ECS) instance.\nFor more information about Terraform, see What is Terraform?\nThis section describes how to install Terraform in Linux or Windows by using an installation package.\nAlibaba Cloud provides the following Terraform online environments. In the online environments, you can run Terraform commands without the need to install Terraform.\nTerraform Explorer: Paste the sample code provided in this topic to the code editor and click Initiate Debugging to automatically run the sample code.\nCloud Shell: Log on to Cloud Shell and paste and run the Terraform commands in the sample code provided in this topic.\nDownload the Terraform installation package that is suitable for your operating system from the Terraform official website.\nConfigure the Terraform runtime environment.\nRun the following command to decompress the installation package to the /usr/local/bin directory.\nDecompress the installation package to a directory, such as D:\\tool\\terraform.\nOn the Windows desktop, right-click This PC and select Properties. On the page that appears, click Advanced system settings. In the System Properties dialog box, click Environment Variables on the Advanced tab. In the Environment Variables dialog box, go to the User variables or System variables section.\nIn the System variables or User variables section, select Path and click Edit. In the dialog box that appears, click New. Then, enter the directory to which you decompressed the Terraform installation package, such as D:\\tool\\terraform, and click OK.\nRun the terraform command to check whether Terraform is installed.\nIf a list of available Terraform options is displayed, as shown in the following figure, the installation is complete.\n\nBefore you use Terraform to manage Alibaba Cloud infrastructure, you must pass the Terraform Provider identity authentication. You can use Terraform to call Alibaba Cloud API operations and create and manage the infrastructure and resources of Alibaba Cloud only after you pass the Terraform Provider identity authentication.\nIf you use Terraform Explorer or Cloud Shell, you do not need to configure Terraform identity authentication. Make sure that your account has permissions to manage Virtual Private Cloud (VPC) and ECS resources.\nIn this example, the AccessKey pair of a Resource Access Management (RAM) user that is obtained from environment variables is used for identity authentication.\nCreate an AccessKey pair for your RAM user. An Alibaba Cloud account has all permissions on resources. If the AccessKey pair of your Alibaba Cloud account is leaked, the resources that belong to the account are exposed to potential risks. We recommend that you use the AccessKey pair of a RAM user. For information about how to create an AccessKey pair for a RAM user, see the Create an AccessKey pair for a RAM user section of the \"Create an AccessKey pair\" topic.\nGrant the RAM user the permissions to manage ECS and VPC resources. We recommend that you follow the principle of least privilege. For information about how to grant permissions to a RAM user, see Grant permissions to a RAM user. The sample code provided in this topic creates resources, such as an ECS instance, a VPC, and a vSwitch. To grant the permissions required to run the sample code, we recommend that you attach the policies described in the following table to the RAM user.\nAlibaba Cloud service\nPolicy\nVPC\nAliyunVPCFullAccess\nECS\nAliyunECSFullAccess\nCreate environment variables to store authentication information.\nThe temporary environment variables configured by using the export command are valid only for the current session. After you exit the session, the configured environment variables become invalid. To configure permanent environment variables, you can add the export command to the startup configuration file of your operating system.\nOn the Windows desktop, right-click This PC and select Properties. On the page that appears, click Advanced system settings. In the System Properties dialog box, click Environment Variables on the Advanced tab. In the Environment Variables dialog box, go to the User variables or System variables section.\nIn the System variables or User variables section, click New. In the dialog box that appears, create the environment variables that are described in the following table.\nVariable\nDescription\nValue\nALICLOUD_ACCESS_KEY\nAccessKey Id\nExample: LTAIUrZCw3********\nALICLOUD_SECRET_KEY\nAccessKey Secret\nExample: zfwwWAMWIAiooj14GQ2*************\nALICLOUD_REGION\nThe region in which you want to deploy resources\nExample: cn-beijing\nThis section describes the Terraform resources that are used in the sample code provided in this topic.\nYou are charged for specific resources. If you no longer require the resources, release or unsubscribe from the resources at the earliest opportunity.\nResources\nalicloud_vpc: creates a VPC.\nalicloud_vswitch: creates a vSwitch.\nalicloud_security_group: creates a security group.\nalicloud_security_group_rule: creates a security group rule.\nalicloud_instance: creates an ECS instance.\nData sources\nalicloud_zones: dynamically queries the zones in which you can create ECS instances of a specific instance type.\nDefine the infrastructure resources required to create an ECS instance, such as a VPC and a vSwitch, in the main.tf configuration file. You can directly copy the sample code in the Complete sample code section of this topic to the configuration file.\nCreate the main.tf configuration file.\nTerraform infrastructure resources are defined in a configuration file. You must first create the configuration file.\nCreate a folder, such as the ecs-quickstart folder, and create the Terraform configuration file in the folder. In this example, the configuration file name is main.tf.\nConfigure the provider settings.\nSpecify a region to deploy Alibaba Cloud resources.\nConfigure the VPC and associate a CIDR block with the VPC.\nA VPC is a dedicated private network in the cloud. You can configure and manage VPCs as logically isolated networks in the public cloud.\nCreate a security group and add a security group rule to the security group.\nA security group acts as a virtual firewall that controls inbound and outbound traffic for ECS instances.\nCreate an ECS instance.\nECS provides high-performance, secure, and low-cost compute capacity and is suitable for various scenarios, such as website hosting, application development, and data processing. By using ECS, you can quickly deploy and run applications and flexibly adjust resources in response to business changes.\nYou can go to the Code tab of Terraform Explorer, paste the following sample code to the code editor, and then click Initiate Debugging to run the sample code.\nAfter you compile the Terraform configuration file, run Terraform commands to automatically create the ECS instance that you defined.\nRun the terraform init command to download and install the plug-in of the Alibaba Cloud provider to the current folder. The command also generates relevant record files.\nOpen the Command Prompt window, go to the folder in which the Terraform configuration file is stored, and then run the terraform init command to initialize Terraform.\nThe following command output indicates that Terraform is initialized:\nRun the terraform plan command to perform the following operations:\nVerify the syntax of the Terraform code in the main.tf configuration file.\nDisplay the preview results of the resources that you want to create by using the current Terraform code.\nThe following command output indicates that the Terraform code in the configuration file does not have syntax errors. In this case, you can run the terraform apply command to create resources. If an error occurs, modify the Terraform configuration file as prompted.\nRun the terraform apply command to automatically create the ECS instance that you defined in the Terraform code and the dependent resources of the instance and automatically install Python. During the creation process, enter yes as prompted to allow Terraform to create all defined resources.\nThe following command output indicates that the ECS instance and its dependent resources are created:\nAfter the ECS instance is created, you can connect to the instance over SSH by using the public IP address of the instance. For more information, see Methods for connecting to an ECS instance.\nRun the following command to view information about the created ECS instance:\nLog on to the ECS console to view information about the created ECS instance.\nIf you want to modify the configurations of the ECS instance, you can modify the resource definitions in the configuration file. For example, you can add an inbound rule to the security group to which the ECS instance belongs.\nIf you want to add a rule to the security group to allow inbound traffic on port 443, add the following code to the configuration file:\nRun the terraform plan command to preview the changes. The following command output indicates that the security group rule will be added to the security group whose ID is sg-2vcdz6b8h9c3XXXXXXXX:\nIf the changes meet your expectation, run the terraform apply command to apply the changes to your infrastructure. When you run the command, you are prompted to confirm whether to apply the changes. Enter yes and press the Enter key to apply the changes. The following command output indicates that the security group rule is added to the security group whose ID is sg-2vcdz6b8h9c3XXXXXXXX:\nIf you no longer require the preceding resources that were created or managed by using Terraform, run the following command to release the resources:\nThe following command output indicates that the resources are released:\nFor information about the resources and data sources supported by ECS, see the Supported resources section of the \"Terraform Reference\" topic.\nYou can debug Terraform code in Terraform Explorer without the need to install or configure Terraform. For more information, see Use Terraform in Terraform Explorer.\nYou can run Terraform commands in Cloud Shell without the need to install or configure Terraform. For more information, see Use Terraform in Cloud Shell."
    },
    "25": {
        "title": "Elastic Compute Service:quick reference for ECS",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/quick-reference",
        "content": "This Product\nElastic Compute Service:quick reference for ECS\nWhen using Elastic Compute Service (ECS), you may encounter various issues such as creating instances, remote connections, changing instance configurations, replacing instance operating systems, and using snapshots. This topic describes common operations on ECS resources for your reference.\nYou can follow these steps to understand the complete lifecycle of an instance from selection, purchase, use, operation, to release.\nUnderstand instance families:\nBefore purchasing an ECS instance, you need to understand the characteristics, available types, and applicable scenarios of different ECS instance families to choose the appropriate instance family based on your business scenario. For more information, see instance families.\nUnderstand billing methods:\nDifferent billing methods are suitable for different business scenarios. For example, subscription is generally suitable for fixed 7\u00d724 services, while pay-as-you-go is generally suitable for applications or services with burst business volumes. For more information, see billing method overview.\nPurchase ECS instances:\nQuick purchase one-click purchase subscription instance: You can purchase an ECS instance in a few minutes in the simplest way, but only specific instance types and images are supported, and most configurations cannot be customized.\nCustom purchase instance: Custom purchase allows you to flexibly choose image types, instance types, storage, bandwidth, security groups, and other configurations based on your business scenario.\nFor more information about purchasing instances, see create an instance.\nRemote connection to instances:\nYou can choose to use Workbench, session management, VNC, and other methods to log on to ECS instances for remote operation and maintenance. For more information, see ECS remote connection methods overview.\nIf you did not set a logon password when you created an ECS instance or if you forget the logon password of an instance, you must reset the logon password for the ECS instance. For more information, see reset instance logon password.\nDeploy common environments, websites, applications, and more using ECS:\nIf you want to upload or download files, see upload or download files.\nIf you want to deploy a basic environment, see set up an environment.\nIf you want to deploy common website services, see set up a website.\nIf you want to deploy common application services such as databases and code hosting platforms, see set up an application.\nManage ECS instance status:\nStart an instance: If an instance is in a stopped state and cannot provide services normally, you need to start the instance to use it.\nStop an instance: You need to stop an instance before performing some operations, such as replacing the operating system, modifying the private IP address, or changing the instance type of a pay-as-you-go instance.\nRestart an instance: Restarting is a common method for maintaining cloud servers, such as for system updates or saving related configurations.\nRelease instance resources:\nWhen you no longer need to use ECS resources, you can release instances in a timely manner to avoid incurring additional costs. For more information, see release an instance.\nWhen using ECS instances, if the current instance configuration cannot meet your business needs, you can modify the instance type (vCPU and memory), public bandwidth configuration, expand the size of cloud disks, or replace the instance operating system as needed.\nUpgrade subscription instance type, Downgrade subscription instance type.\nChange pay-as-you-go instance type.\nChange instance type across zones: Migrate ECS instances to other zones in the same region, and change the instance type within the same instance family (vCPU and memory).\nModify fixed public bandwidth for subscription instances: If you use a fixed public IP, you can change the billing method and bandwidth value of the fixed public IP.\nTemporarily upgrade fixed public bandwidth for subscription instances (continuous period): If you use a subscription instance and have high traffic business needs during a specific period, you can temporarily upgrade the fixed public bandwidth of the instance for a specified continuous period. After the period ends, the bandwidth automatically reverts to the original bandwidth to avoid unnecessary long-term costs.\nChange EIP bandwidth: If you use an Elastic IP Address (EIP), you can adjust the EIP bandwidth peak and billing method through the change EIP bandwidth feature.\nExpand the capacity of existing cloud disks to meet more data storage needs. For specific operations, see cloud disk expansion guide.\nReplace operating system (replace system disk): This operation will replace the system disk and image. After the operation, the original old system disk will be released and all data will be cleared. You need to create a snapshot to back up data for the system disk before the operation.\nMigrate and upgrade operating system: When the operating system stops technical support due to lifecycle, third-party support, or open-source plan evolution, you can replace or migrate the ECS instance to a new operating system. This operation will retain the ECS instance system disk data.\nYou can switch between billing methods for ECS instances as your business requirements change and evolve. The following table describes the resources whose billing methods can be changed.\nResource\nDescription\nReferences\nInstance\nWhen you change the billing method of ECS instances, the billing methods of their computing resources and system disks are changed to match the billing method of the instance.\nIf your workloads become intermittent or you no longer need the instance, you can change the billing method of an instance from subscription to pay-as-you-go. Then, you need to pay only for what you use and can release the instance at any time. This lets you recover a portion of the subscription costs.\nAlibaba Cloud determines whether you can switch the billing method of an instance based on usage metrics of the instance. Go to the ECS console and check for the button or menu item that is used to change the billing method of an instance. If the button or menu item does not exist, the billing method of the instance cannot be changed.\nIf your workloads shift towards long-term, sustained business, you can change the billing method of an instance from pay-as-you-go to subscription to save on costs in the long run.\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nCloud disks\nYou can freely change the billing method of data disks that are attached to subscription instances.\nHowever, the billing methods of system disks and data disks on pay-as-you-go instances change together with the billing methods of the instances.\nChange the billing method of a cloud disk\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nPublic bandwidth\nYou can change the billing method for network usage by upgrading or downgrading instance configurations for instances that have system-assigned public IP addresses.\nChange the billing method for network usage of an ECS instance that uses a static public IP address\nIn addition to subscription, pay-as-you-go and preemptible instance, Alibaba Cloud provides some combinations of billing methods for different ECS resources to reduce costs. You can use a proper combination of billing methods based on your business requirements.\nBilling method\nApplicable resources\nDescription\nReferences\nReserved instance\nCompute resources (vCPUs and memory)\nImage\nReserved instances are coupons that can be used to offset the bills of pay-as-you-go instances.\nReserved instances\nSCU\nDisk\nSnapshot\nStorage capacity units (SCUs) are storage resource plans that can be used to offset the bills of different pay-as-you-go storage resources.\nSCUs\nData transfer plan\nPublic bandwidth\nData transfer plans provide economical solutions designed to offset the fees of IPv4 data transfers from instances billed on a pay-by-traffic basis for network usage.\nData Transfer Plan\nYou can use block storage to store the operating system data and business data of instances, and regularly back up data through snapshots to improve data reliability.\nBlock storage is a block device product provided by Alibaba Cloud for ECS. It is divided into cloud disks, local disks, and elastic temporary disks. You can use block storage on ECS instances in the same manner that you use physical hard disks. You can format block storage devices on ECS instances and create file systems for the devices. For more information, see block storage overview. Common operations for using block storage are as follows:\nCreate and use cloud disks\nCloud disks can be mounted to ECS instances as system disks (to store operating system data) or data disks (to store business data). You can create and use cloud disks to provide persistent storage capabilities for ECS instances. For specific operations, see create and use cloud disks guide.\nReinitialize cloud disks\nIf you need to clear cloud disk data and restore the cloud disk to its state at creation, you can choose to reinitialize the cloud disk. For more information, see reinitialize cloud disks.\nExpand cloud disks\nExpand the capacity of existing cloud disks to meet more data storage needs and avoid data loss due to insufficient storage space. For specific operations, see cloud disk expansion guide.\nSnapshots provide complete point-in-time replicas of cloud disk data and are an important method for disaster recovery. You can use snapshots to periodically back up business data stored on cloud disks to protect against data loss caused by accidental operations, attacks, or viruses. For more information, see snapshot overview.\nCreate manual snapshots\nBefore performing important operations such as rolling back cloud disks, modifying critical system files, or replacing operating systems, it is recommended to create snapshots for cloud disks (system disks or data disks) in advance. If unexpected problems or data loss occur during the operation, you can use snapshots to recover data and ensure business continuity.\nFor specific operations on manually creating snapshots for a single cloud disk, see create snapshots.\nCreate automatic snapshots\nYou can create automatic snapshot policies and associate the created automatic snapshot policies with cloud disks. After association, Alibaba Cloud automatically creates snapshot backups for cloud disks at the time points set in the snapshot policy. For specific operations, see create automatic snapshot policies, set automatic snapshot policies for cloud disks.\nBuilding an elastic and scalable intranet environment in the cloud and implementing strict access control are important parts of network security.\nA virtual private cloud (VPC) is a custom private network that you create on Alibaba Cloud. You can customize the IP address range, subnets, route tables, and network security policies. Different VPCs are logically isolated at Layer 2. Through VPCs, you can better control resource access and improve data security and flexibility. You can learn about the components of VPCs and plan, create, and manage VPCs. For more information, see VPC.\nAfter enabling the public network, ECS instances have public communication capabilities. You can choose to assign a fixed public IP or bind an Elastic IP Address (EIP) to enable the public network for instances. For more information, see enable public network.\nCompared with public network access, intranet access is completely isolated from the outside and is suitable for internal communication with high security and transmission speed requirements. You can use private IP addresses or private domain names for intranet access. For more information, see VPC intranet access.\nYou can improve network performance through eRDMA capabilities. Elastic Remote Direct Memory Access (eRDMA) is a self-developed elastic RDMA network by Alibaba Cloud. It has the advantages of traditional RDMA network cards and applies traditional RDMA technology to VPC networks. The ultra-low latency allows you to experience the superior performance brought by RDMA in the cloud network. The methods for using eRDMA are as follows:\nUse eRDMA on enterprise-level instances.\nConfigure eRDMA on GPU-accelerated instances.\nUse eRDMA in containers (Docker).\nYou can improve IP management efficiency by using prefix lists. A prefix list is a set of one or more network prefixes (CIDR blocks). You can reference prefix lists to configure network rules for other resources. You can add some commonly used CIDR blocks to the prefix list to avoid adding multiple rules for different CIDR blocks when configuring network rules, thereby improving O&M efficiency.\nPrefix lists currently support being referenced when configuring security group rules. For specific operations, see improve security group rule management efficiency using prefix lists.\nYou can use elastic network interfaces (ENIs) to achieve multiple applications and multiple IPs. ENIs are virtual network interfaces that provide network connectivity and IP addresses for ECS instances that are deployed in VPCs. Each ECS instance can attach one or more ENIs. ENIs support multiple IP address configurations, allowing a single instance to provide services or access external resources through multiple IP addresses. For specific operations, see create and use ENIs.\nYou can enhance the security protection of instances from different dimensions through the following features. For more security enhancement capabilities, see ECS security.\nA security group is a virtual firewall that controls the inbound and outbound traffic of ECS instances based on configured security group rules to prevent unauthorized access and malicious intrusions. The composition and common operations of security group rules are as follows:\nRule composition: Security group rules consist of authorization objects, port ranges, protocol types, authorization policies (allow or reject), and priorities. For more information, see security group rules.\nCreate and use security groups: You can create security groups and associate them with ECS instances to control the inbound and outbound traffic of ECS instances, achieving network isolation and intercommunication. For specific operations, see create security groups, associate security groups with instances (primary network interface).\nManage security group rules: You can add, modify, or delete rulesfor security groups. These rule changes automatically apply to all ECS instances in the security group. For specific operations, see manage security group rules.\nApplication cases of security groups\nWe provide you with application cases of security groups in several common scenarios to introduce how to configure security group rules to meet your network traffic management needs. For specific content, see security group application guidance and cases.\nA key pair is a login credential used to connect to instances through SSH. Its security strength is much higher than that of regular user passwords and can eliminate brute-force attack threats. You can bind key pairs to instances to achieve password-free logon through key pairs. For specific operations, see manually bind key pairs for SSH password-free logon.\nCreate ECS instances quickly and automatically to handle sudden Internet traffic.\nLaunch templates\nA launch template is a tool for quickly creating instances. It can store custom configuration information for creating ECS instances. Each template can have multiple versions, and each version can configure different parameters. You can use the specified version of a specified template to quickly create instances.\nFor specific operations on creating launch templates and using templates to create ECS instances, see create launch templates, use launch templates to create instances.\nScaling groups\nIf you need to automatically increase or decrease the number of ECS instances when business demand fluctuates, you can configure scaling groups to automatically adjust business computing power (that is, the number of instances). You can create scaling groups based on existing ECS instances. For specific operations, see create scaling groups based on ECS instances.\nA deployment set is a placement strategy for ECS instances on physical servers. An appropriate strategy can help you avoid single points of failure and reduce network communication latency. You can select a deployment strategy based on your business requirements for high availability, network latency, and deployment scale, create deployment sets based on the deployment strategy, and create or add ECS instances within the deployment set. For specific operations, see deployment sets.\nYou can use infrastructure as code (IaC) tools to more concisely create and manage ECS resources.\nResource Orchestration Service (ROS): A simplified cloud computing resource management and automated deployment service provided by Alibaba Cloud that adopts the infrastructure as code (IaC) design concept. You only need to define the required cloud resources in the ROS template, and the ROS orchestration engine automatically completes the creation and configuration of all resources based on the template, achieving automated deployment and O&M.\n\nYou can create stack templates in the ROS console or by calling API operations, and then use the templates to quickly create and manage resources. For specific operations, see create stack templates or API overview. The following are example templates for common ECS instances and related resources:\nManage multiple ECS instances using scaling groups.\nCreate ECS instance groups and attach them to CLB instances.\nTerraform\nTerraform is an open source, infrastructure as code (IaC) tool that developers can use to define and manage infrastructure configurations by using a declarative language. Terraform provides a simple method to create, modify, or delete ECS resources. Terraform helps reduce the complexity and errors of manual operations to improve the manageability and maintainability of infrastructure.\nYou can install and configure Terraform and use Terraform to manage ECS instances. For specific operations, see Terraform reference.\nYou can enable one-click alarm features or set custom alert rules for ECS instances to promptly detect abnormal situations and handle potential risks. For specific operations, see set ECS instance alert rules.\nSystem events are defined by Alibaba Cloud to record and notify information about cloud resources, helping you understand risks and anomalies and achieve automated O&M. For more information, see ECS system events overview.\nCloud Assistant\nCloud Assistant is a native automated O&M tool developed for ECS. Cloud Assistant allows you to batch run commands, such as shell, PowerShell, and batch commands, to execute various tasks on ECS instances in a password-free manner without the need to log on to the instances or use jump servers. You can use Cloud Assistant to perform automated O&M tasks, poll processes, install or uninstall software, start or stop services, and install patches or security updates.\nCloudOps Orchestration Service (OOS)\nCloudOps Orchestration Service (OOS) is an automated O&M service provided by Alibaba Cloud that helps you manage and run O&M tasks in the cloud. You can create templates to define execution tasks, the sequence of the tasks, input parameters, and output parameters, and use the templates to automatically run O&M tasks.\nAfter learning so much about ECS-related capabilities, it is time to migrate your on-premises services to the cloud.\nYou can migrate local physical machines, local virtual machines, or cloud servers from other cloud providers to Alibaba Cloud. You can choose to migrate by importing custom images or use the Server Migration Center (a migration platform provided by Alibaba Cloud) for migration. For more information, see migrate to the cloud.\nIf you need to migrate Alibaba Cloud ECS instances from one account/region to another account/region due to insufficient regional resource inventory, cost optimization, disaster recovery, disk downsizing, etc., or if you need to migrate Simple Application Server to ECS instances, Dedicated Host (DDH) to ECS instances, etc., you can choose the appropriate migration method based on the migration scenario. For more information, see cloud migration.\nYou can integrate ECS capabilities into your business systems through programming, including but not limited to creating instances, changing configurations, and performing O&M operations, to simplify operations and management costs. For more information, see integration overview.\nECS OpenAPI: ECS open OpenAPI.\nIntegration methods: ECS supports managing cloud resources through SDKs, CLI, and other methods."
    },
    "26": {
        "title": "Elastic Compute Service:Instances",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/instances-4/",
        "content": "This Product\nElastic Compute Service:Instances"
    },
    "27": {
        "title": "Elastic Compute Service:Images",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/images-4/",
        "content": "This Product\nElastic Compute Service:Images"
    },
    "28": {
        "title": "Elastic Compute Service:Block Storage",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/block-storage-1/",
        "content": "This Product\nElastic Compute Service:Block Storage"
    },
    "29": {
        "title": "Elastic Compute Service:Snapshots",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/snapshots-2/",
        "content": "This Product\nElastic Compute Service:Snapshots"
    },
    "30": {
        "title": "Elastic Compute Service:Network",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/network/",
        "content": "This Product\nElastic Compute Service:Network"
    },
    "31": {
        "title": "Elastic Compute Service:Security groups",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/security-groups-1/",
        "content": "This Product\nElastic Compute Service:Security groups"
    },
    "32": {
        "title": "Elastic Compute Service:Elasticity",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/elasticity/",
        "content": "This Product\nElastic Compute Service:Elasticity"
    },
    "33": {
        "title": "Elastic Compute Service:Deployment & Maintenance",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/deployment-and-maintenance/",
        "content": "This Product\nElastic Compute Service:Deployment & Maintenance"
    },
    "34": {
        "title": "Elastic Compute Service:Migration Service",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/migration-service/",
        "content": "This Product\nElastic Compute Service:Migration Service"
    },
    "35": {
        "title": "Elastic Compute Service:Tags & Resources",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/tags-and-resources/",
        "content": "This Product\nElastic Compute Service:Tags & Resources"
    },
    "36": {
        "title": "Elastic Compute Service:Identities and permissions",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/manage-identities-and-permissions/",
        "content": "This Product\nElastic Compute Service:Identities and permissions"
    },
    "37": {
        "title": "Elastic Compute Service:Linux foundations tutorial",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/linux-foundations-tutorial/",
        "content": "This Product\nElastic Compute Service:Linux foundations tutorial"
    },
    "38": {
        "title": "Elastic Compute Service:Windows foundations tutorial",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/windows-foundations-tutorial/",
        "content": "This Product\nElastic Compute Service:Windows foundations tutorial"
    },
    "39": {
        "title": "Elastic Compute Service:Build a software development environment",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/build-a-software-development-environment/",
        "content": "This Product\nElastic Compute Service:Build a software development environment"
    },
    "40": {
        "title": "Elastic Compute Service:Build a website",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/build-a-website/",
        "content": "This Product\nElastic Compute Service:Build a website\nDuring working hours, you may access the corporate website and internal OA system. Outside of work, you can engage in activities such as browsing forums, reading blogs, or online shopping. This topic describes how to build your own website.\nPrepare an Elastic Compute Service (ECS) instance.\nWebsite requirements vary, so choose an instance configuration that matches the size of your site and expected traffic. Basic configurations are sufficient for small websites. For more information, see Create an instance on the Custom Launch tab.\nFor information about instance families and selecting an instance type, see Overview of instance families and Instance type selection.\nYou can upgrade or downgrade your instance to align with business needs. For more information, see Instance types and families that support instance type changes.\nConfigure security group rules.\nBy default, ports 22 and 3389 that are required to connect to an instance are enabled when you create a security group. Enable ports 80 and 443 to allow website access. Ensure these ports are enabled for inbound traffic in the security group. If not, configure them manually. For more information, see Add a security group rule.\nDeploy the website.\nThe topics under the current chapter describe deployment solutions for commonly used websites. You can design, develop, and deploy various types of websites based on your needs.\nPurchase a domain name.\nSearch for and purchase your desired domain name if it is available. For more information, see Register a generic domain name.\nFor the differences between .com and .net domain name suffixes, see Domain name differences.\nApply for an Internet Content Provider (ICP) filing for the domain name.\nIf the instance that hosts your website is located in a region within the Chinese mainland, you must apply for an ICP filing for your domain name. Otherwise, this step can be skipped.\nPrepare for the ICP filing.\nDocument requirements for ICP filing vary by province. Prepare the necessary documents according to the ICP filing regulations of the MIIT for different regions. For more information, see Overview.\nSubmit the ICP filing application.\nResolve the domain name. Configure domain name resolution settings to allow external users to visit your website using your domain name.\nTo associate the domain name with an IP address, add an A record. For more information, see Add a DNS record.\n(Optional) Enable secure HTTPS access.\nSSL Certificates Service allows you to redirect HTTP traffic that is destined for your websites or mobile applications to HTTPS traffic at minimal costs. You can use SSL certificates to authenticate users and encrypt data. For more information, see What is Certificate Management Service? If you purchase and download an SSL certificate, the methods to install the certificate on servers vary based on the server environment. For more information, see Installation overview.\nNow you have built a website on your own. Use the domain name to visit the website and verify that the services are functioning.\nFor information about how to select Alibaba Cloud services and configurations based on your business needs, see Architecture Consulting Service.\nIf you want to migrate your business from your data center or a hosted data center to Alibaba Cloud, you can request technical support from Alibaba Cloud for cloud migration. For more information, see Cloud Migration Service."
    },
    "41": {
        "title": "Elastic Compute Service:Build an application",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/build-an-application/",
        "content": "This Product\nElastic Compute Service:Build an application"
    },
    "42": {
        "title": "Elastic Compute Service:Instances",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/instances-1/",
        "content": "This Product\nElastic Compute Service:Instances"
    },
    "43": {
        "title": "Elastic Compute Service:Images",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/images-2/",
        "content": "This Product\nElastic Compute Service:Images"
    },
    "44": {
        "title": "Elastic Compute Service:Block Storage",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/block-storage/",
        "content": "This Product\nElastic Compute Service:Block Storage"
    },
    "45": {
        "title": "Elastic Compute Service:Networks",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/networks/",
        "content": "This Product\nElastic Compute Service:Networks"
    },
    "46": {
        "title": "Elastic Compute Service:Security",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/security/",
        "content": "This Product\nElastic Compute Service:Security"
    },
    "47": {
        "title": "Elastic Compute Service:Best practices for Resource Assurance",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/resource-assurance-best-practices/",
        "content": "This Product\nElastic Compute Service:Best practices for Resource Assurance"
    },
    "48": {
        "title": "Elastic Compute Service:Data recovery",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/data-recovery/",
        "content": "This Product\nElastic Compute Service:Data recovery"
    },
    "49": {
        "title": "Elastic Compute Service:Deployment & Monitoring",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/deployment-and-monitoring/",
        "content": "This Product\nElastic Compute Service:Deployment & Monitoring"
    },
    "50": {
        "title": "Elastic Compute Service:Best practices for cost optimization",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/best-practices-for-cost-optimization/",
        "content": "This Product\nElastic Compute Service:Best practices for cost optimization\nThis topic describes the cost components and benefits of Elastic Compute Service (ECS) and provides cost management solutions that maximize cost-effectiveness and accelerate business development.\nThe total cost of traditional enterprise IT infrastructure, also known as total cost of ownership (TCO), includes the procurement price and the expenses related to deployment, operation, and maintenance. When you evaluate IT infrastructure, the actual metric that you evaluate is the TCO per unit of IT infrastructure. To calculate TCO, you must consider the actual business deployment environment variables, such as rack rental fees, electricity costs for racks, and server brands and prices, and whether measures such as dual devices and dual uplinks can be used to prevent single points of failure (SPOFs). You can calculate TCO by using the following formula: TCO = Server expenditure + Network expenditure + Data center expenditure + Other expenses (including the labor cost, public network cost, and additional taxes).\nAmong the four components of data center costs, server procurement and network construction costs are categorized as capital expenditure (CAPEX), which must be deprecated over a specific period of time after purchase. The remaining data center expenditures, such as rent and electricity costs, and other expenses, are categorized as operational expenditure (OPEX), which is continuously incurred based on the resource usage duration. From a business operation perspective, CAPEX involves a significant one-time investment with a high degree of business uncertainty and leaves little room for adjustment. Demand changes may result in unnecessary costs. In contrast, OPEX is more adaptable to business variations. Converting all CAPEX into OPEX is a better solution for dealing with demand uncertainty.\nAlibaba Cloud ECS provides cloud computing resources. You can replace the traditional IT infrastructure of your enterprise with ECS to reduce CAPEX and increase the proportion of OPEX. This improves the cash flow and risk resistance capabilities of your enterprise. ECS costs consist of the following components:\nOwnership cost: involves the costs of resources and resource plans, including:\nInstance type fees\nDisk capacity fees\nImage fees\nPublic bandwidth fees\nSnapshot fees\nO&M cost: involves the labor costs generated when you use ECS, which may include:\nLabor costs for system management and maintenance\nLabor costs for security monitoring and protection\nLabor costs for troubleshooting and repair\nLabor costs for software update and configuration\nTo build a data center, consider the direct costs of hardware, networking, electricity, machine rooms, and O&M. You must also consider the scale costs from upgrades and capacity expansions and the risk costs associated with data backup and high-availability implementations. When you scale up your data center to meet growing business requirements, the cost per unit of resources and complexity of the data center increase and the fault tolerance decreases. If you select business models that do not meet your business requirements, additional costs are generated.\nCompared with self-managed data centers, cloud resources eliminate the need to invest upfront in hardware, physical environments, and labor. The unit cost of cloud resources is relatively linear. You can create or release cloud resources based on your business requirements. Cloud resources support multiple billing methods to allow cost optimizations.\nIf you find high-cost resources, you can monitor the resources across different aspects to determine the reasons for the high costs and take targeted optimization measures.\nMonitor resource usage.\nMonitor the usage of resources, such as CPU, memory, disks, and bandwidth. Assess whether the current configuration is higher than the required configuration.\nMonitor idle resources to prevent waste. Idle resources include instances that are upgraded but not restarted, reserved instances that are not matched to pay-as-you-go instances, disks that are not attached to instances, and elastic IP addresses (EIPs) that are not associated with instances.\nMonitor resource usage cycles. If you require resources such as instances and disks for long-term use, we recommend that you purchase subscription resources or purchase resource plans to reduce costs.\nMonitor the lifecycle of resources. Take note of the expiration dates of subscription resources, such as subscription instances, reserved instances, and storage capacity units. Renew resources at the earliest opportunity.\nSelect instance types based on your business scenarios.\nInstance types have significant impacts on ECS costs. Select the most cost-effective instance type and adjust the number of instances based on your business scenarios. This way, you can maximize resource utilization and minimize costs while meeting your business requirements.\nFor example, you use 10 d1ne.14xlarge instances for short-form videos. The monitoring results indicate a proper memory usage but a low CPU utilization of the instances. To resolve the issue, perform the following operations:\nReduce the CPU-to-memory ratio of the instances to increase CPU utilization without affecting your business. The CPU-to-memory ratio of d1ne.14xlarge instances is 1:4. The CPU-to-memory ratio of d2s instances is 1:4.4. Replace the 10 d1ne.14xlarge instances with 13 d2s.10xlarge instances to reduce costs by approximately 18%.\nFor information about how to select instance types, see Instance type selection.\nCombine multiple billing methods.\nDifferent types of business have different requirements for resource usage cycles. Select a billing method for each type of business and combine billing methods to optimize costs.\nUse subscription instances and reserved instances for stable business workloads.\nUse pay-as-you-go instances for stateful and dynamic business workloads.\nUse preemptible instances for stateless and fault-tolerant business workloads.\nUse dedicated hosts to allow the reuse of ECS instance resources.\nIn scenarios in which the absolute stability of CPUs is not a strict requirement, such as development and test environments, you can use CPU-overprovisioned dedicated hosts to deploy additional similar-sized ECS instances to reduce the cost per unit of deployments.\nStopped ECS instances that are deployed on dedicated hosts do not consume resources. During off-peak hours, you can stop specific ECS instances in the production environment and use idle resources to run test tasks that have predictable cycles, such as offline computing and automated tests.\nECS and hardware such as processors are continuously upgraded to improve performance and reduce costs. In most cases, later instance types are more cost-effective than earlier instance types.\nThe following table describes the differences between the g5.2xlarge and g6.2xlarge instance types in terms of performance and price.\nPerformance\nPrice\nThe integer computation performance is improved by 40%.\nThe floating-point computation performance is improved by 30%.\nThe memory bandwidth is increased by 15%.\nThe memory idle latency is decreased by 40%.\nThe internal bandwidth is increased by 220%.\nThe annual subscription price is reduced by 6%.\nThe pay-as-you-go price is reduced by 43%.\nTo ensure that you have access to the next-generation instance types at the earliest opportunity, we recommend that you perform the following operations:\nDesign robust applications that can run on different instance types.\nStay updated on the new instance types that are released on the official Alibaba Cloud website and determine whether to upgrade instance types.\nExamples of instance type upgrade\nYou can use one of the following upgrade schemes to improve business performance without the need to change CPU and memory specifications and reduce costs by at least 15%.\nCurrent instance family\nRecommended compatible instance family\nRecommended alternative instance family\nsn1 and sn2\nc6\ng6\nr6\nc5 and sn1ne\ng5 and sn2ne\nr5 and se1ne\nc4\nhfc6 and c6\nhfc5 and c5\nce4\nr6\nr5 and se1ne\ncm4\nhfc6\nhfc5 and g5\nn1, n2, and e3\nc6\ng6\nr6\nc5 and sn1ne\ng5 and sn2ne\nr5 and se1ne\nt1\ns1, s2, and s3\nm1 and m2\nc1 and c2\nc6\ng6\nr6\nc5 and sn1ne\ng5 and sn2ne\nr5 and se1ne\nYou can use cloud resources based on your business requirements and save on the investment and cost of setting up and operating self-managed data centers. However, you must constantly optimize costs in your daily work to improve cost performance. You can refine the following common operations to create a practical scheme:\nHold regular cost meetings. Review budget implementation with cost-related parties, such as finance and R&D teams, evaluate optimization results, and improve optimization strategies on a regular basis.\nEnforce the use of tags. Tag resources by business, environment, and owner to track daily costs.\nClassify resources and select appropriate usage methods. For example, pay-as-you-go instances are recommended for deploying development and testing environments for short-term projects and can be released immediately after the projects are complete.\nAvoid idle resources. Check resource usage on a regular basis and determine the notification and disposal workflows of idle resources.\nRenew resources at the earliest opportunity. Apply for a budget for subscription resources in advance to avoid the additional cost of purchasing and deploying new resources after existing resources are released upon expiration.\nAlibaba Cloud provides various O&M services to help you improve O&M efficiency and reduce O&M labor costs. Examples:\nAuto Scaling: allows you to maintain instance clusters across different billing methods, instance types, and zones. This service is suitable for scenarios in which business workloads fluctuate.\nAuto Provisioning: allows you to deploy instance clusters across different billing methods, instance types, and zones. This service is suitable for scenarios in which consistent compute capacity must be promptly provisioned and preemptible instances are used to reduce costs.\nCloudOps Orchestration Service: allows you to define a series of O&M operations in a template to perform O&M tasks in an efficient manner. This service is suitable for scenarios in which event-driven, scheduled, batch, or cross-region O&M is required.\nResource Orchestration Service: allows you to deploy and maintain stacks that contain multiple cloud resources and dependencies among the resources. This service is suitable for scenarios in which delivery of an integrated system or environment clone is required."
    },
    "51": {
        "title": "Elastic Compute Service:Best practices for stability",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/stability-best-practices/",
        "content": "This Product\nElastic Compute Service:Best practices for stability"
    },
    "52": {
        "title": "Elastic Compute Service:Deploy a highly available architecture",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/deploy-a-highly-available-architecture/",
        "content": "This Product\nElastic Compute Service:Deploy a highly available architecture"
    },
    "53": {
        "title": "Elastic Compute Service:Best practices for heterogeneous computing services",
        "url": "https://www.alibabacloud.com/help/en/ecs/use-cases/best-practices-for-heterogeneous-computing-services",
        "content": "This Product\nElastic Compute Service:Best practices for heterogeneous computing services\nThis topic describes the best practices for heterogeneous computing services. Refer to the following topics based on your business scenario to learn about the best practices.\nDeploy an NGC environment for deep learning development\nThis topic describes how to deploy an NVIDIA GPU Cloud (NGC) environment on a GPU-accelerated instance for deep learning development. In the topic, a TensorFlow deep learning framework is used.\nBest practices for FaaS f3 instances\nProject modes and directories used by RTL\nThis topic describes the project modes and directories used by the Register Transfer Level (RTL) compiler and also provides a sample framework to help you understand how to use RTL.\nOverview of the FaaS f3 SDAccel development environment\nThe FaaS f3 SDAccel development environment is based on Xilinx SDAccel dynamic 5.0. You can develop applications in the FaaS f3 SDAccel development environment based on Open Computing Language (OpenCL). This topic describes the SDAccel development environment for FaaS f3 instances.\nPerform RTL development on an f3 instance\nThis topic describes how to perform RTL development on a FaaS f3 instance and provides answers to some frequently asked questions about the development process.\nUse OpenCL on an f3 instance\nThis topic describes how to use OpenCL on a FaaS f3 instance to create an image and load the image to an FPGA.\nUse Vitis 2020.1 on an f3 instance\nThis topic describes how to use Vitis 2020.1 on a FaaS f3 instance to create an image and load the image to an FPGA.\n"
    },
    "54": {
        "title": "Elastic Compute Service:Shared security responsibility model of ECS",
        "url": "https://www.alibabacloud.com/help/en/ecs/ecs-shared-responsibility-model",
        "content": "This Product\nElastic Compute Service:Shared security responsibility model of ECS\nThis topic describes the security responsibilities that Elastic Compute Service (ECS) and customers should assume.\nWith the rapid development of the Internet, China has perfected and introduced more than two hundred laws and regulations that are related to cybersecurity and data security in the past few decades, including the Cybersecurity Law of the People's Republic of China (recognized as the basic law on cybersecurity of China) and the Data Security Law of the People's Republic of China (recognized as the basic law on data security of China), to impose strict requirements and standards on the business security and data security of enterprises. As customers embrace cloud computing applications, they shift their focus from how to migrate to the cloud to how to continuously and securely operate business in the cloud to protect the security of both their business and user information. In this context, cloud security and compliance are receiving more attention from enterprises.\nTo maintain good cloud security posture, a set of policies, control means, and technical means are collectively used to safeguard cloud infrastructure, data storage, data access, and applications and protect cloud-based business from security threats. Cloud security and compliance are shared responsibilities between Alibaba Cloud and customers. As an Alibaba Cloud customer, you must familiarize yourself with the risks that are associated with your cloud-based business. You must also engineer and put in place comprehensive safeguards to relieve operational burdens and prevent asset loss that is caused by security events.\nECS is an IaaS offering of Alibaba Cloud. The security of ECS is a shared responsibility between Alibaba Cloud and customers. The shared security responsibility model describes ECS security as security of the cloud and security in the cloud:\nSecurity of the cloud: Alibaba Cloud is responsible for security of the cloud. Alibaba Cloud shall protect the infrastructure that runs ECS and provide you with services and resources that you can securely use, such as physical hardware that host ECS instances, software services, network devices, and management services.\nSecurity in the cloud: You are responsible for security in ECS. Specifically, you shall duly manage guest OSs (including updates and security patches), protect applications or tools that run in ECS, and monitor and safeguard the flow of information into and out of ECS. You shall securely configure and access ECS and the services that are hosted on ECS instances, such as performing network configurations in compliance with security rules and managing ECS permissions based on the principle of least privilege.\nThe following figure shows the shared security responsibility model of ECS.\nAlibaba Cloud provides the following four layers of protection to strengthen security of the cloud:\nData center security: Alibaba Cloud data centers are constructed in compliance with the Class A standards of GB50174 Code for Design of Electronic Information System Room and the Tier 3+ standards of TIA-942 Telecommunications Infrastructure Standard for Data Centers.\nDisaster recovery of data centers: Alibaba Cloud data centers are installed with fire sensors, smoke sensors, and precise air-conditioning systems in hot-standby mode that maintain constant temperature and humidity. The data centers are powered by public power utilities that are backed up by a redundant power system.\nPersonnel management: Dual-factor authentication, such as fingerprint and identity verification, is used to access machine rooms, measurement areas, and storage rooms. Specific areas are physically isolated by using iron cages. Strict account management, identity authentication, authorization management, separation of duties, and access control are implemented.\nO&M audit: Security monitoring systems are put in place in various areas of data centers. Production systems can be operated and maintained only by using bastion hosts. All operation records are logged and stored in a log platform.\nPhysical infrastructure security: Physical infrastructure includes physical servers, network devices, and storage devices. The security of physical infrastructure depends on the security of data centers in the cloud and adds an additional layer of security to services in the public cloud. The following measures are taken to protect Alibaba Cloud physical infrastructure:\nData destruction: Alibaba Cloud develops a mechanism based on the standards of NIST Special Publication 800-88, Guidelines for Media Sanitization to securely erase data from storage media. The mechanism allows Alibaba Cloud to delete data assets at the earliest opportunity and completely destroy data by sanitizing the data from storage media multiple times when Alibaba Cloud terminates services for customers.\nStorage asset management: Alibaba Cloud provides fine-grained, storage component-level management of storage assets and allocates unique hardware identification information to facilitate the search for storage media or small devices in which storage media reside. Storage media that are not securely sanitized or physically destroyed based on specific requirements cannot leave data centers or security control areas.\nNetwork isolation: Alibaba Cloud isolates production networks from non-production networks and uses network access control lists (ACLs) to block access from cloud service networks to physical networks. Bastion hosts are deployed at the edges of production networks, and O&M personnel from office networks can access the production networks only by performing a multi-factor authentication step with domain accounts and dynamic passwords on the bastion hosts.\nVirtualized system security: Virtualization is a pillar technology in cloud computing that allows you to create virtual representations of computing, storage, and network resources to isolate tenants in cloud computing environments. Alibaba Cloud provides virtualization security techniques, including tenant isolation, security hardening, escape detection and fix, live patching, and data erasure, to secure the virtualization layer.\nLive patching: The virtualization platform supports the live patching technique that allows you to apply security patches to running systems without the need to reboot or interrupt runtime.\nData erasure: After instances are released, data is completely erased from the storage media that are associated with the instances. This is a critical step towards data security.\nTenant isolation: Hardware-based virtualization technology provides operating-system-level isolation to isolate each virtual machine from other virtual machines that run on the same hardware. A tenant who has access to the guest OS of a virtual machine cannot breach this layer of isolation to access another virtual machine that the tenant does not have access.\nCompute isolation: Your virtual machines are isolated from the management system and the virtual machines of other customers.\nNetwork isolation: Each virtual network is isolated from other networks.\nStorage isolation: Compute-storage isolation ensures that each virtual machine can access only the physical disks that you make available to it.\nSecurity hardening: Virtualization management programs and host OSs or kernels are security-hardened. Virtualization software must be compiled and run in a trusted execution environment to protect the entire link.\nEscape detection and fix: Advanced virtual machine layout algorithms are used to prevent malicious users from running virtual machines on specific physical machines and virtual machines from detecting the physical host environments in which the virtual machines run. Suspicious behaviors of virtual machines are probed, and vulnerabilities are hotfixed.\nCloud platform security: The cloud platform provides cloud-based account management services, including the management of Alibaba Cloud accounts and RAM users and multi-factor authentication for logons. The cloud platform also provides access control services, including fine-grained access authorization and secure access.\nYou are responsible for security in ECS and shall secure what you put in or connect to ECS. You shall duly install OS update patches on ECS instances, configure appropriate security group rules to block unauthorized access to ECS instances, and encrypt data on ECS to increase data security.\nAlibaba Cloud provides a series of security management and configuration tools that help you perform security configurations based on your requirements for increased business security. For more information, see the following topics:\nInfrastructure security\nOperating system security\nNetwork security\nData security\nIdentity and access control\nApplication security\nMonitoring and logging\n"
    },
    "55": {
        "title": "Elastic Compute Service:ECS instance security",
        "url": "https://www.alibabacloud.com/help/en/ecs/best-security-practices",
        "content": "This Product\nElastic Compute Service:ECS instance security\nThis topic describes measures that Alibaba Cloud takes to handle threats in cybersecurity and challenges and improve security when users use accounts, instances, operating systems (OSs), and Elastic Compute Service (ECS) resources.\nSecurity covers a broad spectrum. Alibaba Cloud provides secure services and is responsible for protecting the underlying infrastructure of Alibaba Cloud services, such as data centers and virtualization platforms. When you use Alibaba Cloud services, it is also important that you follow best security practices such as protecting your Alibaba Cloud accounts, keeping information confidential, and controlling permissions.\nIn recent years, we have seen a rapid increase in cybersecurity threats. State of Security 2022, an annual global research report released by Splunk Inc., reveals the following data:\n49% of organizations say that they have suffered data breaches over the last two years, compared to 39% a year ago.\n79% of respondents say that they have faced ransomware attacks. 35% admit that one or more of those attacks caused them to lose access to data and systems.\n59% of security teams say that they have devoted significant time and resources to taking remedial actions, compared to 42% a year ago.\nOn average, it takes 14 hours to recover from unplanned downtime. Respondents estimate that the average cost of this downtime amounted to USD 200,000 per hour.\nThe shift from traditional IT infrastructure to cloud-based architectures brings new challenges to security. A single accidental operation may expose your application to the Internet or disclose your key and result in a cybersecurity incident. Security and compliance are essential to digital transformation and are job one in your journey to the cloud.\nSecurity is extremely important and you must make it a priority. The security of systems and applications is an ongoing journey of incremental progress and maturity.\nMake a holistic security strategy and integrated protection policies, complete with security tools and controls.\nBuild security into DevOps.\nBuild an automated security defense system to protect your systems.\nDig into cloud security compliance standards.\nIn addition, you must take note of the following items:\nIdentify, define, and categorize all your information assets.\nDefine what asset data to protect.\nDefine who can access the asset data in protection and for what purposes the asset data can be accessed.\nCloud computing security, or cloud security, usually refers to the practice of using a set of policies, controls, and technologies to protect data, infrastructure, and applications within a cloud computing environment from both external and internal cybersecurity threats and vulnerabilities. An ever-growing number of enterprises attach greater importance to cloud security compliance. Security compliance in the cloud depends on a top-down top-level design. To ensure security compliance in the cloud, you must develop cloud-based applications with security in mind.\nIn light of current security trends, we recommend that you use the best security practices described in the following table to protect your information assets in the cloud.\nItem\nBest practice\nDescription\nAccount security\nProtect Alibaba Cloud accounts\nEnable multi-factor authentication (MFA) for accounts.\nUse Resource Access Management (RAM) users instead of Alibaba Cloud accounts and attach appropriate permissions policies to the users.\nUse instance RAM roles instead of AccessKey pairs to call API operations.\nPrevent AccessKey pair leaks.\nFollow the security suggestions for managing accounts and passwords.\nManagement of application resources\nManage information assets in bulk\nUse tags to manage resources in bulk\nUse Cloud Assistant to automate O&M on resource channels.\nUse Cloud Config to conduct compliance audits on resources.\nInformation and data security\nEnable security compliance when you create instances\nHost business that requires high security on security-enhanced instances.\nUse secure images.\nEncrypt data on disks.\nUse snapshots for disaster recovery purposes.\nAccess instance metadata in security hardening mode.\nNetwork environment security\nProperly separate permissions on network resources\nFollow the security suggestions for isolating network resources.\nBuild a secure network environment.\nApplication security\nUse security services to build a security defense system\nUse Anti-DDoS Origin Basic (free-of-charge), Anti-DDoS Pro, and Anti-DDoS Premium to mitigate DDoS attacks.\nUse Security Center Basic for free to protect against exploitation of system vulnerabilities.\nUse Web Application Firewall (WAF) to protect against exploitation of system vulnerabilities.\nSecurity of applications in the guest operating systems of instances\nProtect applications in instance guest operating systems\nConfigure security settings to ensure secure logons to ECS instances.\nEncrypt data in transit.\nMonitor and audit log exceptions.\nWe recommend that you enable MFA for your Alibaba Cloud account. MFA enhances security because it requires you to provide MFA security codes in addition to usernames and passwords when you access Alibaba Cloud services. MFA security codes are dynamically generated by MFA devices.\nMake sure that access permissions on ECS resources are granted to RAM users based on the principle of least privilege. Do not share account information to third parties or grant unnecessary permissions to RAM users. We recommend that you use your Alibaba Cloud account to create RAM users (or user groups) and attach specific permissions policies for fine-grained access control over accounts on ECS resources. For more information, see RAM users.\nRAM user\nIf you purchase multiple ECS instances that need to be accessed by different entities in your organization, such as employees, systems, and applications, you can create RAM users and attach permissions policies to the RAM users to grant only required permissions to prevent security risks.\nRAM user group\nYou can create multiple user groups and attach different permissions policies to the user groups. This way, you can manage user permissions by user group. For example, to enhance network security, you can configure a permission policy that denies access to specific ECS resources from IP addresses outside your corporate network and assign the policy to a specific user group.\nYou can create multiple user groups and attach different policies to manage permissions of personnel with different job responsibilities. For example, if a developer becomes a system administrator, you can move the developer account from the Developers group to the SysAdmins group.\nPolicy for a user group\nSysAdmins: This user group needs permissions to create and manage ECS instances. You can attach a permissions policy to allow members in the SysAdmins group to perform all operations on ECS resources such as instances, images, snapshots, and security groups.\nDevelopers: This user group needs only permissions to use ECS instances. You can attach a permissions policy to allow members in the Developers group to call the DescribeInstances, StartInstances, StopInstances, RunInstances, and DeleteInstance operations.\nTypically, applications that are deployed on ECS instances access the APIs of other Alibaba Cloud services by using the AccessKey pair of an Alibaba Cloud account or RAM user. Before the AccessKey pair can be used on an instance to call API operations, the AccessKey pair must be configured in the instance. For example, you can write the AccessKey pair to a configuration file of the instance. However, this method carries security risks such as information leaks and difficult maintenance. To address these risks, Alibaba Cloud provides instance RAM roles. By using instance RAM role, you can ensure the security of your AccessKey pairs and make use of RAM for fine-grained control and management of permissions.\nYou can attach an instance RAM role to an ECS instance and use a Security Token Service (STS) temporary credential to access the APIs of other Alibaba Cloud services. After you attach the role to the instance, we recommend that you access instance metadata in security hardening mode. The STS temporary credential is updated periodically. For more information, see Overview.\nAccessKey pairs are credentials for Alibaba Cloud accounts to access APIs and must be kept secure. Do not expose your AccessKey pairs to external channels such as GitHub to prevent security threats caused by malicious uses. If the AccessKey pair of your Alibaba Cloud account is disclosed, your resources are exposed to risks.\nSecurity suggestions on how to use AccessKey pairs:\nDo not embed AccessKey pairs in code.\nChange AccessKey pairs on a regular basis.\nRevoke unnecessary AccessKey pairs on a regular basis.\nUse RAM users based on the principle of least privilege.\nEnable log audit and deliver the logs to Object Storage Service (OSS) and Log Service for storage and audits.\nSet acs:SourceIp to control access from specific public IP addresses to Alibaba Cloud APIs.\nSet acs:SecureTransport to true, which indicates that the features and resources are accessed over HTTPS.\nCategory\nPolicy description\nAlibaba Cloud accounts\nMFA must be enabled for administrative accounts.\nConfigure permissions at different levels for accounts and abide by the principle of least privilege to grant permissions.\nDisable root access to APIs or common request methods.\nKeys and credentials\nDo not use expired certificates or credentials.\nDelete the access keys for root accounts.\nRemove the keys and credentials on a regular basis that have not been used for more than 30 days.\nMonitor the latest usage of keys and credentials.\nAutomatically scan your Git repository and historical records for potential key leaks on a regular basis.\nPassword\nChange passwords on a regular basis and make sure that passwords meet strength requirements.\nEnforce password complexity policies.\nSet complex account passwords that differ from those on other platforms to prevent security threats caused by password leaks to resources on multiple platforms.\nHost AccessKey pairs and other account password information in Key Management Service (KMS) securely. Do not store AccessKey pairs or password information in plaintext on disks.\nDo not use the same password or key pair for different accounts on a host.\nConfidential data securely hosted in KMS\nStoring confidential data in plaintext on disks poses leakage risks. We recommend that you activate KMS in advance. KMS allows you to enable data encryption in cloud services without the need to develop and maintain cryptographic infrastructure yourself. For example, you can enable disk encryption and trusted boot on ECS instances.\nAutomatically manage and audit cloud resources in bulk to prevent individual assets being left unprotected due to incorrect configurations. We recommend that you use uniform deployment and naming conventions for instances and security groups and periodically check for, be warned of, and delete security groups or instances that do not comply with the naming conventions. Use tags to manage resources in bulk, use Cloud Assistant to automate O&M on resource channels, and use Cloud Config to conduct compliance audits on resources.\nUse tags to identify, categorize, and find cloud resources in bulk. In the event of a security incident, you can use tags to quickly identify the scope and impact severity of the incident.\nYou can configure security policies with specific tags for resources, such as security groups, at a time.\nFor more information, see Tags.\nTraditional O&M channels depend on SSH to obtain keys and open relevant network ports. Cloud resources are exposed to risks in case of improper management of keys and exposure of network ports. Cloud Assistant is a native automated O&M tool developed for ECS. Cloud Assistant allows you to batch maintain ECS instances and batch execute scripts on and send files to ECS instances in a password-free, logon-free manner without the use of jump servers. Typically, you can use Cloud Assistant to install and uninstall software, start and stop services, distribute configuration files, and run common commands (or scripts), to help manage cloud resources in a secure and efficient manner. You can use Cloud Assistant to batch manage, run commands on, and send files to multiple ECS instances at a time. Cloud Assistant provides the session management feature that allows you to perform interactive O&M on ECS instances. You can perform all of the preceding operations without using passwords, logons, jump servers, or the public IP addresses of ECS instances. Cloud Assistant uses the following security mechanisms to ensure the security of O&M channels:\nAccess control: Cloud Assistant uses RAM policies to control user access to ECS instances based on multiple dimensions, such as instances, resource groups, tags, or source IP addresses. Only users that have the required permissions can use Cloud Assistant to manage ECS instances.\nEnd-to-end reliability: All resources involved in the use of Cloud Assistant interact over HTTPS, and data is encrypted in transit. ECS instances use an internal security mechanism to control inbound access without the need to open ports to users, and minimize intrusion risks. ECS instances communicate outbound over the internal network and become reachable without the need to expose their public IP addresses.\nSecure content: Commands transmitted by Cloud Assistant are encrypted and verified based on signatures to ensure that the commands are secure and not tampered with during transmission.\nLog audit: You can call API operations to audit commands and files that are transmitted by Cloud Assistant. You can query the execution times and results of command tasks or file sending tasks, command or file content, and usernames that are used to run commands or send files. You can also deliver the logs about tasks executed by Cloud Assistant to OSS or Simple Log Service for archiving or analysis purposes.\nFor more information, see Overview.\nCloud Config is a service that allows you to evaluate cloud resources. Cloud Config aggregates resources in different regions to accelerate the query of resources. Cloud Config takes snapshots to record configuration changes of each monitored resource and displays the configuration changes over time in a configuration timeline. Resource configuration changes can trigger compliance evaluation. Cloud Config generates alerts for non-compliant configurations. Cloud Config allows you to monitor the compliance of large amounts of cloud resources against internal and external compliance requirements. For more information, see What is Cloud Config?\nIf your business requires high security and enhanced trust, you can run the business on security-enhanced instances that can ensure trusted boot and the security of private data.\nThis instance family supports encrypted memory and confidential computing based on Intel\u00aeSoftware Guard Extensions (SGX) to protect the confidentiality and integrity of essential code and data from malware attacks.\nThis instance family implements trusted boot based on Trusted Cryptography Module (TCM) or Trusted Platform Module (TPM) chips. During a trusted boot, all modules in the boot chain from the underlying server to the ECS instance are measured and verified.\nExample: c6t instances. For more information about security-enhanced instances, see Overview.\n\nUse public images and enable security hardening for the images.\nUse public images provided by Alibaba Cloud.\nEnable security hardening that is free of charge for public images to obtain various security features, such as webshell detection, security configuration check, and alerting for unusual logons to servers.\n\n\nUse encrypted custom images.\nUse the AES-256 algorithm to encrypt custom images to prevent data leaks in case of image disclosure. You can create encrypted system and encrypted data disks and then create encrypted custom images based on these disks. You can also use the Copy and Encrypt feature when you copy an unencrypted custom image to encrypt the image copy. If you want to share encrypted custom images, we recommend that you create separate BYOK keys (custom keys imported by using Bring Your Own Key feature) for the images to prevent key leaks. For more information, see Copy a custom image.\nYou can encrypt disks to provide maximum protection for data stored on the disks without additional modifications to business or applications. Snapshots that are created from encrypted disks and disks that are created from these snapshots are encrypted. In scenarios that require data security and regulatory compliance, you can use the disk encryption feature to encrypt your data stored in Alibaba Cloud ECS. This way, you can protect the privacy, autonomy, and security of your data without the need to establish or maintain key management infrastructure. Both system disks and data disks can be encrypted. For more information, see Encrypt cloud disks.\n\nUse snapshots to back up data\nData backup is the foundation of disaster recovery and helps reduce the risk of data loss caused by system failures, accidental operations, and security issues. ECS provides the snapshot feature to meet the data backup requirements of most users. You can select a method of creating snapshots based on your needs. For more information, see Create a snapshot.\nWe recommend that you create automatic snapshots on a daily basis and retain the snapshots for at least seven days. This significantly improves disaster tolerance and minimizes potential data loss.\n\n\nUse encrypted snapshots\nECS uses the industry-standard AES-256 algorithm and keys to encrypt snapshots and prevent data leaks in case of snapshot disclosure. You can create encrypted disks and then create encrypted snapshots from the disks.\nECS instance metadata includes the information of ECS instances in Alibaba Cloud. You can view the metadata of running instances and configure or manage the instances based on their metadata. For more information, see Overview of ECS instance metadata.\nWe recommend that you access instance metadata in security hardening mode. In security hardening mode, a session can be established between an ECS instance and the instance metadata server. When you attempt to access the metadata of the instance, the instance metadata server authenticates your identity based on a token. When the token expires, the instance metadata server closes the session and deletes the token. The following limits apply to tokens:\nEach token can be used only for a single ECS instance. If you attempt to use the token of one instance to access a different instance, your access is denied.\nEach token must have a validity period that ranges from 1 second to 21,600 seconds (6 hours). Tokens can be reused until they expire to maintain an optimal balance between security and user experience.\nProxy access is not supported. If a request for creating a token contains the X-Forwarded-For header, the instance metadata server refuses to issue the token.\nAn unlimited number of tokens can be issued for each instance.\nCloud computing leverages Virtual Private Cloud (VPC) to abstract physical networks into isolated secure virtual networks and pool network resources to provide isolation at the data link layer. VPCs are completely isolated from each other and can be connected only by using elastic IP addresses or NAT IP addresses. You can configure IP address ranges or CIDR blocks, route tables, gateways within each VPC. You can connect on-premises data centers to VPCs or connect networks around the world to build a customized network environment so that you can smoothly migrate applications to the cloud or scale the data centers. To connect on-premises data centers to VPCs, you can use VPN Gateway, Express Connect, or Smart Access Gateway (SAG). To connect networks worldwide, you can use Cloud Enterprise Network (CEN).\nNetworks are the basis of cloud services. Networks are vulnerable to various severe cyberattacks and difficult to protect. Cloud computing platforms provide a mature cybersecurity architecture to defend against threats from the Internet. In Alibaba Cloud, you can use security groups, network access control lists (ACLs), routing policies, or Express Connect circuits to control access to VPCs. In addition, you must configure security protections such as Cloud Firewall, WAF, and Anti-DDoS to protect against external cyberthreats.\nConsider the following security suggestions for isolating network resources:\nCreate a network administrator account to manage security groups, network ACLs, and traffic logs in a centralized manner.\nUse network ACLs to restrict access to private data.\nIsolate network resources and preconfigure large subnets to prevent overlapping of subnets.\nConfigure security groups based on access points instead of resources.\nProperly configure security groups to isolate networks and reduce attack surface\nSecurity groups are an important component of network security isolation and are used to control network access to or from ECS instances. The rules of a security group control inbound traffic to and outbound traffic from the instances that are associated with the security group. You can configure security group rules to filter traffic based on port numbers and IP addresses so that you can reduce the attack surface and protect your instances.\nFor example, port 22 is used as the remote connection port on Linux instances by default. Security risks arise if this port is open to external access. You can configure security group rules to allow only specific local IP addresses access to the instances over port 22. If you have higher security requirements, you can use third-party virtual private network (VPN) products to encrypt logon data. Consider the security suggestions described in the following table.\nSuggestion\nDescription\nReferences\nPrinciple of least privilege\nSecurity groups are expected to work like whitelists. Therefore, open and expose as few ports as you need and allocate as few public IP addresses as you need. To query task logs or perform troubleshooting on an instance, log on to the instance by using a VPN or bastion host. Incorrect configurations may leave service ports or IP addresses exposed to the Internet and result in cybersecurity threats.\nYou can create security groups to prevent unauthorized access. You need to open only the ports required by business in security groups that govern Internet traffic and those that govern internal network traffic.\nFor high-risk service ports on ECS instances, you must allow access only from your computer or configure security group rules to allow access only from specific IP addresses.\nFor the management backend of HTTP services, you must configure security group rules to allow access only from specific IP addresses. Enable WAF features for the domain name of the HTTP service.\nSecurity groups for different use cases\nDo not set 0.0.0.0/0 as an authorization object in your security group rules.\nAllowing all inbound access is a common mistake. 0.0.0.0/0 indicates all IP addresses. If a security group rule includes 0.0.0.0/0 as an authorization object to allow inbound access, the rule opens all ports to external access. This poses high security risks. To improve security posture, we recommend that you deny external access over all ports and then configure security group rules to open ports based on your needs. For example, if you need to expose web services, you can open common TCP ports such as ports 80, 8080, and 443 and keep other ports closed.\nAdd a security group rule\nDisable inbound security group rules that are no longer needed.\nIf an inbound security group rule includes 0.0.0.0/0, review the ports and services that your applications must expose. If you do not want specific ports to directly provide external services, you can add a Deny (Forbid) rule for the ports. For example, if you deploy MySQL database services on your instance, port 3306 cannot be exposed to the Internet. In this case, you can add a Deny rule and set the priority of the rule to 100, which indicates the lowest priority.\nAdd a security group rule\nReference security groups as authorization objects in security group rules.\nRules must be added to security groups to allow access based on the principle of lease privilege. Different application layers must use different security groups with appropriate inbound and outbound rules.\nFor example, you can create different security groups for distributed applications. These security groups may not be accessible to each other. In this case, you can add security group rules that reference security groups (instead of IP addresses or CIDR blocks) as authorization objects to allow mutual access between the security groups so that resources in these security groups can access each other.\nFor example, assume that you create the sg-web security group for the web layer and the sg-database security group for the database layer of your applications. In sg-database, you can add a rule that references the sg-web security group to allow all resources in the sg-web security group access over port 3306.\nAdd a security group rule\nFor security groups of the classic network type, do not set CIDR blocks or IP addresses as authorization objects in rules that govern internal network traffic.\nBy default, no inbound rules for internal network traffic are enabled for ECS instances that reside in the classic network. Exercise caution when you configure security group rules that govern internal network traffic.\nSecurity group rule\nConfigure appropriate names and tags for security groups.\nAppropriate names and descriptions help you identify security groups. You can modify the names and descriptions of security groups.\nYou can add tags to security groups by using the ECS console or by calling API operations for easy search and management.\nModify a security group\nCreate or add a tag\nAdd ECS instances that require mutual access to the same security group.\nEach ECS instance can belong to up to five security groups. ECS instances within the same security group can communicate with each other over the internal network. If you have multiple security groups but do not want to configure multiple security group rules, you can create another security group and add the instances that require internal network communication to the new security group.\nWe recommend that you do not add all of your ECS instances to the same security group. For a large or medium-sized application that is distributed across multiple ECS instances, each of these instances plays a different role. You cannot add all the instances to the same security group and must properly configure inbound and outbound security group rules for each instance.\nManage ECS instances in security groups\nIsolate instances within a security group.\nSecurity groups act as virtual firewalls that provide Stateful Packet Inspection (SPI), also known as dynamic packet filtering. A security group contains instances that reside in the same region. These instances have the same security requirements and trust each other. Alibaba Cloud fine-tunes the internal access control policies (or internal network communication policies) of security groups to isolate instances within a security group.\nNetwork isolation within a basic security group\nUse security group quintuple rules.\nSecurity groups are used to control network access to or from one or more ECS instances. Security groups are an important component of security isolation and are used to logically isolate security domains in the cloud. Security group quintuple rules allow you to implement precise access control based on the following five elements: source IP address, source port, destination IP address, destination port, and transport layer protocol.\nSecurity group quintuple rules\nAdd ECS instances that provide Internet-facing services and those that provide internal network-facing services to different security groups.\nApplications hosted on an ECS instance may be accessible to the Internet in scenarios in which the instance provides Internet-facing services. These scenarios include those in which the instance proactively exposes specific ports (such as ports 80 and 443) for external access and in which the instance passively provides port forwarding rules (such as NAT port forwarding rules and forwarding rules that are based on the system-assigned public IP address or elastic IP address of the instance).\nIn the preceding scenarios, use the strictest security group rules for the instance. Add a rule to deny access over all protocols and all ports and then add rules to allow access only to ports required by external services, such as ports 80 and 443. If a security group contains only Internet-facing ECS instances, the rules in the security group are easy to adjust.\nInternet-facing ECS instances within the same security group must have clear and simple responsibilities to ensure that the instances provide no services other than their primary services. For example, for MySQL and Redis applications, we recommend that you deploy them on ECS instances that do not provide Internet access, and then configure security group rules to allow access from specific security groups to the instances.\nAdd a security group rule\nConfigure security domains to isolate services of different security levels within your organization\nYou can build private networks by using VPCs to separately host servers of different security levels in your organization and ensure that the servers do not interfere with each other over an interconnected network. We recommend that you create a VPC, assign a private IP address range in CIDR notation to the VPC, and configure route tables and gateways for the VPC. Then, you can store important data in this VPC, which is logically isolated from the Internet, and use an elastic IP address (EIP) or a jump server to manage data for daily O&M purposes. For more information, see Create and manage a VPC.\nUse jump servers or bastion hosts to protect against internal and external intrusions\nJump servers have a large set of permissions. If you use a jump server, you must use tools to thoroughly record and audit operations on it. We recommend that you use bastion hosts instead to prevent your networks and data from being hacked or disrupted by attackers. Use various technical methods to monitor and record the operations that your O&M personnel perform on servers, network devices, security devices, and databases in your networks, so that your troubleshooting or O&M personnel can be alerted in a centralized manner, handle the alerts in a timely manner, audit the operations, and determine who is responsible for accidental operations or faults.\nWe recommend that you assign the jump server to a dedicated vSwitch in a VPC and then associate the corresponding EIP or NAT port forwarding table with the jump server. Create a dedicated security group named SG_BRIDGE and open required ports. For example, open TCP port 22 for Linux operating systems and RDP port 3389 for Windows operating systems. To restrict inbound access, you can add security group rules to allow only specific public IP addresses of your organization to access the security group. This way, the probability that resources are scanned or accessed is reduced. Add the ECS instance that functions as a jump server to the security group. If you want the jump server to access ECS instances within another security group, you can configure a rule that allows the jump server access to that security group. For example, in a security group named SG_CURRENT, you can add a rule to allow access from the SG_BRIDGE security group over specific protocols and ports. When you use the jump server for SSH communication, we recommend that you use key pairs instead of passwords to log on to ECS instances. For information about key pairs, see SSH key pair overview.\nProperly assign public IP addresses to reduce Internet-exposed attack surface\nProper allocation of public IP addresses facilitates Internet access management and reduces attack surface regardless of whether ECS instances reside in the classic network or VPCs. For ECS instances that reside in a VPC, we recommend that you connect the instances that require Internet access to several specified vSwitches. This makes the instances easy to audit and distinguish and helps prevent accidental exposure of ECS instances to the Internet.\nMost distributed applications have different layers and groups. For ECS instances that do not provide Internet access, we recommend that you do not assign public IP addresses. For multiple instances that provide Internet access, we recommend that you configure Server Load Balancer (SLB) instances to distribute Internet traffic to improve system availability. For more information, see SLB overview.\nIf your ECS instances require Internet access but do not have public IP addresses, we recommend that you use NAT gateways to provide Internet proxy services for the instances. You need only to configure SNAT entries to provide Internet access for specific CIDR blocks or subnets. This way, you can prevent services from being exposed to the Internet after public IP addresses are assigned, when only outbound Internet access is required. For more information, see What is VPN Gateway?\nIn a DDoS attack, multiple compromised computer systems flood one or more targets with fraudulent traffic to deny service to legitimate users of the targets. Alibaba Cloud Security Center can defend against Layer 3 to Layer 7 DDoS attacks, including SYN flood, UDP flood, ACK flood, ICMP flood, DNS flood, and HTTP flood attacks. Anti-DDoS Origin Basic provides a DDoS mitigation capacity of up to 5 Gbit/s free of charge.\nBy default, Anti-DDoS Origin Basic is enabled on ECS instances. Anti-DDoS Origin Basic allows you to maintain normal access speeds in case of DDoS attacks without the need to purchase expensive traffic scrubbing devices. Anti-DDoS Origin Basic ensures the expected bandwidth, availability, and stability of your business. In this case, your business is not affected by other users. After an ECS instance is created, you can set scrubbing thresholds for it. For more information, see Configure a traffic scrubbing threshold.\nSecurity Center is a centralized security management system that identifies, analyzes, and warns of security threats in real time. Security Center provides multiple features to ensure the security of cloud resources and servers in data centers. The features include anti-ransomware, antivirus, web tamper proofing, and compliance check. You can use Security Center to automate security operations, responses, and threat tracing, and meet regulatory compliance requirements.\nSecurity Center Basic is available to you by default. Security Center Basic scans only for the following threats: unusual logons to servers, vulnerabilities, and configuration risks in cloud services. To use advanced features such as threat detection, vulnerability fixing, and virus detection and removal, go to the Security Center console to purchase a paid Security Center edition. For more information, see Introduction to Security Center Basic.\nWeb Application Firewall (WAF) depends on the big data capabilities of Alibaba Cloud Security Center to protect web applications against common attacks reported by the Open Web Application Security Project (OWASP) and HTTP flood attacks. The attacks include SQL injections, cross-site scripting (XSS) attacks, webshells, trojans, and unauthorized access. WAF blocks malicious visits to prevent data leaks and ensure the security and availability of your websites. For more information, see Getting started.\nWAF has the following benefits:\nWAF can handle various web application attacks to ensure the web security and availability of a website without the need to install software or hardware or modify website configurations and code. On top of powerful web protection capabilities, WAF can provide dedicated protection for specific websites and is a great fit for web application protection in fields such as finance, e-commerce, Online To Offline (O2O), Internet Plus, gaming, public services, and insurance.\nWithout WAF, you may be vulnerable to web intrusions in face of attacks such as data leak attacks, HTTP flood attacks, and trojans.\nFor more information about how to use WAF, see Getting started.\nBy default, a non-root account can be used to log on to an ECS instance. Before you can use a non-root account to log on to an ECS instance, you must run the su or sudo command on the instance to grant administrative permissions to the account. By default, you cannot use the root account with a key file in the PEM format to log on to the instance. We recommend that you use a secure access control protocol to access ECS instances and select different logon credentials based on image types. For Linux instances, we recommend that you configure the instances to support only RSA-encrypted key pairs as logon credentials and not to support passwords as logon credentials. For Windows instances, we recommend that you use complex passwords that are more than eight characters in length and contain special characters as logon credentials.\nLinux instance:\nBy default, non-root accounts are used to log on to Linux instances.\nIf you log on to a Linux instance with the root account, you have the highest permissions on the instance. This facilitates O&M operations. However, serious data security risks may arise if the instance is attacked. We recommend that you use the Anolis OS 8.4 or Ubuntu 20.04 public image, which supports logons that use the regular ecs-user account.\n\nUse temporary SSH key pairs to log on to Linux instances.\nYou can use the config_ecs_instance_connect plug-in to send an SSH public key to a specific instance for a specific user to use. The SSH public key is stored on the instance for 60 seconds. During these 60 seconds, you can use the SSH public key to connect to the instance as the specified user without a password. For more information, see Connect to a Linux instance by using the config_ecs_instance_connect plug-in with a public key instead of a password.\nAn SSH key pair consists of a public key and a private key that are generated based on an encryption algorithm. By default, the keys are encrypted by using the RSA-2048 algorithm. Key pair-based authentication has the following advantages over username- and password-based authentication:\nSSH key pairs provide higher security and reliability for logons.\nThe security strength of the key pair is much higher than that of the regular user password, which can prevent the threat of brute-force cracking.\nPrivate keys cannot be deduced even if the public keys are maliciously acquired.\nSSH key pairs are easy to use.\nIf you configure a public key on a Linux instance, you can use the corresponding private key to run SSH commands or other tools to log on to the instance without a password.\nYou can log on to a large number of Linux instances by using a key pair at the same time. If you want to batch manage multiple Linux instances, we recommend that you use an SSH key pair to log on to the instances. You can use an SSH key pair that is bound to a Linux instance to log on to the instance. You can specify an SSH key pair when you create an instance, or bind an SSH key pair to an instance after the instance is created. Then, you can use the private key to connect to the instance.\nWe recommend that you modify the sshd_config file to disable password-based logon and support only RSA key pair-based logon. You can modify the parameters related to password logon in the SSH configuration file.\nWindows instance:\nSet complex passwords and change passwords on a regular basis. Weak passwords are one of the leading vulnerabilities that lead to data breaches. To prevent security risks that arise from weak passwords, we recommend that you use complex passwords for servers. Server passwords must be at least eight characters in length and contain multiple character types such as uppercase letters, lowercase letters, digits, and special characters. We also recommend that you change the passwords on a regular basis.\nSet strong passwords for ECS instances. The passwords must be 8 to 30 characters in length and contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters, including ( ) ` ~ ! @ # $ % ^ & * _ - + = | { } [ ] : ; ' < > , . ? /. For Windows instances, passwords cannot start with a forward slash (/).\nConfigure security groups or firewalls to allow communication only between ports used by network services that encrypt data. You can use encryption protocols such as Transport Layer Security (TLS) 1.2 and later to encrypt sensitive data in transit between clients and ECS instances.\nThe M-Trends 2018 report published by FireEye stated that most enterprises, especially enterprises in Asia Pacific, are vulnerable to cybersecurity attacks. The global median dwell time was 101 days. In Asia Pacific, the median dwell time was 498 days. The dwell time indicates a period from when an attack occurs to when the attack is detected. To shorten the dwell time, enterprises need reliable log data and audit services.\nWe recommend that you use CloudMonitor, ActionTrail, Log Audit Service, VPC flow log, and application logs to build a monitoring and alerting system for abnormal resource and permission access. This system is essential for timely detection of problems, stop loss, and optimization of the security defense system.\nUse CloudMonitor to configure resource usage thresholds for triggering alerts and prevent DDoS attacks. For more information, see What is CloudMonitor?\nUse ActionTrail to detect unauthorized access and identify incorrect security configurations and high-risk or accidental operations. You can also use ActionTrail to perform quality monitoring and compliance auditing, and detect and respond to threats. Use MFA to control access to ActionTrail. For more information, see What is ActionTrail?\nEnable the flow log feature provided by VPC and create flow logs to record information about inbound and outbound traffic of elastic network interfaces (ENIs) that reside in a VPC. This helps analyze the flow logs.\nUse Log Audit Service to collect, scrub, analyze, and virtualize data and generate alerts. You can use Log Audit Service in scenarios related to Simple Log Service, such as DevOps, operations, security, and audit scenarios. For more information, see Overview of Log Audit Service.\nTrace application event logs and API call logs.\nSynchronize all logs to Simple Log Service or OSS on a regular basis for storage and configure access permissions on the logs.\nAdd information such as instance IDs, regions, zones, and environments (test or production environments) to stored logs to facilitate troubleshooting."
    },
    "56": {
        "title": "Elastic Compute Service:Infrastructure security",
        "url": "https://www.alibabacloud.com/help/en/ecs/infrastructure-security",
        "content": "This Product\nElastic Compute Service:Infrastructure security\nThe security of the Elastic Compute Service (ECS) infrastructure involves protecting the security of physical machines, hardware security, and virtualization security. ECS delivers essential security measures for host protection, including unusual logon detection, Cloud Security Scanner, and baseline configuration checks, helping you promptly identify potential security threats.\nAlibaba Cloud data centers are constructed in compliance with the Class A standards of GB50174 Code for Design of Electronic Information System Room and the Tier 3+ standards of TIA-942 Telecommunications Infrastructure Standard for Data Centers.\nData center disaster recovery includes fire and smoke detection systems, dual utility grid power supplies, redundant power systems, and precision air conditioners with hot standby redundancy to maintain consistent temperature and humidity levels.\nPersonnel management involves access control with dual-factor authentication, such as fingerprints and identity verification, for segregated areas including data center rooms, electrical measurement zones, and storage areas. Physical isolation is further enforced with caged areas, complemented by stringent account, identity, authorization management, duty segregation, and access control.\nO&M audit: Security monitoring systems are installed across the data center. O&M operations on production systems are exclusively conducted through Bastionhost, with comprehensive logging of all activities on the log platform.\nStorage device asset management is meticulously detailed to the smallest storage component, each tagged with a unique hardware identification for precise location of storage media or devices containing them. Storage media are prohibited from leaving the data center or secure areas unless they have undergone secure erasure or physical destruction as per standards.\nData destruction protocols adhere to the NIST SP800-88 secure erasure standard. Upon termination of customer services, Alibaba Cloud promptly deletes data assets and follows strict procedures to perform multiple data purges on storage media, ensuring complete data destruction.\nNetwork isolation is enforced between production and non-production networks. Network ACLs prevent Alibaba Cloud service networks from accessing physical networks. Bastionhost is deployed at the production network perimeter, and office network personnel can only access the production network for management operations through Bastionhost, using multi-factor authentication with domain account passwords and dynamic passwords.\nHardware security hardening includes firmware baseline scanning, protection of high-performance GPU-accelerated instances, device firmware signature verification, and BMC firmware protection.\nConfidential computing leverages a hardware trusted execution environment, with the root of trust based on the processor chip rather than the underlying software. This ensures that encrypted data is processed exclusively within the trusted execution environment, offering robust hardware-based data protection.\nTrusted computing on key servers employs TPM/TCM technology. TPM/TCM and vTPM/vTCM technologies measure the startup process of the foundational software stack on physical and virtual machines, establishing a system startup trust chain to safeguard against malware or rootkits at the startup or kernel level.\nVirtualization technology, a cornerstone of cloud computing, ensures multi-tenant data isolation through compute, storage, and network virtualization. Alibaba Cloud's virtualization security contains five key components: tenant isolation, security hardening, escape detection and repair, hotpatching, and data erasure, all of which fortify the security of the Alibaba Cloud hypervisor.\nTenant isolation is achieved using hardware virtualization technology to systemically separate virtual machines across multiple compute nodes, preventing tenants from accessing each other's unauthorized system resources.\nCompute isolation ensures separation between management systems and customer virtual machines, as well as between different customer virtual machines.\nNetwork isolation is maintained for each virtual network, keeping it separate from others.\nStorage isolation is enforced by separating compute and storage resources, allowing virtual machines access only to their allocated physical disk space.\nSecurity hardening involves bolstering the security of the virtualization hypervisor and host OS/kernel, with virtualization software compiled and executed within a trusted execution environment to secure the entire chain.\nEscape detection and repair utilize advanced virtual machine layout algorithms to prevent malicious virtual machines from targeting specific physical machines. The system detects abnormal virtual machine behavior and promptly addresses vulnerabilities through hotpatching.\nHotpatching technology supported by the virtualization platform allows for patching without system restarts, ensuring uninterrupted user operations.\nData erasure ensures that after an instance server is decommissioned, its storage medium is securely erased to protect user data."
    },
    "57": {
        "title": "Elastic Compute Service:Operating system security",
        "url": "https://www.alibabacloud.com/help/en/ecs/operating-system-security",
        "content": "This Product\nElastic Compute Service:Operating system security\nThis topic describes how Elastic Compute Service (ECS) enhances operating system security through secure access, operating system hardening, and advanced security measures.\nTo enhance operating system access security on ECS instances, three main parts are engaged: using key pairs for instance logon, using Session Manager for password-free logon, and restricting access to or from 0.0.0.0/0 over ports.\nKey pairs, which consists of a public and a private key, serve as secure credentials for ECS instance authentication, mitigating the risks associated with weak passwords. Alibaba Cloud default key pairs are generated by using the RSA 2048-bit encryption algorithm. Key pair authentication offers a secure and convenient alternative to traditional username and password methods, with the following benefits:\nKey pairs prevent brute-force attacks, unlike conventional passwords.\nKey pair logon is more convenient, with a one-time configuration and no need to enter a password in the future.\nFor more information, see Connect to a Linux instance by using a password or key and Connect to a Linux instance by using an SSH key pair.\nBesides key pair logon, ECS instances can be accessed securely and conveniently through Session Manager, a feature of Cloud Assistant. This method offers several advantages:\nThe Web Socket Secure (WSS) protocol is used to establish persistent WebSocket connections between Session Manager Client and the Cloud Assistant server as well as between the Cloud Assistant server and Cloud Assistant Agent. The WSS protocol encrypts persistent WebSocket connections by using the SSL protocol to ensure security.\nSession Manager uses the authentication based on Resource Access Management (RAM). When you use Session Manager to connect to instances, you do not need to manage the instance passwords, which avoids security risks due to poor password management.\nAfter WebSocket connections are established between Cloud Assistant Agents installed on instances and the Cloud Assistant servers, you can use Session Manager to connect to the instances, without the need to open ports for inbound traffic on the instances. This way, you can improve the security of the instances.\nFor more information, see Connect to an instance by using Session Manager.\nLinux systems typically use SSH on port 22, while Windows systems default to RDP on port 3389 for remote connections. Unrestricted access (0.0.0.0/0 authorization) poses a security threat by allowing potential unauthorized logons. Alibaba Cloud's security groups act as a virtual firewall at the instance level, enabling network access control and providing essential security isolation. For more information, see Overview of security groups and Manage resources associated with security groups.\nAlibaba Cloud CloudOps Orchestration Service (OOS) automates task management and execution. The OOS patch baseline feature allows you to scan or install patches for ECS instances based on default or custom patch baselines. You can also select updates such as security-related updates to automatically install patches for ECS instances. For more information, see Overview.\nAlibaba Cloud Linux provides the Kernel Live Patching (KLP) feature for fixing the common vulnerabilities and exposures (CVEs) and critical bugs of a kernel. KLP can update hotfixes for CVEs or critical bugs of a kernel in a smooth and quick manner without compromising server security and stability. You do not need to restart servers or other business-related task processes, wait until time-consuming tasks are completed, log off, or migrate business. For more information, see Kernel Live Patching.\nAlibaba Cloud provides a suite of basic security services with new ECS instances using public images, including Security Center Basic Edition. This edition offers essential security hardening features such as server vulnerability scanning and abnormal login alerts. While it is optional, enabling this service is highly recommended. If you have advanced security needs, Security Center Advanced Edition and Enterprise Edition are available. For more information, see Basic security services.\n\n\nECS further enhances system security in compliance and audit scenarios through log auditing and adherence to standards.\nWe recommend that you use Session Manager for instance logon and enable the Session Record Delivery feature of Session Manager. This allows for persistent storage, querying, analysis, and auditing of session records in Simple Log Service (SLS) or Object Storage Service (OSS). For more information, see Use the Session Record Delivery feature.\nECS is integrated with the ActionTrail service, allowing you to query management events triggered by ECS operations. ActionTrail facilitates the delivery of these events to either SLS Logstores or OSS buckets, providing solutions for real-time auditing and troubleshooting analysis. For more information, refer to Audit events of ECS.\nIn addition to logon audit and ActionTrail, we recommend that you enable the Log Audit Service. This service builds upon the capabilities of Simple Log Service (SLS), offering support for real-time, automated, and centralized log collection from various cloud products across multiple accounts for auditing purposes. Additionally, it facilitates the necessary storage, querying, and aggregation of information for audit compliance.\nAlibaba Cloud offers images that meet national Level 3 compliance standards for Multi-Level Protection Scheme (MLPS) 2.0. These images inherently fulfill requirements for identity authentication, access control, and intrusion prevention.\nSecurity Center provides the features of classified protection compliance check and ISO 27001 compliance check. You can use the features to check whether your system meets the requirements of classified protection and ISO 27001. ISO 27001 is an international standard on how to manage information security. For more information, see Use the security check feature."
    },
    "58": {
        "title": "Elastic Compute Service:Network security",
        "url": "https://www.alibabacloud.com/help/en/ecs/network-security/",
        "content": "This Product\nElastic Compute Service:Network security\nNetwork security is essential for preventing unauthorized access to network resources, detecting and stopping ongoing network attacks, and ensuring that authorized users have safe and timely access to necessary network resources. This topic describes how Elastic Compute Service (ECS) secures networks through network isolation, network traffic control, network traffic monitoring and analysis, and cloud security protection.\nECS ensures network isolation with Virtual Private Cloud (VPC), a customizable private network in the cloud that provides complete control over your network environment. You can create multiple VPCs in the cloud according to your needs. VPC offers rich isolation capabilities:\nVPCs are logically separated from one another and do not communicate by default.\nECS instances within a VPC can communicate over the internal network, thus reducing exposure to the public network.\nYou can create multiple vSwitches within a VPC to manage network segmentation and CIDR block division, enhancing isolation between different switches.\nFor more information, see Overview of VPCs and vSwitches and Create and manage a VPC.\nWe recommend that you use vSwitches to divide CIDR blocks for different business scenarios to achieve service isolation. vSwitches, fundamental components of a VPC, connect various instances and allow for easy management. They provide the following security features:\nService isolation: It enables the segregation of websites based on security levels and service types.\nTraffic control: VPC offers network access control lists (ACLs) that can be associated with vSwitches to regulate the traffic they handle.\nFor more information, see Overview of VPCs and vSwitches and Create and manage a vSwitch.\nPrivateLink is a service used to establish private, stable, and secure connections between VPC and ECS, allowing access to ECS as though it were within the VPC, without the need for an Internet gateway, NAT device, or VPN. This simplifies network architecture, enables private network access services, enhances VPC security, and mitigates potential security risks associated with public network access. For more information, see What is PrivateLink?.\nECS uses network ACLs within VPCs to manage traffic. Network ACLs offer a network access control mechanism and\u00a0can\u00a0be\u00a0associated\u00a0with\u00a0vSwitches. By customizing network ACL rules, you can control the flow of data in and out of the vSwitches, thus controlling access to ECS instances within those vSwitches. For more information, see Overview of network ACLs and Create and manage a network ACL.\nECS uses security groups to control Network Interface Controller (NIC) traffic. A security group is a virtual firewall that controls inbound and outbound traffic for ECS instances. You can configure inbound rules for a security group to control traffic to ECS instances in the group and outbound rules to control traffic from the instances. For more information, see Overview and Manage resources associated with security groups.\nSecurity groups are classified into basic security groups and advanced security groups, both available for free. Basic and advanced security groups are suitable for different scenarios and differ in the following items: security group capacity, support for security group rules that reference security groups as authorization objects, support for the internal interconnectivity policy, and default access control rules. For more information, see Basic security groups and advanced security groups.\nECS supports the monitoring and analysis of network traffic through VPC flow logs and traffic mirroring, helping you with the access control rule verification, network traffic monitoring, and network troubleshooting.\nFlow logs can record information about inbound and outbound traffic of an elastic network interface (ENI). You can use the flow log feature to check ACL rules, monitor network traffic, and troubleshoot network errors. For more information, see Overview of flow logs.\nYou can use the traffic mirroring feature to mirror network traffic that flows through an ENI based on specified filters. You can use traffic mirroring to mirror network traffic from an ECS instance in a VPC and forward the traffic to a specified ENI or an internal-facing Classic Load Balancer (CLB) device. You can use this feature in scenarios such as content inspection, threat monitoring, and troubleshooting. For more information, see Overview of traffic mirroring.\nAlibaba Cloud offers a suite of security products to protect ECS instances from potential network attacks and reduce security risks. The following products can be integrated with ECS to improve system security:\nAnti-DDoS Basic is enabled for ECS instances by default. This feature helps scrub the DDoS traffic before it reaches the ECS host, effectively protecting ECS instances from DDoS attacks. For more information, see Anti-DDoS Basic.\nCloud Firewall provides unified security management with Internet firewall, VPC firewall, and internal firewall. The internal firewall can protect inbound and outbound traffic between ECS instances, and prevent unauthorized access. For more information, see Create an access control policy for an internal firewall.\nWeb Application Firewall (WAF) filters out malicious traffic, protecting websites and applications from performance issues due to intrusions. You can add an ECS instance to WAF for protection. After you add an ECS instance to WAF, all web traffic of the instance is routed to WAF by using a specific gateway for inspection. WAF filters out malicious traffic and forwards normal traffic to the ECS instance. For more information, see Add an ECS instance to WAF.\n"
    },
    "59": {
        "title": "Elastic Compute Service:Data security",
        "url": "https://www.alibabacloud.com/help/en/ecs/data-security",
        "content": "This Product\nElastic Compute Service:Data security\nData security involves protecting digital data from unauthorized access, unauthorized use, tampering, and loss throughout the data lifecycle. Data security in the cloud is the lifeline for user business and the most important manifestation of overall cloud security. As cyber threats continue to evolve and expand around the world, data protection becomes critical. Alibaba Cloud has the responsibility and obligation to secure the data of users. This topic describes how to ensure user data security on Elastic Compute Service (ECS) instances in terms of data integrity, confidentiality, and availability.\nData integrity refers to using techniques such as verification to check data accuracy and consistency and prevent data from being accidentally or maliciously tampered with during data transmission and storage.\nTo ensure the integrity of data that is transferred or stored, ECS instances use the triplicate storage technology to achieve a data reliability goal of 99.9999999% (nine 9s), the secure data erasure mechanism to achieve complete data erasure, and the Cyclic Redundancy Check (CRC) feature to protect end-to-end data.\nFeature description: Data that is read from or written to a cloud disk is replicated into three chunk copies that are stored on different data nodes in a storage cluster based on a specific policy. The triplicate storage feature achieves a data reliability goal of 99.9999999% (nine 9s) on ECS instances and ensures data stability during read and write operations. For more information, see Triplicate storage.\nConfiguration method: By default, this feature is supported by cloud disks.\nFeature description: The deleted data in a distributed block storage system is completely erased and cannot be accessed or restored. This ensures the integrity of data.\n\nThe storage system performs sequential writes to append data to existing files at the underlying layer of cloud disks. This mechanism fully utilizes high-bandwidth and low-latency sequential writes to physical disks. If you delete a logical space from a cloud disk after data is appended at the underlying layer of the cloud disk, the delete operation is recorded as metadata. The storage system returns only zeros for all requests of reading data from the logical space. Similarly, when you overwrite the data that is stored in the logical space of a cloud disk, the storage system does not immediately overwrite the data in the corresponding physical space. Instead, the storage system modifies the mapping between the logical space and the physical space. This ensures that data that is already overwritten is no longer readable. Data fragments that result from delete or overwrite operations are forcefully and permanently deleted from the underlying physical disks.\nWhen you release an Elastic Block Storage (EBS) device (cloud disk), the storage system immediately destroys the metadata of the device to ensure that the disk data is no longer accessible. At the same time, the physical storage space of the disk is recycled. The physical storage space must be cleared before it is re-assigned. Before data is written to a new cloud disk, the system returns only zeros for all read requests.\nConfiguration method: By default, this feature is supported by cloud disks.\nFeature description: By default, cloud disks support the CRC feature for end-to-end data during data transmission and storage. This feature can be used in the following scenarios to ensure that disk data is intact and not corrupted during data transmission:\nThe full-link CRC feature is performed for data that is read and written.\nThe block storage system periodically performs the CRC and redundancy and consistency check for data in the persistent media.\nConfiguration method: By default, this feature is supported by cloud disks.\nData confidentiality ensures that data can be accessed only by authorized individuals or systems to prevent unauthorized access and disclosure. Data confidentiality is achieved by using encryption technologies. Data content cannot be decrypted even if the data is intercepted during transmission or illegally accessed while stored.\nECS provides various security capabilities and solutions in the end-to-end process involving data storage, transmission, and runtime to ensure data confidentiality in the following aspects: confidentiality of data storage, confidentiality of network data transmission, and confidentiality of the computing environment for data runtime.\nFeature description: When you create a system disk or data disks together with an ECS instance or when you separately create a data disk, enable encryption for the cloud disk. After the cloud disk is created, the data within the operating system of the ECS instance that serves as the host of the cloud disk is automatically encrypted when the data is written to the cloud disk and is automatically decrypted when the data is read from the cloud disk. You are unaware of whether data is encrypted in the operating system and do not need to build or maintain the key management infrastructure. Disk encryption protects the privacy and autonomy of data and provides a secure boundary for business data.\nConfiguration method: For more information, see Overview of cloud disk encryption.\nFor enterprises that have high security compliance requirements, all Resource Access Management (RAM) users who belong to the Alibaba Cloud accounts of the enterprises require data encryption to ensure data confidentiality. ECS allows you to configure custom policies to allow RAM users to create only encrypted disks. For more information, see the Custom policy that grants a RAM user the permissions to create only encrypted disks section of the \"Custom policies for ECS\" topic.\nSnapshot encryption encrypts snapshots to back up data stored on encrypted cloud disks, including system disks and data disks. If a cloud disk is encrypted, its snapshots inherit the encryption attribute of the cloud disk, which allows the snapshot data to remain encrypted during storage or transmission. The snapshot data remains encrypted even if the snapshots are copied to another region or used to restore the cloud disk.\nImage encryption uses encryption algorithms to encrypt images and protect data stored in images from unauthorized access and disclosure. The image data cannot be read or decrypted even if an unauthorized user attempts to access the data. This secures the data stored in images. You can create an encrypted image from an ECS instance equipped with an encrypted system disk or from an encrypted snapshot. You can use the Copy Image feature to copy a non-encrypted image to an encrypted image.\nECS provides security capabilities in terms of data transmission confidentiality. You can access instance metadata in one of the following modes: security hardening mode, secure access by using a VPN gateway, and access to ECS resources by using HTTPS.\nFeature description: You can access Metadata Service in normal mode to view instance metadata without authentication. If the instance metadata contains sensitive information, eavesdropping or leakage over transmission links may occur. If ECS has a Server-Side Request Forgery (SSRF) vulnerability, attackers can use the data of Metadata Service to obtain Security Token Service (STS) tokens, which leads to risks similar to AccessKey leaks. Compared with the normal mode, the security hardening mode provides better protection against SSRF attacks by using token-based authentication to access instance metadata.\nConfiguration method: We recommend that you select security hardening mode to access Metadata Service and obtain metadata. For more information, see Obtain instance metadata.\nFeature introduction: A VPN gateway allows you to establish encrypted tunnels to connect on-premises enterprise data, office networks, and Internet clients to Alibaba Cloud virtual private clouds (VPCs) in a secure and reliable manner. The VPN gateway provides two network connection methods: IP Security (IPsec) VPN and Secure Sockets Layer (SSL) VPN. The VPN gateway uses Internet Key Exchange (IKE) and IPsec to encrypt transmitted data to ensure the security of data transmission.\nIPsec-VPN connection: Each data packet is encrypted by IPsec before the data packet is transmitted over an IPsec-VPN connection. IPsec is a collection of protocols used for data encryption and data authentication to ensure data integrity.\nSSL-VPN connection: An SSL client certificate is installed on the client to establish an SSL-VPN connection between the client and the VPN gateway. The traffic transmitted over the SSL-VPN connection is encrypted by using SSL to perform data encryption and identity authentication, and ensure data integrity.\nFor more information, see What is VPN Gateway?\nConfiguration method: By default, this feature is supported.\nFeature description: On the basis of HTTP, HTTPS encrypts data during transmission by using Transport Layer Security (TLS) and SSL. This prevents data from being monitored, intercepted, and tampered with by third parties. ECS supports HTTPS for encrypted transmission and provides keys of 256 bits in length to meet the transmission encryption requirements for sensitive information. TLS 1.2 encryption is used when you connect to an instance by using Session Manager, connect to an instance by using a password or key, or use Cloud Assistant to access instances.\nConfiguration method: By default, this feature is supported.\nAlibaba Cloud provides the acs:SecureTransport configuration. The configuration allows you to access ECS resources only over HTTPS to protect the confidentiality of transmitted data. We recommend that you configure a custom policy that references the configuration and attach the custom policy to RAM users to grant RAM users the permissions to access ECS resources only over HTTPS. For more information, see Custom policies for ECS.\nFeature description: In addition to the confidentiality of data storage and transmission, the confidentiality of the computing environment for data runtime is important. Compute- and security-optimized ECS instances use technical methods, such as hardware encryption, isolation, and user audit capabilities, to provide secure, reliable, and isolated computing environments and different layers of protection to meet various security and performance requirements. The instance types of compute- and security-optimized ECS instances cover host memory encryption, trusted computing, and confidential computing. For more information, see Overview of security capabilities.\nConfiguration methods: For more information, see Trusted computing capabilities, Confidential computing capabilities, and Best practices for security capabilities.\nFeature description: Data availability ensures that data remains in a complete, consistent, and accurate state throughout the data lifecycle. Data availability is ensured by data backup and restoration capabilities. ECS provides various security capabilities for data backup and restoration to meet data availability requirements, including snapshot-based backup and restoration, image-based backup and restoration, data restoration for data disk partitions, and multi-zone deployment architecture for data disaster recovery and restoration.\nConfiguration methods: For more information, see Disaster recovery solutions.\n"
    },
    "60": {
        "title": "Elastic Compute Service:Application security",
        "url": "https://www.alibabacloud.com/help/en/ecs/application-security",
        "content": "This Product\nElastic Compute Service:Application security\nApplication security incorporates a set of measures and technologies to safeguard applications from threats and attacks when the applications are deployed and run. Application security is designed to protect software and data against unauthorized access, tampering, or corruption to ensure business continuity and user information security. This topic describes the application security capabilities that are supported by Elastic Compute Service (ECS) instances: host security protection, vulnerability management, network security protection for web applications, and traffic security protection for web applications.\nHost security protection\nMost business relies on the computing power provided by various hosts, which serve as hubs where different cloud services such as web applications, databases, and Object Storage Service (OSS) converge. Ensuring host security is a crucial part of the required efforts to protect applications in the cloud. Selecting effective host security services ensures that you provide your hosts with antivirus and threat detection capabilities to defend against viruses and hacker attacks.\nVulnerability management\nVulnerabilities can be exploited by attackers. You can use the vulnerability management feature of Security Center to ensure that vulnerabilities on ECS instances are discovered and remediated at the earliest opportunity. In addition, you can use the patch management feature of Operation Orchestration Service (OOS) to perform batch patching and scan for and automatically install missing patches on ECS instances.\nNetwork security protection for web applications\nConfiguring Cloud Firewall or security groups ensures that attacks are confined to a limited scope in the event of virus intrusions without affecting the overall business.\nTraffic security protection for web applications\nAttacks targeted at web applications remain one of the sources of security threats over the Internet. In addition to traditional webpages and applications, APIs and miniapps are the new hotspots that generate heavy traffic. Security attacks become diversified as the number of hotspots increases and more convenient call methods are used. Use Web Application Firewall (WAF) and Anti-DDoS services to defend against traffic attacks or vulnerability attacks from networks and prevent business interruptions caused by these attacks.\nRegular operation audit\nYou can use the events in ActionTrail to perform risk, exception, and behavior analysis and trace back all application security operation chains to check their completeness and identify defects. Then, you can make adjustments to ensure the in-cloud security.\nFeature introduction\nECS can use the security features provided by Security Center Basic to protect ECS instances (hosts). Security Center Basic provides basic security features, such as vulnerability detection, unusual logon detection, AccessKey pair leak detection, and compliance check. For more information, see Introduction to Security Center Basic.\nTo use additional security features, such as vulnerability fixing, anti-ransomware, and website tamper-proofing, purchase Security Center. For more information, see Purchase Security Center.\nConfiguration methods\nECS console: When you create ECS instances in the ECS console, select the Free Security Hardening option to enable security hardening. This way, the created ECS instances are protected by the security features of Security Center, such as vulnerability detection and compliance check.\n\n\nYou can also call the RunInstances operation with SecurityEnhancementStrategy set to Active to create ECS instances for which security hardening is enabled.\nSecurity Center console: Install the Security Center agent on existing ECS instances to use the security features of Security Center. For more information, see Install the Security Center agent.\nCheck the security status of ECS instances\nECS console: On the Instance page, move the pointer over the  icon in the Monitoring column corresponding to an ECS instance to check the security status of the instance. You can click Process Now to view the alert details of an unhandled task. If high-severity risks exist, we recommend that you handle the risks as prompted to prevent your business from being affected.\nSecurity Center console: In the left-side navigation pane of the Security Center console, choose Assets > Host. Then, find the ECS instance that you want to manage and view the security details of the instance. For more information, see Manage servers.\nFeature introduction\nSecurity Center provides the vulnerability management feature, which can detect security vulnerabilities in operating systems, web content management systems, and applications, assess the severities of the vulnerabilities, and prioritize the vulnerabilities based on their severities. You can enable the feature to fix specific vulnerabilities with a few clicks and reduce the attack surface in your system.\nBy default, Security Center Basic automatically scans for Linux software vulnerabilities, Windows system vulnerabilities, and Web-CMS vulnerabilities every two days. You can also use the quick scan feature provided by Security Center Basic to manually scan for vulnerabilities. The paid editions of Security Center can not only scan for Linux software vulnerabilities, Windows system vulnerabilities, and Web-CMS vulnerabilities, but also automatically update vulnerability information and fix the vulnerabilities. For more information, see Overview.\nConfiguration methods\nTo protect ECS instances from viruses, we recommend that you scan for vulnerabilities on a regular basis and fix the detected vulnerabilities. For more information, see Scan for vulnerabilities and View and handle vulnerabilities.\nFeature introduction\nThe patch management feature of Alibaba Cloud OOS allows you to use security-related or other updates to automatically install patches on ECS instances. You can use the patch management feature to install a service pack on a Windows ECS instance, update the minor version of a Linux ECS instance, and install patches on multiple ECS instances that run the same type of operating system at a time. You can also use the feature to scan ECS instances for missing patches and automatically install the patches on the instances. For more information, see Overview.\nConfiguration methods\nTo ensure the operating system security and stability of ECS instances, we recommend that you use the patch management feature to automatically scan system patches on the instances and download and install the required patches.\nOOS console: For more information, see Patch baseline and Immediate fix.\nFeature introduction\nAlibaba Cloud Cloud Firewall is a software as a service (SaaS) service that comes with its own operations and management console. Cloud Firewall implements centralized security isolation and traffic management for your cloud assets at the Internet, virtual private cloud (VPC), and host boundaries. Cloud Firewall is your first line of defense for your workloads in Alibaba Cloud. For more information, see What is Cloud Firewall?\nConfiguration methods\nYou can configure firewalls based on network boundaries to facilitate logical layering and subsequent maintenance.\nIf you want to protect only traffic over the Internet, you need to only configure inbound or outbound access control policies for the Internet firewall. For more information, see Create access control policies for the Internet firewall.\nIf you want to manage outbound traffic from resources, such as an ECS instance or elastic container instance, in a VPC to the Internet over a NAT gateway, you can enable a NAT firewall for the NAT gateway and configure an access control policy to manage traffic from internal-facing resources to the Internet in a fine-grained manner. For more information, see Create access control policies for the Internet firewall.\nIf you want to protect traffic over the Internet and traffic between ECS instances, use the Internet firewall together with internal firewalls. For more information, see Create an access control policy for an internal firewall.\nIf you want to protect traffic over the Internet, traffic between VPCs, and traffic between VPCs and data centers, use the Internet firewall together with VPC firewalls. For more information, see Create an access control policy for a VPC firewall.\nFeature introduction\nA security group is a virtual firewall that controls inbound and outbound traffic of ECS instances. You can configure inbound rules for a security group to control traffic to ECS instances in the security group and outbound rules to control traffic from the instances. For more information, see Security groups.\nConfiguration methods\nWhen you create an ECS instance, you can specify one or more security groups for the instance. You can add an existing ECS instance to one or more security groups. For more information, see Manage ECS instances in security groups.\nFeature introduction\nWAF identifies and filters out malicious traffic that is destined for websites and applications and forwards clean, scrubbed traffic to the websites and applications. This protects web servers against intrusion and ensures the security of data and services. For more information, see What is WAF?\nConfiguration methods\nIf you already created an ECS instance, you can add the ports of the instance to WAF to forward web traffic of the instance to WAF for protection. After you add an ECS instance to WAF, all web traffic of the instance is forwarded to WAF for inspection by using a specific gateway. WAF filters out malicious traffic and forwards clean traffic to the ECS instance. For more information, see Enable WAF protection for an ECS instance.\nFeature introduction\nAnti-DDoS Basic provides a basic mitigation capability ranging from 500 Mbit/s to 5 Gbit/s against DDoS attacks for ECS instances free of charge. For more information, see What is Anti-DDoS Basic?\nYou can also use advanced editions of Anti-DDoS, such as Anti-DDoS Origin and Anti-DDoS Proxy, to add more layers of protection for ECS instances. For more information, see What is Anti-DDoS Origin? and What is Anti-DDoS Proxy?\nAfter Anti-DDoS Basic is activated, the service monitors inbound traffic to ECS instances in real time. When network traffic destined for an ECS instance that has a public IP address exceeds the specified traffic scrubbing threshold, Anti-DDoS Basic automatically scrubs the traffic to protect your business from DDoS attacks.\nConfiguration methods\nBy default, Anti-DDoS Basic is activated and cannot be deactivated. You do not need to manually configure Anti-DDoS Basic.\nFeature introduction\nActionTrail monitors and records the operations of your Alibaba Cloud account. You can use this service to perform security analysis, resource change tracking, and compliance audits. ActionTrail can deliver management events to Logstores in Simple Log Service or OSS buckets. This way, you can audit the events in real time and identify the causes of issues. For more information, see What is ActionTrail?\nIn the ActionTrail console, you can query the management events that are generated when you manage ECS resources. For more information, see Audit events of ECS. If an error occurs when you perform operations on ECS instances, you can query the details of the related events to obtain information such as the time when the events occurred, the region where the events occurred, and the ECS instances involved.\nConfiguration methods\nBy default, ECS is integrated with ActionTrail and ActionTrail is activated. You do not need to manually configure ActionTrail."
    },
    "61": {
        "title": "Elastic Compute Service:Identity and access control",
        "url": "https://www.alibabacloud.com/help/en/ecs/identity-and-access-security",
        "content": "This Product\nElastic Compute Service:Identity and access control\nIdentity and access control is used to manage user identities on Alibaba Cloud in a centralized manner. You can use the identity and access control capabilities provided by Alibaba Cloud to allow only users who are authenticated and authorized to access or manage specific Alibaba Cloud resources and prevent malicious access by unauthorized users to your Alibaba Cloud resources, thereby satisfying compliance and audit requirements. This topic describes the following security capabilities supported by Elastic Compute Service (ECS) in terms of identity and access control: increase authentication security, improve the security of access control, and bolster the security of identities and permissions.\nIncrease authentication security\nTo increase the security of your Alibaba Cloud account, we recommend that you enable multi-factor authentication (MFA) for your Alibaba Cloud account and use the AccessKey pair of a Resource Access Management (RAM) user for applications instead of the AccessKey pair of your Alibaba Cloud account. An AccessKey pair consists of an AccessKey ID and an AccessKey secret. Do not expose AccessKey pairs in plaintext in external development platforms. Clear RAM users that remain unused for an extended period of time on a regular basis, and use time-bound temporary Security Token Service (STS) tokens.\nImprove the security of access control\nTo grant permissions to users that have different responsibilities, we recommend that you use the system RAM policies that are predefined by ECS and custom RAM policies. You can manage resources based on resource groups across different dimensions, such as the usage of Alibaba Cloud resources and the department structure, and grant different users access to different resource groups. You can also use tags to manage Alibaba Cloud resources in a fine-grained manner.\nBolster the security of identities and permissions\nWe recommend that you attach RAM roles to ECS instances instead of using AccessKey pairs in plaintext. We also recommend that you activate ActionTrail to perform post-event behavior analysis and security analysis to identify potential security risks and meet compliance and audit requirements.\nAuthentication is a process of verifying the identity of a user based on the credentials. In most cases, users use passwords or AccessKey secrets to authenticate their identities when the users log on to ECS instances.\nFeature introduction\nMFA is an easy-to-use and effective authentication model, which adds an extra layer of protection on top of using a username and a password. MFA verifies users who initiate console logon or perform sensitive operations. This ensures the security of your Alibaba Cloud account. MFA does not affect API operation calls by using AccessKey pairs. For more information, see What is multi-factor authentication?.\nConfiguration method\nWe recommend that you do not use the AccessKey pair of your Alibaba Cloud account to log on to an ECS instance. Instead, we recommend that you enable MFA to add an extra layer of security in addition to using a username and a password to protect your Alibaba Cloud account. After you enable MFA for your Alibaba Cloud account, you are prompted for an authentication code from an MFA device when you log on to an ECS instance. For more information, see Bind an MFA device to an Alibaba Cloud account.\nMake sure that access permissions on ECS resources are granted to RAM users based on the principle of least privilege. Do not share accounts or grant more permissions than necessary.\nIf you purchased multiple ECS instances and multiple users in your organization, such as employees, systems, or applications, need to use the instances, you can create RAM users for the users in your organization and attach RAM policies to grant the RAM users the permissions to access the instances. This eliminates the risk of AccessKey pair leaks and achieves account-level fine-grained access control on ECS resources. For more information, see RAM users.\nRAM provides the following types of identities that can be authenticated and authorized: RAM users, which are physical identities, and RAM roles, which are virtual identities. Virtual identities must be assumed by physical identities to take effect. For more information, see Identities.\nAccessKey pairs are credentials for Alibaba Cloud accounts to access APIs and must be stored in a secure location. To prevent security threats caused by malicious use, do not expose your AccessKey pairs by any means, such as GitHub. If the AccessKey pair of an Alibaba Cloud account is disclosed, the resources in the account are exposed to risks. You can refer to the following security suggestions to minimize the risk of AccessKey pair leaks:\nDo not embed AccessKey pairs in code.\nRotate AccessKey pairs on a regular basis.\nRevoke unnecessary AccessKey pairs on a regular basis.\nUse RAM users based on the principle of least privilege.\nConfigure the acs:SourceIp parameter to control access from specific public IP addresses to Alibaba Cloud APIs.\nSet the acs:SecureTransport parameter to true, which specifies that the features and resources are accessed over HTTPS.\nRAM allows you to keep your Alibaba Cloud account and AccessKey pair strictly confidential when multiple users in your enterprise manage resources in a collaborative manner. RAM also allows you to grant the users the minimum required permissions to ensure high security.\nBy default, an Alibaba Cloud account has all permissions on the resources in the account, and RAM users created by the Alibaba Cloud account do not have permissions. The Alibaba Cloud account must grant permissions to the RAM users. To grant permissions to a RAM user or role, perform the following steps:\nSelect or create policies.\nRAM supports system and custom policies. System policies are created and maintained by Alibaba Cloud. You can use system policies but cannot modify the policies. Custom policies are user-defined policies. You can create, update, and delete custom policies.\nFor information about system policies for ECS, see System policies for ECS.\nFor information about custom policies for ECS, see Custom policies for ECS.\nGrant permissions to the RAM user or role.\nYou can attach one or more system or custom policies to grant permissions to a RAM user or role in an Alibaba Cloud account. You can grant the RAM user or role permissions on all resources in the Alibaba Cloud account or all resources in a specific resource group in the Alibaba Cloud account.\nFor information about how to grant permissions to a RAM user, see RAM users.\nFor information about how to grant permissions to a RAM role, see RAM roles.\nFeature introduction\nResource groups allow you to organize your Alibaba Cloud resources into groups based on different criteria, such as the usage, permissions, and owners of the resources. You can create resource groups to manage resources across multiple users and projects in a hierarchical manner. Each cloud resource can belong to only one resource group. Adding resources to resource groups does not change the associations between the resources. For example, you can add instances used in the production environment to a resource group named Production Environment and instances used in the staging environment to a resource group named Test Environment. For more information, see What is Resource Group?\nConfiguration method\nFor information about how to create a resource group, see Create a resource group.\nAdd ECS instances to resource groups.\nYou can add an ECS instance to a resource group when you create the instance. For more information, see Create an instance on the Custom Launch tab.\nYou can move existing ECS instances from one resource group to another resource group. For more information, see Perform manual resource transfer across resource groups.\nFor the use cases of how to categorize and manage ECS resources by using resource groups, see Use a resource group to grant a RAM user the permissions to manage a specific ECS instance and Allocate the costs of ECS instances by resource group.\nFeature introduction\nTags allow you to categorize resources from different dimensions, such as the region, department, and environment, in a more flexible manner than resource groups. You can add multiple tags to each resource and control access to ECS resources based on tags. For more information, see What is Tag?\nConfiguration method\nFor information about how to create a tag and add the tag to an ECS instance, see Tags.\nFor the use cases of how to categorize and manage ECS resources by using tags, see Use tags to grant access to ECS instances by group and Use tags to enable RAM users to manage only authorized ECS instances.\nFeature introduction\nIn most cases, applications deployed on ECS instances access the APIs of other Alibaba Cloud services by using the AccessKey pair of an Alibaba Cloud account or a RAM user. Before you use the AccessKey pair on an ECS instance to call API operations, you must configure the AccessKey pair in the instance. For example, you can write the AccessKey pair to a configuration file of the instance. However, this practice grants users more than required permissions and may cause issues, such as information leaks and increased maintenance complexity. To resolve the issues, Alibaba Cloud provides instance RAM roles. By using instance RAM roles, you can ensure the security of your AccessKey pairs and use RAM to perform fine-grained access control and permission management.\nConfiguration method\nYou can attach an instance RAM role to an ECS instance to obtain an STS token as a temporary access credential and then use the temporary access credential on the instance to access the APIs of other Alibaba Cloud services. You can obtain temporary access credentials only from within an ECS instance without the need to provide an AccessKey pair. This ensures security of the AccessKey pair of your Alibaba Cloud account and allows you to perform fine-grained access control and permission management by using RAM. For more information, see Instance RAM roles.\nFeature introduction\nActionTrail monitors and records the operations of your Alibaba Cloud account. You can use this service to perform security analysis, resource change tracking, and compliance audits. ActionTrail can deliver management events to Logstores in Simple Log Service or OSS buckets. This way, you can audit the events in real time and identify the causes of issues. For more information, see What is ActionTrail?\nIn the ActionTrail console, you can query the management events that are generated when you manage ECS resources. For more information, see Audit events of ECS. If an error occurs when you perform operations on ECS instances, you can query the details of the related events to obtain information such as the time when the events occurred, the region where the events occurred, and the ECS instances involved.\nConfiguration methods\nBy default, ECS is integrated with ActionTrail and ActionTrail is activated. You do not need to manually configure ActionTrail."
    },
    "62": {
        "title": "Elastic Compute Service:Monitoring and logging",
        "url": "https://www.alibabacloud.com/help/en/ecs/monitoring-and-logging",
        "content": "This Product\nElastic Compute Service:Monitoring and logging\nMonitoring and logging are essential for ensuring the availability, operation, and health of your Elastic Compute Service (ECS) resources. Alibaba Cloud offers a suite of monitoring and log audit services, including CloudMonitor and Cloud Config, to facilitate real-time oversight of cloud resource usage and operational status, enabling prompt responses to abnormal alerts.\nYou can monitor the vCPU utilization of ECS instances, the IOPS of disks, and throughput of disks in the ECS console. This monitoring data helps determine the health of ECS instances and facilitates rapid issue resolution.\nFor instance monitoring information, see View the monitoring information of an ECS instance.\nFor disk monitoring information, see View the monitoring data of a cloud disk and Analyze disks.\nWe recommend that you keep track of the health status of your Alibaba Cloud resources so that you can handle exceptions at the earliest opportunity. For more information, visit Alibaba Cloud status.\nOn the Alibaba Cloud status page, you can check the health status of cloud services in each region, and subscribe to Really Simple Syndication (RSS) feeds about service exceptions.\n\nECS integrates Alibaba Cloud CloudMonitor. You can obtain the real-time monitoring metrics of cloud resources and Internet applications free of charge. CloudMonitor monitors the status of ECS resource usage and business exceptions in real time.\nCloudMonitor allows you to enable alerting for ECS multiple key metrics with a few clicks. This way, you can build an alert system for your cloud service with high efficiency to obtain the overall resource usage and business operation status. For more information, see Enable the initiative alert feature.\nYou can configure alert rules for metrics. Alerts can be sent by using phone calls, text messages, emails, DingTalk chatbots, and the Alibaba Cloud app.\nYou can create an alert blacklist to block alerts for specific metrics. For more information, see Manage alert blacklists.\nCloudMonitor provides a default ECS monitoring dashboard, displaying ECS monitoring data. For more information, see View the monitoring dashboard of a cloud service.\nView ECS instance and disk monitoring information in the  and CloudMonitor console. For more information, see View instance monitoring information and View disk monitoring information.\nECS integrates Alibaba Cloud Cloud Config. You can keep track of resource configuration changes and implement audits to ensure the continuous compliance of your cloud infrastructure free of charge.\nCloud Config can audit the operations performed by your Alibaba Cloud account and all RAM users created by your Alibaba Cloud account. By default, configuration changes are recorded every 10 minutes.\nCloud Config provides rules based on the specifications in Baseline for Classified Protection of Cybersecurity 2.0 (CCSP 2.0) and uses the rules to evaluate the compliance of resources. You can enable the compliance pre-check for CCSP 2.0 with a few clicks. The feature then continuously evaluates resource compliance. You can also download the compliance pre-check result and submit it to an inspection agency.\nYou can deliver the historical configuration changes and non-compliant events of your resources to a Logstore of Simple Log Service. This way, you can query and analyze the logs in a centralized manner. For more information, see Deliver resource data to a Logstore of Simple Log Service.\nECS integrates Alibaba Cloud ActionTrail. You can manage logs of all operations on cloud resources, record user logon and resource access actions, and implement security evaluation, intrusion detection, resource change tracking, and compliance audits.\nActionTrail can generate logs of cloud service access by using the Alibaba Cloud console, API operations, and developer tools. For information about the audit events, see Audit events of supported cloud services.\nBy default, ActionTrail tracks and retains events of the last 90 days. If you need to retain events for a longer period of time, you can create a trail to deliver events to Simple Log Service or OSS. For more information, see Create a trail.\nAfter you create a trail to deliver events to a Logstore of Simple Log Service or an OSS bucket, you can query or analyze the events in the Simple Log Service or OSS console. For more information, see Query events in the Simple Log Service or OSS console.\nECS integrates Alibaba Cloud Simple Log Service (SLS). SLS can collect and process logs of operations on cloud services, service status, and business updates. SLS can also analyze logs in real time or deliver logs to other cloud services for monitoring and auditing. For more information, see Use the Operation Content and Result Delivery feature.\nECS supports the monitoring and analysis of network traffic through VPC flow logs and traffic mirroring, helping you with the access control rule verification, network traffic monitoring, and network issue troubleshooting. For more information, see Overview of flow logs and Overview of traffic mirroring."
    },
    "63": {
        "title": "Elastic Compute Service:Best practices for security",
        "url": "https://www.alibabacloud.com/help/en/ecs/best-practices-for-security/",
        "content": "This Product\nElastic Compute Service:Best practices for security"
    },
    "64": {
        "title": "Elastic Compute Service:ECS integration overview",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/integration-overview",
        "content": "This Product\nElastic Compute Service:ECS integration overview\nIntegrate the capabilities of Elastic Compute Service (ECS) into your business system through programming, enabling the system to automatically create ECS instances and snapshots, query ECS resources, monitor the status of ECS instances, and manage security groups and disks. This integration simplifies operations and reduces management costs. This topic describes ECS OpenAPI and supported integration methods.\nFor a complete overview of the OpenAPI calling process, along with related information on identity, authorization, and credentials, see What is an API?\nECS offers API debugging on the OpenAPI portal. Before you call API operations, familiarize yourself with the versions, endpoints, integration methods, and other relevant details.\nEntry: https://api.alibabacloud.com/api/Ecs/2014-05-26/RunInstances?\nAlibaba Cloud OpenAPI determines how to manage Alibaba Cloud service APIs based on their version number. For example, ECS currently supports the API version 2014-05-26. It is important to note that 2014-05-26 indicates the API version number, not the date when the API was last updated. You are provided with the latest public API data in each version.\nVersion\nDescription\nAPI Reference (2014-05-26)\nRecommended for use.\nIt includes basic features such as ECS instances, images, snapshots, security groups, key pairs, and Elastic Block Storage (EBS).\nAPI Reference (EBS Advanced) 2021-07-30\nIt includes advanced features such as EBS asynchronous replication, data insights, and dedicated block storage clusters.\nAn endpoint is used to access Alibaba Cloud services. Select an endpoint based on the region of your resources to reduce latency. For example, the ECS public endpoint in the China (Hangzhou) region is ecs-cn-hangzhou.aliyuncs.com, and the ECS Virtual Private Cloud (VPC) endpoint is ecs-vpc.cn-hangzhou.aliyuncs.com.\nPublic endpoints can be globally accessed.\nA\u00a0VPC\u00a0endpoint\u00a0of\u00a0an\u00a0Alibaba\u00a0Cloud\u00a0region\u00a0is\u00a0accessible\u00a0only\u00a0from\u00a0a\u00a0VPC\u00a0in\u00a0the\u00a0same\u00a0region. Using VPC endpoints has the following benefits:\nHigher security: VPC endpoints can be accessed only within a VPC. This provides higher security and privacy.\nFaster response: VPC endpoints deliver faster responses than public endpoints because data is transmitted over an internal network. In addition, problems such as network latency and bandwidth limitations can be mitigated.\nLower cost: VPC endpoints are accessed over an internal network.\nFor more information, see Endpoints.\nBy default, after you log on to the OpenAPI portal with your Alibaba Cloud account, the account is used to perform online debugging. An Alibaba Cloud account has permissions on all API operations. If you use an Alibaba Cloud account to call API operations, security risks may arise. We strongly recommend that you use a Resource Access Management (RAM) user to call API operations or perform routine O&M. The following table shows which user identities receive ECS support for accessing OpenAPI:\nUser identity\nSupport status\nAlibaba Cloud account\nSupported\nRAM user (recommended)\nSupported\nRAM role (recommended)\nSupported\nAlibaba Cloud SDKs can be easily integrated with your applications and cover the widest range of operations. We recommend that you use the SDKs associated with your applications to call API operations.\nECS supports managing cloud resources through Alibaba Cloud SDKs, CLI, and other methods. The following table lists the support status of each integration method:\nIntegration method\nSupport status\nAlibaba Cloud SDKs (recommended)\nSupported\nFor information about Alibaba Cloud SDKs, see Alibaba Cloud SDKs.\nFor supported languages and installation instructions, see SDK overview.\nAlibaba Cloud CLI\nSupported\nFor information about the Alibaba Cloud CLI, see What is Alibaba Cloud CLI?\nFor a quick start guide, see CLI reference.\nTerraform\nSupported\nSupports a variety of common resources and data resources. For more information, visit ECS Resource Type Checklist.\nFor a quick guide about how to orchestrate ECS with Terraform, see Terraform references.\nResource Orchestration Service (ROS)\nSupported\nFor a list of orchestrated resources, see ECS.\nFor a quick guide about how to orchestrate ECS with ROS, see ROS reference.\nCustom API encapsulation\nSupported\nTo make native HTTP calls, you must create custom requests and sign the requests. For more information about the signature mechanism, see List of operations by function and Request syntax and signature method V3.\n\nIf an error occurs after calling an ECS API operation, verify the request parameters and their values based on the returned error code. For more information, see Public error codes.\nYou can also record the RequestID returned by the call or the SDK error information for self-diagnosis on the Alibaba Cloud OpenAPI Diagnostic Platform.\n"
    },
    "65": {
        "title": "Elastic Compute Service:API Reference(ECS)",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/api-reference-ecs/",
        "content": "This Product\nElastic Compute Service:API Reference(ECS)"
    },
    "66": {
        "title": "Elastic Compute Service:API Reference(Disks Advanced features)",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/api-reference-ebs/",
        "content": "This Product\nElastic Compute Service:API Reference(Disks Advanced features)"
    },
    "67": {
        "title": "Elastic Compute Service:ECS SDK reference",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/ecs-sdk-reference/",
        "content": "This Product\nElastic Compute Service:ECS SDK reference"
    },
    "68": {
        "title": "Elastic Compute Service:CLI reference",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/create-and-manage-an-ecs-instance-by-using-cli-commands",
        "content": "This Product\nElastic Compute Service:CLI reference\nAlibaba Cloud CLI is a command-line tool that allows you to call Alibaba Cloud API operations in a terminal or a command-line interface to create, configure, and manage Alibaba Cloud resources. This topic describes how to call Elastic Compute Service (ECS) API operations by using Alibaba Cloud CLI to create and manage ECS instances and provides examples.\nFor more information about Alibaba Cloud CLI, see What is Alibaba Cloud CLI?\nInstall Alibaba Cloud CLI.\nYou can install Alibaba Cloud CLI on Windows, Linux, and macOS. Download an installation package that is suitable for the operating system that runs on your computer. For information about how to install Alibaba Cloud CLI in different operating systems, see the following topics:\nWindows\nLinux\nmacOS\nConfigure Alibaba Cloud CLI.\nConfigure the credentials, regions, and languages that are required to call Alibaba Cloud resources. For more information, see the Identity credential configuration methods section of the \"Configure credentials\" topic.\nTo ensure the security of your Alibaba Cloud account, we recommend that you create a Resource Access Management (RAM) user that is used for calling API operations and create an AccessKey pair for the RAM user. For information about how to use an AccessKey pair in a secure manner, see Credential security solutions.\nYou can directly use Alibaba Cloud CLI in Cloud Shell without the need for installation or configuration. Due to the fact that the virtual machine (VM) destruction feature of Cloud Shell may cause data loss, we recommend that you run commands on Alibaba Cloud CLI in Cloud Shell to perform simple and quick operations, such as debugging.\nDestruction on expiration: Each VM that is created by Cloud Shell is valid for only 1 hour. When the VM expires, Cloud Shell immediately destroys the VM. When you restart Cloud Shell, a new VM is created.\nDestruction due to no operations: If no interactive operation is performed on a VM for 30 minutes or all sessions are closed, the VM is destroyed in 15 minutes. When you restart Cloud Shell, a new VM is created. For more information, see Limits.\nLog on to the ECS console and click the Cloud Shell icon in the upper-right corner to go to the Cloud Shell console.\n\nFor information about the formats supported by the fields of different data types, see Parameter formats.\nFor information about the command syntax, see the Syntax section of the \"Generate and run CLI commands\" topic.\nBefore you call an API operation, we recommend that you read the usage notes of the API operation.\nAfter you install and configure Alibaba Cloud CLI, you can run commands in the following format to call ECS API operations:\nLog on to the OpenAPI Portal.\nSelect the API operation for which you want to generate a CLI command and specify parameters.\nClick the CLI Example tab in the right-side pane to view the CLI command that is generated with the specified parameters.\n\nThe following example describes how to use Alibaba Cloud CLI to call ECS API operations.\nThe following sample requests are only for reference. Modify the CLI commands based on your business requirements.\nThe following example describes how to create a subscription ECS instance from an Alibaba Cloud Linux image in the China (Hangzhou) region by using Alibaba Cloud CLI.\nMake preparations.\nBefore you create an ECS instance, create a virtual private cloud (VPC), a vSwitch, and a security group, and obtain the IDs of the preceding resources.\nIf you already created the preceding resources and the resources meet your business requirements, skip this step.\nCall the CreateVpc operation to create a VPC.\nIn this example, a VPC is created in the China (Hangzhou) region and associated with the CIDR block 192.168.0.0/16.\nSample command\nSample command output\nCall the CreateVSwitch operation to create a vSwitch in the VPC.\nIn this example, a vSwitch is created in the VPC whose ID is vpc-bp1d9v4763ym2hlzt**** and is associated with the CIDR block 192.168.0.0/24.\nSample command\nSample command output\nCall the CreateSecurityGroup operation to create a security group in the VPC.\nSample command\nSample command output\nCall the AuthorizeSecurityGroup operation to create a security group rule in the security group.\nIn this example, an inbound security group rule that allows TCP traffic on port 22 is added to the security group whose ID is sg-bp18z2q1jg4gq95t****.\nSample command\nSample command output\nCreate an ECS instance.\nCall the RunInstances operation to create a subscription ECS instance.\nExample scenario\nParameter\nDescription and example\nRegionId\nThe ID of the region in which you want to create the ECS instance. Example: cn-hangzhou.\nImageId\nThe ID of the image. We recommend that you select the Alibaba Cloud Linux image whose ID is aliyun_3_x64_20G_alibase_20240528.vhd.\nInstanceType\nThe instance type. Examples:\nFor personal applications, we recommend that you select the ecs.e-c1m1.large instance type that has 2 vCPUs and 2 GiB of memory.\nFor the applications of small and medium-sized enterprises, we recommend that you select the ecs.c7.large instance type that has 2 vCPUs and 4 GiB of memory.\nSecurityGroupId\nThe ID of the security group. Obtain the value from the response of the CreateSecurityGroup operation.\nExample: sg-bp18z2q1jg4gq95t****.\nVSwitchId\nThe ID of the vSwitch. Obtain the value from the response of the CreateVSwitch operation.\nExample: vsw-bp11hf5r945gewysp****.\nInstanceName\nThe name of the ECS instance.\nExample: ecs_cli_demo.\nInstanceChargeType\nThe billing method of the ECS instance. To create a subscription ECS instance, set the value to PrePaid.\nMake sure that your account balance is sufficient.\nPeriodUnit\nThe unit of the subscription duration. Example: Month.\nPeriod\nThe subscription duration. Example: 1.\nInternetMaxBandwidthOut\nThe maximum outbound public bandwidth. Example: 1.\nPassword\nThe logon password of the ECS instance. Example: <yourPassword>.\nTo ensure instance security, you must specify a complex password.\nSystemDisk.Category\nThe category of the system disk. Example: cloud_essd.\nSystemDisk.Size\nThe size of the system disk. Example: 40.\nSample command\nSample command output\nObtain the public IP address of an ECS instance.\nCall the DescribeInstances operation with the ID of an ECS instance to query the public IP address of the instance. In this example, the ID of the ECS instance is i-bp1ducce5hs1jm98****.\nSample command\nSample command output\nThe PublicIpAddresses parameter indicates the public IP address of the ECS instance.\n\nConnect to the ECS instance.\n\nCall the StartInstance operation to start an ECS instance.\nExample scenario: Start an ECS instance whose ID is i-bp1aq39j2yul5y01**** in the China (Hangzhou) region (cn-hangzhou) after a dry run, and do not perform troubleshooting during instance startup.\nSample command\nSample command output\nCall the DescribeInstances operation to query the details of one or more ECS instances.\nExample 1: Query an ECS instance by instance ID\nIn this example, the details of an ECS instance whose ID is i-bp14a7xie8erwsvo**** are queried.\nSample command\nSample command output\nExample 2: Query ECS instances by tag\nIn this example, the details of ECS instances to which owner:zhangsan tags are added are queried.\nSample command\nSample command output\nExample 3: Query ECS instances by image ID\nIn this example, the details of ECS instances whose images have the m-bp12qhgxbmp5eh02**** tag are queried.\nSample command\nSample command output\nExample 4: Query ECS instances in a specific VPC\nIn this example, the details of ECS instances that reside in a VPC whose ID is vpc-bp1vwnn14rqpyiczj**** and are connected to a vSwitch whose ID is vsw-bp1ddbrxdlrcbim46**** are queried.\nSample command\nSample command output\nExample 5: Query ECS instances by page\nCall the DescribeInstances operation to query ECS instances in the China (Hangzhou) region by page. Each page displays five entries.\nSample command\nSample command output\nCall the CreateSnapshot operation to create a snapshot for a disk.\nExample scenario: Create a snapshot for an Enterprise SSD (ESSD) whose ID is d-bp14bjlwo3t3owin****. Set the snapshot name to demoname, the description to demo, and the retention period to three days.\nSample command\nSample command output\nCall the CreateImage operation to create a custom image from an ECS instance.\nExample scenario\nParameter\nDescription and example\nInstanceId\nThe ID of the ECS instance. Example: i-bp1aq39j2yul5y01****.\nPlatform\nThe operating system distribution for the system disk in the custom image. Example: Aliyun, which indicates Alibaba Cloud Linux.\nRegionId\nThe ID of the region in which to create the custom image. Example: cn-hangzhou.\nSample command\nSample command output\nCall the StopInstance operation with ForceStop parameter set to false and StoppedMode set to KeepCharging to stop an ECS instance in the Running (Running) state after a dry run. The ECS instance is stopped in standard mode, and billing for the ECS instance continues.\nExample scenario: Stop an ECS instance whose ID is i-bp1aq39j2yul5y01**** in the China (Hangzhou) (cn-hangzhou) region.\nSample command\nSample command output\nThis topic describes specific API operations. For information about other API operations, see List of operations by function.\nIn Alibaba Cloud CLI, you can specify command line options to change the behaviors of commands or implement the extended features of commands based on your business requirements. For more information, see Command line options for API calls."
    },
    "69": {
        "title": "Elastic Compute Service:Terraform references",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/terraform/",
        "content": "This Product\nElastic Compute Service:Terraform references\nTerraform is an open-source infrastructure as code (IaC) tool that allows developers to define and manage infrastructure configurations using a declarative language. It simplifies the creation, modification, and deletion of Elastic Compute Service (ECS) resources, reducing the complexity and potential errors associated with manual operations, thus enhancing infrastructure manageability and maintainability. This topic explains how to install and configure Terraform and demonstrates its use in creating an ECS instance.\nTerraform supports the automated orchestration of IT infrastructure, enabling code-based management and maintenance of IT resources. For more information, see Terraform product introduction.\nTerraform's command-line interface (CLI) provides a straightforward way to deploy configuration files on Alibaba Cloud or other supported clouds and manage their versions. It enables the definition of infrastructure resources such as virtual machines (VMs), storage accounts, and network interfaces in configuration files that describe cloud resource topologies.\nTerraform integrates with the Alibaba Cloud provider to support new infrastructure. You can use a template to configure the Alibaba Cloud provider to define, preview, and deploy cloud infrastructure on Alibaba Cloud.\nTerraform can create, modify, and delete resources related to various Alibaba Cloud products.\nFor more information about integrating Alibaba Cloud with Terraform, see Alibaba Cloud Provider.\nAlibaba Cloud Cloud Shell is a complimentary service that facilitates operations and maintenance tasks. It comes with Terraform pre-installed, enabling you to execute Terraform commands directly within Cloud Shell.\nFirst, ensure you have an active Alibaba Cloud account with the required permissions.\nNext, open a browser and navigate to the Cloud Shell address https://shell.alibabacloud.com.\nAfter a successful login, run the following command:\nYou will find that the Terraform component is already integrated into CloudShell and ready for use.\n\nFor additional Cloud Shell usage methods, see Using Cloud Shell.\nVisit the official Terraform website, locate the zip package for your operating system, and download it.\n\nOnce downloaded, extract the package to /usr/local/bin. After copying, you can delete the remaining files without affecting Terraform's operation.\n\nFinally, ensure that the Terraform directory is defined in the PATH variable, which may vary depending on the operating system.\n\nNavigate to Control Panel -> System -> System Settings -> Environment Variables.\nIn the system variables section, locate PATH.\nClick Edit and apply the necessary changes.\nEnsure you add a semicolon as the separator at the end of the previous entry, for example, c:\\path;c:\\path2\nOpen a new console for the changes to take effect.\nFor more details, see: Defining a global path in Windows.\nPrint your PATH configuration:\nMove the Terraform binary file to one of the locations listed. This command assumes the binary file is in your Downloads folder and that your PATH includes /usr/local/bin. If your directory differs, customize the command accordingly.\nFor additional information, see:\nDefining a global path in Linux.\nDefining a global path in Mac.\nTo compile the binary file from source code, clone the HashiCorp Terraform repository.\nYou will see the following progress information. Wait for the process to complete.\n\nAfter completion, a directory named terraform will be created in the directory where you executed the command. Use the cd command to enter this directory.\nNext, execute the install command to compile the directory and move the compiled package to the $GOPATH/bin/terraform directory.\nWhen you see the following prompt, the compilation is underway. Wait for it to finish before moving on to the next step.\n\nNote: If you encounter the message 'zsh: command not found: go', you need to install the Go environment first.\nFinally, ensure that the terraform directory is included in the PATH. The method for defining the PATH depends on your operating system.\nPrint your PATH configuration:\nMove the Terraform binary file to one of the listed locations. This command assumes the binary file is in your Downloads folder and that your PATH includes /usr/local/bin. Customize the directory in the command if needed.\nFor more details, see:\nDefining a global path in Linux.\nDefining a global path in Mac.\nNavigate to Control Panel -> System -> System Settings -> Environment Variables.\nIn the system variables section, locate PATH.\nClick Edit and apply the necessary changes.\nEnsure you add a semicolon as the separator at the end of the previous entry, for example, c:\\path;c:\\path2\nOpen a new console for the changes to take effect.\nFor more information, see: Defining a global path in Windows.\nHomebrew is a widely-used package manager for Mac systems. It simplifies the installation of Terraform with straightforward commands.\nFirst, install HashiCorp's tap to define the package's location in Homebrew.\nThen, execute the installation command to install Terraform:\nThe installation command will index the latest version and install it. To update to the latest version at a later time, simply re-execute the upgrade command.\nTo update to the latest Terraform version, first update Homebrew:\nThen, run the upgrade command to update to the latest version:\n\n\n\nChocolatey is a popular package manager for Windows. Using Chocolatey, you can install Terraform with simple commands.\nIdentity authentication using environment variables involves storing access credentials in specific environment variables. When executing Terraform commands, if the configuration template does not explicitly declare access credentials, Terraform will attempt to retrieve them from the following environment variables:\nRight-click This PC on the desktop and select Properties > > Advanced System Settings > > Environment Variables > > System Variables/User Variables.\nIn System Variables/User Variables, click New to create the following environment variables.\nVariable name\nVariable description\nVariable value\nALICLOUD_ACCESS_KEY\nAccess Key Id\nExample: LTAIUrZCw3********\nALICLOUD_SECRET_KEY\nAccess Key Secret\nExample: zfwwWAMWIAiooj14GQ2*************\nALICLOUD_SECURITY_TOKEN (optional)\nIf the access credential is for STS, configure the Security Token here\nExample: sts.fr2nlrnlwnelr3*******\nEnvironment variables configured with the export command are temporary and valid only for the current session. To set permanent environment variables, add the export command to your operating system's startup configuration file.\nAfter setting the environment variables, the provider block in the configuration template does not need to explicitly declare credentials, or it can declare only the region information:\nAdditionally, the region can be set through the environment variable ALICLOUD_REGION. If the region is not declared or set in the environment variable, cn-beijing will be used as the default value.\nResource: a new resource, such as an ECS instance, a virtual machine (VM), or a security group, that is used to define an infrastructure component.\nResource\nThe alicloud_auto_provisioning_group resource facilitates the rapid deployment of ECS clusters by utilizing preemptible and pay-as-you-go instances.\nalicloud_ecs_disk_attachment: This resource is used to attach either data disks or system disks to ECS instances.\nalicloud_ecs_activation is a resource that generates ECS activation codes. It enables users to set various parameters, including a description, the maximum number of instances that can be registered, a default prefix for instance names, an allowed IP address range for activation code usage, and the activation code's expiration period for batch registration of managed instances.\nalicloud_ecs_auto_snapshot_policy is a resource designed to create automatic snapshot policies for ECS. Users can configure various parameters, including the frequency of snapshot creation (specific days of the week), the times during the day when snapshots are taken, and the retention period for these snapshots. This resource also enables cross-region replication and encryption settings for snapshots.\nalicloud_ecs_auto_snapshot_policy_attachment: This resource enables the attachment of automatic snapshot policies to specified disks. Users can link the configuration by providing the automatic snapshot policy ID and disk ID, thereby applying the predetermined automatic snapshot policy to the selected disks.\nalicloud_ecs_capacity_reservation is a resource that enables users to create capacity reservations on Alibaba Cloud. This ensures the availability of resources for certain instance types, guaranteeing the ability to launch a specified number of instances as required.\nThe alicloud_ecs_command resource allows the creation of commands on Alibaba Cloud ECS instances. Users can execute predefined script commands by specifying various parameters, including command content with Base64 encoding, description, custom parameter enablement, command name, timeout, and command type.\nalicloud_ecs_dedicated_host is a resource that enables the creation of dedicated hosts on Alibaba Cloud. It allows users to configure various parameters, including host type, billing method, auto-renewal cycle, host name, and description.\nThe alicloud_ecs_dedicated_host_cluster resource enables the creation of dedicated host clusters on Alibaba Cloud. Users can configure various parameters, including cluster name, description, zone, and tags, for centralized management and organization of dedicated host resources.\nalicloud_ecs_deployment_set is a resource that facilitates the creation of deployment sets on Alibaba Cloud. It enables users to manage and organize ECS instances distribution by setting parameters like deployment strategy, deployment set name, and description, aiming to meet deployment objectives such as high availability or reduced latency.\nalicloud_ecs_disk is a resource designed for the creation of cloud-based data disks on Alibaba Cloud. It enables users to customize settings including disk type, size, encryption, snapshot ID, performance level, and tags to accommodate various storage requirements.\nThe alicloud_ecs_disk_attachment resource facilitates the mounting and unmounting of ECS instances and disks on Alibaba Cloud. It enables users to link instances and disks by specifying their respective IDs, and offers options including whether to release the disk alongside the instance and if it should be mounted as a system disk.\nThe alicloud_ecs_elasticity_assurance resource allows you to create an elasticity assurance on Alibaba Cloud, guaranteeing the reservation of a specified capacity of computing resources for certain instance types within designated regions.\nalicloud_ecs_hpc_cluster: This resource enables the creation of high-performance computing (HPC) clusters on Alibaba Cloud. Users can configure the cluster's basic information by specifying its name and description.\nalicloud_ecs_image_component is a resource that enables users to create image components on Alibaba Cloud. It allows for the definition of content, type, compatible operating systems, and additional metadata for build or test components, facilitating their reuse in the creation of custom images.\nThe alicloud_ecs_image_pipeline resource enables users to automate the creation and management of custom images on Alibaba Cloud by defining parameters like base image, build content, instance type, and additional configurations.\nalicloud_ecs_image_pipeline_execution is a resource that executes image pipeline tasks on Alibaba Cloud. It facilitates the creation of custom images through predefined image pipelines, initiates image build tasks by specifying the image pipeline ID, and enables users to monitor the task status and outcomes.\nalicloud_ecs_invocation is a resource designed to manage and execute commands on ECS instances. It enables users to execute specific commands across one or multiple ECS instances and retrieve the results.\nalicloud_ecs_key_pair: This resource manages and creates key pairs for ECS instances.\nalicloud_ecs_key_pair_attachment is a resource that attaches existing ECS key pairs to specified ECS instances.\nalicloud_ecs_launch_template: This resource manages ECS launch templates, enabling users to rapidly create and deploy ECS instances with predefined configurations, enhancing efficiency and ensuring uniformity.\nalicloud_ecs_network_interface is a resource designed to manage ECS network interfaces. It enables users to configure and manage instance network connectivity, supports flexible private IP allocation strategies, and is ideal for complex network environments and high availability architectural designs.\nalicloud_ecs_network_interface_attachment: This resource enables the attachment of Elastic Network Interfaces (ENIs) to ECS instances on Alibaba Cloud, allowing for the flexible expansion of network capabilities, including the addition of multiple IP addresses and the implementation of more intricate network configurations.\nThe alicloud_ecs_network_interface_permission resource manages permissions for ECS network interfaces.\nThe alicloud_ecs_prefix_list resource is used for creating and managing prefix lists within the Alibaba Cloud ECS service.\nalicloud_ecs_session_manager_status: This resource manages and configures the session manager status within the Alibaba Cloud ECS service. It enables users to control access and management methods for ECS instances by allowing them to enable or disable session management functions.\nalicloud_ecs_snapshot is a resource that enables users to create disk snapshots on Alibaba Cloud, providing a means to back up data on specified disks for future recovery or archiving purposes.\nalicloud_ecs_snapshot_group: This resource facilitates the creation of snapshots for a collection of disks on Alibaba Cloud.\nalicloud_ecs_storage_capacity_unit: This resource is used to create and manage storage capacity units within the Alibaba Cloud ECS service.\nThe alicloud_image resource allows the creation of custom images from existing ECS instances within Alibaba Cloud.\nThe alicloud_image_copy resource facilitates the copying of custom images between regions.\nalicloud_image_export is a resource that allows the export of custom images to an OSS bucket located in the same region as the image.\nThe alicloud_image_import resource facilitates the import of ECS images.\nThe alicloud_image_share_permission resource manages image sharing permissions.\nThe alicloud_instance resource facilitates the provisioning of ECS instances.\nalicloud_ecs_key_pair: This resource facilitates the creation and management of ECS key pairs.\nThe alicloud_ecs_key_pair_attachment resource allows for the attachment of key pairs to multiple ECS instances.\nThe alicloud_ecs_launch_template resource facilitates the provision of ECS launch templates.\nThe alicloud_ecs_network_interface resource facilitates the provision of ECS network interfaces.\nThe alicloud_ecs_network_interface_attachment resource facilitates the attachment of network interfaces to ECS instances.\nalicloud_ram_role_attachment is a resource designed to attach RAM roles to multiple ECS instances.\nalicloud_reserved_instance: This resource offers reserved instance capacities.\nalicloud_security_group: This resource facilitates the creation of ECS security groups.\nalicloud_security_group_rule: This resource is used to manage security group rules.\nThe alicloud_ecs_snapshot resource facilitates the creation of ECS snapshot resources.\nThe alicloud_ecs_auto_snapshot_policy resource facilitates the creation of ECS automatic snapshot policies.\nThis section explains how to use Terraform to create an ECS instance.\nCreate a working directory and within it, create a configuration file named main.tf. The code below will set up an ECS instance along with the necessary VPC, security group, and switch resources. Copy the code into main.tf.\nInitialize the Terraform runtime environment by running the following command.\nIf you receive the following message, Terraform has been successfully initialized.\nExecute the code by running the command below.\nWhen prompted, type yes and press the Enter key. Wait for the process to complete. A successful execution will display the following information.\n\nVerify the Results\nTo view the details of the resources created by Terraform, run the following command in the working directory:\n\nAccess the Elastic Compute Service management console. Navigate to the Instances & Images > > Instances section, select a region from the upper-left corner, and choose China (Beijing) to view the ECS instance you created.\n\nFor additional practice tutorials, refer to Terraform tutorials.\nFor a list of common Terraform commands, see Common Commands.\nTerraform is available as a managed service in ROS. You can deploy Terraform templates in the ROS console. For more information, see Create a Terraform stack.\n"
    },
    "70": {
        "title": "Elastic Compute Service:ROS reference",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/ros",
        "content": "This Product\nElastic Compute Service:ROS reference\nYou can create templates in Resource Orchestration Service (ROS) to define Alibaba Cloud Elastic Compute Service (ECS) resources, such as ECS instances and security groups, and the dependencies between the resources. The orchestration engine of ROS creates and configures all resources based on the templates to implement automated deployment and O&M. This topic describes how to use a ROS template to automatically create an ECS instance.\nROS is an Alibaba Cloud service that helps simplify the management of cloud computing resources. For more information, see What is ROS?\nThe resources that can be orchestrated by using ROS include regular and data source resources. For more information, see ECS.\nRegular resources\nALIYUN::ECS::AutoProvisioningGroup: creates an auto provisioning group.\nALIYUN::ECS::AutoSnapshotPolicy: creates an automatic snapshot policy.\nALIYUN::ECS::AssignIpv6Addresses: assigns IPv6 addresses to an elastic network interface (ENI).\nALIYUN::ECS::AssignPrivateIpAddresses: assigns secondary private IP addresses to an ENI.\nALIYUN::ECS::Command: creates a Cloud Assistant command.\nALIYUN::ECS::CopyImage: copies a custom image from one region to another region.\nALIYUN::ECS::CustomImage: creates a custom image.\nALIYUN::ECS::DedicatedHost: creates a dedicated host.\nALIYUN::ECS::DeploymentSet: creates a deployment set.\nALIYUN::ECS::Disk: creates a data disk.\nALIYUN::ECS::DiskAttachment: attaches a data disk to an ECS instance.\nALIYUN::ECS::ForwardEntry: configures a Destination Network Address Translation (DNAT) table for a NAT gateway.\nALIYUN::ECS::HpcCluster: creates a High Performance Computing (HPC) cluster.\nALIYUN::ECS::Instance: creates an ECS instance.\nALIYUN::ECS::InstanceClone: clones an ECS instance.\nALIYUN::ECS::InstanceGroup: creates ECS instances.\nALIYUN::ECS::InstanceGroupClone: clones an ECS instance to create one or more ECS instances.\nALIYUN::ECS::Invocation: runs a Cloud Assistant command on ECS instances.\nALIYUN::ECS::JoinSecurityGroup: adds ECS instances to a security group.\nALIYUN::ECS::LaunchTemplate: creates a launch template.\nALIYUN::ECS::NetworkInterface: creates an ENI.\nALIYUN::ECS::NetworkInterfaceAttachment: attaches an ENI to an ECS instance in a virtual private cloud (VPC).\nALIYUN::ECS::NetworkInterfacePermission: grants permissions on an ENI to an account.\nALIYUN::ECS::PrefixList: creates a prefix list.\nALIYUN::ECS::Route: creates a custom route entry.\nALIYUN::ECS::RunCommand: runs a shell, PowerShell, or batch command on ECS instances.\nALIYUN::ECS::SNatEntry: configures a Source Network Address Translation (SNAT) table for a NAT gateway.\nALIYUN::ECS::SecurityGroup: creates a security group.\nALIYUN::ECS::SecurityGroupClone: clones a security group.\nALIYUN::ECS::SecurityGroupEgress: creates an outbound rule in a security group.\nALIYUN::ECS::SecurityGroupIngress: creates an inbound rule in a security group.\nALIYUN::ECS::Snapshot: creates a snapshot for a disk.\nALIYUN::ECS::SSHKeyPair: creates an SSH key pair.\nALIYUN::ECS::SSHKeyPairAttachment: binds an SSH key pair to ECS instances.\nALIYUN::ECS::VPC: creates a VPC.\nALIYUN::ECS::VSwitch: creates a vSwitch in a VPC.\nALIYUN::ECS::RamRoleAttachment: attaches an instance Resource Access Management (RAM) role to ECS instances.\nALIYUN::ECS::Activation: creates an activation code.\nALIYUN::ECS::ImageSharePermission: manages the share permissions on a custom image.\nALIYUN::ECS::CapacityReservation: creates a capacity reservation.\nALIYUN::ECS::ElasticityAssurance: creates an elasticity assurance.\nALIYUN::ECS::ImagePipeline: creates an image template.\nALIYUN::ECS::ImageComponent: creates an image component.\nALIYUN::ECS::SecurityGroupEgresses: associates multiple outbound rules with a security group at a time.\nALIYUN::ECS::SecurityGroupIngresses: associates multiple inbound rules with a security group at a time.\nALIYUN::ECS::SnapshotGroup: creates a snapshot-consistent group for the disks of an ECS instance. A snapshot-consistent group contains snapshots of one or more disks.\nData source resources\nDATASOURCE::ECS::AutoSnapshotPolicies: queries automatic snapshot policies.\nDATASOURCE::ECS::DedicatedHosts: queries the details of dedicated hosts.\nDATASOURCE::ECS::DeploymentSets: queries the attributes of one or more deployment sets.\nDATASOURCE::ECS::Disks: queries block storage devices that you created, including cloud disks and local disks.\nDATASOURCE::ECS::DiskCategories: queries disk categories.\nDATASOURCE::ECS::HpcClusters: queries available HPC clusters.\nDATASOURCE::ECS::Images: queries available images.\nDATASOURCE::ECS::Instances: queries the details of ECS instances.\nDATASOURCE::ECS::KeyPairs: queries key pairs.\nDATASOURCE::ECS::NetworkInterfaces: queries the details of ENIs.\nDATASOURCE::ECS::RecommendInstanceTypes: queries ECS instance types.\nDATASOURCE::ECS::SecurityGroups: queries the basic information about security groups.\nDATASOURCE::ECS::Snapshots: queries all snapshots of an ECS instance or a cloud disk.\nDATASOURCE::ECS::Zones: queries zones.\nDATASOURCE::ECS::ManagedInstances: queries managed instances.\nDATASOURCE::ECS::Commands: queries all available commands that you created.Elastic Compute Service (ECS)\nDATASOURCE::ECS::DedicatedHostClusters: queries information about dedicated host clusters.\nDATASOURCE::ECS::Activations: queries activation codes.\nDATASOURCE::ECS::Activation: queries the details of an activation code.\nDATASOURCE::ECS::AutoSnapshotPolicy: queries the details of an automatic snapshot policy.\nDATASOURCE::ECS::Command: queries the details of an available command that you created.\nDATASOURCE::ECS::DedicatedHostCluster: queries the details of a dedicated host cluster.\nDATASOURCE::ECS::DeploymentSet: queries the details of a deployment set.\nDATASOURCE::ECS::Disk: queries the details of a cloud disk.\nDATASOURCE::ECS::HpcCluster: queries the details of an HPC cluster.\nDATASOURCE::ECS::Instance: queries the details of an ECS instance.\nDATASOURCE::ECS::KeyPair: queries the details of a key pair.\nDATASOURCE::ECS::LaunchTemplate: queries the details of a launch template.\nDATASOURCE::ECS::SecurityGroup: queries the details of a security group.\nDATASOURCE::ECS::Snapshot: queries the details of a snapshot.\nDATASOURCE::ECS::LaunchTemplates: queries available launch templates.\nThis section describes how to create an ECS instance based on a predefined ROS template.\nBy default, ROS uses the credentials of the user logged on to the ROS console. If you log on to the ROS console by using an Alibaba Cloud account, you do not need to obtain the permissions described in the following table. If you log on to the ROS console as a RAM user, the user must obtain the required permissions. The following table describes the permissions.\nAlibaba Cloud service\nRequired permission\nVirtual Private Cloud\nAliyunVPCFullAccess: the permissions to query VPCs and vSwitches and create elastic IP addresses (EIPs).\nElastic Compute Service\nAliyunECSFullAccess: the permissions to create and manage ECS resources, such as ECS instances.\nResource Orchestration Service\nAliyunROSFullAccess: the permissions to create and manage ROS resources, such as stacks.\nElastic IP Address\nAliyunEIPFullAccess: the permissions to create and manage EIPs.\nThe following figure shows the architecture of resources required by the Elastic Compute Service instance that you want to create.\nRegion: Select the region in which you want to create an ECS instance. The region that you select in the ECS console is automatically used. You do not need to specify a region.\nNetwork and zone: Alibaba Cloud provides a default VPC per region and a default vSwitch per zone in each default VPC.\nInstance type: Select an instance type, such as an instance type that has 2 vCPUs and 4 GiB of memory.\nImage: Select an image, such as an Alibaba Cloud Linux image or a Windows Server image. An image contains the operating system and provisioned data that are required to start and run an ECS instance.\nStorage: Configure Elastic Block Storage (EBS) devices as the system disk and data disks of the ECS instance based on your business requirements.\nEIP: Create an EIP for the ECS instance. The instance can be accessed by using the EIP.\nSecurity group: Select or create a security group for the ECS instance. A security group serves as a virtual firewall to control inbound and outbound traffic for ECS instances.\nKey pair: Select or create a key pair for the ECS instance. Alibaba Cloud provides the secure and convenient key pair-based authentication method for logons to ECS instances. Key pairs are security credentials used for authentication. After you create a key pair, the public key is stored on the ECS instance, and the private key is stored on your on-premises computer.\nThe preceding resources correspond to the following Resource Orchestration Service resources:\nRegion: The region that you select in the ROS console is automatically used. You do not need to specify a region.\nNetwork and zone: ALIYUN::ECS::VPC.\nInstance type: DATASOURCE::ECS::Instance.\nImage: DATASOURCE::ECS::Images.\nStorage: ALIYUN::ECS::Disk.\nEIP: ALIYUN::VPC::EIP.\nSecurity group: ALIYUN::ECS::SecurityGroup.\nKey pair: DATASOURCE::ECS::KeyPair.\nClick Quick Deploy and perform the following operations.\nLog on to the ROS console. In the top navigation bar, select a region from the Region drop-down list.\nIn the left-side navigation pane, click Stacks. On the Stacks page, choose Create Stack. On the Create Stack page, configure the Specify Template parameter. In this example, the Specify Template parameter is set to Use a Sample Template. In this case, you must select a sample template provided by ROS from the Sample Templates drop-down list.\nConfirm the template content in the Template Content code editor and click Next.\nIn this example, a sample template that uses an existing VPC, vSwitch, and security group is selected to create two ECS instances and associate EIPs with the instances. The following code snippets show the sample template content in the YAML and JSON formats:\nTemplate content in YAML format\nTemplate content in JSON format\nFollow the on-screen instructions to configure the parameters, such as VPC ID, VSwitch Availability Zone, VSwitch ID, and Business Security Group ID, based on your business requirements. Then, click Create to create a stack.\nView the result.\n\nWhen the stack is created, ECS instances are created based on the template specified in the stack and enter the Running state. You can view the instances in the ECS console, by calling an API operation, or by using an SDK.\nROS allows you to deploy resources with a few clicks in various scenarios, such as environment building, website building, application building, and Artificial Intelligence Generated Content (AIGC) practices. For information about more use cases for ROS, see the following topics:\nIPv6 communication\nInstall Docker\nDeploy MySQL on a Linux instance\nUse ROS to deploy an LNMP stack\nBuild a WordPress website by using ROS\nBuild an FTP site on a Linux instance\nBuild a Hadoop environment\nDeploy a Java web environment on an instance that runs Alibaba Cloud Linux 2, Alibaba Cloud Linux 3, or CentOS 7.x\nDeploy and use SVN\nConnect an ECS instance to an ApsaraDB RDS instance to initialize data"
    },
    "71": {
        "title": "Elastic Compute Service:Best practices and common issues in development",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/appendix/",
        "content": "This Product\nElastic Compute Service:Best practices and common issues in development"
    },
    "72": {
        "title": "Elastic Compute Service:ECS FAQs",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/faq",
        "content": "This Product\nElastic Compute Service:ECS FAQs\nThis topic provides a summary of common issues and their solutions for Elastic Compute Service (ECS) users.\nBilling FAQ\nInstance FAQ\nConnection FAQ\nBlock Storage FAQ\nImage FAQ\nSnapshot FAQ\nSecurity FAQ\nNetwork FAQ\nFAQ about O&M and monitoring\nCloud Migration Tool FAQ\nBest Practices and Common Issues in Development\n"
    },
    "73": {
        "title": "Elastic Compute Service:Instance downtime issues",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/instance-downtime-issues/",
        "content": "This Product\nElastic Compute Service:Instance downtime issues"
    },
    "74": {
        "title": "Elastic Compute Service:Instance startup issues",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/solution-of-instances-cannot-be-started/",
        "content": "This Product\nElastic Compute Service:Instance startup issues"
    },
    "75": {
        "title": "Elastic Compute Service:Operating system issues",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/the-operating-system-problem/",
        "content": "This Product\nElastic Compute Service:Operating system issues"
    },
    "76": {
        "title": "Elastic Compute Service:High load issues on ECS instances",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/instance-high-load-problem/",
        "content": "This Product\nElastic Compute Service:High load issues on ECS instances"
    },
    "77": {
        "title": "Elastic Compute Service:Network connection issues",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/ecs-instances-within-the-website-slow-or-cannot-access-problems/",
        "content": "This Product\nElastic Compute Service:Network connection issues"
    },
    "78": {
        "title": "Elastic Compute Service:Disk and memory issues",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/memory-issues/",
        "content": "This Product\nElastic Compute Service:Disk and memory issues"
    },
    "79": {
        "title": "Elastic Compute Service:Other issues of ECS usage",
        "url": "https://www.alibabacloud.com/help/en/ecs/support/other-issues-when-using-ecs",
        "content": "This Product\nElastic Compute Service:Other issues of ECS usage\nThis topic describes the common issues that may occur when you configure and use third-party software on Elastic Compute Service (ECS) instances and provides the corresponding solutions.\nAfter you install and log on to MySQL on an ECS instance, the following error message appears when you connect to MySQL from a remote IP address by using the correct username and password: 1045 - Access denied for user 'root'@'****'(using password:YES).\n\nAfter you install MySQL on the ECS instance, MySQL allows logons only from the local IP addresses and does not allow logons from remote IP addresses.\nPerform the following steps to allow logons to MySQL from remote IP addresses:\nConnect to the ECS instance.\nFor more information, see Methods for connecting to an ECS instance.\nLog on to MySQL and execute the following SQL statement to grant remote logon permissions on MySQL to the root user:\nAfter you execute the preceding SQL statement, the root user can log on to MySQL from all IP addresses and perform operations on objects in MySQL databases.\nThe following table describes the parameters in the SQL statement.\nParameter\nDescription\n*.*\nThe first asterisk (*) is a database placeholder. If you specify *, this parameter specifies all databases. The second asterisk (*) is a placeholder for database tables. If you specify *, this parameter specifies all tables in the database.\n'root'@'%'\nroot is the database account to which the logon permissions are granted. The percent sign (%) is an IP address placeholder. For example, if you want only the 1.1.1.1 IP address to log on to the databases, change % to 1.1.1.1. If you specify %, this parameter specifies that all IP addresses are allowed to log on.\nTo refresh permissions, execute the following SQL statement:\nReconnect to MySQL. If the issue is resolved, the preceding error message no longer appears.\nYou cannot connect to MySQL on a Linux ECS instance and receive the following error message: ERROR 2003 (HY000): Can't connect to MySQL server on '39.106.**.**' (110).\nThe preceding issue may occur because port 3306 on the Linux ECS instance is not in the Listening state. As a result, the 39.106.**.** IP address of the instance does not have access to MySQL.\nConnect to the Linux ECS instance on which MySQL is installed.\nFor more information, see Connect to a Linux instance by using a password or a key.\nRun the following command to back up the my.cnf configuration file:\nModify the my.cnf configuration file.\nRun the following command to open the my.cnf configuration file:\nPress the i key to enter Insert mode and add the following content to the my.cnf file:\nThe following figure shows where the content is added.\n\nPress the Esc key to exit Insert mode, enter :wq, and then press the Enter key to save and close the file.\nRun the following command to restart MySQL and make sure that port 3306 is in the Listening state:\nYou cannot use VSFTP to upload files to a Linux ECS instance, and the \"553 Could not create file\" error message appears.\nThe preceding issue may occur because of the following reasons:\nThe disk space of the Linux instance is full.\nThe write permissions on the FTP home directory are not granted.\nPerform the following steps to check the disk space usage of the Linux instance and the permissions on the FTP home directory:\nConnect to the Linux ECS instance.\nFor more information, see Connect to a Linux instance by using a password or key.\nRun the following command to check whether the disk space of the instance is full:\nIf the partition usage on a disk reaches 100%, the disk space is full.\nThe following figure shows a sample command output. In the sample command output, the usage of the /dev/xvda1 partition is 59%.\n\nRun the following command to check whether the write permissions on the FTP home directory are granted.\nSpecify the actual FTP home directory. In this example, the /home/user directory is used as the FTP home directory.\nIf the write permissions on the FTP home directory are not granted, w is not included in the permission settings, as shown in the red box in the following figure.\n\nRun the following command to grant the write permissions on the FTP home directory:\nRun the following command to check whether the write permissions on the FTP home directory are granted. If w is displayed in the command output, the write permissions on the FTP home directory are granted.\nThe 550 Permission denied error message appears when you upload a file to FileZilla Server by using FTP on a Windows ECS instance.\n\nThe FTP account does not have the write permissions on FileZilla Server.\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nRun FileZilla Server. In the Users window, select Shared folders.\nSelect the user and directory that correspond to the FTP account, select Write, and then click OK to grant the write permissions to the user.\n\nAn AD domain controller cannot be installed on a Windows ECS instance and the \"Failed to install active directory domain services binaries\" error message appears.\n\nThe error displayed on the Windows Event Viewer indicates that the Remote Registry service is disabled and cannot be started as expected.\nPerform the following steps to start the Remote Registry service:\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nIn the taskbar on the desktop, click Start and select Run. In the Run dialog box, enter services.msc and click OK.\nIn the Services window, double-click Remote Registry to open the Remote Registry Properties window. In the Remote Registry Properties window, configure the following settings:\nSet Startup type to Automatic.\nIn the Service status section, click Start and make sure that the Remote Registry service can be started as expected.\n\nClick OK.\nWhen you install an AD domain controller on a Windows ECS instance, the \"This computer has dynamically assigned IP addresses\" error message appears.\n\nAt least one physical network adapter on the instance does not have a static IP address.\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nInstall an AD domain controller.\nIn the Static IP assignment window, click Yes.\nLoopback uses the Dynamic Host Configuration Protocol (DHCP) and can work as expected without a static IP address.\nWhen you install an AD domain controller on a Windows ECS instance, the 0x0000232B RCODE_NAME_ERROR error code is returned.\n\nIP addresses are incorrectly configured in the DNS server.\nPerform the following steps to change the DNS server addresses to the private IP address of the Windows ECS instance:\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nOpen the Internet Protocol Version 4 (TCP/IP) Properties window, change the DNS server addresses, and then click OK.\nChange the DNS server addresses to the private IP address of the Windows ECS instance.\n\nCheck whether the IP address of the DNS server can be pinged.\nWhen you install an AD domain controller on a Windows ECS instance, the \"The network path was not found\" error message appears.\n\nThe preceding issue may occur because of the following reasons:\nThe TCP/IP NetBIOS Helper and Remote Registry services are not started on the AD domain controller and the client.\nThe DNS configurations of the AD domain controller and the client are incorrect.\nThe security identifier (SID) of the client is the same as the SID of the AD domain controller.\nThe firewall or security software blocks the client.\nPerform the following operations:\nStart the TCP/IP NetBIOS Helper and Remote Registry services\nStart the TCP/IP NetBIOS Helper and Remote Registry services on the ECS instance on which you want to install AD domain controller and the ECS instance that serves as the client. For more information, see the Solution subsections in the \"AD domain controller installation failures\" section of this topic.\nModify the DNS configurations of the client\nFor more information, see the Solution subsections in the \"AD domain controller installation failures\" section of this topic.\nChange the SID of the client\nPerform the following steps:\nConnect to the Windows ECS instance that serves as the client.\nFor more information, see Connect to a Windows instance by using a password.\nDownload the PowerShell script that is used to change the SID of the client.\nDownload link: AutoSysprep.ps1\nScript source: Alibaba Cloud\nOpen Command Prompt and enter PowerShell. The Windows PowerShell window appears.\nIf your ECS instance runs a 64-bit operating system, do not use a 32-bit PowerShell (Windows PowerShell (x86)) script. Otherwise, an error occurs.\nGo to the path in which the script is stored and run the following command to view the description of the script tool:\nRun the following command to re-initialize the SID of the client:\nAfter the SID is initialized, the ECS instance that serves as the client is restarted. Take note of the following items:\nThe IP address of the client is changed from a dynamic IP address that is assigned based on DHCP to a static IP address. Make sure that the static IP address is the same as the IP address of the ECS instance. You can configure the IP address that you want to assign based on DHCP to obtain the primary private IP address of the ECS instance.\nDo not change the primary private IP address of the ECS instance in the ECS console. Otherwise, access exceptions occur.\n\nAfter you re-initialize the SID, the configurations of the firewall on the ECS instance are changed to the default configurations of Microsoft. As a result, the instance cannot be pinged. You must disable the Windows firewall for the Guest or public networks profile or open the required ports.\nOpen Control Panel to disable the firewall for the Guest or public network profile.\n\nAfter you disable the Windows firewall for the Guest or public network profile, the instance can be pinged.\nConfigure the firewall or security software to allow access from the client\nFor more information, see Configure firewall rules for an ECS instance that runs Windows Server.\nWhen you run a wget command on a Linux ECS instance, the \"command not found\" error message appears. When you run the yum install wget command, the \"already installed and latest version\" error message appears.\nThe wge file exists in the /usr/bin directory instead of the wget file. The preceding issue may occur because the file is renamed wge.\nPerform the following steps:\nConnect to the Linux ECS instance.\nFor more information, see Connect to a Linux instance by using a password or key.\nRun the following command to query the path of the wge file:\nThe following command output is returned, which indicates that the wge file is stored in the /usr/bin/wge path:\nRun the following command to rename the wge file in the /usr/bin/wge directory:\nRerun the wget command. If the issue is resolved, the error message no longer appears.\nWhen you run a wget command to download data on a Linux ECS instance, the following error message appears:\nThe permissions of the wget utility on the Linux ECS instance are set to 000, which means that no user is allowed to read, write, or execute the utility.\nPerform the following steps:\nConnect to the Linux ECS instance.\nFor more information, see Connect to a Linux instance by using a password or key.\nRun the following command to query the permissions on the wget utility:\nThe following command output is returned, which indicates that the permissions of the wget utility are set to 000:\nRun the following command to query the attributes of the /usr/bin/wget directory:\nThe following command output is returned, which indicates that the /usr/bin/wget directory has the i attribute and is immutable. In this case, you cannot create files in or delete files from the directory.\nRun the following command to remove the i attribute of the /usr/bin/wget directory:\nRun the following command to grant permissions on the /usr/bin/wget directory:\nRerun the wget command. If the issue is resolved, the error message no longer appears.\nWindows instances\nYou cannot access an FTP server that is deployed on a Windows ECS instance from external networks.\nThe preceding issue may occur because of the following reasons:\nRequired FTP ports are not open in security groups of the Windows ECS instance. To resolve the issue, use Solution 1: Add security group rules to open the required FTP ports.\nThe FTP process is blocked by the firewall. To resolve the issue, use Solution 2: Configure the FTP Firewall Support feature.\nUse one of the following solutions to resolve the issue based on the actual scenario:\nSolution 1: Add security group rules to open the required FTP ports\nAfter you build an FTP site on the Windows ECS instance, add inbound rules to the security groups of the instance to open port 21 and ports in the range from 1024 to 65535 for passive connections to the FTP service. For information about how to add an inbound security group rule, see Add a security group rule.\nFor information about security groups, see Security groups for different use cases and Common ports.\nSolution 2: Configure the FTP Firewall Support feature\nIf your firewall is enabled, configure Internet Information Services (IIS) Manager to open TCP port 21 and ports in the range from 1024 to 65535 for the FTP service. Perform the following steps:\nBy default, the firewall of the Windows ECS instance is disabled.\nThis section describes how to use IIS Manager to configure FTP.\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nOpen IIS Manager and double-click FTP Firewall Support in the list of features in the middle pane.\n\nOn the FTP Firewall Support page in the middle pane, configure the parameters and click Apply in the Actions pane.\n\nTake note of the following parameters:\nExternal IP Address of Firewall: Enter the public IP address of the Windows ECS instance.\nData Channel Port Range: Enter a port range for passive connections to the FTP service. Valid range for port numbers: 1024 to 65535. Enter a port range based on your business requirements. In this example, 1024-65535 is entered.\nOpen Command Prompt and run the following command to restart the FTP service for the configurations of all FTP sites to take effect:\n(Optional) After you configure an FTP server on the Windows ECS instance, you can access the FTP service locally, but not from another ECS instance. This issue is caused by incorrect firewall configurations. To resolve the issue, perform the following steps:\nCheck the inbound rules in Server Manager to ensure that the FTP server is enabled.\n\nAdd the host process (svchost.exe) for Windows services.\nOpen Control Panel and click Windows Defender Firewall. In the left-side navigation pane of the Windows Defender Firewall window, click Allow an app or feature through Windows Defender Firewall.\nIn the window that appears, click Allow another app. Browse to C:\\Windows\\System32\\svchost.exe and add svchost.exe.\nThe Host Process for Windows Services option is displayed in the Allowed apps and features section. Select Private and Public for the option and click OK.\n\nWhen you connect to an FTP server that is deployed on a Windows ECS instance, the following error message appears:\nThe preceding issue may occur because of the following reasons:\nIncorrect FTP password: To resolve the issue, use Solution 1: Change the FTP password.\nInsufficient permissions of your FTP account: To resolve the issue, use Solution 2: Grant permissions to your FTP account.\nUse one of the following solutions to resolve the issue based on the actual scenario:\nSolution 1: Change the FTP password\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nOn the Windows desktop, right-click This PC and select Manage to open the Computer Management window.\nIn the left-side navigation pane, choose Local Users and Groups > Users. Right-click the FTP account that you use and select Set Password.\n\nSolution 2: Grant permissions to your FTP account\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nCheck whether a folder for sharing files with the FTP site exists.\nIf the folder does not exist, create the folder and grant the required permissions on the folder to your FTP account. For more information, see the Step 3: Configure permissions for sharing files section of the \"Build an FTP site on a Windows instance\" topic.\nIf the folder exists, right-click the folder, select Properties, click the Security tab, select your FTP account, and then grant the required permissions to the account.\n\nAfter you configure an FTP site in IIS 7.5 on a Windows ECS instance and bind a domain name to the FTP site, the 530 valid hostname is expected or 503 Login with USER first error message appears when you connect to the FTP server on the instance by using an IP address or other methods.\nThe format of the domain name that you entered when you connect to the FTP server is invalid.\nIf the www.example.com domain name is bound to the FTP site and you use the user username for connection, you must use the www.example.com|user domain name to connect to the FTP server.\nSeparate the domain name that is bound to the FTP site and the username with a vertical bar (|).\nYou can also remove the site bindings and directly use the username to connect to the FTP server, as shown in the following figure.\n\nThe 550 Permission denied error message appears when you upload a file to FileZilla Server by using FTP on a Windows ECS instance.\n\nThe FTP account does not have the write permissions on FileZilla Server.\nConnect to the Windows ECS instance.\nFor more information, see Connect to a Windows instance by using a password.\nRun FileZilla Server. In the Users window, select Shared folders.\nSelect the user and directory that correspond to the FTP account, select Write, and then click OK to grant the write permissions to the user.\n\nYou cannot use FTP over TLS to access an FTP site that is created by IIS on a Windows ECS instance, and the \"534 Policy requires SSL\" error message appears.\nThe \"534 Local policy on server does not allow TLS secure connections\" error message indicates that the issue is caused by incorrect parameter settings in FTP SSL Settings.\nConnect to the Windows ECS instance.\nFor more information, see Methods for connecting to an ECS instance.\nIn the lower-left corner of the desktop, choose  > Windows Administrative Tools > Internet Information Services (IIS) Manager.\nIn the FTP section on the FTP homepage, click FTP SSL Settings.\nOn the FTP SSL Settings page, set SSL Policy to Allow SSL connections. Then, click Apply in the Actions pane.\nAccess the FTP site.\nLinux instances\nWhen you upload a file to an FTP site deployed on a Linux ECS instance, the \"425 Security:Bad IP connection\" error message appears.\nIn most cases, the preceding issue occurs when the client resides in a NAT network and is associated with multiple public IP addresses. This causes inconsistencies between the source IP addresses of the two connections maintained by the FTP service and results in an error.\nThe FTP service simultaneously maintains two connections: a control connection and a data connection. By default, during data transmission, the FTP server checks whether the source IP addresses of the two connections are consistent. If the source IP addresses are inconsistent, the FTP server reports a \"425 Security: Bad IP connection\" error.\nPerform the following steps to disable the IP security check for FTP passive mode:\nConnect to the Linux ECS instance.\nFor more information, see Connect to a Linux instance by using a password or key.\nRun the following command to open the FTP configuration file:\nPress the i key to enter Insert mode and add the following content to the file:\nPress the Esc key to exit Insert mode. Then, enter :wq and press the Enter key to save and close the file.\nRun the following command to restart the FTP service:\nYou cannot use VSFTP to upload files to a Linux ECS instance, and the \"553 Could not create file\" error message appears.\nThe preceding issue may occur because of the following reasons:\nThe disk space of the Linux instance is full.\nThe write permissions on the FTP home directory are not granted.\nPerform the following steps to check the disk space usage of the Linux instance and the permissions on the FTP home directory:\nConnect to the Linux ECS instance.\nFor more information, see Connect to a Linux instance by using a password or key.\nRun the following command to check whether the disk space of the instance is full:\nIf the partition usage on a disk reaches 100%, the disk space is full.\nThe following figure shows a sample command output. In the sample command output, the usage of the /dev/xvda1 partition is 59%.\n\nRun the following command to check whether the write permissions on the FTP home directory are granted.\nSpecify the actual FTP home directory. In this example, the /home/user directory is used as the FTP home directory.\nIf the write permissions on the FTP home directory are not granted, w is not included in the permission settings, as shown in the red box in the following figure.\n\nRun the following command to grant the write permissions on the FTP home directory:\nRun the following command to check whether the write permissions on the FTP home directory are granted. If w is displayed in the command output, the write permissions on the FTP home directory are granted.\nThe token of the WeChat Official Accounts Platform that is deployed on an ECS instance fails verification.\n\nThe preceding issue may occur because of the following reasons:\nThe token file is improperly edited, such as by using Notepad or an online editor. As a result, a UTF-8 Byte Order Mark (BOM) signature is added to the file.\nSafe Dog or Security Center is installed on the ECS instance and blocks requests from the Tencent server.\nThe ECS instance uses a temporary domain name for the token verification, and the request is intercepted by the Tencent system.\nThe PHP file contains a line break or other characters after the closing tag.\nOther debugging verification methods are used.\nAn exception occurs during Gzip encryption in your program.\nPerform the following operations to resolve the issue based on the cause:\nThe token file is improperly edited, such as by using Notepad or an online editor\nTo remove the UTF-8 BOM signature from the token file, we recommend that you use a multifunctional editor.\nSafe Dog or Security Center is installed on the ECS instance\nWe recommend that you uninstall Safe Dog or add the Tencent server to the whitelist of Security Center.\nThe ECS instance uses a temporary domain name for the token verification\nWhen you perform verification, we recommend that you use a domain name that is registered with Alibaba Cloud.\nThe PHP file contains a line break or other characters after the closing tag\nDelete extra characters after the closing tag.\nOther debugging and verification methods are used\nRun the curl http://xxx/index.php/api/xx command to perform debugging and verification. Simulate a WeChat API request and perform analysis.\nAn exception occurs during Gzip encryption in your program\nWe recommend that you temporarily disable the Gzip encryption feature for your program and troubleshoot the issue.\nWhen you connect to a Linux ECS instance by using a third-party SSH client, the Chinese characters on the instance are garbled.\n\nThe preceding issue may occur because of the following reasons:\nChinese fonts are not installed on the Linux operating system. By default, Linux does not support the display of Chinese characters. To enable the display of Chinese characters on Linux, you must install a Chinese language pack by using Solution 1: Install a Chinese language pack on Linux.\nThe character set of the third-party SSH client tool is incorrectly configured. To resolve the issue, use Solution 2: Modify the character set of the third-party SSH client tool.\nUse one of the following solutions to resolve the issue based on the actual scenario:\nSolution 1: Install a Chinese language pack on the Linux ECS instance\nIn this example, an instance that runs CentOS 7.8 is used. Configurations and commands may vary based on the operating system, such as specific CentOS versions and distributions such as Red Hat, Debian, and Ubuntu. For more information, see the official documentation of the operating systems.\nCentOS 6 and CentOS 8 reached the end of life (EOL). In compliance with Linux community rules, all content is removed from the default repository addresses of CentOS 6 and CentOS 8. If you continue using the default repository addresses of CentOS 6 or CentOS 8, an error is reported. We recommend that you change the repository addresses of CentOS 6 or CentOS 8. For more information, see How do I change CentOS 6 repository addresses? and Change CentOS 8 repository addresses.\nConnect to the Linux ECS instance.\nFor more information, see Connect to a Windows instance by using a password or key.\nRun the following command to query the language that is used by the operating system:\nIf English is used, proceed to Step 3.\nIf Chinese is used, a Chinese language pack is installed on the Linux operating system. In this case, the garbled Chinese characters are not caused by unsupported Chinese fonts. To resolve the issue, use Solution 2: Modify the character set of the third-party SSH client tool.\nRun the following command to check whether a Chinese language pack is installed on the operating system:\nThe following command output is displayed. zh indicates Chinese, CN indicates China, and gb18030, gb2312, gbk, and utf8 are character sets.\nIf a Chinese language pack is not installed, run the following command to install the language pack:\nRun the following command to open the /etc/locale.conf configuration file:\nPress the i key to enter Insert mode. Then, change LANG=en_US.UTF-8 to LANG=zh_CN.UTF-8 to change the system language to Chinese.\nPress the Esc key, enter :wq, and then press the Enter key to save and close the configuration file.\nRun the following command for the configuration to take effect:\nRun the following command to restart the instance:\n(Optional) If the system language is still English after the instance is restarted, run the following command to open the /etc/profile.d/lang.sh configuration file:\nPress the i key to enter Insert mode. Then, change zh*) LANG=en_US.UTF-8 to zh*) LANG=zh_CN.UTF-8. The following figure shows the modified content.\nPress the Esc key, enter :wq, and then press the Enter key to save and close the configuration file.\nRun the following command to restart the instance:\nSolution 2: Modify the character set of the third-party SSH client tool\nThe following section describes how to change the character set of the Xshell client.\nOpen the Xshell client.\nIn the Xshell client window, set Default Language to Unicode (UTF-8).\n\nLog on to the instance. If the issue is resolved, the error message no longer appears."
    },
    "80": {
        "title": "Elastic Compute Service:What is ECS?",
        "url": "https://www.alibabacloud.com/help/en/ecs/product-overview/what-is-ecs",
        "content": "This Product\nElastic Compute Service:What is ECS?\nElastic Compute Service (ECS) is a high-performance, stable, reliable, and scalable IaaS-level service provided by Alibaba Cloud. ECS eliminates your need to invest in hardware up front. You can create as many or as few instances as you need in response to changes in requirements or popularity of your workloads. ECS provides a variety of instance types that suit various business needs and helps boost business growth.\nDiversified computing capabilities: Alibaba Cloud ECS supports the mainstream x86 and Arm architectures and provides various types of instances, including compute-optimized, GPU-accelerated, ECS Bare Metal, and Super Computing Cluster (SCC) instances, from hundreds of instance families to meet the business requirements of customers of different scales and types.\nEase of use: You do not need to build self-managed data centers. Alibaba Cloud can deliver ECS instances in minutes. ECS provides standard APIs, a performance monitoring framework, and a proactive O&M system. ECS supports various O&M capabilities, such as Terraform, CloudOps Orchestration Service (OOS), and Resource Orchestration Service (ROS), to improve usability and applicability.\nCost optimization: ECS provides multiple billing methods such as pay-as-you-go, subscription, and preemptible instances to meet the requirements of different application scenarios. You can also use discount policies such as savings plans and reserved instances, as well as Auto Scaling and Auto Provisioning capabilities to ensure stable computing power and maximize resource cost-efficiency.\nElasticity and flexibility: You can scale up or down ECS instances in compute capacity, storage capacity, or network bandwidth as your requirements change. You can also use Alibaba Cloud Auto Scaling to scale resources as scheduled or against business loads.\nStability and reliability: A single instance reaches an availability of 99.975%, and multiple instances across zones reach an availability of 99.995%. Storage attached to ECS instances makes use of a multi-replica mechanism to provide a data durability of 99.9999999% (nine 9's). ECS provides various availability and reliability features such as snapshots and automatic alerting.\nSecurity: ECS is secured by high-standard data center security and physical infrastructure protection measures. To enhance the operating system security, access security, network security, and application security, ECS provides multiple guarantees such as hardware encryption, virtual firewalls, Resource Access Management (RAM), Anti-DDoS, vulnerability scanning, and data encryption. This comprehensively protects user business in the cloud.\nFor more information about the benefits and supported scenarios of ECS, see Benefits and Common scenarios.\nECS provides various features and components, including instances, images, block storage devices, snapshots, and security groups, for use in different networks. The following figure shows the service architecture of ECS. For information about the features and components shown in the following figure, see Terms.\nIn ECS, compute resources (vCPUs and memory), images, block storage devices, public bandwidth, and snapshots are the resources that you need to pay for.\nECS supports multiple billing methods for resources:\nSubscription: Subscription instances are resources that you secure for an extended period of time for an upfront payment.\nPay-as-you-go: Pay-as-you-go instances allow you to pay only for the resources that you use without making prior commitments or upfront payments.\nPreemptible Instance: Preemptible instances are unused ECS capacity in Alibaba Cloud. You can purchase preemptible instances at steep discounts, but these instances may be reclaimed by Alibaba Cloud with a short notice.\nReserved Instance: Reserved instances are capacity reservations that are offered at a discounted rate. The discounted rate is applied when the attributes of the ECS instance (including instance type, region, and zone) match those of your reserved instances.\nSavings Plan: Savings plans are a flexible pricing model that offers lower prices for pay-as-you-go instances. Savings plans can be applied to ECS resources such as compute resources and disks, and offer savings on the pay-as-you-go rate on these resources in exchange for a commitment to use a specific amount (measured in USD/hour) within a specific timeframe.\nStorage Capacity Unit (SCU): SCUs are resource plans that offer lower prices for pay-as-you-go storage resources. When you purchase SCUs, you make a commitment to use storage resources of a specific type and capacity in exchange for a lower price. SCUs can be applied to Elastic Block Storage (EBS) devices, File Storage NAS file systems, and Object Storage Service (OSS) buckets.\nFor more information about the billing of ECS resources, see Billing overview and visit the Pricing tab of the Elastic Compute Service product page.\nAfter you create an Alibaba Cloud account, you can log on to Alibaba Cloud and create, use, or release ECS resources by using one of the following methods:\nECS console: a web service page used to manage ECS resources. For information about the operations that you can perform in the ECS console, see Quick reference.\nECS API: A Remote Procedure Call (RPC) API that supports GET and POST requests. For more information, see API overview. You can use the following developer tools or services to call ECS API operations:\nAlibaba Cloud CLI\nOpenAPI Explorer: an Alibaba Cloud service that facilitates API lookup, simplifies the creation of requests, and dynamically generates SDK sample code.\nAlibaba Cloud SDK: provides SDKs for a variety of programming languages such as Java, Python, and PHP.\nROS: an Alibaba Cloud service that you can use to automatically create and configure all Alibaba Cloud resources based on templates that you create.\nOOS: an Alibaba Cloud automated O&M service that you can use to automatically manage and execute O&M tasks. You can define items such as tasks, task steps, inputs, and outputs in execution templates and use the templates to automate O&M tasks.\nTerraform references: an open source tool that can help you version control configuration files or use them to call compute resources of Alibaba Cloud and other platforms that support Terraform.\nAlibaba Cloud Client: a client provided by Alibaba Cloud that can be used to query, view, and connect to ECS instances, elastic container instances, simple application servers, and managed instances.\nTo maximize the benefits of ECS, we recommend that you follow the best practices described in this section.\nRegion and zone\nAlibaba Cloud ECS is available in multiple locations across the world. These locations are classified into regions and zones. Regions are geographical areas in which Alibaba Cloud data centers reside and provide services. Zones are discrete locations within a region with independent power and networking capacities. After an ECS instance is created, its metadata is created, and its region cannot be changed. Metadata is supported only by ECS instances of the Virtual Private Cloud (VPC) type. You can select a region and zone based on your geographical location, the availability of Alibaba Cloud services, application availability requirements, and whether internal network communication is required. For example, if you want to create an ApsaraDB for RDS instance over an internal network, the RDS instance and the ECS instance must reside in the same region. For more information, see Regions and zones.\nHigh availability\nTo ensure business consistency and continuity, create snapshots to back up data, deploy critical components of applications across multiple zones, and use deployment sets and Server Load Balancer (SLB) for disaster recovery.\nNetworking\nAlibaba Cloud VPC allows you to deploy ECS instances in a logically isolated virtual networking environment exclusive to your account. You have full control over the network topology of your VPCs, and can assign private IP addresses to your ECS instances in the VPCs. Alibaba Cloud VPC is compatible with all ECS instance types and features, and is useful for isolating applications or interconnecting services that span multiple regions. For more information, see What is a VPC?\nSecurity\nSecurity groups serve as virtual firewalls for your ECS instances, and allow you to control inbound and outbound traffic and configure port listening settings. Security groups are provided at no extra cost to you. For more information about security groups, see Overview.\nAlibaba Cloud provides free basic security and attack mitigation services in the form of Anti-DDoS Origin Basic and Alibaba Cloud Security Center Basic. The basic security and attack mitigation services secure applications deployed on your ECS instances. For more information, see Anti-DDoS Origin Basic and Basic security services.\nAnti-DDoS Origin Basic provides a DDoS mitigation capacity of up to 5 Gbit/s and is enabled by default. For more advanced DDoS mitigation capabilities, you can opt to purchase an Anti-DDoS Pro or Anti-DDoS Premium instance. For more information, see What is Anti-DDoS Proxy?\nSecurity Center Basic provides ECS instances with basic security services free of charge, such as suspicious logon detection, vulnerability scan, and baseline check. You can upgrade your Security Center to the Anti-virus, Advanced, or Enterprise edition to obtain additional security features and further enhance the security of your ECS instances. For more information, see What is Security Center?"
    },
    "81": {
        "title": "Elastic Compute Service:Common scenarios",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/scenarios",
        "content": "This Product\nElastic Compute Service:Common scenarios\nElastic Compute Service (ECS) is compatible with a wide range of Alibaba Cloud services. You can build applications by using only ECS instances, or pair ECS instances with other Alibaba Cloud services to extend your application capabilities.\nThis topic describes some typical use scenarios of ECS.\nNew websites usually have low or sporadic traffic. In cases such as these, you can host your websites on low-configuration instances that can provide sufficient performance for basic website components. As your business grows, you can scale up your instance or scale out to more instances at any time to handle traffic spikes.\nSome e-commerce applications, especially applications used in flash sales or promotions, may experience brief, sharp fluctuations in traffic. In cases such as these, you can use Auto Scaling feature to automatically scale your ECS instances based on business forecasts to maintain steady, predictable performance at the lowest possible cost. You can also leverage Server Load Balancer (SLB) to the mix to improve service availability and ensure consistent user experience. For more information, see What is Auto Scaling? and What is SLB?\nECS caters to data analytics scenarios with its big data instance families. Instances in these instance families are ideal for distributed computing workloads based on the Hadoop framework, log processing jobs, and massive-scale data warehouses. These instance families leverage locally attached storage and interconnected internal networking capabilities to provide immense storage capabilities and minimize network latency for Hadoop and Spark clusters. For more information, see Big data instance families.\nGPU-accelerated instances leverage GPUs to deliver accelerated computing capabilities through hardware acceleration. These instances are capable of near-real-time rendering and are ideal for graphics-intensive workloads, such as rendering, cloud graphics workstation, and video transcoding workloads.\nvgn6i and gn6i instances are powered by Turing-based NVIDIA Tesla T4 GPUs and are designed to deliver top-of-the-line graphics processing capabilities. vgn6i instances also support virtual GPUs (vGPUs), which allows you to virtualize the equipped GPU into multiple GPUs. This way, you can effectively dedicate portions (1/2, 1/4, or 1/8) of the GPU's computing capabilities towards different tasks.\nGPU-accelerated instances provide great price performance balance for time-consuming, compute-intensive deep learning workloads. These instances are ideal for performing floating point computing, data pattern matching, and training deep learning models for machine learning applications. For more information, see GPU-accelerated compute-optimized and vGPU-accelerated instance.\nECS offers instances that are ideal for high-performance computing applications in which you want to run parallel and compute-intensive workloads, such as highly complex simulations. These applications include weather forecasting, biopharmaceutical manufacturing, gene sequencing, and graphics processing.\nFor highly compute-intensive applications such as these, we recommend that you use Elastic High Performance Computing (E-HPC) to manage ECS with other computing resources. E-HPC helps you aggregate and scale computing capabilities with ease, allowing you to build powerful applications that help solve major challenges across multiple fields, including science, engineering, and commerce.\nFor more information about the use scenarios of ECS, see Alibaba Cloud solutions."
    },
    "82": {
        "title": "Elastic Compute Service:Benefits",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/product-introduction-benefits",
        "content": "This Product\nElastic Compute Service:Benefits\nElastic Compute Service (ECS) offers a wide range of instance options, providing convenient, scalable, and reliable compute capacity in the cloud. With ECS, you no longer have to invest precious time and money to purchase, set up, and manage your IT infrastructure, so you can focus on developing and deploying your applications.\nECS provides a broad and deep selection of instances to fit different use cases.\nState-of-the-art computing architecture\nECS instances run on the x86 and ARM architectures, which are sufficient to cover almost all types of workloads.\nDiversified instance types\nECS provides a wide selection of instance types and gives you the flexibility to size your compute resources to match capacity needs at the lowest cost. Instance types comprise varying combinations of compute, memory, and storage capacity, allowing you to choose an appropriate mix of resources for your applications. General-purpose, network-enhanced, storage-enhanced, memory-optimized, security-enhanced, big data, high clock speed, GPU-accelerated, and FPGA-accelerated instance types are available with different options for CPU, memory, and network resources to provide exceptional cost performance for general-purpose computing, heterogeneous computing, and high performance computing scenarios.\nMultiple deployment models\nAside from the typical virtual machine deployment model, ECS also offers dedicated physical resources in the form of ECS bare metal instances and dedicated hosts. ECS bare metal instances provide direct access to the processor and memory resources without virtualization overheads. You can deploy containerized applications on top of ECS bare metal instances in cases where performance is key. Dedicated hosts are physical servers that are entirely dedicated to you. You can create and run ECS instances on dedicated hosts on demand, gaining additional visibility and control over how instances are placed on physical servers.\nAlibaba Cloud's global network allows you to deploy ECS instances in multiple locations all around the world. Equipped with abundant state-of-the-art resources, 10,000 ECS instances can be provisioned securely and reliably within a few minutes. You can use ECS to create as many or as few instances as you need and scale in or out in response to changes in requirements or popularity of your workloads.\nVertical scaling\nYou can scale up or down ECS instances in compute capacity, storage capacity, or network bandwidth as your requirements change.\nHorizontal scaling\nMost business sees different volumes of traffic at different times of the day. In cases such as these, you can use ECS with Auto Scaling to scale in or out resources based on a predetermined schedule or in response to traffic fluctuations to maintain steady, predictable performance at the lowest possible cost.\nService reliability\nECS operates with a single-instance availability of 99.975% and a cross-zone multi-instance availability of 99.995%.\nData durability\nStorage attached to ECS instances makes use of a multi-replica mechanism to provide a data durability of 99.9999999% (nine 9's).\nAvailability and disaster tolerance\nECS provides a host of availability and reliability features such as failover, snapshots, and automatic alerting to ensure service availability and data recovery even when one or more instances fail.\nIntuitive interface\nECS provides a user-friendly, web-based console, which you can use to start, stop, configure, and modify ECS instances in the same way you would with a physical machine.\nPush-button deployment\nECS images are preconfigured with an ever-growing list of operating systems and software. Images allow you to deploy multiple instances with the same configurations quickly and easily.\nRich management and migration tools\nAlibaba Cloud provides rich management and governance tools such as Terraform, CloudOps Orchestration Service, and Resource Orchestration Service (ROS). ECS can also work with Server Migration Center (SMC) to facilitate migration of your business to the cloud.\nDiversified security features\nAlibaba Cloud provides a host of security services and features that meet international standards and requirements for data security. These services include Anti-DDoS Origin Basic, port intrusion detection, vulnerability scanning, and trojan scanning to protect your applications hosted in ECS.\nHardware encryption\nECS supports Virtual Trusted Platform Module (vTPM), confidential computing based on Intel Software Guard Extensions (SGX), and vSGX and provides comprehensive hardware encryption capabilities.\nMultiple billing methods\nECS provides the following purchasing options for instances to help you optimize costs at every stage of your business: subscription instances, pay-as-you-go instances, and preemptible instances.\nFlexible pricing models\nECS also provides modular pricing models in the form of savings plans and reserved instances to help you further reduce costs on ECS resources. Savings plans are a flexible pricing model that offers lower prices than pay-as-you-go pricing, in exchange for a commitment to a consistent amount of usage (measured in USD per hour) for a one- or three-year period. After you purchase savings plans, the lower prices are applied for resources that match the configurations of the savings plans. Reserved instances give you the option to reserve capacity for a period of time and in return receive significant discounts compared to pay-as-you-go Instance pricing. Reserved instances can be applied to pay-as-you-go instances that match the attributes of the reserved instances.\nMix-and-match billing methods\nYou can mix and match billing methods of different ECS resources to achieve the perfect blend of performance and costs tailored towards your use case."
    },
    "83": {
        "title": "Elastic Compute Service:Instance families available for purchase",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/instance-family",
        "content": "This Product\nElastic Compute Service:Instance families available for purchase\nThis topic describes all Elastic Compute Service (ECS) instance families available for purchase and introduces their features, instance types, and supported scenarios to facilitate instance type selection.\nBefore you read further in this topic, you must be familiar with the following information:\nClassification and naming of instance types. Familiarize yourself with the instance family categories, naming conventions of instance types, and differences between instance families. For more information, see Classification and naming of instance types.\nInstance type metrics. For information about the metrics of instance types, see Instance type metrics. You can also call the DescribeInstanceTypeFamilies and DescribeInstanceTypes operations to query the instance families provided by ECS and the details of all instance types.\nInstructions for selecting instance types based on your business scenarios. For more information, see Instance type selection.\nAfter you determine an instance type for your use case, you may need to learn about the following information:\nRegions in which the instance type is available for purchase. Instance types that are available for purchase vary based on the region. You can go to the Instance Types Available for Each Region page to view the instance types available for purchase in each region. Alternatively, you can call the DescribeRegions and DescribeZones operations to query the supported regions and the zones in a specific region.\nEstimated instance costs. You can calculate the price of instances that uses different billing methods in the Price Calculator. You can also call the DescribePrice operation to query information about the most recent prices of ECS resources.\nInstructions for purchasing an instance. You can go to the ECS instance buy page to place a purchase order for instances.\nYou may be concerned about the following information:\nRetired instance families. If you cannot find an instance type in this topic, the instance type may be in a retired instance family. For information about retired instance families, see Retired instance types.\nSupported instance type changes. Before you change the instance type of an instance, check whether the instance type can be changed and identify compatible instance types. For more information, see Instance types and families that support instance type changes.\nIntel processor-powered instance families\nAMD processor-powered instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the instance families in the preceding columns.)\ng8i, general-purpose instance family\ng7, general-purpose instance family\ng6e, performance-enhanced general-purpose instance family\ng6, general-purpose instance family\n\ng8a, general-purpose instance family\ng8ae, performance-enhanced general-purpose instance family\ng7a, general-purpose instance family\ng6a, general-purpose instance family\ng5, general-purpose instance family\nsn2ne, network-enhanced general-purpose instance family\nIntel processor-powered instance families\nAMD processor-powered instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the instance families in the preceding columns.)\nc8i, compute-optimized instance family\nc7, compute-optimized instance family\nc6e, performance-enhanced compute-optimized instance family\nc6, compute-optimized instance family\nc8a, compute-optimized instance family\nc8ae, performance-enhanced compute-optimized instance family\nc7a, compute-optimized instance family\nc6a, compute-optimized instance family\nic5, compute-intensive instance family\nc5, compute-optimized instance family\nsn1ne, network-enhanced compute-optimized instance family\nIntel processor-powered instance families\nAMD processor-powered instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the instance families in the preceding columns.)\nr8i, memory-optimized instance family\nr7, memory-optimized instance family\nr6e, performance-enhanced memory-optimized instance family\nr6, memory-optimized instance family\nr8a, memory-optimized instance family\nr8ae, performance-enhanced memory-optimized instance family\nr7a, memory-optimized instance family\nr6a, memory-optimized instance family\n\nr5, memory-optimized instance family\nse1ne, network-enhanced memory-optimized instance family\nse1, memory-optimized instance family\nu1, universal instance family\nRecommended instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the recommended instance families.)\nd3s, storage-intensive big data instance family\nd3c, compute-intensive big data instance family\nd2c, compute-intensive big data instance family\nd2s, storage-intensive big data instance family\nd1ne, network-enhanced big data instance family\nd1, big data instance family\nRecommended instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the instance families in the preceding columns.)\nInstance families powered by Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors\nInstance families powered by Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors\nInstance families powered by Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors\ni4, instance family with local SSDs\ni4g, instance family with local SSDs\ni4r, instance family with local SSDs\ni4p, performance-enhanced instance family with local SSDs\ni3g, instance family with local SSDs\ni3, instance family with local SSDs\ni2, instance family with local SSDs\ni2g, instance family with local SSDs\ni2ne, instance family with local SSDs\ni2gne, instance family with local SSDs\ni1, instance family with local SSDs\nRecommended instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the instance families in the preceding columns.)\nInstance families powered by Intel\u00ae Xeon\u00ae Cooper Lake processors\nInstance families powered by Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors\nhfc7, compute-optimized instance family with high clock speeds\nhfg7, general-purpose instance family with high clock speeds\nhfr7, memory-optimized instance family with high clock speeds\nhfc6, compute-optimized instance family with high clock speeds\nhfg6, general-purpose instance family with high clock speeds\nhfr6, memory-optimized instance family with high clock speeds\nhfc5, compute-optimized instance family with high clock speeds\nhfg5, general-purpose instance family with high clock speeds\nStorage-enhanced instance families\nNetwork-enhanced instance families\nSecurity-enhanced instance families\nMemory-enhanced instance families\ng7se, storage-enhanced general-purpose instance family\nc7se, storage-enhanced compute-optimized instance family\nr7se, storage-enhanced memory-optimized instance family\ng7nex, network-enhanced general-purpose instance family\nc7nex, network-enhanced compute-optimized instance family\ng7ne, network-enhanced general-purpose instance family\ng5ne, network-enhanced general-purpose instance family\ng7t, security-enhanced general-purpose instance family\nc7t, security-enhanced compute-optimized instance family\nr7t, security-enhanced memory-optimized instance family\ng6t, security-enhanced general-purpose instance family\nc6t, security-enhanced compute-optimized instance family\nRecommended instance families\nre6p, persistent memory-optimized instance family\nre6, high-memory instance family\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the preceding recommended instance families.)\nre4, high-memory instance family\nre4e, high-memory instance family\nRecommended instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the recommended instance families.)\ne, economy instance family\nt6, burstable instance family\nt5, burstable instance family\nv5, CPU-overprovisioned instance family\nxn4, n4, mn4, and e4, previous-generation shared instance families\nYiTian 710 processor-powered instance families\nAmpere\u00ae Altra\u00ae processor-powered instance families\ng8y, general-purpose instance family\nc8y, compute-optimized instance family\nr8y, memory-optimized instance family\ng6r, general-purpose instance family\nc6r, compute-optimized instance family\nRecommended instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the instance families in the preceding columns.)\nGeneral-purpose instance families (g series)\nCompute-optimized instance families (c series)\nMemory-optimized instance families (r series)\nInstance families with high clock speeds (hf series)\nGPU-accelerated compute-optimized instance families (gn series)\nebmg8y, general-purpose ECS Bare Metal Instance family\nebmg8i, general-purpose ECS Bare Metal Instance family\nebmg7, general-purpose ECS Bare Metal Instance family\nebmg7a, general-purpose ECS Bare Metal Instance family\nebmg6a, general-purpose ECS Bare Metal Instance family\nebmg6e, performance-enhanced general-purpose ECS Bare Metal Instance family\nebmg6, general-purpose ECS Bare Metal Instance family\nebmc8y, compute-optimized ECS Bare Metal Instance family\nebmc8i, compute-optimized ECS Bare Metal Instance family\nebmc7, compute-optimized ECS Bare Metal Instance family\nebmc7a, compute-optimized ECS Bare Metal Instance family\nebmc6me, compute-optimized ECS Bare Metal Instance family\nebmc6a, compute-optimized ECS Bare Metal Instance family\nebmc6e, performance-enhanced compute-optimized ECS Bare Metal Instance family\nebmc6, compute-optimized ECS Bare Metal Instance family\n\nebmr8y, memory-optimized ECS Bare Metal Instance family\nebmr7, memory-optimized ECS Bare Metal Instance family\nebmr7a, memory-optimized ECS Bare Metal Instance family\nebmr6a, memory-optimized ECS Bare Metal Instance family\nebmr6e, performance-enhanced memory-optimized ECS Bare Metal Instance family\nebmr6, memory-optimized ECS Bare Metal Instance family\nebmre6p, performance-enhanced persistent-memory-optimized ECS Bare Metal Instance family\nebmre6-6t, performance-enhanced memory-optimized ECS Bare Metal Instance family\n\nebmhfg7, general-purpose ECS Bare Metal Instance family with high clock speeds\nebmhfc7, compute-optimized ECS Bare Metal Instance family with high clock speeds\nebmhfr7, memory-optimized ECS Bare Metal Instance family with high clock speeds\nebmhfg6, general-purpose ECS Bare Metal Instance family with high clock speeds\nebmhfc6, compute-optimized ECS Bare Metal Instance family with high clock speeds\nebmhfr6, memory-optimized ECS Bare Metal Instance family with high clock speeds\nebmgn8v, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn8is, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn7e, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn7i, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn7, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn6e, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn6v, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmgn6i, GPU-accelerated compute-optimized ECS Bare Metal Instance family\nebmc5s, network-enhanced compute-optimized ECS Bare Metal Instance family\nebmg5s, network-enhanced general-purpose ECS Bare Metal Instance family\nebmr5s, network-enhanced memory-optimized ECS Bare Metal Instance family\nebmg5, general-purpose ECS Bare Metal Instance family\nscchfc6, compute-optimized SCC instance family with high clock speeds\nscchfg6, general-purpose SCC instance family with high clock speeds\nscchfr6, memory-optimized SCC instance family with high clock speeds\nscch5, SCC instance family with high clock speeds\nRecommended instance families\nNot recommended instance families (If the following instance families are sold out, we recommend that you use the recommended instance families.)\nsgn8ia, vGPU-accelerated instance family\nsgn7i-vws, vGPU-accelerated instance family with shared CPUs\nvgn7i-vws, vGPU-accelerated instance family\nvgn6i-vws, vGPU-accelerated instance family\ngn8is, GPU-accelerated compute-optimized instance family\ngn7e, GPU-accelerated compute-optimized instance family\ngn7i, GPU-accelerated compute-optimized instance family\ngn7s, GPU-accelerated compute-optimized instance family\ngn7, GPU-accelerated compute-optimized instance family\ngn6i, GPU-accelerated compute-optimized instance family\ngn6e, GPU-accelerated compute-optimized instance family\ngn6v, GPU-accelerated compute-optimized instance family\ngn5, GPU-accelerated compute-optimized instance family\ngn5i, GPU-accelerated compute-optimized instance family\nIntroduction: This instance family uses the innovative Cloud Infrastructure Processing Unit (CIPU) architecture developed by Alibaba Cloud to provide consistent computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios: general-purpose enterprise-level applications such as Java, in-memory database and relational database applications, big data applications such as Kafka and Elasticsearch, web applications, AI training and inference, and audio and video transcoding applications.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.7 GHz AMD EPYCTM Genoa 9T24 processors that deliver a turbo frequency of up to 3.7 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview.\ng8a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g8a.large\n2\n8\n1.5/12.5\n900,000\nUp to 250,000\n2\n3\n6\n6\n20,000/110,000\n1.5/10\necs.g8a.xlarge\n4\n16\n2.5/12.5\n1,000,000\nUp to 250,000\n4\n4\n6\n6\n30,000/110,000\n2/10\necs.g8a.2xlarge\n8\n32\n4/12.5\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n45,000/110,000\n2.5/10\necs.g8a.4xlarge\n16\n64\n7/12.5\n2,000,000\n300,000\n16\n8\n30\n30\n60,000/110,000\n3.5/10\necs.g8a.8xlarge\n32\n128\n10/25\n3,000,000\n600,000\n32\n8\n30\n30\n80,000/110,000\n5/10\necs.g8a.12xlarge\n48\n192\n16/25\n4,500,000\n750,000\n48\n8\n30\n30\n120,000/none\n8/10\necs.g8a.16xlarge\n64\n256\n20/25\n6,000,000\n1,000,000\n64\n8\n30\n30\n160,000/none\n10/none\necs.g8a.24xlarge\n96\n384\n32/none\n9,000,000\n1,500,000\n64\n15\n30\n30\n240,000/none\n16/none\necs.g8a.32xlarge\n128\n512\n40/none\n12,000,000\n2,000,000\n64\n15\n30\n30\n320,000/none\n20/none\necs.g8a.48xlarge\n192\n768\n64/none\n18,000,000\n3,000,000\n64\n15\n30\n30\n500,000/none\n32/none\nPacket forwarding rates significantly vary based on business scenarios. We recommend that you perform business stress tests on instances to select appropriate instance types.\nFor ecs.g8a.large and ecs.g8a.xlarge instances, you must enable the Jumbo Frames feature before the instances can burst their network bandwidths to 12.5 Gbit/s. For more information, see Jumbo Frames.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide consistent computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios: scenarios where large volumes of packets are received and transmitted, game servers, small and medium-sized database systems, caches, search clusters, search promotion applications, websites, application servers, data analytics and computing, and scenarios that require secure and trusted computing.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses Intel\u00ae Xeon\u00ae Emerald Rapids or Intel\u00ae Xeon\u00ae Sapphire Rapids processors that deliver a clock speed of at least 2.7 GHz and an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nWhen you purchase an instance of this instance family, the system randomly allocates one type of the preceding processors to the instance. You cannot select a processor type for the instance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides high network performance based on large computing capacity.\nSecurity:\nSupports the vTPM feature. For more information, see Overview.\nSupports Intel Total Memory Encryption (TME) to encrypt memory.\nSupports CPU-based Intel\u00ae Trust Domain Extensions (TDX) confidential computing. For more information, see Build a TDX confidential computing environment.\ng8i instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g8i.large\n2\n8\n2.5/burstable up to 15\n1,000,000\nUp to 300,000\n2\n3\n6\n6\n25,000/burstable up to 200,000\n2/burstable up to 10\necs.g8i.xlarge\n4\n16\n4/burstable up to 15\n1,200,000\nUp to 300,000\n4\n4\n15\n15\n50,000/burstable up to 200,000\n2.5/burstable up to 10\necs.g8i.2xlarge\n8\n32\n6/burstable up to 15\n1,600,000\nUp to 300,000\n8\n4\n15\n15\n60,000/burstable up to 200,000\n4/burstable up to 10\necs.g8i.3xlarge\n12\n48\n10/burstable up to 15\n2,400,000\nUp to 300,000\n12\n8\n15\n15\n80,000/burstable up to 200,000\n5/burstable up to 10\necs.g8i.4xlarge\n16\n64\n12/burstable up to 25\n3,000,000\n350,000\n16\n8\n30\n30\n100,000/burstable up to 200,000\n6/burstable up to 10\necs.g8i.6xlarge\n24\n96\n15/burstable up to 25\n4,500,000\n500,000\n24\n8\n30\n30\n120,000/burstable up to 200,000\n7.5/burstable up to 10\necs.g8i.8xlarge\n32\n128\n20/burstable up to 25\n6,000,000\n800,000\n32\n8\n30\n30\n200,000/none\n10/none\necs.g8i.12xlarge\n48\n192\n25/none\n9,000,000\n1,000,000\n48\n8\n30\n30\n300,000/none\n12/none\necs.g8i.16xlarge\n64\n256\n32/none\n12,000,000\n1,600,000\n64\n8\n30\n30\n360,000/none\n20/none\necs.g8i.24xlarge\n96\n384\n50/none\n18,000,000\n2,000,000\n64\n15\n30\n30\n500,000/none\n24/none\necs.g8i.48xlarge\n192\n1,024\n100/none\n30,000,000\n4,000,000\n64\n15\n50\n50\n1,000,000/none\n48/none\nIf you want to use the ecs.g8i.48xlarge instance type, submit a ticket.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide consistent computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios: AI scenarios such as deep learning, training, and AI inference, high-performance scientific computing scenarios such as high-performance computing (HPC), large and medium-sized database systems, caches, search clusters, servers for massively multiplayer online (MMO) games, and other general-purpose enterprise-level applications that require high performance.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 3.4 GHz AMD EPYC\u2122 Genoa processors that deliver a single-core turbo frequency of up to 3.75 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview.\ng8ae instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g8ae.large\n2\n8\n3/burstable up to 15\n1,000,000\nYes\nUp to 300,000\n2\n3\n6\n6\n30,000/burstable up to 200,000\n2/burstable up to 10\necs.g8ae.xlarge\n4\n16\n4/burstable up to 15\n1,200,000\nYes\nUp to 300,000\n4\n4\n15\n15\n50,000/burstable up to 200,000\n2.5/burstable up to 10\necs.g8ae.2xlarge\n8\n32\n6/burstable up to 15\n1,600,000\nYes\nUp to 300,000\n8\n4\n15\n15\n60,000/burstable up to 200,000\n3/burstable up to 10\necs.g8ae.4xlarge\n16\n64\n12/burstable up to 25\n3,000,000\nYes\n500,000\n16\n8\n30\n30\n100,000/burstable up to 200,000\n6/burstable up to 10\necs.g8ae.8xlarge\n32\n128\n20/burstable up to 25\n6,000,000\nYes\n1,000,000\n32\n8\n30\n30\n200,000/none\n10/none\necs.g8ae.16xlarge\n64\n256\n32/none\n9,000,000\nYes\n1,500,000\n64\n8\n30\n30\n250,000/none\n16/none\necs.g8ae.32xlarge\n128\n512\n64/none\n18,000,000\nYes\n3,000,000\n64\n15\n30\n30\n500,000/none\n32/none\nFor ecs.g8ae.large and ecs.g8ae.xlarge instances, you must enable the Jumbo Frames feature before the instances can burst their network bandwidths to 15 Gbit/s. For more information, see Jumbo Frames.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios: video encoding and decoding, scenarios where large volumes of packets are received and transmitted, websites, application servers, small and medium-sized database systems, caches, search clusters, game servers, scenarios where applications such as DevOps applications are developed and tested, and other general-purpose enterprise-level applications.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.55 GHz AMD EPYC\u2122 MILAN processors that deliver a single-core turbo frequency of up to 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\ng7a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g7a.large\n2\n8\n1/burstable up to 10\n900,000\nUp to 250,000\n2\n3\n6\n6\n12,500/burstable up to 110,000\n1/burstable up to 6\necs.g7a.xlarge\n4\n16\n1.5/burstable up to 10\n1,000,000\nUp to 250,000\n4\n4\n15\n15\n20,000/burstable up to 110,000\n1.5/burstable up to 6\necs.g7a.2xlarge\n8\n32\n2.5/burstable up to 10\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n30,000/burstable up to 110,000\n2/burstable up to 6\necs.g7a.4xlarge\n16\n64\n5/burstable up to 10\n2,000,000\n300,000\n8\n8\n30\n30\n60,000/burstable up to 110,000\n3.7/burstable up to 10.5\necs.g7a.8xlarge\n32\n128\n8/burstable up to 10\n3,000,000\n600,000\n16\n7\n30\n30\n75,000/burstable up to 110,000\n4.1/burstable up to 11\necs.g7a.16xlarge\n64\n256\n16/none\n6,000,000\n1,000,000\n32\n8\n30\n30\n150,000/none\n8.2/none\necs.g7a-nps1.16xlarge\n64\n256\n16/none\n6,000,000\n1,000,000\n32\n8\n30\n30\n150,000/none\n8.2/none\necs.g7a.32xlarge\n128\n512\n32/none\n12,000,000\n2,000,000\n32\n15\n30\n30\n300,000/none\n16.4/none\nUbuntu 16 and Debian 9 operating system kernels do not support AMD EPYC\u2122 MILAN processors. Do not use Ubuntu 16 or Debian 9 images to create instances of this instance family. Instances of this instance family created from Ubuntu 16 or Debian 9 images cannot be started.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios: scenarios where large volumes of packets are received and transmitted such as live commenting on videos and telecom data forwarding, game servers, small and medium-sized database systems, caches, search clusters, enterprise-level applications of various types and sizes, websites, application servers, data analytics and computing, scenarios that require secure and trusted computing, and blockchain scenarios.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity:\nSupports the vTPM feature. For more information, see Overview.\nSupports the Enclave feature and provides virtualization-based confidential computing environments. For more information, see Build a confidential computing environment by using Enclave.\ng7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g7.large\n2\n8\n2/burstable up to 12.5\n1,100,000\nYes\nUp to 500,000\n2\n3\n6\n6\n8\n20,000/burstable up to 160,000\n1.5/burstable up to 10\necs.g7.xlarge\n4\n16\n3/burstable up to 12.5\n1,100,000\nYes\nUp to 500,000\n4\n4\n15\n15\n8\n40,000/burstable up to 160,000\n2/burstable up to 10\necs.g7.2xlarge\n8\n32\n5/burstable up to 15\n1,600,000\nYes\nUp to 500,000\n8\n4\n15\n15\n16\n50,000/burstable up to 160,000\n3/burstable up to 10\necs.g7.3xlarge\n12\n48\n8/burstable up to 15\n2,400,000\nYes\nUp to 500,000\n8\n8\n15\n15\n16\n70,000/burstable up to 160,000\n4/burstable up to 10\necs.g7.4xlarge\n16\n64\n10/burstable up to 25\n3,000,000\nYes\n500,000\n8\n8\n30\n30\n16\n80,000/burstable up to 160,000\n5/burstable up to 10\necs.g7.6xlarge\n24\n96\n12/burstable up to 25\n4,500,000\nYes\n550,000\n12\n8\n30\n30\n16\n110,000/burstable up to 160,000\n6/10\necs.g7.8xlarge\n32\n128\n16/burstable up to 32\n6,000,000\nYes\n600,000\n16\n8\n30\n30\n24\n160,000/none\n10/none\necs.g7.16xlarge\n64\n256\n32/none\n12,000,000\nYes\n1,200,000\n32\n8\n30\n30\n32\n360,000/none\n16/none\necs.g7.32xlarge\n128\n512\n64/none\n24,000,000\nYes\n2,400,000\n32\n15\n30\n30\n32\n600,000/none\n32/none\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nThe maximum performance of disks varies based on the instance families. A single instance of this instance family can deliver up to 200,000 IOPS.\nProvides high network and storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nNetwork performance varies based on the instance families. For higher concurrent connection and network packet forwarding capabilities, we recommend that you use the g7ne instance family.\nProvides high network performance based on large computing capacity.\nSupported instance type changes: Supports changes to c6 or r6 instance types.\ng6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g6.large\n2\n8\n1/burstable up to 3\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.g6.xlarge\n4\n16\n1.5/burstable up to 5\n500,000\nUp to 250,000\n4\n3\n10\n1\n20,000\n1.5\necs.g6.2xlarge\n8\n32\n2.5/burstable up to 8\n800,000\nUp to 250,000\n8\n4\n10\n1\n25,000\n2\necs.g6.3xlarge\n12\n48\n4/burstable up to 10\n900,000\nUp to 250,000\n8\n6\n10\n1\n30,000\n2.5\necs.g6.4xlarge\n16\n64\n5/burstable up to 10\n1,000,000\n300,000\n8\n8\n20\n1\n40,000\n3\necs.g6.6xlarge\n24\n96\n7.5/burstable up to 10\n1,500,000\n450,000\n12\n8\n20\n1\n50,000\n4\necs.g6.8xlarge\n32\n128\n10/none\n2,000,000\n600,000\n16\n8\n20\n1\n60,000\n5\necs.g6.13xlarge\n52\n192\n12.5/none\n3,000,000\n900,000\n32\n7\n20\n1\n100,000\n8\necs.g6.26xlarge\n104\n384\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nVideo encoding and decoding\nScenarios where large volumes of packets are received and transmitted\nWebsites and application servers\nSmall and medium-sized database systems, caches, and search clusters\nGame servers\nScenarios where applications such as DevOps applications are developed and tested\nOther general-purpose enterprise-level applications\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.6 GHz AMD EPYC\u2122 ROME processors that deliver a turbo frequency of 3.3 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high network and storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\ng6a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g6a.large\n2\n8\n1/10\n900,000\nUp to 250,000\n2\n2\n6\n1\n12,500\n1\necs.g6a.xlarge\n4\n16\n1.5/10\n1,000,000\nUp to 250,000\n4\n3\n15\n1\n20,000\n1.5\necs.g6a.2xlarge\n8\n32\n2.5/10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n30,000\n2\necs.g6a.4xlarge\n16\n64\n5/10\n2,000,000\n300,000\n8\n8\n30\n1\n60,000\n3.1\necs.g6a.8xlarge\n32\n128\n8/10\n3,000,000\n600,000\n16\n7\n30\n1\n75,000\n4.1\necs.g6a.16xlarge\n64\n256\n16/none\n6,000,000\n1,000,000\n32\n8\n30\n1\n150,000\n8.2\necs.g6a.32xlarge\n128\n512\n32/none\n12,000,000\n2,000,000\n32\n15\n30\n1\n300,000\n16.4\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high network and storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nNetwork performance varies based on the instance families. For higher concurrent connection and network packet forwarding capabilities, we recommend that you use the g7ne instance family.\nProvides high network performance based on large computing capacity.\ng6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g6e.large\n2\n8\n1.2/burstable up to 10\n900,000\nUp to 250,000\n2\n3\n6\n1\n20,000\n1\necs.g6e.xlarge\n4\n16\n2/burstable up to 10\n1,000,000\nUp to 250,000\n4\n4\n15\n1\n40,000\n1.5\necs.g6e.2xlarge\n8\n32\n3/burstable up to 10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n50,000\n2\necs.g6e.4xlarge\n16\n64\n6/burstable up to 10\n3,000,000\n300,000\n8\n8\n30\n1\n80,000\n3\necs.g6e.8xlarge\n32\n128\n10/none\n6,000,000\n600,000\n16\n8\n30\n1\n150,000\n5\necs.g6e.13xlarge\n52\n192\n16/none\n9,000,000\n1,000,000\n32\n7\n30\n1\n240,000\n8\necs.g6e.26xlarge\n104\n384\n32/none\n24,000,000\n1,800,000\n32\n15\n30\n1\n480,000\n16\nThe results for network capabilities are the maximum values obtained from single-item tests. For example, when network bandwidth is tested, no stress tests are performed on the packet forwarding rate or other network metrics.\nIf you want to use the ecs.g6e.26xlarge instance type, submit a ticket.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nInstances of this instance family may be deployed on different server platforms. If your business requires all instances to be deployed on the same server platform, we recommend that you use the g6, g6e, or g7 instance family instead.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nThe maximum performance of disks varies based on the instance families. A single instance of this instance family can deliver up to 200,000 IOPS.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nNetwork performance varies based on the instance families. For higher concurrent connection and network packet forwarding capabilities, we recommend that you use the g7ne instance family.\nProvides high network performance based on large computing capacity.\ng5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.g5.large\n2\n8\n1\n300,000\n2\n2\n6\n1\necs.g5.xlarge\n4\n16\n1.5\n500,000\n2\n3\n10\n1\necs.g5.2xlarge\n8\n32\n2.5\n800,000\n4\n4\n10\n1\necs.g5.3xlarge\n12\n48\n4\n900,000\n4\n6\n10\n1\necs.g5.4xlarge\n16\n64\n5\n1,000,000\n4\n8\n20\n1\necs.g5.6xlarge\n24\n96\n7.5\n1,500,000\n6\n8\n20\n1\necs.g5.8xlarge\n32\n128\n10\n2,000,000\n8\n8\n20\n1\necs.g5.16xlarge\n64\n256\n20\n4,000,000\n16\n8\n20\n1\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor more information about these specifications, see the \"Instance type specifications\" section in Overview of instance families. Packet forwarding rates vary significantly based on business scenarios. We recommend that you perform business stress tests on instances to choose appropriate instance types.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell), Platinum 8163 (Skylake), or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nInstances of this instance family may be deployed on different server platforms. If your business requires all instances to be deployed on the same server platform, we recommend that you use the g6, g6e, or g7 instance family instead.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nsn2ne instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.sn2ne.large\n2\n8\n1\n300,000\n2\n2\n6\n1\necs.sn2ne.xlarge\n4\n16\n1.5\n500,000\n2\n3\n10\n1\necs.sn2ne.2xlarge\n8\n32\n2\n1,000,000\n4\n4\n10\n1\necs.sn2ne.3xlarge\n12\n48\n2.5\n1,300,000\n4\n6\n10\n1\necs.sn2ne.4xlarge\n16\n64\n3\n1,600,000\n4\n8\n20\n1\necs.sn2ne.6xlarge\n24\n96\n4.5\n2,000,000\n6\n8\n20\n1\necs.sn2ne.8xlarge\n32\n128\n6\n2,500,000\n8\n8\n20\n1\necs.sn2ne.14xlarge\n56\n224\n10\n4,500,000\n14\n8\n20\n1\nIntroduction: This instance family uses the innovative Cloud Infrastructure Processing Unit (CIPU) architecture developed by Alibaba Cloud to provide consistent computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios: big data applications, web applications, AI training and inference, and audio and video transcoding applications.\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.7 GHz AMD EPYCTM Genoa processors that deliver a turbo frequency of up to 3.7 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview.\nc8a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c8a.large\n2\n4\n1.5/burstable up to 12.5\n900,000\nUp to 250,000\n2\n3\n6\n6\n20,000/burstable up to 110,000\n1.5/burstable up to 10\necs.c8a.xlarge\n4\n8\n2.5/burstable up to 12.5\n1,000,000\nUp to 250,000\n4\n4\n6\n6\n30,000/burstable up to 110,000\n2/burstable up to 10\necs.c8a.2xlarge\n8\n16\n4/burstable up to 12.5\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n45,000/burstable up to 110,000\n2.5/burstable up to 10\necs.c8a.4xlarge\n16\n32\n7/burstable up to 12.5\n2,000,000\n300,000\n16\n8\n30\n30\n60,000/burstable up to 110,000\n3.5/burstable up to 10\necs.c8a.8xlarge\n32\n64\n10/burstable up to 25\n3,000,000\n600,000\n32\n8\n30\n30\n80,000/burstable up to 110,000\n5/burstable up to 10\necs.c8a.12xlarge\n48\n96\n16/25\n4,500,000\n750,000\n48\n8\n30\n30\n120,000/none\n8/burstable up to 10\necs.c8a.16xlarge\n64\n128\n20/25\n6,000,000\n1,000,000\n64\n8\n30\n30\n160,000/none\n10/none\necs.c8a.24xlarge\n96\n192\n32/none\n9,000,000\n1,500,000\n64\n15\n30\n30\n240,000/none\n16/none\necs.c8a.32xlarge\n128\n256\n40/none\n12,000,000\n2,000,000\n64\n15\n30\n30\n320,000/none\n20/none\necs.c8a.48xlarge\n192\n384\n64/none\n18,000,000\n3,000,000\n64\n15\n30\n30\n500,000/none\n32/none\nFor ecs.c8a.large and ecs.c8a.xlarge instances, you must enable the Jumbo Frames feature before the instances can burst their network bandwidths to 12.5 Gbit/s. For more information, see Jumbo Frames.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide consistent computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios: machine learning inference applications, data analytics, batch computing, video encoding, frontend servers for games, high-performance scientific and engineering applications, and web frontend servers.\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses Intel\u00ae Xeon\u00ae Emerald Rapids or Intel\u00ae Xeon\u00ae Sapphire Rapids processors that deliver a clock speed of at least 2.7 GHz and an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nWhen you purchase an instance of this instance family, the system randomly allocates one type of the preceding processors to the instance. You cannot select a processor type for the instance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity:\nSupports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview.\nImplements trusted boot based on Trusted Cryptography Module (TCM) or TPM chips to provide ultra-high security capabilities. During a trusted boot, all modules in the boot chain from the underlying server to the ECS instance are measured and verified.\nSupports Intel Total Memory Encryption (TME) to encrypt memory.\nc8i instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c8i.large\n2\n4\n2.5/burstable up to 15\n1,000,000\nUp to 300,000\n2\n3\n6\n6\n25,000/burstable up to 200,000\n2/burstable up to 10\necs.c8i.xlarge\n4\n8\n4/burstable up to 15\n1,200,000\nUp to 300,000\n4\n4\n15\n15\n50,000/burstable up to 200,000\n2.5/burstable up to 10\necs.c8i.2xlarge\n8\n16\n6/burstable up to 15\n1,600,000\nUp to 300,000\n8\n4\n15\n15\n60,000/burstable up to 200,000\n4/burstable up to 10\necs.c8i.3xlarge\n12\n24\n10/burstable up to 15\n2,400,000\nUp to 300,000\n12\n8\n15\n15\n80,000/burstable up to 200,000\n5/burstable up to 10\necs.c8i.4xlarge\n16\n32\n12/burstable up to 25\n3,000,000\n350,000\n16\n8\n30\n30\n100,000/burstable up to 200,000\n6/burstable up to 10\necs.c8i.6xlarge\n24\n48\n15/burstable up to 25\n4,500,000\n500,000\n24\n8\n30\n30\n120,000/burstable up to 200,000\n7.5/burstable up to 10\necs.c8i.8xlarge\n32\n64\n20/burstable up to 25\n6,000,000\n800,000\n32\n8\n30\n30\n200,000/none\n10/none\necs.c8i.12xlarge\n48\n96\n25/none\n9,000,000\n1,000,000\n48\n8\n30\n30\n300,000/none\n12/none\necs.c8i.16xlarge\n64\n128\n32/none\n12,000,000\n1,600,000\n64\n8\n30\n30\n360,000/none\n20/none\necs.c8i.24xlarge\n96\n192\n50/none\n18,000,000\n2,000,000\n64\n15\n30\n30\n500,000/none\n24/none\necs.c8i.48xlarge\n192\n512\n100/none\n30,000,000\n4,000,000\n64\n15\n50\n50\n1,000,000/none\n48/none\nIf you want to use the ecs.c8i.48xlarge instance type, submit a ticket.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide consistent computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios:\nAI scenarios, such as deep learning and training, and AI inference\nHigh-performance scientific computing scenarios, such as high-performance computing (HPC)\nLarge and medium-sized database systems, caches, and search clusters\nServers for massively multiplayer online (MMO) games\nOther general-purpose enterprise-level applications that have high performance requirements\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 3.4 GHz AMD EPYCTM Genoa processors that deliver a single-core turbo frequency of up to 3.75 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview.\nc8ae instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c8ae.large\n2\n4\n3/burstable up to 15\n1,000,000\nYes\nUp to 300,000\n2\n3\n6\n6\n30,000/burstable up to 200,000\n2/burstable up to 10\necs.c8ae.xlarge\n4\n8\n4/burstable up to 15\n1,200,000\nYes\nUp to 300,000\n4\n4\n15\n15\n50,000/burstable up to 200,000\n2.5/burstable up to 10\necs.c8ae.2xlarge\n8\n16\n6/burstable up to 15\n1,600,000\nYes\nUp to 300,000\n8\n4\n15\n15\n60,000/burstable up to 200,000\n3/burstable up to 10\necs.c8ae.4xlarge\n16\n32\n12/burstable up to 25\n3,000,000\nYes\n500,000\n16\n8\n30\n30\n100,000/burstable up to 200,000\n6/burstable up to 10\necs.c8ae.8xlarge\n32\n64\n20/burstable up to 25\n6,000,000\nYes\n1,000,000\n32\n8\n30\n30\n200,000/none\n10/none\necs.c8ae.16xlarge\n64\n128\n32/none\n9,000,000\nYes\n1,500,000\n64\n8\n30\n30\n250,000/none\n16/none\necs.c8ae.32xlarge\n128\n256\n64/none\n18,000,000\nYes\n3,000,000\n64\n15\n30\n30\n500,000/none\n32/none\nFor ecs.c8ae.large and ecs.c8ae.xlarge instances, you must enable the Jumbo Frames feature before the instances can burst their network bandwidths to 15 Gbit/s. For more information, see Jumbo Frames.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nVideo encoding and decoding\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers for MMO games\nScenarios where applications such as DevOps applications are developed and tested\nData analytics and batch computing\nHigh-performance scientific and engineering applications\nEnterprise-level applications of various types and sizes\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.55 GHz AMD EPYC\u2122 MILAN processors that deliver a single-core turbo frequency of up to 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nc7a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c7a.large\n2\n4\n1/burstable up to 10\n900,000\nUp to 250,000\n2\n3\n6\n6\n12,500/burstable up to 110,000\n1/burstable up to 6\necs.c7a.xlarge\n4\n8\n1.5/burstable up to 10\n1,000,000\nUp to 250,000\n4\n4\n15\n15\n20,000/burstable up to 110,000\n1.5/burstable up to 6\necs.c7a.2xlarge\n8\n16\n2.5/burstable up to 10\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n30,000/burstable up to 110,000\n2/burstable up to 6\necs.c7a.4xlarge\n16\n32\n5/burstable up to 10\n2,000,000\n300,000\n8\n8\n30\n30\n60,000/burstable up to 110,000\n3/burstable up to 6\necs.c7a.8xlarge\n32\n64\n8/burstable up to 10\n3,000,000\n600,000\n16\n7\n30\n30\n75,000/burstable up to 110,000\n4/burstable up to 6\necs.c7a-nps1.8xlarge\n32\n64\n8/burstable up to 10\n3,000,000\n600,000\n16\n7\n30\n30\n75,000/burstable up to 110,000\n4/burstable up to 6\necs.c7a.16xlarge\n64\n128\n16/none\n6,000,000\n1,000,000\n32\n7\n30\n30\n150,000/none\n8/none\necs.c7a-nps1.16xlarge\n64\n128\n16/none\n6,000,000\n1,000,000\n32\n7\n30\n30\n150,000/none\n8/none\necs.c7a.32xlarge\n128\n256\n32/none\n12,000,000\n2,000,000\n32\n15\n30\n30\n300,000/none\n16/none\nUbuntu 16 and Debian 9 operating system kernels do not support AMD EPYC\u2122 MILAN processors. Do not use Ubuntu 16 or Debian 9 images to create instances of this instance family. Instances of this instance family created from Ubuntu 16 or Debian 9 images cannot be started.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nFrontend servers for MMO games\nWeb frontend servers\nData analytics, batch computing, and video encoding\nHigh-performance scientific and engineering applications\nScenarios that require secure and trusted computing\nEnterprise-level applications of various types and sizes\nBlockchain scenarios\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity:\nSupports the vTPM feature. For more information, see Overview.\nSupports the Enclave feature and provides virtualization-based confidential computing environments. For more information, see Build a confidential computing environment by using Enclave.\nc7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c7.large\n2\n4\n2/burstable up to 12.5\n1,100,000\nYes\nUp to 500,000\n2\n3\n6\n6\n8\n20,000/burstable up to 160,000\n1.5/burstable up to 10\necs.c7.xlarge\n4\n8\n3/burstable up to 12.5\n1,100,000\nYes\nUp to 500,000\n4\n4\n15\n15\n8\n40,000/burstable up to 160,000\n2/burstable up to 10\necs.c7.2xlarge\n8\n16\n5/burstable up to 15\n1,600,000\nYes\nUp to 500,000\n8\n4\n15\n15\n16\n50,000/burstable up to 160,000\n3/burstable up to 10\necs.c7.3xlarge\n12\n24\n8/burstable up to 15\n2,400,000\nYes\nUp to 500,000\n8\n8\n15\n15\n16\n70,000/burstable up to 160,000\n4/burstable up to 10\necs.c7.4xlarge\n16\n32\n10/burstable up to 25\n3,000,000\nYes\n500,000\n8\n8\n30\n30\n16\n80,000/burstable up to 160,000\n5/burstable up to 10\necs.c7.6xlarge\n24\n48\n12/burstable up to 25\n4,500,000\nYes\n550,000\n12\n8\n30\n30\n16\n110,000/burstable up to 160,000\n6/10\necs.c7.8xlarge\n32\n64\n16/burstable up to 32\n6,000,000\nYes\n600,000\n16\n8\n30\n30\n24\n160,000/none\n10/none\necs.c7.16xlarge\n64\n128\n32/none\n12,000,000\nYes\n1,200,000\n32\n8\n30\n30\n32\n360,000/none\n16/none\necs.c7.32xlarge\n128\n256\n64/none\n24,000,000\nYes\n2,400,000\n32\n15\n30\n30\n32\n600,000/none\n32/none\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers for MMO games\nData analytics, batch computing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nThe maximum performance of disks varies based on the instance families. A single instance of this instance family can deliver up to 200,000 IOPS.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nSupported instance type changes: Supports changes to g6 or r6 instance types.\nc6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.c6.large\n2\n4\n1/burstable up to 3\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.c6.xlarge\n4\n8\n1.5/burstable up to 5\n500,000\nUp to 250,000\n4\n3\n10\n1\n20,000\n1.5\necs.c6.2xlarge\n8\n16\n2.5/burstable up to 8\n800,000\nUp to 250,000\n8\n4\n10\n1\n25,000\n2\necs.c6.3xlarge\n12\n24\n4/burstable up to 10\n900,000\nUp to 250,000\n8\n6\n10\n10\n30,000\n2.5\necs.c6.4xlarge\n16\n32\n5/burstable up to 10\n1,000,000\n300,000\n8\n8\n20\n1\n40,000\n3\necs.c6.6xlarge\n24\n48\n7.5/burstable up to 10\n1,500,000\n450,000\n12\n8\n20\n1\n50,000\n4\necs.c6.8xlarge\n32\n64\n10/none\n2,000,000\n600,000\n16\n8\n20\n1\n60,000\n5\necs.c6.13xlarge\n52\n96\n12.5/none\n3,000,000\n900,000\n32\n7\n20\n1\n100,000\n8\necs.c6.26xlarge\n104\n192\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios: video encoding and decoding, scenarios in which large volumes of packets are received and transmitted, web frontend servers, frontend servers for MMO games, and scenarios where applications such as DevOps applications are developed and tested.\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.6 GHz AMD EPYC\u2122 ROME processors that deliver a turbo frequency of 3.3 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nc6a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.c6a.large\n2\n4\n1/10\n900,000\nUp to 250,000\n2\n2\n6\n1\n12,500\n1\necs.c6a.xlarge\n4\n8\n1.5/10\n1,000,000\nUp to 250,000\n4\n3\n15\n1\n20,000\n1.5\necs.c6a.2xlarge\n8\n16\n2.5/10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n30,000\n2\necs.c6a.4xlarge\n16\n32\n5/10\n2,000,000\n300,000\n8\n8\n30\n1\n60,000\n3.1\necs.c6a.8xlarge\n32\n64\n8/10\n3,000,000\n600,000\n16\n7\n30\n1\n75,000\n4.1\necs.c6a.16xlarge\n64\n128\n16/none\n6,000,000\n1,000,000\n32\n8\n30\n1\n150,000\n8.2\necs.c6a.32xlarge\n128\n256\n32/none\n12,000,000\n2,000,000\n32\n15\n30\n1\n300,000\n16.4\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers for MMO games\nData analytics, batch computing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nNetwork performance varies based on the instance families. For higher concurrent connection and network packet forwarding capabilities, we recommend that you use the g7ne instance family.\nProvides high network performance based on large computing capacity.\nc6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.c6e.large\n2\n4\n1.2/burstable up to 10\n900,000\nUp to 250,000\n2\n3\n6\n1\n20,000\n1\necs.c6e.xlarge\n4\n8\n2/burstable up to 10\n1,000,000\nUp to 250,000\n4\n4\n15\n1\n40,000\n1.5\necs.c6e.2xlarge\n8\n16\n3/burstable up to 10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n50,000\n2\necs.c6e.4xlarge\n16\n32\n6/burstable up to 10\n3,000,000\n300,000\n8\n8\n30\n1\n80,000\n3\necs.c6e.8xlarge\n32\n64\n10/none\n6,000,000\n600,000\n16\n8\n30\n1\n150,000\n5\necs.c6e.13xlarge\n52\n96\n16/none\n9,000,000\n1,000,000\n32\n7\n30\n1\n240,000\n8\necs.c6e.26xlarge\n104\n192\n32/none\n24,000,000\n1,800,000\n32\n15\n30\n1\n480,000\n16\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers for MMO games\nData analytics, batch computing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nInstances of this instance family may be deployed on different server platforms. If your business requires all instances to be deployed on the same server platform, we recommend that you use the c6, c6e, or c7 instance family.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nThe maximum performance of disks varies based on the instance families. A single instance of this instance family can deliver up to 200,000 IOPS.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nc5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.c5.large\n2\n4\n1\n300,000\n2\n2\n6\n1\necs.c5.xlarge\n4\n8\n1.5\n500,000\n2\n3\n10\n1\necs.c5.2xlarge\n8\n16\n2.5\n800,000\n4\n4\n10\n1\necs.c5.3xlarge\n12\n24\n4\n900,000\n4\n6\n10\n1\necs.c5.4xlarge\n16\n32\n5\n1,000,000\n4\n8\n20\n1\necs.c5.6xlarge\n24\n48\n7.5\n1,500,000\n6\n8\n20\n1\necs.c5.8xlarge\n32\n64\n10\n2,000,000\n8\n8\n20\n1\necs.c5.16xlarge\n64\n128\n20\n4,000,000\n16\n8\n20\n1\nSupported scenarios:\nWeb frontend servers\nData analytics, batch computing, and video encoding\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nFrontend servers for MMO games\nCompute:\nOffers a CPU-to-memory ratio of 1:1.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) or 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 2.7 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports only IPv4.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nic5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.ic5.large\n2\n2\n1\n300,000\n2\n2\n6\necs.ic5.xlarge\n4\n4\n1.5\n500,000\n2\n3\n10\necs.ic5.2xlarge\n8\n8\n2.5\n800,000\n2\n4\n10\necs.ic5.3xlarge\n12\n12\n4\n900,000\n4\n6\n10\necs.ic5.4xlarge\n16\n16\n5\n1,000,000\n4\n8\n20\necs.ic5.6xlarge\n24\n24\n7.5\n1,500,000\n6\n8\n20\necs.ic5.8xlarge\n32\n32\n10\n2,000,000\n8\n8\n20\necs.ic5.16xlarge\n64\n64\n20\n3,000,000\n16\n8\n20\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers for MMO games\nData analytics, batch computing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell), Platinum 8163 (Skylake), or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nInstances of this instance family may be deployed on different server platforms. If your business requires all instances to be deployed on the same server platform, we recommend that you use the c6, c6e, or c7 instance family.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nsn1ne instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.sn1ne.large\n2\n4\n1\n300,000\n2\n2\n6\n1\necs.sn1ne.xlarge\n4\n8\n1.5\n500,000\n2\n3\n10\n1\necs.sn1ne.2xlarge\n8\n16\n2\n1,000,000\n4\n4\n10\n1\necs.sn1ne.3xlarge\n12\n24\n2.5\n1,300,000\n4\n6\n10\n1\necs.sn1ne.4xlarge\n16\n32\n3\n1,600,000\n4\n8\n20\n1\necs.sn1ne.6xlarge\n24\n48\n4.5\n2,000,000\n6\n8\n20\n1\necs.sn1ne.8xlarge\n32\n64\n6\n2,500,000\n8\n8\n20\n1\nIntroduction: This instance family uses the innovative Cloud Infrastructure Processing Unit (CIPU) architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios:\nMemory-intensive, general-purpose, enterprise-level applications such as Java\nVarious in-memory database applications such as Redis and Memcache\nBig data applications such as Kafka and Elasticsearch\nAudio and video transcoding applications\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.7 GHz AMD EPYCTM Genoa processors that deliver a turbo frequency of up to 3.7 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see the Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types section of the \"Compatibility between AMD instance types and operating systems\" topic.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports Elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview of trusted computing capabilities.\nr8a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r8a.large\n2\n16\n1.5/burstable up to 12.5\n900,000\nUp to 250,000\n2\n3\n6\n6\n25,000/burstable up to 110,000\n1.5/burstable up to 10\necs.r8a.xlarge\n4\n32\n2.5/burstable up to 12.5\n1,000,000\nUp to 250,000\n4\n4\n6\n6\n30,000/burstable up to 110,000\n2/burstable up to 10\necs.r8a.2xlarge\n8\n64\n4/burstable up to 12.5\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n45,000/burstable up to 110,000\n2.5/burstable up to 10\necs.r8a.4xlarge\n16\n128\n7/burstable up to 12.5\n2,000,000\n300,000\n16\n8\n30\n30\n60,000/burstable up to 110,000\n3.5/burstable up to 10\necs.r8a.8xlarge\n32\n256\n10/burstable up to 25\n3,000,000\n600,000\n32\n8\n30\n30\n80,000/burstable up to 110,000\n5/burstable up to 10\necs.r8a.12xlarge\n48\n384\n16/25\n4,500,000\n750,000\n48\n8\n30\n30\n120,000/none\n8/burstable up to 10\necs.r8a.16xlarge\n64\n512\n20/25\n6,000,000\n1,000,000\n64\n8\n30\n30\n160,000/none\n10/none\necs.r8a.24xlarge\n96\n768\n32/none\n9,000,000\n1,500,000\n64\n15\n30\n30\n240,000/none\n16/none\necs.r8a.32xlarge\n128\n1,024\n40/none\n12,000,000\n2,000,000\n64\n15\n30\n30\n320,000/none\n20/none\necs.r8a.48xlarge\n192\n1,536\n64/none\n18,000,000\n3,000,000\n64\n15\n30\n30\n500,000/none\n32/none\nFor ecs.r8a.large and ecs.r8a.xlarge instances, you must enable the Jumbo Frames feature before the instances can burst their network bandwidths to 12.5 Gbit/s. For more information, see Jumbo Frames.\nTo use the ecs.r8a.48xlarge instance type, submit a ticket.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios:\nData analytics and mining\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nDistributed in-memory cache, such as Redis\nWebsites and application servers\nServers of massively multiplayer online (MMO) games\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses Intel\u00ae Xeon\u00ae Emerald Rapids or Intel\u00ae Xeon\u00ae Sapphire Rapids processors that deliver a clock speed of at least 2.7 GHz and an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports ERIs. For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity:\nSupports the vTPM feature. For more information, see Overview of trusted computing capabilities.\nSupports Intel Total Memory Encryption (TME) to encrypt memory.\nr8i instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r8i.large\n2\n16\n2.5/burstable up to 15\n1,000,000\nUp to 300,000\n2\n3\n6\n6\n25,000/burstable up to 200,000\n2/burstable up to 10\necs.r8i.xlarge\n4\n32\n4/burstable up to 15\n1,200,000\nUp to 300,000\n4\n4\n15\n15\n50,000/burstable up to 200,000\n2.5/burstable up to 10\necs.r8i.2xlarge\n8\n64\n6/burstable up to 15\n1,600,000\nUp to 300,000\n8\n4\n15\n15\n60,000/burstable up to 200,000\n4/burstable up to 10\necs.r8i.3xlarge\n12\n96\n10/burstable up to 15\n2,400,000\nUp to 300,000\n12\n8\n15\n15\n80,000/burstable up to 200,000\n5/burstable up to 10\necs.r8i.4xlarge\n16\n128\n12/burstable up to 25\n3,000,000\n350,000\n16\n8\n30\n30\n100,000/burstable up to 200,000\n6/burstable up to 10\necs.r8i.6xlarge\n24\n192\n15/burstable up to 25\n4,500,000\n500,000\n24\n8\n30\n30\n120,000/burstable up to 200,000\n7.5/burstable up to 10\necs.r8i.8xlarge\n32\n256\n20/burstable up to 25\n6,000,000\n800,000\n32\n8\n30\n30\n200,000/none\n10/none\necs.r8i.12xlarge\n48\n384\n25/none\n9,000,000\n1,000,000\n48\n8\n30\n30\n300,000/none\n12/none\necs.r8i.16xlarge\n64\n512\n32/none\n12,000,000\n1,600,000\n64\n8\n30\n30\n360,000/none\n20/none\necs.r8i.32xlarge\n128\n1,024\n64/none\n24,000,000\n3,000,000\n64\n15\n30\n30\n700,000/none\n40/none\nTo use the ecs.r8i.16xlarge and ecs.r8i.32xlarge instance types, submit a ticket.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and chip-level security hardening.\nSupported scenarios:\nAI scenarios, such as deep learning and training, and AI inference\nHigh-performance scientific computing scenarios such as high-performance computing (HPC)\nLarge and medium-sized database systems, caches, and search clusters\nServers of MMO games\nOther general-purpose enterprise-level applications that have high performance requirements\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 3.4 GHz AMD EPYCTM Genoa processors that deliver a single-core turbo frequency of up to 3.75 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see the Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types section of the \"Compatibility between AMD instance types and operating systems\" topic.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports ERIs. For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the vTPM feature. For more information, see Overview of trusted computing capabilities.\nr8ae instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r8ae.large\n2\n16\n3/burstable up to 15\n1,000,000\nYes\nUp to 300,000\n2\n3\n6\n6\n30,000/burstable up to 200,000\n2/burstable up to 10\necs.r8ae.xlarge\n4\n32\n4/burstable up to 15\n1,200,000\nYes\nUp to 300,000\n4\n4\n15\n15\n50,000/burstable up to 200,000\n2.5/burstable up to 10\necs.r8ae.2xlarge\n8\n64\n6/burstable up to 15\n1,600,000\nYes\nUp to 300,000\n8\n4\n15\n15\n60,000/burstable up to 200,000\n3/burstable up to 10\necs.r8ae.4xlarge\n16\n128\n12/burstable up to 25\n3,000,000\nYes\n500,000\n16\n8\n30\n30\n100,000/burstable up to 200,000\n6/burstable up to 10\necs.r8ae.8xlarge\n32\n256\n20/burstable up to 25\n6,000,000\nYes\n1,000,000\n32\n8\n30\n30\n200,000/none\n10/none\nFor ecs.r8ae.large and ecs.r8ae.xlarge instances, you must enable the Jumbo Frames feature before the instances can burst their network bandwidths to 15 Gbit/s. For more information, see Jumbo Frames.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.55 GHz AMD EPYCTM MILAN processors that deliver a single-core turbo frequency of up to 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see the Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types section of the \"Compatibility between AMD instance types and operating systems\" topic.\nSupported scenarios:\nHigh-performance databases and in-memory databases\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nBlockchain applications\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nr7a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r7a.large\n2\n16\n1/burstable up to 10\n900,000\nUp to 250,000\n2\n3\n6\n6\n12,500/burstable up to 110,000\n1/burstable up to 6\necs.r7a.xlarge\n4\n32\n1.5/burstable up to 10\n1,000,000\nUp to 250,000\n4\n4\n15\n15\n20,000/burstable up to 110,000\n1.5/burstable up to 6\necs.r7a.2xlarge\n8\n64\n2.5/burstable up to 10\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n30,000/burstable up to 110,000\n2/burstable up to 6\necs.r7a.4xlarge\n16\n128\n5/burstable up to 10\n2,000,000\n300,000\n8\n8\n30\n30\n60,000/burstable up to 110,000\n3/burstable up to 6\necs.r7a.8xlarge\n32\n256\n8/burstable up to 10\n3,000,000\n600,000\n16\n7\n30\n30\n75,000/burstable up to 110,000\n4/burstable up to 6\necs.r7a-nps1.8xlarge\n32\n256\n8/burstable up to 10\n3,000,000\n8/burstable up to 10\n16\n7\n30\n30\n75,000/burstable up to 110,000\n4/burstable up to 6\necs.r7a.16xlarge\n64\n512\n16/none\n6,000,000\n1,000,000\n32\n7\n30\n30\n150,000/none\n8/none\necs.r7a-nps1.16xlarge\n64\n512\n16/none\n6,000,000\n1,000,000\n32\n7\n30\n30\n150,000/none\n8/none\necs.r7a.32xlarge\n128\n1,024\n32/none\n12,000,000\n2,000,000\n32\n15\n30\n30\n300,000/none\n16/none\nUbuntu 16 and Debian 9 operating system kernels do not support AMD EPYCTM MILAN processors. Do not use Ubuntu 16 or Debian 9 images to create instances of this instance family. Instances of this instance family created from Ubuntu 16 or Debian 9 images cannot be started.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nHigh-performance databases and in-memory databases\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nScenarios that require secure and trusted computing\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nAllows you to enable or disable Hyper-Threading.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nSecurity:\nSupports the vTPM feature. For more information, see Overview of trusted computing capabilities.\nSupports the Enclave feature and provides a virtualization-based confidential computing environment. For more information, see Build a confidential computing environment by using Enclave.\nr7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r7.large\n2\n16\n2/burstable up to 12.5\n1,100,000\nYes\nUp to 500,000\n2\n3\n6\n6\n8\n20,000/burstable up to 160,000\n1.5/burstable up to 10\necs.r7.xlarge\n4\n32\n3/burstable up to 12.5\n1,100,000\nYes\nUp to 500,000\n4\n4\n15\n15\n8\n40,000/burstable up to 160,000\n2/burstable up to 10\necs.r7.2xlarge\n8\n64\n5/burstable up to 15\n1,600,000\nYes\nUp to 500,000\n8\n4\n15\n15\n16\n50,000/burstable up to 160,000\n3/burstable up to 10\necs.r7.3xlarge\n12\n96\n8/burstable up to 15\n2,400,000\nYes\nUp to 500,000\n8\n8\n15\n15\n16\n70,000/burstable up to 160,000\n4/burstable up to 10\necs.r7.4xlarge\n16\n128\n10/burstable up to 25\n3,000,000\nYes\n500,000\n8\n8\n30\n30\n16\n80,000/burstable up to 160,000\n5/burstable up to 10\necs.r7.6xlarge\n24\n192\n12/burstable up to 25\n4,500,000\nYes\n550,000\n12\n8\n30\n30\n16\n110,000/160,000\n6/10\necs.r7.8xlarge\n32\n256\n16/burstable up to 32\n6,000,000\nYes\n600,000\n16\n8\n30\n30\n24\n160,000/none\n10/none\necs.r7.16xlarge\n64\n512\n32/none\n12,000,000\nYes\n1,200,000\n32\n8\n30\n30\n32\n360,000/none\n20/none\necs.r7.32xlarge\n128\n1,024\n64/none\n24,000,000\nYes\n2,400,000\n32\n15\n30\n30\n32\n600,000/none\n32/none\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nThe maximum performance of disks varies based on the instance families. A single instance of this instance family can deliver up to 200,000 IOPS.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nInstance type change: Supports changes to g6 or c6 instance types.\nr6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.r6.large\n2\n16\n1/burstable up to 3\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.r6.xlarge\n4\n32\n1.5/burstable up to 5\n500,000\nUp to 250,000\n4\n3\n10\n1\n20,000\n1.5\necs.r6.2xlarge\n8\n64\n2.5/burstable up to 8\n800,000\nUp to 250,000\n8\n4\n10\n1\n25,000\n2\necs.r6.3xlarge\n12\n96\n4/burstable up to 10\n900,000\nUp to 250,000\n8\n6\n10\n1\n30,000\n2.5\necs.r6.4xlarge\n16\n128\n5/burstable up to 10\n1,000,000\n300,000\n8\n8\n20\n1\n40,000\n3\necs.r6.6xlarge\n24\n192\n7.5/burstable up to 10\n1,500,000\n450,000\n12\n8\n20\n1\n50,000\n4\necs.r6.8xlarge\n32\n256\n10/none\n2,000,000\n600,000\n16\n8\n20\n1\n60,000\n5\necs.r6.13xlarge\n52\n384\n12.5/none\n3,000,000\n900,000\n32\n7\n20\n1\n100,000\n8\necs.r6.26xlarge\n104\n768\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios: scenarios where large volumes of packets are received and transmitted, video encoding and decoding, in-memory databases, enterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters, and scenarios where applications such as DevOps applications are developed and tested.\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.6 GHz AMD EPYCTM ROME processors that deliver a turbo frequency of 3.3 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see the Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types section of the \"Compatibility between AMD instance types and operating systems\" topic.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nr6a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.r6a.large\n2\n16\n1/10\n900,000\nUp to 250,000\n2\n2\n6\n1\n12,500\n1\necs.r6a.xlarge\n4\n32\n1.5/10\n1,000,000\nUp to 250,000\n4\n3\n15\n1\n20,000\n1.5\necs.r6a.2xlarge\n8\n64\n2.5/10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n30,000\n2\necs.r6a.4xlarge\n16\n128\n5/10\n2,000,000\n300,000\n8\n8\n30\n1\n60,000\n3.1\necs.r6a.8xlarge\n32\n256\n8/10\n3,000,000\n600,000\n16\n7\n30\n1\n75,000\n4.1\necs.r6a.16xlarge\n64\n512\n16/none\n6,000,000\n1,000,000\n32\n8\n30\n1\n150,000\n8.2\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nNetwork performance varies based on the instance families. For higher concurrent connection and network packet forwarding capabilities, we recommend that you use the g7ne instance family.\nr6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.r6e.large\n2\n16\n1.2/burstable up to 10\n900,000\nUp to 250,000\n2\n3\n6\n1\n20,000\n1\necs.r6e.xlarge\n4\n32\n2/burstable up to 10\n1,000,000\nUp to 250,000\n4\n4\n15\n1\n40,000\n1.5\necs.r6e.2xlarge\n8\n64\n3/burstable up to 10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n50,000\n2\necs.r6e.4xlarge\n16\n128\n6/burstable up to 10\n3,000,000\n300,000\n8\n8\n30\n1\n80,000\n3\necs.r6e.8xlarge\n32\n256\n10/none\n6,000,000\n600,000\n16\n8\n30\n1\n150,000\n5\necs.r6e.13xlarge\n52\n384\n16/none\n9,000,000\n1,000,000\n32\n7\n30\n1\n240,000\n8\necs.r6e.26xlarge\n104\n768\n32/none\n24,000,000\n1,800,000\n32\n15\n30\n1\n480,000\n16\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) or Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors to provide consistent computing performance.\nInstances of this instance family may be deployed on different server platforms. If your business requires all instances to be deployed on the same server platform, we recommend that you use the r6, r6e, or r7 instance family instead.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nThe maximum performance of disks varies based on the instance families. A single instance of this instance family can deliver up to 200,000 IOPS.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nr5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.r5.large\n2\n16\n1\n300,000\n2\n2\n6\n1\necs.r5.xlarge\n4\n32\n1.5\n500,000\n2\n3\n10\n1\necs.r5.2xlarge\n8\n64\n2.5\n800,000\n4\n4\n10\n1\necs.r5.3xlarge\n12\n96\n4\n900,000\n4\n6\n10\n1\necs.r5.4xlarge\n16\n128\n5\n1,000,000\n4\n8\n20\n1\necs.r5.6xlarge\n24\n192\n7.5\n1,500,000\n6\n8\n20\n1\necs.r5.8xlarge\n32\n256\n10\n2,000,000\n8\n8\n20\n1\necs.r5.16xlarge\n64\n512\n20\n4,000,000\n16\n8\n20\n1\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) or Platinum 8163 (Skylake) or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nInstances of this instance family may be deployed on different server platforms. If your business requires all instances to be deployed on the same server platform, we recommend that you use the r6, r6e, or r7 instance family instead.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nse1ne instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.se1ne.large\n2\n16\n1\n300,000\n2\n2\n6\n1\necs.se1ne.xlarge\n4\n32\n1.5\n500,000\n2\n3\n10\n1\necs.se1ne.2xlarge\n8\n64\n2\n1,000,000\n4\n4\n10\n1\necs.se1ne.3xlarge\n12\n96\n2.5\n1,300,000\n4\n6\n10\n1\necs.se1ne.4xlarge\n16\n128\n3\n1,600,000\n4\n8\n20\n1\necs.se1ne.6xlarge\n24\n192\n4.5\n2,000,000\n6\n8\n20\n1\necs.se1ne.8xlarge\n32\n256\n6\n2,500,000\n8\n8\n20\n1\necs.se1ne.14xlarge\n56\n480\n10\n4,500,000\n14\n8\n20\n1\nSupported scenarios:\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) or Platinum 8163 (Skylake) or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports only IPv4.\nProvides high network performance based on large computing capacity.\nse1 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.se1.large\n2\n16\n0.5\n100,000\n1\n2\n6\necs.se1.xlarge\n4\n32\n0.8\n200,000\n1\n3\n10\necs.se1.2xlarge\n8\n64\n1.5\n400,000\n1\n4\n10\necs.se1.4xlarge\n16\n128\n3\n500,000\n2\n8\n20\necs.se1.8xlarge\n32\n256\n6\n800,000\n3\n8\n20\necs.se1.14xlarge\n56\n480\n10\n1,200,000\n4\n8\n20\nFeatures:\nCompute:\nOffers the following CPU-to-memory ratios: 1:2, 1:4, and 1:8.\nUses Intel\u00ae Xeon\u00ae Platinum Scalable processors.\nu1 instances are randomly deployed to different server platforms during instance creation and may be migrated across server platforms during the lifecycle of the instances. u1 instances use technological capabilities to promote cross-platform compatibility. However, business performance significantly varies between server platforms. If your business requires performance consistency, we recommend that you use g7, c7, or r7 instances.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports enhanced SSDs (ESSDs), ESSD Entry disks, and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6.\nSupports only virtual private clouds (VPCs).\nProvides high network performance based on large computing capacity.\nSupported scenarios:\nSmall and medium-sized enterprise-level applications\nWebsites and application servers\nData analytics and computing\nSmall and medium-sized database systems, caches, and search clusters\nInstance types\nInstance type\nvCPUs\nMemory size (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.u1-c1m1.large\n2\n2\n1\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.u1-c1m2.large\n2\n4\n1\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.u1-c1m4.large\n2\n8\n1\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.u1-c1m8.large\n2\n16\n1\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.u1-c1m1.xlarge\n4\n4\n1.5\n500,000\nUp to 250,000\n2\n3\n10\n1\n20,000\n1.5\necs.u1-c1m2.xlarge\n4\n8\n1.5\n500,000\nUp to 250,000\n2\n3\n10\n1\n20,000\n1.5\necs.u1-c1m4.xlarge\n4\n16\n1.5\n500,000\nUp to 250,000\n2\n3\n10\n1\n20,000\n1.5\necs.u1-c1m8.xlarge\n4\n32\n1.5\n500,000\nUp to 250,000\n2\n3\n10\n1\n20,000\n1.5\necs.u1-c1m1.2xlarge\n8\n8\n2.5\n800,000\nUp to 250,000\n4\n4\n10\n1\n25,000\n2\necs.u1-c1m2.2xlarge\n8\n16\n2.5\n800,000\nUp to 250,000\n4\n4\n10\n1\n25,000\n2\necs.u1-c1m4.2xlarge\n8\n32\n2.5\n800,000\nUp to 250,000\n4\n4\n10\n1\n25,000\n2\necs.u1-c1m8.2xlarge\n8\n64\n2.5\n800,000\nUp to 250,000\n4\n4\n10\n1\n25,000\n2\necs.u1-c1m1.3xlarge\n12\n12\n4\n900,000\nUp to 250,000\n4\n6\n10\n1\n30,000\n2.5\necs.u1-c1m2.3xlarge\n12\n24\n4\n900,000\nUp to 250,000\n4\n6\n10\n1\n30,000\n2.5\necs.u1-c1m4.3xlarge\n12\n48\n4\n900,000\nUp to 250,000\n4\n6\n10\n1\n30,000\n2.5\necs.u1-c1m8.3xlarge\n12\n96\n4\n900,000\nUp to 250,000\n4\n6\n10\n1\n30,000\n2.5\necs.u1-c1m1.4xlarge\n16\n16\n5\n1,000,000\nUp to 300,000\n4\n8\n20\n1\n40,000\n3\necs.u1-c1m2.4xlarge\n16\n32\n5\n1,000,000\nUp to 300,000\n4\n8\n20\n1\n40,000\n3\necs.u1-c1m4.4xlarge\n16\n64\n5\n1,000,000\nUp to 300,000\n4\n8\n20\n1\n40,000\n3\necs.u1-c1m8.4xlarge\n16\n128\n5\n1,000,000\nUp to 300,000\n4\n8\n20\n1\n40,000\n3\necs.u1-c1m1.8xlarge\n32\n32\n10\n2,000,000\nUp to 300,000\n8\n8\n20\n1\n60,000\n5\necs.u1-c1m2.8xlarge\n32\n64\n10\n2,000,000\nUp to 300,000\n8\n8\n20\n1\n60,000\n5\necs.u1-c1m4.8xlarge\n32\n128\n10\n2,000,000\nUp to 300,000\n8\n8\n20\n1\n60,000\n5\necs.u1-c1m8.8xlarge\n32\n256\n10\n2,000,000\nUp to 300,000\n8\n8\n20\n1\n60,000\n5\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor information about the specifications of the instance types, see the Instance type specifications section of the \"Overview of instance families\" topic.\nExceptions may occur when you deploy Data Plane Development Kit (DPDK) applications on u1 instances. To resolve the issue, replace Userspace I/O (UIO) drivers with Virtual Function I/O (VFIO) drivers. For more information, see Replace UIO drivers with VFIO drivers.\nFor frequently asked questions about universal instances, see the sections that are related to u1 instances in Instance FAQ.\nFeatures:\nThis instance family is equipped with 12-TB, large-capacity, high-throughput local SATA HDDs and can provide a maximum network bandwidth of 64 Gbit/s between instances.\nSupported scenarios:\nBig data computing and storage business scenarios in which services such as Hadoop MapReduce, HDFS, Hive, and HBase are used\nMachine learning scenarios such as Spark in-memory computing and MLlib\nSearch and log data processing scenarios in which solutions such as Elasticsearch and Kafka are used\nThis instance family supports online replacement and hot swapping of damaged disks to prevent instance shutdown.\nIf a local disk fails, you receive a system event. You can handle the system event by initiating the process of repairing the damaged disk. For more information, see O&M scenarios and system events for instances equipped with local disks.\nAfter you initiate the process of repairing the damaged disk, data stored on the damaged disk cannot be restored.\nCompute:\nUses 2.7 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports only ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nd3s instance types\nInstance type\nvCPUs\nMemory size (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline/burst bandwidth (Gbit/s)\necs.d3s.2xlarge\n8\n32\n4 * 11,918 GB (4 * 11,100 GiB)\n10/burstable up to 15\n2,000,000\n3/burstable up to 5\necs.d3s.4xlarge\n16\n64\n8 * 11,918 GB (8 * 11,100 GiB)\n25/none\n3,000,000\n5/none\necs.d3s.8xlarge\n32\n128\n16 * 11,918 GB (16 * 11,100 GiB)\n40/none\n6,000,000\n8/none\necs.d3s.12xlarge\n48\n192\n24 * 11,918 GB (24 * 11,100 GiB)\n60/none\n9,000,000\n12/none\necs.d3s.16xlarge\n64\n256\n32 * 11,918 GB (32 * 11,100 GiB)\n80/none\n12,000,000\n16/none\nFeatures:\nThis instance family is equipped with high-capacity and high-throughput local disks and can provide a maximum bandwidth of 40 Gbit/s between instances.\nSupported scenarios:\nBig data computing and storage business scenarios in which services such as Hadoop MapReduce, HDFS, Hive, and HBase are used\nScenarios in which EMR JindoFS and Object Storage Service (OSS) are used in combination to separately store hot and cold data and decouple storage from computing\nMachine learning scenarios such as Spark in-memory computing and MLlib\nSearch and log data processing scenarios in which solutions such as Elasticsearch and Kafka are used\nThis instance family supports online replacement and hot swapping of damaged disks to prevent instance shutdown.\nIf a local disk fails, you receive a system event. You can handle the system event by initiating the process of repairing the damaged disk. For more information, see O&M scenarios and system events for instances equipped with local disks.\nAfter you initiate the process of repairing the damaged disk, data stored on the damaged disk cannot be restored.\nCompute:\nUses third-generation 2.9 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports only ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nd3c instance types\nInstance type\nvCPUs\nMemory size (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.d3c.3xlarge\n14\n56.0\n1 * 13,743 GB (1 * 12,800 GiB)\n8/burstable up to 10\n1,600,000\n40,000/none\n3/none\necs.d3c.7xlarge\n28\n112.0\n2 * 13,743 GB (2 * 12,800 GiB)\n16/burstable up to 25\n2,500,000\n50,000/none\n4/none\necs.d3c.14xlarge\n56\n224.0\n4 * 13,743 GB (4 * 12,800 GiB)\n40/none\n5,000,000\n100,000/none\n8/none\nThis instance family supports only Linux images. When you create an instance of this instance family, select a Linux image.\nFeatures:\nThis instance family is equipped with high-capacity and high-throughput local SATA HDDs and can provide a maximum bandwidth of 35 Gbit/s between instances.\nSupported scenarios:\nBig data computing and storage business scenarios in which services such as Hadoop MapReduce, HDFS, Hive, and HBase are used\nScenarios in which EMR JindoFS and OSS are used in combination to separately store hot and cold data and decouple storage from computing\nMachine learning scenarios such as Spark in-memory computing and MLlib\nSearch and log data processing scenarios in which solutions such as Elasticsearch and Kafka are used\nThis instance family supports online replacement and hot swapping of damaged disks to prevent instance shutdown.\nIf a local disk fails, you receive a system event. You can handle the system event by initiating the process of repairing the damaged disk. For more information, see O&M scenarios and system events for instances equipped with local disks.\nAfter you initiate the process of repairing the damaged disk, data stored on the damaged disk cannot be restored.\nCompute:\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports enhanced SSDs (ESSDs), ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nd2c instance types\nInstance type\nvCPUs\nMemory size (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.d2c.6xlarge\n24\n88.0\n3 * 3,972 GB (3 * 3,700 GiB)\n12.0\n1,600,000\necs.d2c.12xlarge\n48\n176.0\n6 * 3,972 GB (6 * 3,700 GiB)\n20.0\n2,000,000\necs.d2c.24xlarge\n96\n352.0\n12 * 3,972 GB (12 * 3,700 GiB)\n35.0\n4,500,000\nFeatures:\nThis instance family is equipped with high-capacity and high-throughput local SATA HDDs and can provide a maximum bandwidth of 35 Gbit/s between instances.\nSupported scenarios:\nBig data computing and storage business scenarios in which services such as Hadoop MapReduce, HDFS, Hive, and HBase are used\nMachine learning scenarios such as Spark in-memory computing and MLlib\nSearch and log data processing scenarios in which solutions such as Elasticsearch and Kafka are used\nThis instance family supports online replacement and hot swapping of damaged disks to prevent instance shutdown.\nIf a local disk fails, you receive a system event. You can handle the system event by initiating the process of repairing the damaged disk. For more information, see O&M scenarios and system events for instances equipped with local disks.\nAfter you initiate the process of repairing the damaged disk, data stored on the damaged disk cannot be restored.\nCompute:\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nd2s instance types\nInstance type\nvCPUs\nMemory size (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.d2s.5xlarge\n20\n88.0\n8 * 7,838 GB (8 * 7,300 GiB)\n12.0\n1,600,000\necs.d2s.10xlarge\n40\n176.0\n15 * 7,838 GB (15 * 7,300 GiB)\n20.0\n2,000,000\necs.d2s.20xlarge\n80\n352.0\n30 * 7,838 GB (30 * 7,300 GiB)\n35.0\n4,500,000\nFeatures:\nThis instance family is equipped with high-capacity and high-throughput local SATA HDDs and can provide a maximum bandwidth of 35 Gbit/s between instances.\nSupported scenarios:\nScenarios in which services such as Hadoop MapReduce, HDFS, Hive, and HBase are used\nMachine learning scenarios such as Spark in-memory computing and MLlib\nSearch and log data processing scenarios in which solutions such as Elasticsearch are used\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for big data scenarios.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports only standard SSDs and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nd1ne instance types\nInstance type\nvCPUs\nMemory size (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.d1ne.2xlarge\n8\n32.0\n4 * 5,905 GB (4 * 5,500 GiB)\n6.0\n1,000,000\necs.d1ne.4xlarge\n16\n64.0\n8 * 5,905 GB (8 * 5,500 GiB)\n12.0\n1,600,000\necs.d1ne.6xlarge\n24\n96.0\n12 * 5,905 GB (12 * 5,500 GiB)\n16.0\n2,000,000\necs.d1ne-c8d3.8xlarge\n32\n128.0\n12 * 5,905 GB (12 * 5,500 GiB)\n20.0\n2,000,000\necs.d1ne.8xlarge\n32\n128.0\n16 * 5,905 GB (16 * 5,500 GiB)\n20.0\n2,500,000\necs.d1ne-c14d3.14xlarge\n56\n160.0\n12 * 5,905 GB (12 * 5,500 GiB)\n35.0\n4,500,000\necs.d1ne.14xlarge\n56\n224.0\n28 * 5,905 GB (28 * 5,500 GiB)\n35.0\n4,500,000\nFeatures:\nThis instance family is equipped with high-capacity and high-throughput local SATA HDDs and can provide a maximum bandwidth of 17 Gbit/s between instances.\nSupported scenarios:\nScenarios in which services such as Hadoop MapReduce, HDFS, Hive, and HBase are used\nMachine learning scenarios such as Spark in-memory computing and MLlib\nScenarios in which customers in industries such as Internet and finance need to compute, store, and analyze big data\nSearch and log data processing scenarios in which solutions such as Elasticsearch are used\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for big data scenarios.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports IPv4\nProvides high network performance based on large computing capacity.\nd1 instance types\nInstance type\nvCPUs\nMemory size (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.d1.2xlarge\n8\n32.0\n4 * 5,905 GB (4 * 5,500 GiB)\n3.0\n300,000\necs.d1.3xlarge\n12\n48.0\n6 * 5,905 GB (6 * 5,500 GiB)\n4.0\n400,000\necs.d1.4xlarge\n16\n64.0\n8 * 5,905 GB (8 * 5,500 GiB)\n6.0\n600,000\necs.d1.6xlarge\n24\n96.0\n12 * 5,905 GB (12 * 5,500 GiB)\n8.0\n800,000\necs.d1-c8d3.8xlarge\n32\n128.0\n12 * 5,905 GB (12 * 5,500 GiB)\n10.0\n1,000,000\necs.d1.8xlarge\n32\n128.0\n16 * 5,905 GB (16 * 5,500 GiB)\n10.0\n1,000,000\necs.d1-c14d3.14xlarge\n56\n160.0\n12 * 5,905 GB (12 * 5,500 GiB)\n17.0\n1,800,000\necs.d1.14xlarge\n56\n224.0\n28 * 5,905 GB (28 * 5,500 GiB)\n17.0\n1,800,000\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra and MongoDB, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nUses 2.7 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nIs compatible with specific operating systems. For more information, see Compatibility between the i4 instance types and operating systems.\ni4 instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.i4.large\n2\n16\n1 * 479 GB (1 * 447 GiB)\n2.5/15\n900,000\n20,000/burstable up to 110,000\n1.5/6\necs.i4.xlarge\n4\n32\n1 * 959 GB (1 * 894 GiB)\n4/15\n1,000,000\n40,000/burstable up to 110,000\n2/6\necs.i4.2xlarge\n8\n64\n1 * 1,919 GB (1 * 1,788 GiB)\n6/15\n1,600,000\n50,000/burstable up to 110,000\n3/6\necs.i4.4xlarge\n16\n128\n1 * 3,839 GB (1 * 3,576 GiB)\n10/25\n3,000,000\n80,000/burstable up to 110,000\n5/6\necs.i4.8xlarge\n32\n256\n2 * 3,839 GB (2 * 3,576 GiB)\n25/none\n6,000,000\n150,000/none\n8/none\necs.i4.16xlarge\n64\n512\n4 * 3,839 GB (4 * 3,576 GiB)\n50/none\n12,000,000\n300,000/none\n16/none\necs.i4.32xlarge\n128\n1,024\n8 * 3,839 GB (8 * 3,576 GiB)\n100/none\n24,000,000\n600,000/none\n32/none\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, E-MapReduce big data scenarios such as tiering of hot and cold data, storage and computing separation, and data lakes, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for high-performance databases.\nUses 2.7 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\ni4g instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.i4g.4xlarge\n16\n64\n1 * 959 GB (1 * 894 GiB)\n8/25\n3,000,000\n100,000\n6\necs.i4g.8xlarge\n32\n128\n1 * 1,919 GB (1 * 1,788 GiB)\n16/25\n6,000,000\n150,000\n8\necs.i4g.16xlarge\n64\n256\n2 * 1,919 GB (2 * 1,788 GiB)\n32/none\n12,000,000\n300,000\n16\necs.i4g.32xlarge\n128\n512\n4 * 1,919 GB (4 * 1,788 GiB)\n64/none\n24,000,000\n600,000\n32\nThis instance family supports only Linux images. When you create an instance of this instance family, you must select a Linux image.\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra and MongoDB, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:8, which is designed for high-performance databases. This instance family is the most cost-effective instance family that is suitable for scenarios such as hot data tiering and data lakes.\nUses 2.7 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\ni4r instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.i4r.4xlarge\n16\n128\n1 * 959 GB (1 * 894 GiB)\n8/25\n3,000,000\n100,000\n6\necs.i4r.8xlarge\n32\n256\n1 * 1,919 GB (1 * 1,788 GiB)\n16/25\n6,000,000\n150,000\n8\necs.i4r.16xlarge\n64\n512\n2 * 1,919 GB (2 * 1,788 GiB)\n32/none\n12,000,000\n300,000\n16\necs.i4r.32xlarge\n128\n1,024\n4 * 1,919 GB (4 * 1,788 GiB)\n64/none\n24,000,000\n600,000\n32\nIntroduction: This instance family uses the Intel\u00ae Second-generation Optane persistent memory (BPS) to provide ultra-high-performance local disks. For information about how to initialize local disks, see the Configure persistent memory as a local disk section of the \"Configure the usage mode of persistent memory\" topic.\nSupported scenarios:\nGene sequencing applications. For more information, see Case description.\nOn-disk key-value (KV) databases, such as RocksDB and ClickHouse.\nOLTP and high-performance relational databases for write-ahead log (WAL) optimization.\nNoSQL databases, such as Cassandra, MongoDB, and HBase.\nSearch scenarios that use solutions such as Elasticsearch.\nOther I/O-intensive applications that frequently write data to disks, such as message middleware and containers.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ni4p instance types\nInstance type\nvCPUs\nMemory (GiB)\nPersistent memory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.i4p.2xlarge\n8\n32\n1 * 126\n5/10\n1,600,000\n50,000/burstable up to 110,000\n3/6\necs.i4p.4xlarge\n16\n64\n2 * 126\n10/25\n3,000,000\n80,000/burstable up to 110,000\n5/6\necs.i4p.6xlarge\n24\n96\n3 * 126\n12/25\n4,500,000\n110,000/none\n6/none\necs.i4p.8xlarge\n32\n128\n4 * 126\n16/25\n6,000,000\n150,000/none\n8/none\necs.i4p.16xlarge\n64\n256\n1 * 1008\n32/none\n12,000,000\n300,000/none\n16/none\necs.i4p.32xlarge\n128\n512\n2 * 1008\n64/none\n24,000,000\n600,000/none\n32/none\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra, MongoDB, and HBase, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for high-performance databases.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ni3g instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.i3g.2xlarge\n8\n32\n1 * 479 GB (1 * 447 GiB)\n3/10\n1,750,000\n52,500\n2\necs.i3g.4xlarge\n16\n64\n1 * 959 GB (1 * 894 GiB)\n5/10\n3,500,000\n84,000\n3\necs.i3g.8xlarge\n32\n128\n2 * 959 GB (2 * 894 GiB)\n12/none\n7,000,000\n157,500\n5\necs.i3g.13xlarge\n52\n192\n3 * 959 GB (3 * 894 GiB)\n16/none\n12,000,000\n252,000\n8\necs.i3g.26xlarge\n104\n384\n6 * 959 GB (6 * 894 GiB)\n32/none\n24,000,000\n500,000\n16\nThis instance family supports only Linux images. When you create an instance of this instance family, you must select a Linux image.\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency, and allows damaged disks to be isolated online.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra and MongoDB, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ni3 instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.i3.xlarge\n4\n32\n1 * 959 GB (1 * 894 GiB)\n1.5/10\n1,000,000\n40,000\n1.5\necs.i3.2xlarge\n8\n64\n1 * 1,919 GB (1 * 1,788 GiB)\n2.5/10\n1,600,000\n50,000\n2\necs.i3.4xlarge\n16\n128\n2 * 1,919 GB (2 * 1,788 GiB)\n5/10\n3,000,000\n80,000\n3\necs.i3.8xlarge\n32\n256\n4 * 1,919 GB (4 * 1,788 GiB)\n10/none\n6,000,000\n150,000\n5\necs.i3.13xlarge\n52\n384\n6 * 1,919 GB (6 * 1,788 GiB)\n16/none\n9,000,000\n240,000\n8\necs.i3.26xlarge\n104\n768\n12 * 1,919 GB (12 * 1,788 GiB)\n32/none\n24,000,000\n480,000\n16\nThis instance family supports only Linux images. When you create an instance of this instance family, you must select a Linux image.\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra, MongoDB, and HBase, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:8, which is designed for high-performance databases.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ni2 instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk bandwidth (Gbit/s)\necs.i2.xlarge\n4\n32\n1 * 959 GB (1 * 894 GiB)\n1\n500,000\nUp to 16\necs.i2.2xlarge\n8\n64\n1 * 1,919 GB (1 * 1,788 GiB)\n2\n1,000,000\nUp to 16\necs.i2.4xlarge\n16\n128\n2 * 1,919 GB (2 * 1,788 GiB)\n3\n1,500,000\nUp to 16\necs.i2.8xlarge\n32\n256\n4 * 1,919 GB (4 * 1,788 GiB)\n6\n2,000,000\nUp to 16\necs.i2.16xlarge\n64\n512\n8 * 1,919 GB (8 * 1,788 GiB)\n10\n4,000,000\nUp to 16\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra, MongoDB, and HBase, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for high-performance databases.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports only IPv4.\nProvides high network performance based on large computing capacity.\ni2g instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.i2g.2xlarge\n8\n32\n1 * 959 GB (1 * 894 GiB)\n2\n1,000,000\necs.i2g.4xlarge\n16\n64\n1 * 1,919 GB (1 * 1,788 GiB)\n3\n1,500,000\necs.i2g.8xlarge\n32\n128\n2 * 1,919 GB (2 * 1,788 GiB)\n6\n2,000,000\necs.i2g.16xlarge\n64\n256\n4 * 1,919 GB (4 * 1,788 GiB)\n10\n4,000,000\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra, MongoDB, and HBase, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:8, which is designed for high-performance databases.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nProvides a network bandwidth of up to 20 Gbit/s.\ni2ne instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk bandwidth (Gbit/s)\necs.i2ne.xlarge\n4\n32\n1 * 959 GB (1 * 894 GiB)\n1.5\n500,000\nUp to 16\necs.i2ne.2xlarge\n8\n64\n1 * 1,919 GB (1 * 1,788 GiB)\n2.5\n1,000,000\nUp to 16\necs.i2ne.4xlarge\n16\n128\n2 * 1,919 GB (2 * 1,788 GiB)\n5\n1,500,000\nUp to 16\necs.i2ne.8xlarge\n32\n256\n4 * 1,919 GB (4 * 1,788 GiB)\n10\n2,000,000\nUp to 16\necs.i2ne.16xlarge\n64\n512\n8 * 1,919 GB (8 * 1,788 GiB)\n20\n4,000,000\nUp to 16\necs.i2ne.20xlarge\n80\n704\n10 * 1,919 GB (10 * 1,788 GiB)\n25\n4,500,000\nUp to 16\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra, MongoDB, and HBase, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for high-performance databases.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nProvides a network bandwidth of up to 20 Gbit/s.\ni2gne instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.i2gne.2xlarge\n8\n32\n1 * 959 GB (1 * 894 GiB)\n2.5\n1,000,000\necs.i2gne.4xlarge\n16\n64\n1 * 1,919 GB (1 * 1,788 GiB)\n5\n1,500,000\necs.i2gne.8xlarge\n32\n128\n2 * 1,919 GB (2 * 1,788 GiB)\n10\n2,000,000\necs.i2gne.16xlarge\n64\n256\n4 * 1,919 GB (4 * 1,788 GiB)\n20\n4,000,000\nIntroduction: This instance family is equipped with high-performance local NVMe SSDs that deliver high IOPS, high I/O throughput, and low latency.\nSupported scenarios: OLTP and high-performance relational databases, NoSQL databases such as Cassandra and MongoDB, and search scenarios that use solutions such as Elasticsearch.\nCompute:\nOffers a CPU-to-memory ratio of 1:4, which is designed for high-performance databases.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports only IPv4.\nProvides high network performance based on large computing capacity.\ni1 instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\necs.i1.xlarge\n4\n16\n2 * 111 GB (2 * 104 GiB)\n0.8\n200,000\necs.i1.2xlarge\n8\n32\n2 * 223 GB (2 * 208 GiB)\n1.5\n400,000\necs.i1.3xlarge\n12\n48\n2 * 335 GB (2 * 312 GiB)\n2\n400,000\necs.i1.4xlarge\n16\n64\n2 * 446 GB (2 * 416 GiB)\n3\n500,000\necs.i1-c5d1.4xlarge\n16\n64\n2 * 1,563 GB (2 * 1,456 GiB)\n3\n400,000\necs.i1.6xlarge\n24\n96\n2 * 670 GB (2 * 624 GiB)\n4.5\n600,000\necs.i1.8xlarge\n32\n128\n2 * 893 GB (2 * 832 GiB)\n6\n800,000\necs.i1-c10d1.8xlarge\n32\n128\n2 * 1,563 GB (2 * 1,456 GiB)\n6\n800,000\necs.i1.14xlarge\n56\n224\n2 * 1,563 GB (2 * 1,456 GiB)\n10\n1,200,000\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance frontend server clusters\nFrontend servers of MMO games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses Intel\u00ae Xeon\u00ae Cooper Lake processors that deliver an all-core turbo frequency of 3.8 GHz and a clock speed of at least 3.3 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nhfc7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.hfc7.large\n2\n4\n1.2/10\n900,000\n250,000\n2\n2\n6\n6\n20,000\n1\necs.hfc7.xlarge\n4\n8\n2/10\n1,000,000\n250,000\n4\n3\n15\n15\n30,000\n1.5\necs.hfc7.2xlarge\n8\n16\n3/10\n1,600,000\n250,000\n8\n4\n15\n15\n45,000\n2\necs.hfc7.3xlarge\n12\n24\n4.5/10\n2,000,000\n250,000\n8\n6\n15\n15\n60,000\n2.5\necs.hfc7.4xlarge\n16\n32\n6/10\n2,500,000\n300,000\n8\n8\n30\n30\n75,000\n3\necs.hfc7.6xlarge\n24\n48\n8/10\n3,000,000\n450,000\n12\n8\n30\n30\n90,000\n4\necs.hfc7.8xlarge\n32\n64\n10/none\n4,000,000\n600,000\n16\n8\n30\n30\n105,000\n5\necs.hfc7.12xlarge\n48\n96\n16/none\n6,000,000\n1,000,000\n24\n8\n30\n30\n150,000\n8\necs.hfc7.24xlarge\n96\n192\n32/none\n12,000,000\n1,800,000\n32\n15\n30\n30\n300,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers of MMO games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.5 GHz to provide consistent computing performance.\nThe processors used by this instance family have a clock speed of 3.1 GHz. However, the Intel System Studio (ISS) feature may cause a lower clock speed to be displayed. Alibaba Cloud is working on this issue. This issue does not affect the actual clock speeds of your instances.\nYou can separately run the following commands to use the turbostat tool to view the actual clock speeds:\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs), ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nhfc6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.hfc6.large\n2\n4\n1/3\n300,000\n35,000\n2\n2\n6\n1\n10,000\n1\necs.hfc6.xlarge\n4\n8\n1.5/5\n500,000\n70,000\n4\n3\n10\n1\n20,000\n1.5\necs.hfc6.2xlarge\n8\n16\n2.5/8\n800,000\n150,000\n8\n4\n10\n1\n25,000\n2\necs.hfc6.3xlarge\n12\n24\n4/10\n900,000\n220,000\n8\n6\n10\n1\n30,000\n2.5\necs.hfc6.4xlarge\n16\n32\n5/10\n1,000,000\n300,000\n8\n8\n20\n1\n40,000\n3\necs.hfc6.6xlarge\n24\n48\n7.5/10\n1,500,000\n450,000\n12\n8\n20\n1\n50,000\n4\necs.hfc6.8xlarge\n32\n64\n10/none\n2,000,000\n600,000\n16\n8\n20\n1\n60,000\n5\necs.hfc6.10xlarge\n40\n96\n12.5/none\n3,000,000\n1,000,000\n32\n7\n20\n1\n100,000\n8\necs.hfc6.16xlarge\n64\n128\n20/none\n4,000,000\n1,200,000\n32\n8\n20\n1\n120,000\n10\necs.hfc6.20xlarge\n80\n192\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nHigh-performance scientific computing\nVideo encoding applications\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses Intel\u00ae Xeon\u00ae Cooper Lake processors that deliver an all-core turbo frequency of 3.8 GHz and a clock speed of at least 3.3 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nhfg7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.hfg7.large\n2\n8\n1.2/10\n900,000\n250,000\n2\n2\n6\n6\n20,000\n1\necs.hfg7.xlarge\n4\n16\n2/10\n1,000,000\n250,000\n4\n3\n15\n15\n30,000\n1.5\necs.hfg7.2xlarge\n8\n32\n3/10\n1,600,000\n250,000\n8\n4\n15\n15\n45,000\n2\necs.hfg7.3xlarge\n12\n48\n4.5/10\n2,000,000\n250,000\n8\n6\n15\n15\n60,000\n2.5\necs.hfg7.4xlarge\n16\n64\n6/10\n2,500,000\n300,000\n8\n8\n30\n30\n75,000\n3\necs.hfg7.6xlarge\n24\n96\n8/10\n3,000,000\n450,000\n12\n8\n30\n30\n90,000\n4\necs.hfg7.8xlarge\n32\n128\n10/none\n4,000,000\n600,000\n16\n8\n30\n30\n105,000\n5\necs.hfg7.12xlarge\n48\n192\n16/none\n6,000,000\n1,000,000\n24\n8\n30\n30\n150,000\n8\necs.hfg7.24xlarge\n96\n384\n32/none\n12,000,000\n1,800,000\n32\n15\n30\n30\n300,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.5 GHz to provide consistent computing performance.\nThe processors used by this instance family have a clock speed of 3.1 GHz. However, the Intel System Studio (ISS) feature may cause a lower clock speed to be displayed. Alibaba Cloud is working on this issue. This issue does not affect the actual clock speeds of your instances.\nYou can separately run the following commands to use the turbostat tool to view the actual clock speeds:\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nhfg6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.hfg6.large\n2\n8\n1/3\n300,000\n35,000\n2\n2\n6\n1\n10,000\n1\necs.hfg6.xlarge\n4\n16\n1.5/5\n500,000\n70,000\n4\n3\n10\n1\n20,000\n1.5\necs.hfg6.2xlarge\n8\n32\n2.5/8\n800,000\n150,000\n8\n4\n10\n1\n25,000\n2\necs.hfg6.3xlarge\n12\n48\n4/10\n900,000\n220,000\n8\n6\n10\n1\n30,000\n2.5\necs.hfg6.4xlarge\n16\n64\n5/10\n1,000,000\n300,000\n8\n8\n20\n1\n40,000\n3\necs.hfg6.6xlarge\n24\n96\n7.5/10\n1,500,000\n450,000\n12\n8\n20\n1\n50,000\n4\necs.hfg6.8xlarge\n32\n128\n10/none\n2,000,000\n600,000\n16\n8\n20\n1\n60,000\n5\necs.hfg6.10xlarge\n40\n192\n12.5/none\n3,000,000\n1,000,000\n32\n7\n20\n1\n100,000\n8\necs.hfg6.16xlarge\n64\n256\n20/none\n4,000,000\n1,200,000\n32\n8\n20\n1\n120,000\n10\necs.hfg6.20xlarge\n80\n384\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses Intel\u00ae Xeon\u00ae Cooper Lake processors that deliver an all-core turbo frequency of 3.8 GHz and a clock speed of at least 3.3 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nhfr7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.hfr7.large\n2\n16\n1.2/10\n900,000\n250,000\n2\n2\n6\n6\n20,000\n1\necs.hfr7.xlarge\n4\n32\n2/10\n1,000,000\n250,000\n4\n3\n15\n15\n30,000\n1.5\necs.hfr7.2xlarge\n8\n64\n3/10\n1,600,000\n250,000\n8\n4\n15\n15\n45,000\n2\necs.hfr7.3xlarge\n12\n96\n4.5/10\n2,000,000\n250,000\n8\n6\n15\n15\n60,000\n2.5\necs.hfr7.4xlarge\n16\n128\n6/10\n2,500,000\n300,000\n8\n8\n30\n30\n75,000\n3\necs.hfr7.6xlarge\n24\n192\n8/10\n3,000,000\n450,000\n12\n8\n30\n30\n90,000\n4\necs.hfr7.8xlarge\n32\n256\n10/none\n4,000,000\n600,000\n16\n8\n30\n30\n105,000\n5\necs.hfr7.12xlarge\n48\n384\n16/none\n6,000,000\n1,000,000\n24\n8\n30\n30\n150,000\n8\necs.hfr7.24xlarge\n96\n768\n32/none\n12,000,000\n1,800,000\n32\n15\n30\n30\n300,000\n16\nIntroduction: This instance family offloads a large number of virtualization features to dedicated hardware by using the SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.5 GHz to provide consistent computing performance.\nThe processors used by this instance family have a clock speed of 3.1 GHz. However, the Intel System Studio (ISS) feature may cause a lower clock speed to be displayed. Alibaba Cloud is working on this issue. This issue does not affect the actual clock speeds of your instances.\nYou can separately run the following commands to use the turbostat tool to view the actual clock speeds:\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nhfr6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.hfr6.large\n2\n16\n1/3\n300,000\n35,000\n2\n2\n6\n1\n10,000\n1\necs.hfr6.xlarge\n4\n32\n1.5/5\n500,000\n70,000\n4\n3\n10\n1\n20,000\n1.5\necs.hfr6.2xlarge\n8\n64\n2.5/8\n800,000\n150,000\n8\n4\n10\n1\n25,000\n2\necs.hfr6.3xlarge\n12\n96\n4/10\n900,000\n220,000\n8\n6\n10\n1\n30,000\n2.5\necs.hfr6.4xlarge\n16\n128\n5/10\n1,000,000\n300,000\n8\n8\n20\n1\n40,000\n3\necs.hfr6.6xlarge\n24\n192\n7.5/10\n1,500,000\n450,000\n12\n8\n20\n1\n50,000\n4\necs.hfr6.8xlarge\n32\n256\n10/none\n2,000,000\n600,000\n16\n8\n20\n1\n60,000\n5\necs.hfr6.10xlarge\n40\n384\n12.5/none\n3,000,000\n1,000,000\n32\n7\n20\n1\n100,000\n8\necs.hfr6.16xlarge\n64\n512\n20/none\n4,000,000\n1,200,000\n32\n8\n20\n1\n120,000\n10\necs.hfr6.20xlarge\n80\n768\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16\nSupported scenarios: Scenarios such as high-performance frontend servers, high-performance scientific and engineering applications, MMO games, and video encoding.\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Gold 6149 (Skylake) processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports only IPv4.\nProvides high network performance based on large computing capacity.\nhfc5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.hfc5.large\n2\n4\n1\n300,000\n2\n2\n6\necs.hfc5.xlarge\n4\n8\n1.5\n500,000\n2\n3\n10\necs.hfc5.2xlarge\n8\n16\n2\n1,000,000\n2\n4\n10\necs.hfc5.3xlarge\n12\n24\n2.5\n1,300,000\n4\n6\n10\necs.hfc5.4xlarge\n16\n32\n3\n1,600,000\n4\n8\n20\necs.hfc5.6xlarge\n24\n48\n4.5\n2,000,000\n6\n8\n20\necs.hfc5.8xlarge\n32\n64\n6\n2,500,000\n8\n8\n20\nSupported scenarios: Scenarios such as high-performance frontend servers, high-performance scientific and engineering applications, MMO games, and video encoding.\nCompute:\nOffers a CPU-to-memory ratio of 1:4 (excluding the instance type with 56 vCPUs).\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Gold 6149 (Skylake) processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports only IPv4.\nProvides high network performance based on large computing capacity.\nhfg5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.hfg5.large\n2\n8\n1\n300,000\n2\n2\n6\necs.hfg5.xlarge\n4\n16\n1.5\n500,000\n2\n3\n10\necs.hfg5.2xlarge\n8\n32\n2\n1,000,000\n2\n4\n10\necs.hfg5.3xlarge\n12\n48\n2.5\n1,300,000\n4\n6\n10\necs.hfg5.4xlarge\n16\n64\n3\n1,600,000\n4\n8\n20\necs.hfg5.6xlarge\n24\n96\n4.5\n2,000,000\n6\n8\n20\necs.hfg5.8xlarge\n32\n128\n6\n2,500,000\n8\n8\n20\necs.hfg5.14xlarge\n56\n160\n10\n4,000,000\n14\n8\n20\nIntroduction: This instance family uses the third-generation SHENLONG architecture and Intel Ice Lake processors to improve storage I/O performance.\nSupported scenarios: I/O-intensive scenarios such as large and medium-sized online transaction processing (OLTP) core databases, large and medium-sized NoSQL databases, search and real-time log analytics, and traditional large enterprise-level commercial software such as SAP.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.9 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nAllows up to 64 data disks to be attached per instance. You can attach up to 16 data disks to an instance when you create the instance. If the instance requires additional data disks, attach more data disks after the instance is created. For more information, see Attach a data disk.\nDelivers a sequential read/write throughput of up to 64 Gbit/s and up to 1,000,000 IOPS per instance.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\ng7se instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g7se.large\n2\n8\n1.2/burstable up to 3\n450,000\nUp to 250,000\n2\n3\n6\n6\n16\n30,000/burstable up to 150,000\n3/10\necs.g7se.xlarge\n4\n16\n2/burstable up to 5\n500,000\nUp to 250,000\n4\n4\n15\n15\n16\n60,000/burstable up to 150,000\n4/10\necs.g7se.2xlarge\n8\n32\n3/burstable up to 8\n800,000\nUp to 250,000\n8\n4\n15\n15\n16\n100,000/burstable up to 150,000\n6/10\necs.g7se.3xlarge\n12\n48\n4.5/burstable up to 10\n1,200,000\nUp to 250,000\n8\n8\n15\n15\n16\n120,000/burstable up to 150,000\n8/10\necs.g7se.4xlarge\n16\n64\n6/burstable up to 10\n1,500,000\n300,000\n8\n8\n30\n30\n24\n150,000/none\n10/none\necs.g7se.6xlarge\n24\n96\n8/burstable up to 10\n2,250,000\n450,000\n12\n8\n30\n30\n24\n200,000/none\n12/none\necs.g7se.8xlarge\n32\n128\n10/none\n3,000,000\n600,000\n16\n8\n30\n30\n30\n300,000/none\n16/none\necs.g7se.16xlarge\n64\n256\n16/none\n6,000,000\n1,200,000\n32\n8\n30\n30\n56\n500,000/none\n32/none\nIntroduction: This instance family uses the third-generation SHENLONG architecture and Intel Ice Lake processors to improve storage I/O performance.\nSupported scenarios: I/O-intensive scenarios such as large and medium-sized OLTP core databases, large and medium-sized NoSQL databases, search and real-time log analytics, and traditional large enterprise-level commercial software such as SAP.\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.9 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nAllows up to 64 data disks to be attached per instance. You can attach up to 16 data disks to an instance when you create the instance. If the instance requires additional data disks, attach more data disks after the instance is created. For more information, see Attach a data disk.\nDelivers a sequential read/write throughput of up to 64 Gbit/s and up to 1,000,000 IOPS per instance.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nc7se instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c7se.large\n2\n4\n1.2/burstable up to 3\n450,000\nUp to 250,000\n2\n3\n6\n6\n16\n30,000/burstable up to 150,000\n3/10\necs.c7se.xlarge\n4\n8\n2/burstable up to 5\n500,000\nUp to 250,000\n4\n4\n15\n15\n16\n60,000/burstable up to 150,000\n4/10\necs.c7se.2xlarge\n8\n16\n3/burstable up to 8\n800,000\nUp to 250,000\n8\n4\n15\n15\n16\n100,000/burstable up to 150,000\n6/10\necs.c7se.3xlarge\n12\n24\n4.5/burstable up to 10\n1,200,000\nUp to 250,000\n8\n8\n15\n15\n16\n120,000/burstable up to 150,000\n8/10\necs.c7se.4xlarge\n16\n32\n6/burstable up to 10\n1,500,000\n300,000\n8\n8\n30\n30\n24\n150,000/none\n10/none\necs.c7se.6xlarge\n24\n48\n8/burstable up to 10\n2,250,000\n450,000\n12\n8\n30\n30\n24\n200,000/none\n12/none\necs.c7se.8xlarge\n32\n64\n10/none\n3,000,000\n600,000\n16\n8\n30\n30\n30\n300,000/none\n16/none\necs.c7se.16xlarge\n64\n128\n16/none\n6,000,000\n1,200,000\n32\n8\n30\n30\n56\n500,000/none\n32/none\nIntroduction: This instance family uses the third-generation SHENLONG architecture and Intel Ice Lake processors to improve storage I/O performance.\nSupported scenarios:\nI/O-intensive scenarios such as large and medium-sized OLTP core databases\nLarge and medium-sized NoSQL databases\nSearch and real-time log analytics\nTraditional large enterprise-level commercial software such as SAP\nHigh-density deployment of containers\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.9 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nAllows up to 64 data disks to be attached per instance. You can attach up to 16 data disks to an instance when you create the instance. If the instance requires additional data disks, attach more data disks after the instance is created. For more information, see Attach a data disk.\nDelivers a sequential read/write throughput of up to 64 Gbit/s and up to 1,000,000 IOPS per instance.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nr7se instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r7se.large\n2\n16\n1.2/burstable up to 3\n450,000\nUp to 250,000\n2\n3\n6\n6\n16\n30,000/burstable up to 150,000\n3/10\necs.r7se.xlarge\n4\n32\n2/burstable up to 5\n500,000\nUp to 250,000\n4\n4\n15\n15\n16\n60,000/burstable up to 150,000\n4/10\necs.r7se.2xlarge\n8\n64\n3/burstable up to 8\n800,000\nUp to 250,000\n8\n4\n15\n15\n16\n100,000/burstable up to 150,000\n6/10\necs.r7se.3xlarge\n12\n96\n4.5/burstable up to 10\n1,200,000\nUp to 250,000\n8\n8\n15\n15\n16\n120,000/burstable up to 150,000\n8/10\necs.r7se.4xlarge\n16\n128\n6/burstable up to 10\n1,500,000\n300,000\n8\n8\n30\n30\n24\n150,000/none\n10/none\necs.r7se.6xlarge\n24\n192\n8/burstable up to 10\n2,250,000\n450,000\n12\n8\n30\n30\n24\n200,000/none\n12/none\necs.r7se.8xlarge\n32\n256\n10/none\n3,000,000\n600,000\n16\n8\n30\n30\n30\n300,000/none\n16/none\necs.r7se.16xlarge\n64\n512\n16/none\n6,000,000\n1,200,000\n32\n8\n30\n30\n56\n500,000/none\n32/none\nIntroduction: This instance family uses the fourth-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nNetwork-intensive scenarios such as Network Functions Virtualization (NFV) or Software-defined Wide Area Network (SD-WAN), mobile Internet, live commenting on videos, and telecom data forwarding\nSmall and medium-sized database systems, caches, and search clusters\nEnterprise-level applications of various types and sizes\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nSignificantly improves the network throughput and packet forwarding rate per instance. A single instance can deliver a packet forwarding rate of up to 30,000,000 pps.\nProvides high network performance based on large computing capacity.\ng7nex instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nEBS queues\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g7nex.large\n2\n8\n3/burstable up to 20\n450,000\n2\n3\n10\n10\n1\n10,000/burstable up to 50,000\n1.5/burstable up to 8\necs.g7nex.xlarge\n4\n16\n5/burstable up to 24\n900,000\n4\n4\n15\n15\n1\n20,000/burstable up to 50,000\n2/burstable up to 8\necs.g7nex.2xlarge\n8\n32\n10/burstable up to 32\n1,750,000\n8\n6\n15\n15\n2\n25,000/burstable up to 50,000\n3/burstable up to 8\necs.g7nex.4xlarge\n16\n64\n20/burstable up to 40\n3,000,000\n16\n8\n30\n30\n2\n40,000/burstable up to 50,000\n5/burstable up to 8\necs.g7nex.8xlarge\n32\n128\n40/none\n6,000,000\n32\n8\n30\n30\n4\n75,000/none\n8/none\necs.g7nex.16xlarge\n64\n256\n80/none\n8,000,000\n32\n15\n50\n50\n4\n150,000/none\n16/none\necs.g7nex.32xlarge\n128\n512\n160/none\n16,000,000\n32\n15\n50\n50\n4\n300,000/none\n32/none\nEach ecs.g7nex.32xlarge instance must have at least two elastic network interfaces (ENIs) that are assigned different network card indexes before the instance can burst its network bandwidth to 160 Gbit/s. If all ENIs on the instance are assigned the same network card index, the instance can burst its network bandwidth only to 100 Gbit/s. For more information, see AttachNetworkInterface.\nIntroduction: This instance family uses the fourth-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nNetwork-intensive scenarios such as NFV or SD-WAN, mobile Internet, live commenting on videos, and telecom data forwarding\nSmall and medium-sized database systems, caches, and search clusters\nEnterprise-level applications of various types and sizes\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nSignificantly improves the network throughput and packet forwarding rate per instance. A single instance can deliver a packet forwarding rate of up to 30,000,000 pps.\nProvides high network performance based on large computing capacity.\nSecurity: Supports the virtual Trusted Platform Module (vTPM) feature. For more information, see Overview of trusted computing capabilities.\nc7nex instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nEBS queues\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c7nex.large\n2\n4\n3/burstable up to 20\n450,000\n2\n3\n10\n10\n1\n10,000/burstable up to 50,000\n1.5/burstable up to 8\necs.c7nex.xlarge\n4\n8\n5/burstable up to 24\n900,000\n4\n4\n15\n15\n1\n20,000/burstable up to 50,000\n2/burstable up to 8\necs.c7nex.2xlarge\n8\n16\n10/burstable up to 32\n1,750,000\n8\n6\n15\n15\n2\n25,000/burstable up to 50,000\n3/burstable up to 8\necs.c7nex.4xlarge\n16\n32\n20/burstable up to 40\n3,000,000\n16\n8\n30\n30\n2\n40,000/burstable up to 50,000\n5/burstable up to 8\necs.c7nex.8xlarge\n32\n64\n40/none\n6,000,000\n32\n8\n30\n30\n4\n75,000/none\n8/none\necs.c7nex.16xlarge\n64\n128\n80/none\n8,000,000\n32\n15\n50\n50\n4\n150,000/none\n16/none\necs.c7nex.32xlarge\n128\n256\n160/none\n16,000,000\n32\n15\n50\n50\n4\n300,000/none\n32/none\nEach ecs.c7nex.32xlarge instance must have at least two ENIs that are assigned different network card indexes before the instance can burst its network bandwidth to 160 Gbit/s. If all ENIs on the instance are assigned the same network card index, the instance can burst its network bandwidth only to 100 Gbit/s. For more information, see AttachNetworkInterface.\nIntroduction: This instance family significantly improves the network throughput and packet forwarding rate per instance. A single instance can deliver a packet forwarding rate of up to 24,000,000 pps.\nSupported scenarios:\nNetwork-intensive scenarios such as NFV or SD-WAN, mobile Internet, live commenting on videos, and telecom data forwarding\nSmall and medium-sized database systems, caches, and search clusters\nEnterprise-level applications of various types and sizes\nBig data analytics and machine learning\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses Intel\u00ae Xeon\u00ae Platinum 8369HB (Cooper Lake) or Intel\u00ae Xeon\u00ae Platinum 8369HC (Cooper Lake) processors that deliver a turbo frequency of 3.8 GHz and a clock speed of at least 3.3 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides high network performance based on large computing capacity.\ng7ne instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g7ne.large\n2\n8\n1.5/10\n900,000\n450,000\n2\n3\n10\n10\n10,000\n0.75\necs.g7ne.xlarge\n4\n16\n3/10\n1,000,000\n900,000\n4\n4\n15\n15\n20,000\n1\necs.g7ne.2xlarge\n8\n32\n6/15\n1,500,000\n1,750,000\n8\n6\n15\n15\n25,000\n1.2\necs.g7ne.4xlarge\n16\n64\n12/25\n3,000,000\n3,500,000\n16\n8\n30\n30\n40,000\n2\necs.g7ne.8xlarge\n32\n128\n25/none\n6,000,000\n6,000,000\n16\n8\n30\n30\n75,000\n5\necs.g7ne.12xlarge\n48\n192\n40/none\n12,000,000\n8,000,000\n32\n8\n30\n30\n100,000\n8\necs.g7ne.24xlarge\n96\n384\n80/none\n24,000,000\n16,000,000\n32\n15\n50\n50\n240,000\n16\nIntroduction: This instance family significantly improves the network throughput and packet forwarding rate per instance. A single instance can deliver a packet forwarding rate of up to 10,000,000 pps.\nSupported scenarios:\nData Plane Development Kit (DPDK) applications\nNetwork-intensive scenarios such as NFV or SD-WAN, mobile Internet, live commenting on videos, and telecom data forwarding\nSmall and medium-sized database systems, caches, and search clusters\nEnterprise-level applications of various types and sizes\nBig data analytics and machine learning\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) or 8269CY (Cascade Lake) processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nTo deploy DPDK applications, we recommend that you select instance types in the g5ne instance family.\ng5ne instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g5ne.large\n2\n8\n1\n400,000\n450,000\n2\n3\n10\n10\n10,000\n1\necs.g5ne.xlarge\n4\n16\n2\n750,000\n900,000\n4\n4\n15\n15\n15,000\n1\necs.g5ne.2xlarge\n8\n32\n3.5\n1,500,000\n1,750,000\n8\n6\n15\n15\n30,000\n1\necs.g5ne.4xlarge\n16\n64\n7\n3,000,000\n3,500,000\n16\n8\n30\n30\n60,000\n2\necs.g5ne.8xlarge\n32\n128\n15\n6,000,000\n7,000,000\n32\n8\n30\n30\n110,000\n4\necs.g5ne.16xlarge\n64\n256\n30\n12,000,000\n14,000,000\n32\n8\n30\n30\n130,000\n8\necs.g5ne.18xlarge\n72\n288\n33\n13,500,000\n15,000,000\n32\n15\n50\n50\n160,000\n9\nIntroduction:\nThis instance family supports up to 256 GiB of encrypted memory and confidential computing based on Intel\u00ae Software Guard Extensions (SGX) to protect the confidentiality and integrity of essential code and data from malware attacks.\nThis instance family supports Virtual SGX (vSGX) and allows you to select instance types based on your business requirements.\nIf you use keys (such as SGX sealing keys) that are bound to hardware to encrypt the data of an instance within an Intel SGX enclave, the encrypted data cannot be decrypted after the host of the instance is changed. We recommend that you perform data redundancy and backup at the application layer to ensure application reliability.\nThis instance family implements trusted boot based on Trusted Cryptography Module (TCM) or Trusted Platform Module (TPM) chips. During a trusted boot, all modules in the boot chain from the underlying server to the guest operating system are measured and verified.\nThis instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios that involve sensitive information such as personal identity information, healthcare information, financial information, and intellectual property data\nScenarios in which confidential data is shared among multiple parties\nBlockchain scenarios\nConfidential machine learning\nScenarios that require high security and enhanced trust, such as services for financial organizations, public service sectors, and enterprises\nEnterprise-level applications of various types and sizes\nCompute:\nOffers a CPU-to-memory ratio of 1:4. About 50% of memory is encrypted.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\ng7t instance types\nInstance type\nvCPU\nMemory (GiB)\nEncrypted memory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g7t.large\n2\n8\n4\n2/burstable up to 10\n900,000\nYes\nUp to 250,000\n2\n3\n6\n6\n20,000/burstable up to 110,000\n1.5/burstable up to 6\necs.g7t.xlarge\n4\n16\n8\n3/burstable up to 10\n1,000,000\nYes\nUp to 250,000\n4\n4\n15\n15\n40,000/burstable up to 110,000\n2/burstable up to 6\necs.g7t.2xlarge\n8\n32\n16\n5/burstable up to 10\n1,600,000\nYes\nUp to 250,000\n8\n4\n15\n15\n50,000/burstable up to 110,000\n3/burstable up to 6\necs.g7t.3xlarge\n12\n48\n24\n8/burstable up to 10\n2,400,000\nYes\nUp to 250,000\n8\n8\n15\n15\n70,000/burstable up to 110,000\n4/burstable up to 6\necs.g7t.4xlarge\n16\n64\n32\n10/burstable up to 25\n3,000,000\nYes\n300,000\n8\n8\n30\n30\n80,000/burstable up to 110,000\n5/burstable up to 6\necs.g7t.6xlarge\n24\n96\n48\n12/burstable up to 25\n4,500,000\nYes\n450,000\n12\n8\n30\n30\n110,000/none\n6/none\necs.g7t.8xlarge\n32\n128\n64\n16/burstable up to 25\n6,000,000\nYes\n600,000\n16\n8\n30\n30\n150,000/none\n8/none\necs.g7t.16xlarge\n64\n256\n128\n32/none\n12,000,000\nYes\n1,200,000\n32\n8\n30\n30\n300,000/none\n16/none\necs.g7t.32xlarge\n128\n512\n256\n64/none\n24,000,000\nYes\n2,400,000\n32\n15\n30\n30\n600,000/none\n32/none\nIntel Ice Lake supports only remote attestation based on Intel Software Guard Extensions Data Center Attestation Primitives (Intel SGX DCAP) and does not support remote attestation based on Intel Enhanced Privacy ID (EPID). You must adapt applications before you can use the remote attestation feature. For more information about remote attestation, see Strengthen Enclave Trust with Attestation.\nIntel SGX depends on host hardware. This instance family does not support hot migration.\nOperations, such as changing instance types and enabling the economical mode, may cause the host of an instance to change. For instances of this instance family, the host change may cause data decryption to fail. Proceed with caution.\nBy default, failover is disabled. You can enable failover. For more information, see Modify instance maintenance attributes. Failover causes the host of an instance to change. For instances of this instance family, the host change may cause data decryption to fail. Proceed with caution.\nWhen you create a security-enhanced instance, you must select a dedicated image to use the security features. For more information, see Create a trusted instance.\nTo use the ecs.g7t.32xlarge instance type, submit a ticket.\nIntroduction:\nThis instance family supports up to 128 GiB of encrypted memory and confidential computing based on Intel\u00ae SGX to protect the confidentiality and integrity of essential code and data from malware attacks.\nThis instance family supports vSGX and allows you to select instance types based on your business requirements.\nIf you use keys (such as SGX sealing keys) that are bound to hardware to encrypt the data of an instance within an Intel SGX enclave, the encrypted data cannot be decrypted after the host of the instance is changed. We recommend that you perform data redundancy and backup at the application layer to ensure application reliability.\nThis instance family implements trusted boot based on TCM or TPM chips. During a trusted boot, all modules in the boot chain from the underlying server to the guest operating system are measured and verified.\nThis instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nScenarios that involve sensitive information such as personal identity information, healthcare information, financial information, and intellectual property data\nScenarios in which confidential data is shared among multiple parties\nBlockchain scenarios\nConfidential machine learning\nScenarios that require high security and enhanced trust, such as services for financial organizations, public service sectors, and enterprises\nEnterprise-level applications of various types and sizes\nCompute:\nOffers a CPU-to-memory ratio of 1:2. About 50% of memory is encrypted.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nc7t instance types\nInstance type\nvCPU\nMemory (GiB)\nEncrypted memory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c7t.large\n2\n4\n2\n2/burstable up to 10\n900,000\nYes\nUp to 250,000\n2\n3\n6\n6\n20,000/burstable up to 110,000\n1.5/burstable up to 6\necs.c7t.xlarge\n4\n8\n4\n3/burstable up to 10\n1,000,000\nYes\nUp to 250,000\n4\n4\n15\n15\n40,000/burstable up to 110,000\n2/burstable up to 6\necs.c7t.2xlarge\n8\n16\n8\n5/burstable up to 10\n1,600,000\nYes\nUp to 250,000\n8\n4\n15\n15\n50,000/burstable up to 110,000\n3/burstable up to 6\necs.c7t.3xlarge\n12\n24\n12\n8/burstable up to 10\n2,400,000\nYes\nUp to 250,000\n8\n8\n15\n15\n70,000/burstable up to 110,000\n4/burstable up to 6\necs.c7t.4xlarge\n16\n32\n16\n10/burstable up to 25\n3,000,000\nYes\n300,000\n8\n8\n30\n30\n80,000/burstable up to 110,000\n5/burstable up to 6\necs.c7t.6xlarge\n24\n48\n24\n12/burstable up to 25\n4,500,000\nYes\n450,000\n12\n8\n30\n30\n110,000/none\n6/none\necs.c7t.8xlarge\n32\n64\n32\n16/burstable up to 25\n6,000,000\nYes\n600,000\n16\n8\n30\n30\n150,000/none\n8/none\necs.c7t.16xlarge\n64\n128\n64\n32/none\n12,000,000\nYes\n1,200,000\n32\n8\n30\n30\n300,000/none\n16/none\necs.c7t.32xlarge\n128\n256\n128\n64/none\n24,000,000\nYes\n2,400,000\n32\n15\n30\n30\n600,000/none\n32/none\nIntel Ice Lake supports only remote attestation based on Intel Software Guard Extensions Data Center Attestation Primitives (Intel SGX DCAP) and does not support remote attestation based on Intel Enhanced Privacy ID (EPID). You must adapt applications before you can use the remote attestation feature. For more information about remote attestation, see Strengthen Enclave Trust with Attestation.\nIntel SGX depends on host hardware. This instance family does not support hot migration.\nOperations, such as changing instance types and enabling the economical mode, may cause the host of an instance to change. For instances of this instance family, the host change may cause data decryption to fail. Proceed with caution.\nBy default, failover is disabled. You can enable failover. For more information, see Modify instance maintenance attributes. Failover causes the host of an instance to change. For instances of this instance family, the host change may cause data decryption to fail. Proceed with caution.\nWhen you create a security-enhanced instance, you must select a dedicated image to use the security features. For more information, see Create a trusted instance.\nTo use the ecs.c7t.32xlarge instance type, submit a ticket.\nIntroduction:\nThis instance family supports up to 512 GiB of encrypted memory and confidential computing based on Intel\u00ae SGX to protect the confidentiality and integrity of essential code and data from malware attacks.\nThis instance family supports vSGX and allows you to select instance types based on your business requirements.\nIf you use keys (such as SGX sealing keys) that are bound to hardware to encrypt the data of an instance within an Intel SGX enclave, the encrypted data cannot be decrypted after the host of the instance is changed. We recommend that you perform data redundancy and backup at the application layer to ensure application reliability.\nThis instance family implements trusted boot based on TCM or TPM chips. During a trusted boot, all modules in the boot chain from the underlying server to the guest operating system are measured and verified.\nThis instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads.\nSupported scenarios:\nEncrypted computing applications for databases\nScenarios that involve sensitive information such as personal identity information, healthcare information, financial information, and intellectual property data\nScenarios in which confidential data is shared among multiple parties\nBlockchain scenarios\nConfidential machine learning\nScenarios that require high security and enhanced trust, such as services for financial organizations, public service sectors, and enterprises\nEnterprise-level applications of various types and sizes\nCompute:\nOffers a CPU-to-memory ratio of 1:8. About 50% of memory is encrypted.\nUses the third-generation Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver a base frequency of 2.7 GHz and an all-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nr7t instance types\nInstance type\nvCPU\nMemory (GiB)\nEncrypted memory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r7t.large\n2\n16\n8\n2/burstable up to 10\n900,000\nYes\nUp to 250,000\n2\n3\n6\n6\n20,000/burstable up to 110,000\n1.5/burstable up to 6\necs.r7t.xlarge\n4\n32\n16\n3/burstable up to 10\n1,000,000\nYes\nUp to 250,000\n4\n4\n15\n15\n40,000/burstable up to 110,000\n2/burstable up to 6\necs.r7t.2xlarge\n8\n64\n32\n5/burstable up to 10\n1,600,000\nYes\nUp to 250,000\n8\n4\n15\n15\n50,000/burstable up to 110,000\n3/burstable up to 6\necs.r7t.3xlarge\n12\n96\n48\n8/burstable up to 10\n2,400,000\nYes\nUp to 250,000\n8\n8\n15\n15\n70,000/burstable up to 110,000\n4/burstable up to 6\necs.r7t.4xlarge\n16\n128\n64\n10/burstable up to 25\n3,000,000\nYes\n300,000\n8\n8\n30\n30\n80,000/burstable up to 110,000\n5/burstable up to 6\necs.r7t.6xlarge\n24\n192\n96\n12/burstable up to 25\n4,500,000\nYes\n450,000\n12\n8\n30\n30\n110,000/none\n6/none\necs.r7t.8xlarge\n32\n256\n128\n16/burstable up to 25\n6,000,000\nYes\n600,000\n16\n8\n30\n30\n150,000/none\n8/none\necs.r7t.16xlarge\n64\n512\n256\n32/none\n12,000,000\nYes\n1,200,000\n32\n8\n30\n30\n300,000/none\n16/none\necs.r7t.32xlarge\n128\n1024\n512\n64/none\n24,000,000\nYes\n2,400,000\n32\n15\n30\n30\n600,000/none\n32/none\nIntel Ice Lake supports only remote attestation based on Intel Software Guard Extensions Data Center Attestation Primitives (Intel SGX DCAP) and does not support remote attestation based on Intel Enhanced Privacy ID (EPID). You must adapt applications before you can use the remote attestation feature. For more information about remote attestation, see Strengthen Enclave Trust with Attestation.\nIntel SGX depends on host hardware. This instance family does not support hot migration.\nOperations, such as changing instance types and enabling the economical mode, may cause the host of an instance to change. For instances of this instance family, the host change may cause data decryption to fail. Proceed with caution.\nBy default, failover is disabled. You can enable failover. For more information, see Modify instance maintenance attributes. Failover causes the host of an instance to change. For instances of this instance family, the host change may cause data decryption to fail. Proceed with caution.\nWhen you create a security-enhanced instance, you must select a dedicated image to use the security features. For more information, see Create a trusted instance.\nTo use the ecs.r7t.32xlarge instance type, submit a ticket.\nFeatures:\nIntroduction:\nThis instance family implements trusted boot based on TCM or TPM chips. During a trusted boot, all modules in the boot chain from the underlying server to the guest operating system are measured and verified.\nThis instance family supports the vTPM feature and delivers trusted capabilities at the IaaS layer based on integrity monitoring.\nThis instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nScenarios that require high security and enhanced trust, such as services for financial organizations, public service sectors, and enterprises\nScenarios in which large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\ng6t instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g6t.large\n2\n8\n1.2/burstable up to 10\n900,000\nYes\nUp to 250,000\n2\n3\n6\n1\n20,000\n1\necs.g6t.xlarge\n4\n16\n2/burstable up to 10\n1,000,000\nYes\nUp to 250,000\n4\n4\n15\n1\n40,000\n1.5\necs.g6t.2xlarge\n8\n32\n3/burstable up to 10\n1,600,000\nYes\nUp to 250,000\n8\n4\n15\n1\n50,000\n2\necs.g6t.4xlarge\n16\n64\n6/burstable up to 10\n3,000,000\nYes\n300,000\n8\n8\n30\n1\n80,000\n3\necs.g6t.8xlarge\n32\n128\n10/none\n6,000,000\nYes\n600,000\n16\n8\n30\n1\n150,000\n5\necs.g6t.13xlarge\n52\n192\n16/none\n9,000,000\nYes\n900,000\n32\n7\n30\n1\n240,000\n8\necs.g6t.26xlarge\n104\n384\n32/none\n24,000,000\nYes\n1,800,000\n32\n15\n30\n1\n480,000\n16\nThe results for network capabilities are the maximum values obtained from single-item tests. For example, when network bandwidth is tested, no stress tests are performed on the packet forwarding rate or other network metrics.\nIntroduction:\nThis instance family implements trusted boots based on TPM chips. During a trusted boot, all modules in the boot chain from the underlying hardware to the guest operating system are measured and verified.\nThis instance family supports integrity monitoring and provides trusted capabilities at the IaaS layer.\nThis instance family offloads a large number of virtualization features to dedicated hardware by using the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance and reduce virtualization overheads. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nScenarios that require high security and enhanced trust, such as services for financial organizations, public service sectors, and enterprises\nScenarios in which large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers of massively multiplayer online (MMO) games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides high network performance based on large computing capacity.\nc6t instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nSupport for vTPM\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.c6t.large\n2\n4\n1.2/burstable up to 10\n900,000\nYes\nUp to 250,000\n2\n3\n6\n1\n20,000\n1\necs.c6t.xlarge\n4\n8\n2/burstable up to 10\n1,000,000\nYes\nUp to 250,000\n4\n4\n15\n1\n40,000\n1.5\necs.c6t.2xlarge\n8\n16\n3/burstable up to 10\n1,600,000\nYes\nUp to 250,000\n8\n4\n15\n1\n50,000\n2\necs.c6t.4xlarge\n16\n32\n6/burstable up to 10\n3,000,000\nYes\n300,000\n8\n8\n30\n1\n80,000\n3\necs.c6t.8xlarge\n32\n64\n10/none\n6,000,000\nYes\n600,000\n16\n8\n30\n1\n150,000\n5\necs.c6t.13xlarge\n52\n96\n16/none\n9,000,000\nYes\n900,000\n32\n7\n30\n1\n240,000\n8\necs.c6t.26xlarge\n104\n192\n32/none\n24,000,000\nYes\n1,800,000\n32\n15\n30\n1\n480,000\n16\nThe results for network capabilities are the maximum values obtained from single-item tests. For example, when network bandwidth is tested, no stress tests are performed on the packet forwarding rate or other network metrics.\nFor answers to commonly asked questions about persistent memory-optimized instances, see Instance FAQ.\nFeatures:\nIntroduction:\nThis instance family uses Intel\u00ae OptaneTM persistent memory.\nThe reliability of data stored in persistent memory varies based on the reliability of persistent memory devices and the physical servers to which these devices are attached. Risks of single points of failure exist. To ensure the reliability of application data, we recommend that you implement data redundancy at the application layer and use cloud disks for long-term data storage.\nThis instance family allows persistent memory to be used as memory or as local SSDs on instances of some instance types.\nFor more information, see Configure the usage mode of persistent memory.\nThis instance family provides the ecs.re6p-redis.<nx>large instance types for Redis applications.\necs.re6p-redis.<nx>large instance types are exclusively provided for Redis applications. Persistent memory on instances of these instance types is used as memory by default and cannot be re-configured as local SSDs. For information about how to deploy a Redis application, see Deploy Redis on persistent memory-optimized instances.\nSupported scenarios:\nRedis and other NoSQL databases such as Cassandra and MongoDB\nStructured databases such as MySQL\nI/O-intensive applications such as e-commerce, online games, and media applications\nSearch scenarios that use solutions such as Elasticsearch\nLive video streaming, instant messaging, and room-based online games that require persistent connections\nHigh-performance relational databases and OLTP systems\nCompute:\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nre6p instance types\nInstance type\nvCPU\nMemory (GiB)\nPersistent memory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.re6p.large\n2\n8\n31.5\n1/3\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.re6p.xlarge\n4\n16\n63\n1.5/5\n500,000\nUp to 250,000\n4\n3\n10\n1\n20,000\n1.5\necs.re6p.2xlarge\n8\n32\n126\n2.5/10\n800,000\nUp to 250,000\n8\n4\n20\n1\n25,000\n2\necs.re6p.13xlarge\n52\n192\n756\n12.5/none\n3,000,000\n900,000\n32\n7\n20\n1\n100,000\n8\necs.re6p.26xlarge\n104\n384\n1512\n25/none\n6,000,000\n1,800,000\n32\n15\n20\n1\n200,000\n16,0\necs.re6p-redis.large\n2\n8\n31.5\n1/3\n300,000\nUp to 250,000\n2\n2\n6\n1\n10,000\n1\necs.re6p-redis.xlarge\n4\n16\n63\n1.5/5\n500,000\nUp to 250,000\n4\n3\n10\n1\n20,000\n1.5\necs.re6p-redis.2xlarge\n8\n32\n126\n2.5/10\n800,000\nUp to 250,000\n8\n4\n20\n1\n25,000\n2\necs.re6p-redis.13xlarge\n52\n192\n756\n12.5/none\n3,000,000\n900,000\n32\n7\n20\n1\n100,000\n8\nFeatures:\nIntroduction: This instance family is optimized for high-performance databases, in-memory databases, and enterprise-level memory-intensive applications.\nSupported scenarios:\nHigh-performance databases and in-memory databases such as SAP HANA\nMemory-intensive applications\nBig data processing engines such as Apache Spark and Presto\nCompute:\nOffers a CPU-to-memory ratio of 1:15 and up to 3 TiB of memory.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver a turbo frequency of 3.2 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nre6 instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.re6.4xlarge\n16\n256\n5\n900,000\n8\n7\n20\n1\n25,000\n2\necs.re6.8xlarge\n32\n512\n10\n1,800,000\n16\n7\n20\n1\n50,000\n4\necs.re6.13xlarge\n52\n768\n10\n1,800,000\n16\n7\n20\n1\n50,000\n4\necs.re6.16xlarge\n64\n1024\n16\n3,000,000\n32\n7\n20\n1\n100,000\n8\necs.re6.26xlarge\n104\n1536\n16\n3,000,000\n32\n7\n20\n1\n100,000\n8\necs.re6.32xlarge\n128\n2048\n32\n6,000,000\n32\n15\n20\n1\n200,000\n16\necs.re6.52xlarge\n208\n3072\n32\n6,000,000\n32\n15\n20\n1\n200,000\n16\nTo use the ecs.re6.32xlarge instance type, submit a ticket.\nIntroduction:\nThis instance family is optimized for high-performance databases, in-memory databases, and enterprise-level memory-intensive applications.\nThe ecs.re4.20xlarge and ecs.re4.40xlarge instance types are SAP HANA-certified.\nSupported scenarios:\nHigh-performance databases and in-memory databases such as SAP HANA\nMemory-intensive applications\nBig data processing engines such as Apache Spark and Presto\nCompute:\nOffers a CPU-to-memory ratio of 1:12 and up to 1,920 GiB of memory.\nUses 2.2 GHz Intel\u00ae Xeon\u00ae E7 8880 v4 (Broadwell) processors that deliver a turbo frequency of up to 2.4 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nre4 instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.re4.10xlarge\n40\n480\n8\n1,000,000\n8\n4\n10\n1\necs.re4.20xlarge\n80\n960\n15\n2,000,000\n16\n8\n20\n1\necs.re4.40xlarge\n160\n1920\n30\n4,500,000\n16\n8\n20\n1\nTo use the re4e instance family, submit a ticket.\nIntroduction: This instance family is optimized for high-performance databases, in-memory databases, and enterprise-level memory-intensive applications.\nCompute:\nOffers a CPU-to-memory ratio of 1:24 and up to 3,840 GiB of memory.\nUses 2.2 GHz Intel\u00ae Xeon\u00ae E7 8880 v4 (Broadwell) processors that deliver a turbo frequency of up to 2.4 GHz to provide consistent computing performance.\nSupported scenarios:\nHigh-performance databases and in-memory databases such as SAP HANA\nMemory-intensive applications\nBig data processing engines such as Apache Spark and Presto\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nre4e instance types\nInstance type\nvCPU\nMemory (GiB)\nNetwork bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nPrivate IPv6 addresses per ENI\necs.re4e.40xlarge\n160\n3840\n30\n4,500,000\n16\n15\n20\n1\nFeatures:\nCompute:\nOffers multiple CPU-to-memory ratios such as 1:1, 1:2, and 1:4.\nUses Intel\u00ae Xeon\u00ae Platinum Scalable processors.\nInstances of the e instance family use a CPU-unbound scheduling scheme, in which each vCPU is randomly allocated to an idle CPU hyperthread. Compared with enterprise-level instances, e instances share resources and cost less.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports enhanced SSDs (ESSDs), ESSD Entry disks, and ESSD AutoPL disks.\nDue to the limits of economy instance types, ESSDs at performance levels 1, 2, and 3 (PL1, PL2, and PL3 ESSDs) cannot deliver their maximum performance on e instances. We recommend that you select ESSD Entry disks or PL0 ESSDs for the instances.\nNetwork:\nSupports IPv4 and IPv6.\nSupports only virtual private clouds (VPCs).\nProvides high network performance based on large computing capacity.\nSupported scenarios:\nSmall and medium-sized websites\nDevelopment and testing\nLightweight applications\nInstance types\nInstance type\nvCPUs\nMemory size (GiB)\nBaseline/burst bandwidth (Gbit/s)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.e-c4m1.large\n2\n0.5\n0.2/burstable up to 2\n1\n2\n2\n1\n8,000/none\n0.4/none\necs.e-c2m1.large\n2\n1\n0.2/burstable up to 2\n1\n2\n2\n1\n8,000/none\n0.4/none\necs.e-c1m1.large\n2\n2.0\n0.2/burstable up to 2\n1\n2\n2\n1\n8,000/none\n0.4/none\necs.e-c1m2.large\n2\n4.0\n0.2/burstable up to 2\n1\n2\n2\n1\n8,000/none\n0.4/none\necs.e-c1m4.large\n2\n8.0\n0.4/burstable up to 2\n1\n2\n2\n1\n16,000/none\n0.8/none\necs.e-c1m2.xlarge\n4\n8.0\n0.4/burstable up to 3\n1\n2\n6\n1\n16,000/none\n0.8/none\necs.e-c1m4.xlarge\n4\n16.0\n0.8/burstable up to 4\n1\n2\n6\n1\n16,000/none\n0.8/none\necs.e-c1m2.2xlarge\n8\n16.0\n0.8/burstable up to 6\n1\n2\n6\n1\n16,000/none\n0.8/none\necs.e-c1m4.2xlarge\n8\n32.0\n1.2/burstable up to 6\n1\n2\n6\n1\n16,000/none\n0.8/none\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor more information about these specifications, see the \"Instance type specifications\" section in Overview of instance families. Packet forwarding rates vary significantly based on business scenarios. We recommend that you perform business stress tests on instances to choose appropriate instance types.\nThe following limits apply to the ecs.e-c4m1.large, ecs.e-c2m1.large, ecs.e-c1m1.large, ecs.e-c1m2.large, and ecs.e-c1m4.large instance types:\nSecondary elastic network interfaces (ENIs) cannot be bound to ecs.e-c1m1.large, ecs.e-c1m2.large, or ecs.e-c1m4.large instances during instance creation and can be bound after the instances are created.\nYou can bind secondary ENIs to or unbind secondary ENIs from ecs.e-c1m1.large, ecs.e-c1m2.large, and ecs.e-c1m4.large instances only when the instances are in the Stopped state.\nThe ecs.e-c4m1.large and ecs.e-c2m1.large1.large instance types are available for purchase only in the following regions: China (Hong Kong), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Thailand (Bangkok), Japan (Tokyo), South Korea (Seoul), UK (London), Germany (Frankfurt), US (Virginia), and US (Silicon Valley).\nFeatures:\nProvides a CPU performance baseline and the ability to burst above the baseline, which are governed by accrued CPU credits.\nMore cost-effective compared with the t5 burstable instance family.\nCompute:\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Cascade Lake processors that deliver a turbo frequency of 3.2 GHz.\nUses DDR4 memory.\nStorage:\nIs an I/O optimized instance.\nSupports Enterprise SSDs (ESSDs), ESSD AutoPL disks, standard SSDs, and ultra disks.\nESSDs at performance level (PL) 2 and 3 cannot provide maximum performance due to the specification limits of burstable instances. We recommend that you use enterprise-level instances or ESSDs of lower performance levels.\nNetwork:\nSupports IPv4 and IPv6.\nSupports only virtual private clouds (VPCs).\nSupported scenarios:\nWeb application servers\nLightweight applications and microservices\nDevelopment and testing environments\nInstance types\nInstance type\nvCPU\nMemory (GiB)\nAverage baseline CPU performance\nCPU credits per hour\nMax CPU credit balance\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.t6-c4m1.large\n2\n0.5\n5%\n6\n144\n0.08/burstable up to 0.4\n40,000\n1\n2\n2\n1\necs.t6-c2m1.large\n2\n1.0\n10%\n12\n288\n0.08/burstable up to 0.6\n60,000\n1\n2\n2\n1\necs.t6-c1m1.large\n2\n2.0\n20%\n24\n576\n0.08/burstable up to 1\n100,000\n1\n2\n2\n1\necs.t6-c1m2.large\n2\n4.0\n20%\n24\n576\n0.08/burstable up to 1\n100,000\n1\n2\n2\n1\necs.t6-c1m4.large\n2\n8.0\n30%\n36\n864\n0.08/burstable up to 1\n100,000\n1\n2\n2\n1\necs.t6-c1m4.xlarge\n4\n16.0\n40%\n96\n2304\n0.16/burstable up to 2\n200,000\n1\n2\n6\n1\necs.t6-c1m4.2xlarge\n8\n32.0\n40%\n192\n4608\n0.32/burstable up to 4\n400,000\n1\n2\n6\n1\nSecondary elastic network interfaces (ENIs) cannot be bound to instances of this instance family when the instances are being created and can be bound to the instances after the instances are created. When you bind secondary ENIs to or unbind secondary ENIs from instances of the following instance types, make sure that the instances are in the Stopped state: ecs.t6-c1m1.large, ecs.t6-c1m2.large, ecs.t6-c1m4.large, ecs.t6-c2m1.large, and ecs.t6-c4m1.large.\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor information about instance type metrics, see Instance type metrics.\nFeatures:\nProvides a CPU performance baseline and the ability to burst above the baseline, which are governed by accrued CPU credits.\nBalances compute, memory, and network resources.\nCompute:\nOffers multiple CPU-to-memory ratios.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae processors.\nUses DDR4 memory.\nStorage: supports only ultra disks and standard SSDs.\nNetwork:\nSupports IPv4 and IPv6.\nSupports only VPCs.\nSupported scenarios:\nWeb application servers\nLightweight applications and microservices\nDevelopment and testing environments\nInstance types\nInstance type\nvCPU\nMemory (GiB)\nAverage baseline CPU performance\nCPU credits per hour\nMax CPU credit balance\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.t5-lc2m1.nano\n1\n0.5\n20%\n12\n288\n0.1\n40,000\n1\n2\n2\n1\necs.t5-lc1m1.small\n1\n1.0\n20%\n12\n288\n0.2\n60,000\n1\n2\n2\n1\necs.t5-lc1m2.small\n1\n2.0\n20%\n12\n288\n0.2\n60,000\n1\n2\n2\n1\necs.t5-lc1m2.large\n2\n4.0\n20%\n24\n576\n0.4\n100,000\n1\n2\n2\n1\necs.t5-lc1m4.large\n2\n8.0\n20%\n24\n576\n0.4\n100,000\n1\n2\n2\n1\necs.t5-c1m1.large\n2\n2.0\n25%\n30\n720\n0.5\n100,000\n1\n2\n2\n1\necs.t5-c1m2.large\n2\n4.0\n25%\n30\n720\n0.5\n100,000\n1\n2\n2\n1\necs.t5-c1m4.large\n2\n8.0\n25%\n30\n720\n0.5\n100,000\n1\n2\n2\n1\necs.t5-c1m1.xlarge\n4\n4.0\n25%\n60\n1440\n0.8\n200,000\n1\n2\n6\n1\necs.t5-c1m2.xlarge\n4\n8.0\n25%\n60\n1440\n0.8\n200,000\n1\n2\n6\n1\necs.t5-c1m4.xlarge\n4\n16.0\n25%\n60\n1440\n0.8\n200,000\n1\n2\n6\n1\necs.t5-c1m1.2xlarge\n8\n8.0\n25%\n120\n2880\n1.2\n400,000\n1\n2\n6\n1\necs.t5-c1m2.2xlarge\n8\n16.0\n25%\n120\n2880\n1.2\n400,000\n1\n2\n6\n1\necs.t5-c1m4.2xlarge\n8\n32.0\n25%\n120\n2880\n1.2\n400,000\n1\n2\n6\n1\necs.t5-c1m1.4xlarge\n16\n16.0\n25%\n240\n5760\n1.2\n600,000\n1\n2\n6\n1\necs.t5-c1m2.4xlarge\n16\n32.0\n25%\n240\n5760\n1.2\n600,000\n1\n2\n6\n1\nSecondary ENIs cannot be bound to instances of this instance family when the instances are being created and can be bound to the instances after the instances are created. When you bind secondary ENIs to or unbind secondary ENIs from instances of the following instance types, make sure that the instances are in the Stopped state: ecs.t5-lc2m1.nano, ecs.t5-c1m1.large, ecs.t5-c1m2.large, ecs.t5-c1m4.large, ecs.t5-lc1m1.small, ecs.t5-lc1m2.large, ecs.t5-lc1m2.small, and ecs.t5-lc1m4.large.\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor information about instance type metrics, see Instance type metrics.\nFeatures:\nOffer multiple CPU-to-memory ratios.\nUse 2.5 GHz Intel\u00ae Xeon\u00ae processors.\nUse DDR4 memory.\nAre instance families in which all instances are I/O optimized.\nSupport only IPv4.\nInstance family\nDescription\nvCPU-to-memory ratio\nScenario\nxn4\nShared compact instance family\n1:1\nWeb frontend applications\nLightweight applications and microservices\nDevelopment and testing environments\nn4\nShared compute instance family\n1:2\nWebsites and web applications\nDevelopment environments, servers, code repositories, microservices, and testing and staging environments\nLightweight enterprise-level applications\nmn4\nShared general-purpose instance family\n1:4\nWebsites and web applications\nLightweight databases and caches\nIntegrated applications and lightweight enterprise-level services\ne4\nShared memory instance family\n1:8\nApplications that require a large amount of memory\nLightweight databases and caches\nxn4 instance types\nInstance type\nvCPUs\nMemory size (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNetwork interface controller (NIC) queues\nENIs\nPrivate IPv4 addresses per ENI\necs.xn4.small\n1\n1.0\n0.5\n5\n1\n2\n2\nSecondary ENIs cannot be bound to instances of this instance family during instance creation and can be bound after the instances are created. You can bind secondary ENIs to or unbind secondary ENIs from an ecs.xn4.small instance only when the instance is in the Stopped state.\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor more information about these specifications, see the \"Instance type specifications\" section in Overview of instance families. Packet forwarding rates vary significantly based on business scenarios. We recommend that you perform business stress tests on instances to choose appropriate instance types.\nn4 instance types\nInstance type\nvCPUs\nMemory size (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.n4.small\n1\n2.0\n0.5\n5\n1\n2\n2\necs.n4.large\n2\n4.0\n0.5\n10\n1\n2\n2\necs.n4.xlarge\n4\n8.0\n0.8\n15\n1\n2\n6\necs.n4.2xlarge\n8\n16.0\n1.2\n30\n1\n2\n6\necs.n4.4xlarge\n16\n32.0\n2.5\n40\n1\n2\n6\necs.n4.8xlarge\n32\n64.0\n5.0\n50\n1\n2\n6\nSecondary ENIs cannot be bound to instances of this instance family during instance creation and can be bound after the instances are created. You can bind secondary ENIs to or unbind secondary ENIs from instances of specific instance types, including ecs.n4.small and ecs.n4.large, only when the instances are in the Stopped state.\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor more information about these specifications, see the \"Instance type specifications\" section in Overview of instance families. Packet forwarding rates vary significantly based on business scenarios. We recommend that you perform business stress tests on instances to choose appropriate instance types.\nmn4 instance types\nInstance type\nvCPUs\nMemory size (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.mn4.small\n1\n4.0\n0.5\n5\n1\n2\n2\necs.mn4.large\n2\n8.0\n0.5\n10\n1\n2\n2\necs.mn4.xlarge\n4\n16.0\n0.8\n15\n1\n2\n6\necs.mn4.2xlarge\n8\n32.0\n1.2\n30\n1\n2\n6\necs.mn4.4xlarge\n16\n64.0\n2.5\n40\n1\n8\n6\necs.mn4.8xlarge\n32\n128.0\n5\n50\n2\n8\n6\nSecondary ENIs cannot be bound to instances of this instance family during instance creation and can be bound after the instances are created. You can bind secondary ENIs to or unbind secondary ENIs from instances of specific instance types, including ecs.mn4.small and ecs.mn4.large, only when the instances are in the Stopped state.\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor more information about these specifications, see the \"Instance type specifications\" section in Overview of instance families. Packet forwarding rates vary significantly based on business scenarios. We recommend that you perform business stress tests on instances to choose appropriate instance types.\ne4 instance types\nInstance type\nvCPUs\nMemory size (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.e4.small\n1\n8.0\n0.5\n5\n1\n2\n2\necs.e4.large\n2\n16.0\n0.5\n10\n1\n2\n2\necs.e4.xlarge\n4\n32.0\n0.8\n15\n1\n2\n6\necs.e4.2xlarge\n8\n64.0\n1.2\n30\n1\n3\n6\necs.e4.4xlarge\n16\n128.0\n2.5\n40\n1\n8\n6\nSecondary ENIs cannot be bound to instances of this instance family during instance creation and can be bound after the instances are created. You can bind secondary ENIs to or unbind secondary ENIs from instances of specific instance types, including ecs.e4.small and ecs.e4.large, only when the instances are in the Stopped state.\nYou can go to the Instance Types Available for Each Region page to view the instance types available in each region.\nFor more information about these specifications, see the \"Instance type specifications\" section in Overview of instance families. Packet forwarding rates vary significantly based on business scenarios. We recommend that you perform business stress tests on instances to choose appropriate instance types.\nIntroduction: This instance family uses in-house Arm-based YiTian 710 processors and the fourth-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios: containers, microservices, websites, application servers, video encoding and decoding, HPC, and CPU-based machine learning.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.75 GHz Yitian 710 processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high network and storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\ng8y instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.g8y.small\n1\n4\n1/10\n500,000\nUp to 250,000\n1\n2\n3\n3\n5\n10,000/burstable up to 110,000\n1/burstable up to 10\necs.g8y.large\n2\n8\n2/10\n900,000\nUp to 250,000\n2\n3\n6\n6\n8\n20,000/burstable up to 110,000\n1.5/burstable up to 10\necs.g8y.xlarge\n4\n16\n3/10\n1,000,000\nUp to 250,000\n4\n4\n15\n15\n8\n40,000/burstable up to 110,000\n2/burstable up to 10\necs.g8y.2xlarge\n8\n32\n5/10\n1,600,000\nUp to 250,000\n8\n4\n15\n15\n16\n50,000/burstable up to 110,000\n3/burstable up to 10\necs.g8y.4xlarge\n16\n64\n10/25\n3,000,000\n400,000\n25\n8\n30\n30\n16\n80,000/burstable up to 110,000\n5/burstable up to 10\necs.g8y.8xlarge\n32\n128\n16/25\n5,000,000\n750,000\n32\n8\n30\n30\n16\n125,000\n10\necs.g8y.16xlarge\n64\n256\n32/none\n10,000,000\n1,500,000\n32\n8\n30\n30\n32\n250,000\n16\necs.g8y.32xlarge\n128\n512\n64/none\n20,000,000\n3,000,000\n32\n15\n30\n30\n32\n500,000\n32\nIf you want to use the ecs.g8y.32xlarge instance type, submit a ticket.\nIntroduction: This instance family uses in-house Arm-based YiTian 710 processors and the fourth-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios: containers, microservices, websites, application servers, video encoding and decoding, HPC, and CPU-based machine learning.\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.75 GHz YiTian 710 processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nOffers burstable disk IOPS and burstable disk bandwidth for low-specification instances and provides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nc8y instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nERIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.c8y.small\n1\n2\n1/10\n500,000\nUp to 250,000\n1\n2\n0\n3\n3\n5\n10,000/burstable up to 110,000\n1/burstable up to 10\necs.c8y.large\n2\n4\n2/10\n900,000\nUp to 250,000\n2\n3\n1\n6\n6\n8\n20,000/burstable up to 110,000\n1.5/burstable up to 10\necs.c8y.xlarge\n4\n8\n3/10\n1,000,000\nUp to 250,000\n4\n4\n1\n15\n15\n8\n40,000/burstable up to 110,000\n2/burstable up to 10\necs.c8y.2xlarge\n8\n16\n5/10\n1,600,000\nUp to 250,000\n8\n4\n1\n15\n15\n16\n50,000/burstable up to 110,000\n3/burstable up to 10\necs.c8y.4xlarge\n16\n32\n10/25\n3,000,000\n400,000\n25\n8\n1\n30\n30\n16\n80,000/burstable up to 110,000\n5/burstable up to 10\necs.c8y.8xlarge\n32\n64\n16/25\n5,000,000\n750,000\n32\n8\n1\n30\n30\n16\n125,000\n10\necs.c8y.16xlarge\n64\n128\n32/none\n10,000,000\n1,500,000\n32\n8\n1\n30\n30\n32\n250,000\n16\necs.c8y.32xlarge\n128\n256\n64/none\n20,000,000\n3,000,000\n32\n15\n1\n30\n30\n32\n500,000\n32\nIf you want to use the ecs.c8y.32xlarge instance type, submit a ticket.\nIntroduction: This instance family uses in-house Arm-based YiTian 710 processors and the fourth-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios: scenarios such as containers, microservices, websites and application servers, video encoding and decoding, high-performance computing, and CPU-based machine learning.\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.75 GHz YiTian 710 processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the NVMe protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports ERIs. For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nr8y instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nERIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum attached data disks\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.r8y.small\n1\n8\n1/10\n500,000\nUp to 250,000\n1\n2\n0\n3\n3\n5\n10,000/burstable up to 110,000\n1/burstable up to 10\necs.r8y.large\n2\n16\n2/10\n900,000\nUp to 250,000\n2\n3\n1\n6\n6\n8\n20,000/burstable up to 110,000\n1.5/burstable up to 10\necs.r8y.xlarge\n4\n32\n3/10\n1,000,000\nUp to 250,000\n4\n4\n1\n15\n15\n8\n40,000/burstable up to 110,000\n2/burstable up to 10\necs.r8y.2xlarge\n8\n64\n5/10\n1,600,000\nUp to 250,000\n8\n4\n1\n15\n15\n16\n50,000/burstable up to 110,000\n3/burstable up to 10\necs.r8y.4xlarge\n16\n128\n10/25\n3,000,000\n400,000\n25\n8\n1\n30\n30\n16\n80,000/burstable up to 110,000\n5/burstable up to 10\necs.r8y.8xlarge\n32\n256\n16/25\n5,000,000\n750,000\n32\n8\n1\n30\n30\n16\n125,000\n10\necs.r8y.16xlarge\n64\n512\n32/none\n10,000,000\n1,500,000\n32\n8\n1\n30\n30\n32\n250,000\n16\necs.r8y.32xlarge\n128\n1,024\n64/none\n20,000,000\n3,000,000\n32\n15\n1\n30\n30\n32\n500,000\n32\nTo use the ecs.r8y.32xlarge instance type, submit a ticket.\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios: containers, microservices, scenarios where applications such as DevOps applications are developed and tested, websites, application servers, game servers, and CPU-based machine learning and inference.\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.8 GHz Ampere\u00ae Altra\u00ae processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\ng6r instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.g6r.large\n2\n8\n1/10\n900,000\nUp to 250,000\n2\n3\n6\n1\n12,500\n1\necs.g6r.xlarge\n4\n16\n1.5/10\n1,000,000\nUp to 250,000\n4\n4\n15\n1\n20,000\n1.5\necs.g6r.2xlarge\n8\n32\n2.5/10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n30,000\n2\necs.g6r.4xlarge\n16\n64\n5/10\n2,000,000\n300,000\n8\n8\n30\n1\n60,000\n3\necs.g6r.8xlarge\n32\n128\n8/10\n3,000,000\n600,000\n16\n7\n30\n1\n75,000\n4\necs.g6r.16xlarge\n64\n256\n16/none\n6,000,000\n900,000\n32\n7\n30\n1\n150,000\n8\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nContainers and microservices\nScenarios where applications such as DevOps applications are developed and tested\nWebsites and application servers\nCPU-based machine learning and inference\nHigh-performance nce and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.8 GHz Ampere\u00ae Altra\u00ae processors to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nProvides high storage I/O performance based on large computing capacity. For more information, see Storage I/O performance.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high packet forwarding rates.\nProvides burstable network bandwidth for low-specification instances.\nProvides high network performance based on large computing capacity.\nc6r instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.c6r.large\n2\n4\n1/10\n900,000\nUp to 250,000\n2\n3\n6\n1\n12,500\n1\necs.c6r.xlarge\n4\n8\n1.5/10\n1,000,000\nUp to 250,000\n4\n4\n15\n1\n20,000\n1.5\necs.c6r.2xlarge\n8\n16\n2.5/10\n1,600,000\nUp to 250,000\n8\n4\n15\n1\n30,000\n2\necs.c6r.4xlarge\n16\n32\n5/10\n2,000,000\n300,000\n8\n8\n30\n1\n60,000\n3\necs.c6r.8xlarge\n32\n64\n8/10\n3,000,000\n600,000\n16\n7\n30\n1\n75,000\n4\necs.c6r.16xlarge\n64\n128\n16/none\n6,000,000\n900,000\n32\n7\n30\n1\n150,000\n8\nThis instance family is available only in specific regions, including regions outside China. To use the instance family, contact Alibaba Cloud sales personnel.\nIntroduction: This instance family is an 8th-generation GPU-accelerated compute-optimized ECS Bare Metal Instance family provided by Alibaba Cloud for AI model training and ultra-large models. Each instance of this instance family is equipped with eight GPUs.\nSupported scenarios:\nMulti-GPU parallel inference computing for large language models (LLMs) that have more than 70 billion parameters\nTraditional AI model training and autonomous driving training, for which each GPU delivers computing power of up to 39.5 TFLOPS in the single-precision floating-point format (FP32)\nSmall and medium-sized model training scenarios that leverage the NVLink connections among the eight GPUs\nBenefits and positioning:\nHigh-speed and large-capacity GPU memory: Each GPU is equipped with 96 GB of HBM3 memory and delivers up to 4 TB/s of memory bandwidth, which greatly accelerates model training and inference.\nHigh bandwidth between GPUs: Multiple GPUs are interconnected by using 900 GB/s NVLink connections. The efficiency of multi-GPU training and inference is much higher than that of previous generations of GPU-accelerated instances.\nQuantization of large models: This instance family supports computing power in the 8-bit floating point format (FP8) and optimizes computing power for large-scale parameter training and inference. This significantly improves the computing speed of training and inference and reduces memory usage.\nCompute:\nUses the latest CIPU 1.0 processors.\nDecouples computing capabilities from storage capabilities, allowing you to flexibly select storage resources based on your business requirements, and increases inter-instance bandwidth to 160 Gbit/s for faster data transmission and processing compared with 7th-generation instance families.\nUses the bare metal capabilities provided by CIPU processors to support peer-to-peer (P2P) communication between GPU-accelerated instances.\nUses the 4th-generation Intel Xeon Scalable processors that deliver an all-core turbo frequency of up to 3.1 GHz and provides 192 vCPUs.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, and elastic ephemeral disks (EEDs). For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 30,000,000 pps.\nSupports elastic RDMA interfaces (ERIs) to allow inter-instance RDMA-based communication in VPCs and provides up to 160 Gbit/s of bandwidth per instance, which is suitable for training tasks based on CV models and traditional models.\nFor information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nebmgn8v instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nNIC queues (Primary ENI/Secondary ENI)\nENIs\nMaximum attached data disks\nMaximum disk bandwidth (Gbit/s)\necs.ebmgn8v.48xlarge\n192\n1024\n96GB*8\n160 (80 \u00d7 2)\n30,000,000\n30\n30\n64\n32\n31\n6\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the images support the UEFI boot mode and the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nThis instance family is available only in specific regions, including regions outside China. To use the instance family, contact Alibaba Cloud sales personnel.\nIntroduction: This instance family is an 8th-generation GPU-accelerated compute-optimized ECS Bare Metal instance family provided by Alibaba Cloud in response to the recent developments in the AI generation field. Each instance of this instance family is equipped with eight GPUs.\nSupported scenarios:\nProduction and rendering of special effects for animation, film, and television based on workstation-level graphics processing capabilities in scenarios in which Alibaba Cloud Marketplace GRID images are used, the GRID driver is installed, and OpenGL and Direct3D graphics capabilities are enabled\nScenarios in which the management services provided by Container Service for Kubernetes (ACK) for containerized applications are used to support AI-generated graphic content and LLM inference tasks with up to 130 billion parameters\nOther general-purpose AI recognition, image recognition, and speech recognition scenarios\nBenefits and positioning:\nGraphic processing: This instance family uses high-frequency 5th-generation Intel Xeon Scalable processors to deliver sufficient CPU computing power in 3D modeling scenarios and achieve smooth graphics rendering and design.\nInference tasks: This instance family uses innovative GPUs, each with 48 GB of memory, which accelerate inference tasks and support the FP8 floating-point format. You can use this instance family together with ACK to support the inference of various AI-generated content (AIGC) models and accommodate inference tasks for LLMs that have less than 70 billion parameters.\nTraining tasks: This instance family provides cost-effective computing capabilities and delivers the FP32 computing performance double that of the 7th-generation inference instances. Instances of this instance family are suitable for training FP32-based CV models and other small and medium-sized models.\nUses the latest CIPU 1.0 processors that provide the following benefits:\nDecouples computing capabilities from storage capabilities, allowing you to flexibly select storage resources based on your business requirements, and increases inter-instance bandwidth to 160 Gbit/s for faster data transmission and processing compared with previous-generation instance families.\nUses the bare metal capabilities provided by CIPU processors to support Peripheral Component Interconnect Express (PCIe) P2P communication between GPU-accelerated instances.\nCompute:\nUses innovative GPUs that have the following features:\nSupport for acceleration features such as vGPU, RTX technology, and TensorRT inference engine\nSupport for PCIe Switch interconnect, which achieves a 36% increase in NVIDIA Collective Communications Library (NCCL) performance compared with the CPU direct connection scheme and helps improve inference performance by up to 9% when you run LLM inference tasks on multiple GPUs in parallel\nSupport for eight GPUs per instance with 48 GB of memory per GPU to support LLM inference tasks with 70 billion or more parameters on a single instance\nUses 3.4 GHz Intel\u00ae Xeon\u00ae Scalable (SPR) processors that deliver an all-core turbo frequency of up to 3.9 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, and EEDs. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 30,000,000 pps.\nSupports ERIs to allow inter-instance RDMA-based communication in VPCs and provides up to 160 Gbit/s of bandwidth per instance, which is suitable for training tasks based on CV models and traditional models.\nFor information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nebmgn8is instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nNIC queues (Primary ENI/Secondary ENI)\nENIs\nMaximum attached data disks\nMaximum disk bandwidth (Gbit/s)\necs.ebmgn8is.32xlarge\n128\n1024\n48GB*8\n160 (80 \u00d7 2)\n30,000,000\n30\n30\n64/16\n32\n31\n6\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the images support the UEFI boot mode and the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nIntroduction: This instance family uses the SHENLONG architecture to provide flexible and powerful software-defined compute.\nSupported scenarios:\nDeep learning training and development\nHigh-performance computing (HPC) and simulations\nWhen you use AI training services that feature a high communication load, such as transformer models, you must enable NVLink for GPU-to-GPU communication. Otherwise, data may be damaged due to unpredictable failures that are caused by large-scale data transmission over Peripheral Component Interconnect Express (PCIe) links. If you do not understand the topology of the communication links that are used for AI training services, submit a ticket to obtain technical support.\nCompute:\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Scalable processors that deliver an all-core turbo frequency of 3.5 GHz and supports PCIe 4.0 interfaces.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmgn7e instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues (Primary NIC/Secondary NIC)\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.ebmgn7e.32xlarge\n128\n1024\n80GB * 8\n64\n24,000,000\n32/12\n32\n10\n1\nYou must check the status of the multi-instance GPU (MIG) feature and enable or disable the MIG feature after you start an ebmgn7e instance. For information about the MIG feature, see NVIDIA Multi-Instance GPU User Guide.\nThe following table describes whether the MIG feature is supported by the instance types in the ebmgn7e instance family.\nInstance type\nSupport for MIG\nDescription\necs.ebmgn7e.32xlarge\nYes\nThe MIG feature is supported by ebmgn7e instances.\nIntroduction: This instance family uses the SHENLONG architecture to provide flexible and powerful software-defined compute.\nSupported scenarios:\nConcurrent AI inference tasks that require high-performance CPUs, memory, and GPUs, such as image recognition, speech recognition, and behavior identification\nCompute-intensive graphics processing tasks that require high-performance 3D graphics virtualization capabilities, such as remote graphic design and cloud gaming\nScenarios that require high network bandwidth and disk bandwidth, such as the creation of high-performance render farms\nSmall-scale deep learning and training applications that require high network bandwidth\nCompute:\nUses NVIDIA A10 GPUs that have the following features:\nInnovative NVIDIA Ampere architecture\nSupport for acceleration features such as vGPU, RTX technology, and TensorRT inference engine\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmgn7i instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.ebmgn7i.32xlarge\n128\n768\nNVIDIA A10 * 4\n24GB * 4\n64\n24,000,000\n32\n32\n10\n1\nIntroduction: This instance family uses the SHENLONG architecture to provide flexible and powerful software-defined compute.\nSupported scenarios:\nDeep learning applications, such as training applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications that require robust GPU computing capabilities, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nCompute:\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nebmgn7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.ebmgn7.26xlarge\n104\n768\n40GB*8\n30\n18,000,000\n16\n15\n10\n1\nIntroduction:\nThis instance family uses the SHENLONG architecture to provide flexible and powerful software-defined compute.\nThis instance family uses NVIDIA V100 GPUs that each have 32 GB of GPU memory and support NVLink.\nThis instance family uses NVIDIA V100 GPUs (SXM2-based) that have the following features:\nInnovative NVIDIA Volta architecture\n32 GB of HBM2 memory (900 GB/s bandwidth) per GPU\n5,120 CUDA cores per GPU\n640 Tensor cores per GPU\nUp to six NVLink connections per GPU, each of which provides a bandwidth of 25 GB/s in each direction for a total bandwidth of 300 GB/s (6 \u00d7 25 \u00d7 2 = 300)\nSupported scenarios:\nDeep learning applications, such as training and inference applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nebmgn6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.ebmgn6e.24xlarge\n96\n768\nNVIDIA V100 * 8\n32GB * 8\n32\n4,800,000\n16\n15\n10\n1\nIntroduction:\nThis instance family uses the SHENLONG architecture to provide flexible and powerful software-defined compute.\nThis instance family uses NVIDIA V100 GPUs.\nThis instance family uses NVIDIA V100 GPUs (SXM2-based) that have the following features:\nInnovative NVIDIA Volta architecture\n16 GB of HBM2 memory (900 GB/s bandwidth) per GPU\n5,120 CUDA cores per GPU\n640 Tensor cores per GPU\nUp to six NVLink connections per GPU, each of which provides a bandwidth of 25 GB/s in each direction for a total bandwidth of 300 GB/s (6 \u00d7 25 \u00d7 2 = 300)\nSupported scenarios:\nDeep learning applications, such as training and inference applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nebmgn6v instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.ebmgn6v.24xlarge\n96\n384\nNVIDIA V100 * 8\n16GB * 8\n30\n4,500,000\n8\n32\n10\n1\nIntroduction:\nThis instance family uses the SHENLONG architecture to provide flexible and powerful software-defined compute.\nThis instance family uses NVIDIA T4 GPUs that have the following features:\nInnovative NVIDIA Turing architecture\n16 GB of memory (320 GB/s bandwidth) per GPU\n2,560 CUDA cores per GPU\nUp to 320 Turing Tensor cores per GPU\nMixed-precision Tensor cores that support 65 FP16 TFLOPS, 130 INT8 TOPS, and 260 INT4 TOPS\nSupported scenarios:\nAI (deep learning and machine learning) inference for computer vision, voice recognition, speech synthesis, natural language processing (NLP), machine translation, and reference systems\nReal-time rendering for cloud gaming\nReal-time rendering for Augmented Reality (AR) and Virtual Reality (VR) applications\nGraphics workstations or graphics-heavy computing\nGPU-accelerated databases\nHigh-performance computing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nebmgn6i instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.ebmgn6i.24xlarge\n96\n384\nNVIDIA T4 * 4\n16GB * 4\n30\n4,500,000\n8\n32\n10\n1\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVOD and live streaming\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nData analytics and computing\nHigh-performance scientific and engineering applications\nCompute:\nUses in-house Arm-based YiTian 710 processors that deliver a clock speed of at least 2.75 GHz to provide consistent computing performance. Hyper-threading is not supported.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nebmc8y instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.ebmc8y.32xlarge\n128\n256\n64/none\n20,000,000\n3,000,000\n64 (primary ENI)/32 (secondary ENI)\n38\n30\n30\n500,000/none\n32/none\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers of massively multiplayer online (MMO) games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nUses Intel\u00ae Xeon\u00ae Emerald Rapids or Intel\u00ae Xeon\u00ae Sapphire Rapids processors that deliver a clock speed of at least 2.7 GHz and an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nWhen you purchase an instance of this instance family, the system randomly allocates one type of the preceding processors to the instance. You cannot select a processor type for the instance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Operating system versions that support AMD Genoa processors used by eighth-generation AMD instance types.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nebmc8i instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.ebmc8i.48xlarge\n192\n512\n100/none\n30,000,000\n4,000,000\n64 (primary ENI)/16 (secondary ENI)\n72\n30\n30\n1,000,000/none\n48/none\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers of MMO games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.9 GHz Intel \u00ae Xeon \u00ae Platinum 8369B (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmc7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc7.32xlarge\n128\n256\n64\n24,000,000\n2,400,000\n32\n20\n20\n600,000\n32\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nData analytics and computing\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.55 GHz AMD EPYCTM MILAN processors that deliver a single-core turbo frequency of up to 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmc7a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc7a.64xlarge\n256\n512\n64\n24,000,000\n4,000,000\n32\n31\n15\n1\n600,000\n32\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nUbuntu 18 and Debian 9 operating system kernels do not support AMD EPYCTM MILAN processors. Do not use Ubuntu 18 or Debian 9 images to create instances of this instance family. Instances of this instance family that are created from Ubuntu 18 or Debian 9 images cannot start.\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nFrontend servers of MMO games\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:3.\nUses 2.3 GHz Intel\u00ae Xeon\u00ae Gold 5218 (Cascade Lake) processors that deliver a turbo frequency of 3.9 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmc6me instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc6me.16xlarge\n64\n192\n32\n6,000,000\n1,800,000\n32\n10\n1\n200,000\n16\nThis instance family is in invitational preview. To use the instance family, submit a ticket.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nData analytics and computing\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.6 GHz AMD EPYCTM ROME processors that deliver a turbo frequency of 3.3 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmc6a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc6a.64xlarge\n256\n512\n64\n24,000,000\n32\n31\n10\n1\n600,000\n32\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWeb frontend servers\nFrontend servers of MMO games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmc6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc6e.26xlarge\n104\n192\n32\n24,000,000\n1,800,000\n32\n10\n1\n480,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nFrontend servers of MMO games\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmc6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc6.26xlarge\n104\n192\n32\n6,000,000\n1,800,000\n32\n20\n1\n200,000\n16\nIntroduction: This instance family uses the innovative Cloud Infrastructure Processing Unit (CIPU) architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo on demand (VOD) and live streaming\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nData analytics and computing\nHigh-performance scientific and engineering applications\nCompute:\nUses in-house Arm-based YiTian 710 processors that deliver a clock speed of at least 2.75 GHz to provide consistent computing performance. Hyper-threading is not supported.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nebmg8y instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.ebmc8y.32xlarge\n128\n512\n64/none\n20,000,000\n3,000,000\n64 (primary ENI)/32 (secondary ENI)\n38\n30\n30\n500,000/none\n32/none\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nHigh-performance scientific and engineering applications\nCompute:\nUses Intel\u00ae Xeon\u00ae Emerald Rapids or Intel\u00ae Xeon\u00ae Sapphire Rapids processors that deliver a clock speed of at least 2.7 GHz and an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nWhen you purchase an instance of this instance family, the system randomly allocates one type of the preceding processors to the instance. You cannot select a processor type for the instance.\nSupports Hyper-Threading. By default, Hyper-Threading is enabled. For more information, see Specify and view CPU options.\nIs compatible with specific operating systems. For more information, see Compatibility between Intel instance types and operating systems.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports ESSDs and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nebmg8i instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.ebmg8i.48xlarge\n192\n1024\n100/none\n30,000,000\n4,000,000\n64 (primary ENI)/16 (secondary ENI)\n72\n30\n30\n1,000,000/none\n48/none\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Platinum 8369B (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmg7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmg7.32xlarge\n128\n512\n64\n24,000,000\n2,400,000\n32\n20\n20\n600,000\n32\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nComputing clusters and memory-intensive data processing\nVideo encoding, decoding, and rendering\nData analytics and computing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.55 GHz AMD EPYC\u2122 MILAN processors that deliver a single-core turbo frequency of up to 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmg7a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmg7a.64xlarge\n256\n1024\n64\n24,000,000\n4,000,000\n32\n31\n15\n1\n600,000\n32\nThe boot mode of the images that are used by instances of this instance family must be Unified Extensible Firmware Interface (UEFI). If you want to use custom images on the instances, make sure that the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nUbuntu 18 and Debian 9 operating system kernels do not support AMD EPYCTM MILAN processors. Do not use Ubuntu 18 or Debian 9 images to create instances of this instance family. Instances of this instance family that are created from Ubuntu 18 or Debian 9 images cannot start.\nThis instance family is in invitational preview. To use this instance family, submit a ticket.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nComputing clusters and memory-intensive data processing\nData analytics and computing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.6 GHz AMD EPYC\u2122 ROME processors that deliver a turbo frequency of 3.3 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmg6a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmg6a.64xlarge\n256\n1024\n64\n24,000,000\n32\n31\n10\n1\n600,000\n32\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nFeatures:\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nData analytics and computing\nComputing clusters and memory-intensive data processing\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmg6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmg6e.26xlarge\n104\n384\n32\n24,000,000\n1,800,000\n32\n10\n1\n480,000\n16\nFeatures:\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nEnterprise-level applications such as large and medium-sized databases\nComputing clusters and memory-intensive data processing\nData analytics and computing\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmg6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmg6.26xlarge\n104\n384\n32\n6,000,000\n1,800,000\n32\n20\n1\n200,000\n16\nThe CPU monitoring information about ECS bare metal instances cannot be obtained. To obtain the CPU monitoring information about an ECS bare metal instance, install the CloudMonitor agent on the instance. For more information, see Install and uninstall the CloudMonitor agent.\nTo use the ebmr8y instance family, submit a ticket.\nIntroduction: This instance family uses the innovative CIPU architecture developed by Alibaba Cloud to provide stable computing power, a more robust I/O engine, and dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVOD and live streaming\nEnterprise-level applications of various types and sizes\nWebsites and application servers\nData analytics and computing\nHigh-performance scientific and engineering applications\nCompute:\nUses in-house Arm-based YiTian 710 processors that deliver a clock speed of at least 2.75 GHz to provide consistent computing performance. Hyper-threading is not supported.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports the Non-Volatile Memory Express (NVMe) protocol. For more information, see NVMe protocol.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports elastic RDMA interfaces (ERIs). For information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\nSupports the Jumbo Frames feature. For more information, see Jumbo Frames.\nebmr8y instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline/burst IOPS\nDisk baseline/burst bandwidth (Gbit/s)\necs.ebmr8y.32xlarge\n128\n1024\n64/none\n20,000,000\n3,000,000\n64 (primary ENI)/32 (secondary ENI)\n38\n30\n30\n500,000/none\n32/none\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.9 GHz Intel \u00ae Xeon \u00ae Platinum 8369B (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmr7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmr7.32xlarge\n128\n1024\n64\n24,000,000\n2,400,000\n32\n20\n20\n600,000\n32\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nIn-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.55 GHz AMD EPYCTM MILAN processors that deliver a maximum single-core turbo frequency of 3.5 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmr7a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmr7a.64xlarge\n256\n2048\n64\n24,000,000\n4,000,000\n32\n31\n15\n1\n600,000\n32\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nUbuntu 18 and Debian 9 operating system kernels do not support AMD EPYCTM MILAN processors. Do not use Ubuntu 18 or Debian 9 images to create instances of this instance family. Instances of this instance family that are created from Ubuntu 18 or Debian 9 images cannot start.\nThis instance family is in invitational preview. To use the instance family, submit a ticket.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nIn-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.6 GHz AMD EPYCTM ROME processors that deliver a turbo frequency of 3.3 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmr6a instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmr6a.64xlarge\n256\n2048\n64\n24,000,000\n32\n31\n10\n1\n600,000\n32\nThe boot mode of the images that are used by instances of this instance family must be UEFI. If you want to use custom images on the instances, make sure that the boot mode of the images is set to UEFI. For information about how to set the boot mode of a custom image, see Set the boot mode of custom images to the UEFI mode by calling API operations.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmr6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmr6e.26xlarge\n104\n768\n32\n24,000,000\n1,800,000\n32\n10\n1\n480,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmr6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmr6.26xlarge\n104\n768\n32\n6,000,000\n1,800,000\n32\n20\n1\n200,000\n16\nTo use the ebmre6p instance family, submit a ticket.\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nIn-memory databases such as Redis\nHigh-performance databases such as SAP HANA\nOther memory-intensive applications such as AI applications and smart search applications\nCompute:\nUses the Intel\u00ae OptaneTM persistent memory and is tuned for Redis applications in an end-to-end manner to provide cost-effectiveness.\nSupports a total memory capacity of up to 1,920 GiB (384 GiB of DRAM + 1,536 GiB of Intel\u00ae OptaneTM persistent memory), offers a CPU-to-memory ratio of 1:20, and can meet the needs of memory-intensive applications.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz to provide consistent computing performance.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmre6p instance types\nInstance type\nvCPUs\nMemory (GiB)\nPersistent memory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmre6p.26xlarge\n104\n384\n1536\n32\n6,000,000\n32\n10\n1\n200,000\n16\nTo use the ebmre6-6t instance family, submit a ticket.\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nIn-memory databases and high-performance databases such as SAP HANA\nMemory-intensive applications\nBig data processing engines such as Apache Spark and Presto\nCompute:\nOffers a CPU-to-memory ratio of 1:30.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8269 (Cascade Lake) processors that deliver an all-core turbo frequency of 3.2 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmre6-6t instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmre6-6t.52xlarge\n208\n6144\n32\n6,000,000\n1,800,000\n32\n10\n1\n200,000\n16\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nEnterprise-level applications of various types and sizes\nGame servers\nSmall and medium-sized database systems, caches, and search clusters\nHigh-performance scientific computing\nVideo encoding applications\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses third-generation Intel\u00ae Xeon\u00ae Scalable (Cooper Lake) processors that deliver a base frequency of at least 3.3 GHz and an all-core turbo frequency of 3.8 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmhfg7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmhfg7.48xlarge\n192\n768\n64\n24,000,000\n32\n31\n10\n1\n600,000\n32\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance frontend server clusters\nFrontend servers of MMO games\nData analytics, batch processing, and video encoding\nHigh-performance scientific and engineering applications\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses third-generation Intel\u00ae Xeon\u00ae Scalable (Cooper Lake) processors that deliver a base frequency of at least 3.3 GHz and an all-core turbo frequency of 3.8 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports only ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmhfc7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmhfc7.48xlarge\n192\n384\n64\n24,000,000\n32\n31\n10\n1\n600,000\n32\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture and fast path acceleration on chips to provide predictable and consistent ultra-high computing, storage, and network performance.\nThis instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses third-generation Intel\u00ae Xeon\u00ae Scalable (Cooper Lake) processors that deliver a base frequency of at least 3.3 GHz and an all-core turbo frequency of 3.8 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides ultra-high network performance with a packet forwarding rate of 24,000,000 pps.\nebmhfr7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmhfr7.48xlarge\n192\n1536\n64\n24,000,000\n32\n31\n10\n1\n600,000\n32\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nEnterprise-level applications such as large and medium-sized databases\nVideo encoding, decoding, and rendering\nCompute:\nOffers a CPU-to-memory ratio of 1:4.8.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmhfg6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmhfg6.20xlarge\n80\n384\n32\n6,000,000\n1,800,000\n32\n20\n1\n200,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nCompute:\nOffers a CPU-to-memory ratio of 1:2.4.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmhfc6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmhfc6.20xlarge\n80\n192\n32\n6,000,000\n1,800,000\n32\n20\n1\n200,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:9.6.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269CY (Cascade Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 6,000,000 pps.\nebmhfr6 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmhfr6.20xlarge\n80\n768\n32\n6,000,000\n1,800,000\n32\n20\n1\n200,000\n16\nTo use it, submit a ticket.\nIntroduction: This instance family provides all features of ECS Bare Metal Instance. For more information, see Overview of ECS Bare Metal Instance families.\nSupported scenarios:\nLarge-scale machine learning training\nLarge-scale high-performance scientific computing and simulations\nLarge-scale data analytics, batch processing, and video encoding\nCompute:\nOffers a CPU-to-memory ratio of 1:2.4.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269 (Cascade Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports enhanced SSDs (ESSDs), ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports both RoCE networks and VPCs. RoCE networks are dedicated to RDMA communication.\nInstance types\nInstance type\nvCPU\nPhysical cores\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nRoCE network bandwidth (Gbit/s)\nENIs\necs.scchfc6.20xlarge\n80\n40\n192.0\n30\n6,000,000\n50\n32\necs.scchfc6.20xlarge provides 80 logical processors on 40 physical cores.\nTo use it, submit a ticket.\nIntroduction: This instance family provides all features of ECS Bare Metal Instance. For more information, see Overview of ECS Bare Metal Instance families.\nSupported scenarios:\nLarge-scale machine learning training\nLarge-scale high-performance scientific computing and simulations\nLarge-scale data analytics, batch processing, and video encoding\nCompute:\nOffers a CPU-to-memory ratio of 1:4.8.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269 (Cascade Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports both RoCE networks and VPCs. RoCE networks are dedicated to RDMA communication.\nInstance types\nInstance type\nvCPU\nPhysical cores\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nRoCE network bandwidth (Gbit/s)\nENIs\necs.scchfg6.20xlarge\n80\n40\n384.0\n30\n6,000,000\n50\n32\necs.scchfg6.20xlarge provides 80 logical processors on 40 physical cores.\nTo use it, submit a ticket.\nIntroduction: This instance family provides all features of ECS Bare Metal Instance. For more information, see Overview of ECS Bare Metal Instance families.\nSupported scenarios:\nLarge-scale machine learning training\nLarge-scale high-performance scientific computing and simulations\nLarge-scale data analytics, batch processing, and video encoding\nCompute:\nOffers a CPU-to-memory ratio of 1:9.6.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Platinum 8269 (Cascade Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports both RoCE networks and VPCs. RoCE networks are dedicated to RDMA communication.\nInstance types\nInstance type\nvCPU\nPhysical cores\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nRoCE network bandwidth (Gbit/s)\nENIs\necs.scchfr6.20xlarge\n80\n40\n768.0\n30\n6,000,000\n50\n32\necs.scchfr6.20xlarge provides 80 logical processors on 40 physical cores.\nIntroduction: This instance family provides all features of ECS Bare Metal Instance. For more information, see Overview of ECS Bare Metal Instance families.\nSupported scenarios:\nLarge-scale machine learning training\nLarge-scale high-performance scientific computing and simulations\nLarge-scale data analytics, batch processing, and video encoding\nCompute:\nOffers a CPU-to-memory ratio of 1:3.\nUses 3.1 GHz Intel\u00ae Xeon\u00ae Gold 6149 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports only standard SSDs and ultra disks.\nNetwork:\nSupports only IPv4.\nSupports both RoCE networks and VPCs. RoCE networks are dedicated to RDMA communication.\nInstance types\nInstance type\nvCPU\nPhysical cores\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nRoCE network bandwidth (Gbit/s)\nENIs\necs.scch5.16xlarge\n64\n32\n192.0\n10\n4,500,000\n50\n32\necs.scch5.16xlarge provides 64 logical processors on 32 physical cores.\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nScenarios where large volumes of packets are received and transmitted, such as live commenting on videos and telecom data forwarding\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nVideo encoding, decoding, and rendering\nCompute:\nOffers a CPU-to-memory ratio of 1:2.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors that deliver an all-core turbo frequency of 2.7 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 4,500,000 pps.\nebmc5s instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmc5s.24xlarge\n96\n192\n32\n4,500,000\n1,800,000\n32\n10\n1\n200,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nEnterprise-level applications such as large and medium-sized databases\nVideo encoding\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors that deliver an all-core turbo frequency of 2.7 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance with a packet forwarding rate of 4,500,000 pps.\nebmg5s instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmg5s.24xlarge\n96\n384\n32\n4,500,000\n1,800,000\n32\n10\n1\n200,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nHigh-performance databases and in-memory databases\nData analytics, data mining, and distributed memory caching\nEnterprise-level memory-intensive applications such as Hadoop clusters and Spark clusters\nCompute:\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors that deliver an all-core turbo frequency of 2.7 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports only IPv4.\nProvides high network performance with a packet forwarding rate of 4,500,000 pps.\nebmr5s instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nConnections\nENIs\nPrivate IPv4 addresses per ENI\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.ebmr5s.24xlarge\n96\n768\n32\n4,500,000\n1,800,000\n32\n10\n200,000\n16\nIntroduction: This instance family provides dedicated hardware resources and physical isolation.\nSupported scenarios:\nWorkloads that require direct access to physical resources or that require a license to be bound to the hardware\nScenarios that require compatibility with third-party hypervisors to implement hybrid-cloud and multi-cloud deployments\nContainers such as Docker, Clear Containers, and Pouch\nEnterprise-level applications such as large and medium-sized databases\nVideo encoding\nCompute:\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors that deliver an all-core turbo frequency of 2.7 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks. For information about disks, see Overview of Block Storage.\nNetwork:\nSupports only IPv4.\nProvides high network performance with a packet forwarding rate of 4,000,000 pps.\nebmg5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nENIs\nPrivate IPv4 addresses per ENI\necs.ebmg5.24xlarge\n96\n384\n10\n4,000,000\n32\n10\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude. This way, this instance family accelerates the speed of data storage and model loading.\nThis instance family comes with an NVIDIA GRID vWS license and provides certified graphics acceleration capabilities for Computer Aided Design (CAD) software to meet the requirements of professional graphic design. Instances of this instance family can serve as lightweight GPU-accelerated compute-optimized instances to reduce the costs of small-scale AI inference tasks.\nSupported scenarios:\nConcurrent AI inference tasks that require high-performance CPUs, memory, and GPUs, such as image recognition, speech recognition, and behavior identification\nCompute-intensive graphics processing tasks that require high-performance 3D graphics virtualization capabilities, such as remote graphic design and cloud gaming\n3D modeling in fields that require the use of AMD Genoa processors with high clock speeds, such as animation and film production, cloud gaming, and mechanical design\nCompute:\nUses NVIDIA Lovelace GPUs that have the following features:\nLarge GPU memory and multiple GPU slicing solutions\nSupport for acceleration features, such as vGPU, RTX, and TensorRT, to provide diversified business support\nUses AMD Genoa processors that deliver a clock speed of 3.4 GHz to 3.75 GHz to provide high computing power for 3D modeling.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports Enterprise SSDs (ESSDs) and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nsgn8ia instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4/IPv6 addresses per ENI\nMaximum disks\nDisk baseline IOPS\nDisk baseline BPS (MB/s)\necs.sgn8ia-m2.xlarge\n4\n16\n2 GB\n2.5\n1,000,000\n4\n4\n15/15\n9\n30,000\n244\necs.sgn8ia-m4.2xlarge\n8\n32\n4 GB\n4\n1,600,000\n8\n4\n15/15\n9\n45,000\n305\necs.sgn8ia-m8.4xlarge\n16\n64\n8 GB\n7\n2,000,000\n16\n8\n30/30\n17\n60,000\n427\necs.sgn8ia-m16.8xlarge\n32\n128\n16 GB\n10\n3,000,000\n32\n8\n30/30\n33\n80,000\n610\necs.sgn8ia-m24.12xlarge\n48\n192\n24 GB\n16\n4,500,000\n48\n8\n30/30\n33\n120,000\n1,000\necs.sgn8ia-m48.24xlarge\n96\n384\n48 GB\n32\n9,000,000\n64\n15\n30/30\n33\n24,000\n2,000\nThe\u00a0columns related to GPUs in the preceding table are for vGPUs that are sliced by using the vGPU slicing technology.\nThe memory and GPU memory of an sgn8ia instance are exclusive to the instance. The CPUs of the instance are shared resources with an overcommit ratio of approximately 1:1.5. If you have special requirements for the CPU computing power, we recommend that you use GPU-accelerated dedicated instance families, such as gn7i GPU-accelerated compute-optimized instances.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude. This way, data storage and model loading can be performed more quickly.\nInstances of this instance family share CPU and network resources to maximize the utilization of underlying resources. Each instance has exclusive access to its memory and GPU memory to provide data isolation and performance assurance.\nIf you want to use exclusive CPU resources, select the vgn7i-vws instance family.\nThis instance family comes with an NVIDIA GRID vWS license and provides certified graphics acceleration capabilities for CAD software to meet the requirements of professional graphic design. Instances of this instance family can serve as lightweight GPU-accelerated compute-optimized instances to reduce the costs of small-scale AI inference tasks.\nSupported scenarios:\nConcurrent AI inference tasks that require high-performance CPUs, memory, and GPUs, such as image recognition, speech recognition, and behavior identification\nCompute-intensive graphics processing tasks that require high-performance 3D graphics virtualization capabilities, such as remote graphic design and cloud gaming\n3D modeling in fields that require the use of Ice Lake processors, such as animation and film production, cloud gaming, and mechanical design\nCompute:\nUses NVIDIA A10 GPUs that have the following features:\nInnovative NVIDIA Ampere architecture\nSupport for acceleration features, such as vGPU, RTX, and TensorRT, to provide diversified business support\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nsgn7i-vws instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline/burst bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.sgn7i-vws-m2.xlarge\n4\n15.5\nNVIDIA A10 * 1/12\n24GB * 1/12\n1.5/5\n500,000\n4\n2\n2\n1\necs.sgn7i-vws-m4.2xlarge\n8\n31\nNVIDIA A10 * 1/6\n24GB * 1/6\n2.5/10\n1,000,000\n4\n4\n6\n1\necs.sgn7i-vws-m8.4xlarge\n16\n62\nNVIDIA A10 * 1/3\n24GB * 1/3\n5/20\n2,000,000\n8\n4\n10\n1\necs.sgn7i-vws-m2s.xlarge\n4\n8\nNVIDIA A10 * 1/12\n24GB * 1/12\n1.5/5\n500,000\n4\n2\n2\n1\necs.sgn7i-vws-m4s.2xlarge\n8\n16\nNVIDIA A10 * 1/6\n24GB * 1/6\n2.5/10\n1,000,000\n4\n4\n6\n1\necs.sgn7i-vws-m8s.4xlarge\n16\n32\nNVIDIA A10 * 1/3\n24GB * 1/3\n5/20\n2,000,000\n8\n4\n10\n1\nThe GPU column in the preceding table indicates the GPU model and GPU slicing information for each instance type. Each GPU can be sliced into multiple GPU partitions, and each GPU partition can be allocated as a vGPU to an instance. Example:\nNVIDIA A10 * 1/12. NVIDIA A10 is the GPU model. 1/12 indicates that a GPU is sliced into 12 GPU partitions, and each GPU partition can be allocated as a vGPU to an instance.\nIntroduction:\nThis instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude. This way, data storage and model loading can be performed more quickly.\nThis instance family comes with an NVIDIA GRID vWS license and provides certified graphics acceleration capabilities for CAD software to meet the requirements of professional graphic design. Instances of this instance family can serve as lightweight GPU-accelerated compute-optimized instances to reduce the costs of small-scale AI inference tasks.\nSupported scenarios:\nConcurrent AI inference tasks that require high-performance CPUs, memory, and GPUs, such as image recognition, speech recognition, and behavior identification\nCompute-intensive graphics processing tasks that require high-performance 3D graphics virtualization capabilities, such as remote graphic design and cloud gaming\n3D modeling in fields that require the use of Ice Lake processors, such as animation and film production, cloud gaming, and mechanical design\nCompute:\nUses NVIDIA A10 GPUs that have the following features:\nInnovative NVIDIA Ampere architecture\nSupport for acceleration features, such as vGPU, RTX, and TensorRT, to provide diversified business support\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nvgn7i-vws instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.vgn7i-vws-m4.xlarge\n4\n30\nNVIDIA A10 * 1/6\n24GB * 1/6\n3\n1,000,000\n4\n4\n10\n1\necs.vgn7i-vws-m8.2xlarge\n10\n62\nNVIDIA A10 * 1/3\n24GB * 1/3\n5\n2,000,000\n8\n6\n10\n1\necs.vgn7i-vws-m12.3xlarge\n14\n93\nNVIDIA A10 * 1/2\n24GB * 1/2\n8\n3,000,000\n8\n6\n15\n1\necs.vgn7i-vws-m24.7xlarge\n30\n186\nNVIDIA A10 * 1\n24GB * 1\n16\n6,000,000\n12\n8\n30\n1\nThe GPU column in the preceding table indicates the GPU model and GPU slicing information for each instance type. Each GPU can be sliced into multiple GPU partitions, and each GPU partition can be allocated as a vGPU to an instance. Example:\nNVIDIA A10 * 1/6. NVIDIA A10 is the GPU model. 1/6 indicates that a GPU is sliced into six GPU partitions, and each GPU partition can be allocated as a vGPU to an instance.\nIn light of the NVIDIA GRID driver upgrade, Alibaba Cloud upgrades the vgn6i instance family to the vgn6i-vws instance family. The vgn6i-vws instance family uses the latest NVIDIA GRID driver and provides an NVIDIA GRID vWS license. To apply for free images for which the NVIDIA GRID driver is pre-installed, submit a ticket.\nTo use other public images or custom images that do not contain an NVIDIA GRID driver, submit a ticket to apply for the GRID driver file and install the NVIDIA GRID driver. Alibaba Cloud does not charge additional license fees for the GRID driver.\nSupported scenarios:\nReal-time rendering for cloud gaming\nReal-time rendering for Augmented Reality (AR) and Virtual Reality (VR) applications\nAI (deep learning and machine learning) inference for elastic Internet service deployment\nEducational environment of deep learning\nModeling experiment environment of deep learning\nCompute:\nUses NVIDIA T4 GPUs.\nUses vGPUs.\nSupports the 1/4 and 1/2 compute capacity of NVIDIA Tesla T4 GPUs.\nSupports 4 GB and 8 GB of GPU memory.\nOffers a CPU-to-memory ratio of 1:5.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\nvgn6i-vws instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.vgn6i-m4-vws.xlarge\n4\n23\nNVIDIA T4 * 1/4\n16GB * 1/4\n2\n500,000\n4/2\n3\n10\n1\necs.vgn6i-m8-vws.2xlarge\n10\n46\nNVIDIA T4 * 1/2\n16GB * 1/2\n4\n800,000\n8/2\n4\n10\n1\necs.vgn6i-m16-vws.5xlarge\n20\n92\nNVIDIA T4 * 1\n16GB * 1\n7.5\n1,200,000\n6\n4\n10\n1\nThe GPU column in the preceding table indicates the GPU model and GPU slicing information for each instance type. Each GPU can be sliced into multiple GPU partitions, and each GPU partition can be allocated as a vGPU to an instance. Example:\nNVIDIA T4 * 1/4. NVIDIA T4 is the GPU model. 1/4 indicates that a GPU is sliced into four GPU partitions, and each GPU partition can be allocated as a vGPU to an instance.\nThis instance family is available only in specific regions, including regions outside China. To use the instance family, contact Alibaba Cloud sales personnel.\nIntroduction: This instance family is an 8th-generation GPU-accelerated compute-optimized instance family provided by Alibaba Cloud in response to the recent developments in the AI generation field. This instance family consists of multiple instance types that provide one, two, four, or eight GPUs per instance and have different CPU-to-GPU ratios to fit various use cases.\nBenefits and positioning:\nGraphic processing: This instance family uses high-frequency 5th-generation Intel Xeon Scalable processors to provide sufficient CPU capacity for smooth graphics rendering and design in 3D modeling scenarios.\nInference tasks: This instance family uses innovative GPUs, each with 48 GB of memory, which accelerate inference tasks and support the FP8 floating-point format. You can use this instance family together with Container Service for Kubernetes (ACK) to support the inference of various AI-generated content (AIGC) models and especially accommodate inference tasks for LLMs that have less than 70 billion parameters.\nSupported scenarios:\nAnimation, special effects for film and television, and rendering\nGeneration of AIGC images and inference of LLMs\nOther general-purpose AI recognition, image recognition, and speech recognition scenarios\nCompute:\nUses innovative GPUs that have the following features:\nSupport for acceleration features, such as TensorRT, and the FP8 floating-point format to improve LLM inference performance.\nUp to 48 GB of memory per GPU and support for the inference of 70B or larger LLMs on a single instance with multiple GPUs.\nImproved graphic processing capabilities. For example, after you install a GRID driver on a gn8is instance by using Cloud Assistant or an Alibaba Cloud Marketplace image, the instance can provide graphic processing performance twice that of a 7th-generation instance.\nUses the latest high-frequency Intel\u00ae Xeon\u00ae processors that deliver an all-core turbo frequency of 3.9 GHz to meet complex 3D modeling requirements.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, and EEDs.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nSupports ERIs.\nFor information about how to use ERIs, see Configure eRDMA on an enterprise-level instance.\ngn8is instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nENIs\nNIC queues per primary ENI\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nMaximum disks\nDisk baseline IOPS\nDisk baseline bandwidth (Gbit/s)\necs.gn8is.2xlarge\n8\n64\n48GB * 1\n8\n4\n8\n15\n15\n17\n60,000\n0.75\necs.gn8is.4xlarge\n16\n128\n48GB * 1\n16\n8\n16\n30\n30\n17\n120,000\n1.25\necs.gn8is-2x.8xlarge\n32\n256\n48GB * 2\n32\n8\n32\n30\n30\n33\n250,000\n2\necs.gn8is-4x.16xlarge\n64\n512\n48GB * 4\n64\n8\n64\n30\n30\n33\n450,000\n4\necs.gn8is-8x.32xlarge\n128\n1,024\n48GB * 8\n100\n15\n64\n50\n50\n65\n900,000\n8\nFeatures:\nIntroduction:\nThis instance family allows you to select instance types that provide different numbers of GPUs and CPUs to meet your business requirements in AI use cases.\nThis instance family uses the third-generation SHENLONG architecture and doubles the average bandwidths of virtual private clouds (VPCs), networks, and disks compared with instance families of the previous generation.\nSupported scenarios:\nSmall- and medium-scale AI training\nHigh-performance computing (HPC) business accelerated by using Compute Unified Device Architecture (CUDA)\nAI inference tasks that require high GPU processing capabilities or large amounts of GPU memory\nDeep learning applications, such as training applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications that require robust GPU computing capabilities, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nWhen you use AI training services that feature a high communication load, such as transformer models, you must enable NVLink for GPU-to-GPU communication. Otherwise, data may be damaged due to unpredictable failures that are caused by large-scale data transmission over Peripheral Component Interconnect Express (PCIe) links. If you do not understand the topology of the communication links that are used for AI training services, submit a ticket to obtain technical support.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn7e instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn7e-c16g1.4xlarge\n16\n125\n80GB * 1\n8\n3,000,000\n8\n8\n10\n1\necs.gn7e-c16g1.8xlarge\n32\n250\n80GB * 2\n16\n6,000,000\n16\n8\n10\n1\necs.gn7e-c16g1.16xlarge\n64\n500\n80GB * 4\n32\n12,000,000\n32\n8\n10\n1\necs.gn7e-c16g1.32xlarge\n128\n1,000\n80GB * 8\n64\n24,000,000\n32\n16\n15\n1\nIntroduction: This instance family uses the third-generation SHENLONG architecture to provide predictable and consistent ultra-high performance. This instance family utilizes fast path acceleration on chips to improve storage performance, network performance, and computing stability by an order of magnitude.\nSupported scenarios:\nConcurrent AI inference tasks that require high-performance CPUs, memory, and GPUs, such as image recognition, speech recognition, and behavior identification\nCompute-intensive graphics processing tasks that require high-performance 3D graphics virtualization capabilities, such as remote graphic design and cloud gaming\nCompute:\nUses NVIDIA A10 GPUs that have the following features:\nInnovative NVIDIA Ampere architecture\nSupport for acceleration features, such as RTX and TensorRT\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nProvides up to 752 GiB of memory, which is much larger than the memory sizes of the gn6i instance family.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn7i instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn7i-c8g1.2xlarge\n8\n30\nNVIDIA A10 * 1\n24GB * 1\n16\n1,600,000\n8\n4\n15\n15\necs.gn7i-c16g1.4xlarge\n16\n60\nNVIDIA A10 * 1\n24GB * 1\n16\n3,000,000\n8\n8\n30\n30\necs.gn7i-c32g1.8xlarge\n32\n188\nNVIDIA A10 * 1\n24GB * 1\n16\n6,000,000\n12\n8\n30\n30\necs.gn7i-c32g1.16xlarge\n64\n376\nNVIDIA A10 * 2\n24GB * 2\n32\n12,000,000\n16\n15\n30\n30\necs.gn7i-c32g1.32xlarge\n128\n752\nNVIDIA A10 * 4\n24GB * 4\n64\n24,000,000\n32\n15\n30\n30\necs.gn7i-c48g1.12xlarge\n48\n310\nNVIDIA A10 * 1\n24GB * 1\n16\n9,000,000\n16\n8\n30\n30\necs.gn7i-c56g1.14xlarge\n56\n346\nNVIDIA A10 * 1\n24GB * 1\n16\n12,000,000\n16\n12\n30\n30\necs.gn7i-2x.8xlarge\n32\n128\nNVIDIA A10 * 2\n24GB * 2\n16\n6,000,000\n16\n8\n30\n30\necs.gn7i-4x.8xlarge\n32\n128\nNVIDIA A10 * 4\n24GB * 4\n16\n6,000,000\n16\n8\n30\n30\necs.gn7i-4x.16xlarge\n64\n256\nNVIDIA A10 * 4\n24GB * 4\n32\n12,000,000\n32\n8\n30\n30\necs.gn7i-8x.32xlarge\n128\n512\nNVIDIA A10 * 8\n24GB * 8\n64\n24,000,000\n32\n16\n30\n30\necs.gn7i-8x.16xlarge\n64\n256\nNVIDIA A10 * 8\n24GB * 8\n32\n12,000,000\n32\n8\n30\n30\nYou can change the following instance types only to ecs.gn7i-c8g1.2xlarge or ecs.gn7i-c16g1.4xlarge: ecs.gn7i-2x.8xlarge, ecs.gn7i-4x.8xlarge, ecs.gn7i-4x.16xlarge, ecs.gn7i-8x.32xlarge, and ecs.gn7i-8x.16xlarge.\nTo use the gn7s instance family, submit a ticket.\nIntroduction:\nThis instance family uses the latest Intel Ice Lake processors and NVIDIA A30 GPUs that are based on NVIDIA Ampere architecture. You can select instance types that comprise appropriate mixes of GPUs and vCPUs to meet your business requirements in AI scenarios.\nThis instance family uses the third-generation SHENLONG architecture and doubles the average bandwidths of VPCs, networks, and disks compared with instance families of the previous generation.\nSupported scenarios: concurrent AI inference tasks that require high-performance CPUs, memory, and GPUs, such as image recognition, speech recognition, and behavior identification.\nCompute:\nUses NVIDIA A30 GPUs that have the following features:\nInnovative NVIDIA Ampere architecture\nSupport for the multi-instance GPU (MIG) feature and acceleration features (based on second-generation Tensor cores) to provide diversified business support\nUses 2.9 GHz Intel\u00ae Xeon\u00ae Scalable (Ice Lake) processors that deliver an all-core turbo frequency of 3.5 GHz.\nImproves memory sizes significantly from instance families of the previous generation.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn7s instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\nNIC queues\nENIs\necs.gn7s-c8g1.2xlarge\n8\n60\nNVIDIA A30 * 1\n24GB * 1\n16\n6,000,000\n5\n1\n12\n8\necs.gn7s-c16g1.4xlarge\n16\n120\nNVIDIA A30 * 1\n24GB * 1\n16\n6,000,000\n5\n1\n12\n8\necs.gn7s-c32g1.8xlarge\n32\n250\nNVIDIA A30 * 1\n24GB * 1\n16\n6,000,000\n5\n1\n12\n8\necs.gn7s-c32g1.16xlarge\n64\n500\nNVIDIA A30 * 2\n24GB * 2\n32\n12,000,000\n5\n1\n16\n15\necs.gn7s-c32g1.32xlarge\n128\n1,000\nNVIDIA A30 * 4\n24GB * 4\n64\n24,000,000\n10\n1\n32\n15\necs.gn7s-c48g1.12xlarge\n48\n380\nNVIDIA A30 * 1\n24GB * 1\n16\n6,000,000\n8\n1\n12\n8\necs.gn7s-c56g1.14xlarge\n56\n440\nNVIDIA A30 * 1\n24GB * 1\n16\n6,000,000\n8\n1\n12\n8\nSupported scenarios:\nDeep learning applications, such as training applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications that require robust GPU computing capabilities, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs and ESSD AutoPL disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn7 instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn7-c12g1.3xlarge\n12\n94\n40GB * 1\n4\n2,500,000\n4\n8\n10\n1\necs.gn7-c13g1.13xlarge\n52\n378\n40GB * 4\n16\n9,000,000\n16\n8\n30\n30\necs.gn7-c13g1.26xlarge\n104\n756\n40GB * 8\n30\n18,000,000\n16\n15\n10\n1\nSupported scenarios:\nAI (deep learning and machine learning) inference for computer vision, speech recognition, speech synthesis, natural language processing (NLP), machine translation, and recommendation systems\nReal-time rendering for cloud gaming\nReal-time rendering for AR and VR applications\nGraphics workstations or graphics-heavy computing\nGPU-accelerated databases\nHigh-performance computing\nCompute:\nUses NVIDIA T4 GPUs that have the following features:\nInnovative NVIDIA Turing architecture\n16 GB of memory (320 GB/s bandwidth) per GPU\n2,560 CUDA cores per GPU\nUp to 320 Turing Tensor cores per GPU\nMixed-precision Tensor cores that support 65 FP16 TFLOPS, 130 INT8 TOPS, and 260 INT4 TOPS\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn6i instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline IOPS\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn6i-c4g1.xlarge\n4\n15\nNVIDIA T4 * 1\n16GB * 1\n4\n500,000\nNone\n2\n2\n10\n1\necs.gn6i-c8g1.2xlarge\n8\n31\nNVIDIA T4 * 1\n16GB * 1\n5\n800,000\nNone\n2\n2\n10\n1\necs.gn6i-c16g1.4xlarge\n16\n62\nNVIDIA T4 * 1\n16GB * 1\n6\n1,000,000\nNone\n4\n3\n10\n1\necs.gn6i-c24g1.6xlarge\n24\n93\nNVIDIA T4 * 1\n16GB * 1\n7.5\n1,200,000\nNone\n6\n4\n10\n1\necs.gn6i-c40g1.10xlarge\n40\n155\nNVIDIA T4 * 1\n16GB * 1\n10\n1,600,000\nNone\n16\n10\n10\n1\necs.gn6i-c24g1.12xlarge\n48\n186\nNVIDIA T4 * 2\n16GB * 2\n15\n2,400,000\nNone\n12\n6\n10\n1\necs.gn6i-c24g1.24xlarge\n96\n372\nNVIDIA T4 * 4\n16GB * 4\n30\n4,800,000\n250,000\n24\n8\n10\n1\nSupported scenarios:\nDeep learning applications, such as training and inference applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nCompute:\nUses NVIDIA V100 GPUs that each have 32 GB of GPU memory and support NVLink.\nUses NVIDIA V100 GPUs (SXM2-based) that have the following features:\nInnovative NVIDIA Volta architecture\n32 GB of HBM2 memory (900 GB/s bandwidth) per GPU\n5,120 CUDA cores per GPU\n640 Tensor cores per GPU\nUp to six NVLink bidirectional connections per GPU, each of which provides a bandwidth of 25 Gbit/s in each direction for a total bandwidth of 300 Gbit/s (6 \u00d7 25 \u00d7 2 = 300)\nOffers a CPU-to-memory ratio of 1:8.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn6e instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn6e-c12g1.3xlarge\n12\n92\nNVIDIA V100 * 1\n32GB * 1\n5\n800,000\n8\n6\n10\n1\necs.gn6e-c12g1.6xlarge\n24\n182\nNVIDIA V100 * 2\n32GB * 2\n8\n1,200,000\n8\n8\n20\n1\necs.gn6e-c12g1.12xlarge\n48\n368\nNVIDIA V100 * 4\n32GB * 4\n16\n2,400,000\n8\n8\n20\n1\necs.gn6e-c12g1.24xlarge\n96\n736\nNVIDIA V100 * 8\n32GB * 8\n32\n4,800,000\n16\n8\n20\n1\nSupported scenarios:\nDeep learning applications, such as training and inference applications of AI algorithms used in image classification, autonomous vehicles, and speech recognition\nScientific computing applications, such as computational fluid dynamics, computational finance, molecular dynamics, and environmental analytics\nCompute:\nUses NVIDIA V100 GPUs.\nUses NVIDIA V100 GPUs (SXM2-based) that have the following features:\nInnovative NVIDIA Volta architecture\n16 GB of HBM2 memory (900 GB/s bandwidth) per GPU\n5,120 CUDA cores per GPU\n640 Tensor cores per GPU\nUp to six NVLink bidirectional connections per GPU, each of which provides a bandwidth of 25 Gbit/s in each direction for a total bandwidth of 300 Gbit/s (6 \u00d7 25 \u00d7 2 = 300)\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae Platinum 8163 (Skylake) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports ESSDs, ESSD AutoPL disks, standard SSDs, and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn6v instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nDisk baseline IOPS\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn6v-c8g1.2xlarge\n8\n32\nNVIDIA V100 * 1\n16GB * 1\n2.5\n800,000\nNone\n4\n4\n10\n1\necs.gn6v-c8g1.4xlarge\n16\n64\nNVIDIA V100 * 2\n16GB * 2\n5\n1,000,000\nNone\n4\n8\n20\n1\necs.gn6v-c8g1.8xlarge\n32\n128\nNVIDIA V100 * 4\n16GB * 4\n10\n2,000,000\nNone\n8\n8\n20\n1\necs.gn6v-c8g1.16xlarge\n64\n256\nNVIDIA V100 * 8\n16GB * 8\n20\n2,500,000\nNone\n16\n8\n20\n1\necs.gn6v-c10g1.20xlarge\n82\n336\nNVIDIA V100 * 8\n16GB * 8\n32\n4,500,000\n250,000\n16\n8\n20\n1\nSupported scenarios:\nDeep learning\nScientific computing applications, such as computational fluid dynamics, computational finance, genomics, and environmental analytics\nServer-side GPU compute workloads, such as high-performance computing, rendering, and multi-media encoding and decoding\nCompute:\nUses NVIDIA P100 GPUs.\nOffers multiple CPU-to-memory ratios.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) processors.\nStorage:\nSupports high-performance local Non-Volatile Memory Express (NVMe) SSDs.\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports only IPv4.\nProvides high network performance based on large computing capacity.\ngn5 instance types\nInstance type\nvCPUs\nMemory (GiB)\nLocal storage (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\necs.gn5-c4g1.xlarge\n4\n30\n440\nNVIDIA P100 * 1\n16GB * 1\n3\n300,000\n1\n3\n10\necs.gn5-c8g1.2xlarge\n8\n60\n440\nNVIDIA P100 * 1\n16GB * 1\n3\n400,000\n1\n4\n10\necs.gn5-c4g1.2xlarge\n8\n60\n880\nNVIDIA P100 * 2\n16GB * 2\n5\n1,000,000\n2\n4\n10\necs.gn5-c8g1.4xlarge\n16\n120\n880\nNVIDIA P100 * 2\n16GB * 2\n5\n1,000,000\n4\n8\n20\necs.gn5-c28g1.7xlarge\n28\n112\n440\nNVIDIA P100 * 1\n16GB * 1\n5\n1,000,000\n8\n8\n20\necs.gn5-c8g1.8xlarge\n32\n240\n1,760\nNVIDIA P100 * 4\n16GB * 4\n10\n2,000,000\n8\n8\n20\necs.gn5-c28g1.14xlarge\n56\n224\n880\nNVIDIA P100 * 2\n16GB * 2\n10\n2,000,000\n14\n8\n20\necs.gn5-c8g1.14xlarge\n54\n480\n3,520\nNVIDIA P100 * 8\n16GB * 8\n25\n4,000,000\n14\n8\n20\nSupported scenarios: server-side GPU compute workloads, such as deep learning inference and multi-media encoding and decoding.\nCompute:\nUses NVIDIA P4 GPUs.\nOffers a CPU-to-memory ratio of 1:4.\nUses 2.5 GHz Intel\u00ae Xeon\u00ae E5-2682 v4 (Broadwell) processors.\nStorage:\nIs an instance family in which all instances are I/O optimized.\nSupports standard SSDs and ultra disks.\nNetwork:\nSupports IPv4 and IPv6. For information about IPv6 communication, see IPv6 communication.\nProvides high network performance based on large computing capacity.\ngn5i instance types\nInstance type\nvCPUs\nMemory (GiB)\nGPUs\nGPU memory\nNetwork baseline bandwidth (Gbit/s)\nPacket forwarding rate (pps)\nNIC queues\nENIs\nPrivate IPv4 addresses per ENI\nIPv6 addresses per ENI\necs.gn5i-c2g1.large\n2\n8\nNVIDIA P4 * 1\n8GB * 1\n1\n100,000\n2\n2\n6\n1\necs.gn5i-c4g1.xlarge\n4\n16\nNVIDIA P4 * 1\n8GB * 1\n1.5\n200,000\n2\n3\n10\n1\necs.gn5i-c8g1.2xlarge\n8\n32\nNVIDIA P4 * 1\n8GB * 1\n2\n400,000\n4\n4\n10\n1\necs.gn5i-c16g1.4xlarge\n16\n64\nNVIDIA P4 * 1\n8GB * 1\n3\n800,000\n4\n8\n20\n1\necs.gn5i-c16g1.8xlarge\n32\n128\nNVIDIA P4 * 2\n8GB * 2\n6\n1,200,000\n8\n8\n20\n1\necs.gn5i-c28g1.14xlarge\n56\n224\nNVIDIA P4 * 2\n8GB * 2\n10\n2,000,000\n14\n8\n20\n1"
    },
    "84": {
        "title": "Elastic Compute Service:Billing overview",
        "url": "https://www.alibabacloud.com/help/en/ecs/product-overview/billing-overview",
        "content": "This Product\nElastic Compute Service:Billing overview\nThis topic walks you through Elastic Compute Service (ECS) billable items, billing methods, usage fees, and instance pricing.\nAn ECS instance is a virtual server in the cloud that consists of computing resources (such as vCPUs and memory), an operating system (provided by an image), block storage devices, and networking resources. The following table describes how each individual component is billed.\nResource\nDescription\nBilling method\nReferences\nComputing resources (vCPUs and system disk memory)\nThe computing resources you can obtain are determined by the instance type. Each instance type offers a unique combination of vCPUs, memory, and related capabilities, which determine the price of the instance.\nWhen you create an instance, you occupy computing resources in the cloud. As long as you occupy these resources, you are billed for these resources even if they are idle. This is particularly true for pay-as-you-go instances. To avoid paying for idle resources, we recommend that you stop such instances in economical mode. For more information about the economical mode, see Economical mode.\nSubscription\nPay-as-you-go\nPreemptible Instance\nPay-as-you-go + Reserved Instance\nPay-as-you-go + Savings Plan\nInstance types\nImages\nImage fees are determined based on the types and usage of images.\nSubscription\nPay-as-you-go\nPay-as-you-go + Reserved Instance (for public images)\nImages can be used only with ECS instances. Reserved instances for Windows instances include the costs for the instance and the public image.\nImages\nBlock storage device (cloud disk or local disk)\nBilling for cloud disks is determined by their size and usage duration.\nLocal disks only come with specific instance types and cannot be separately purchased. The prices of the instances include the costs of their local disks.\nSubscription\nPay-as-you-go\nStorage Capacity Unit (SCU)\nPay-as-you-go + Savings Plan\nBlock storage devices\nPublic bandwidth\nIf your instance uses a system-assigned public IP address to access the Internet, you are charged only for outbound data transfers to the Internet.\nAn instance can also use an elastic IP address (EIP) or a NAT gateway to access the Internet. For information about how EIPs are billed and how NAT gateways are billed , see Overview and Billing of Internet NAT gateways respectively.\nPay-by-bandwidth\nPay-by-traffic\nPublic bandwidth\nSnapshots\nWhen you create snapshots, you are charged for them based on their size and storage duration. Fees are region-specific and vary from region to region.\nWhen you copy snapshots, you are charged data transfer fees in addition to the storage fees generated for the snapshot copies.\nPay-as-you-go\nSCU\nSnapshots\nECS resources support the subscription and pay-as-you-go billing methods. You can mix and match different billing methods for different resources to reduce costs. For more information, see Overview.\nThe following figure shows the fees charged for your ECS usage and illustrates how individual resources are billed.\nFor information about the instance price schedule, visit the Instance tab on the Pricing tab of the Elastic Compute Service product page.\nYou can switch between billing methods for ECS instances as your business requirements change and evolve. The following table describes the resources whose billing methods can be changed.\nResource\nDescription\nReferences\nInstance\nWhen you change the billing method of ECS instances, the billing methods of their computing resources and system disks are changed to match the billing method of the instance.\nIf your workloads become intermittent or you no longer need the instance, you can change the billing method of an instance from subscription to pay-as-you-go. Then, you need to pay only for what you use and can release the instance at any time. This lets you recover a portion of the subscription costs.\nAlibaba Cloud determines whether you can switch the billing method of an instance based on usage metrics of the instance. Go to the ECS console and check for the button or menu item that is used to change the billing method of an instance. If the button or menu item does not exist, the billing method of the instance cannot be changed.\nIf your workloads shift towards long-term, sustained business, you can change the billing method of an instance from pay-as-you-go to subscription to save on costs in the long run.\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nCloud disks\nYou can freely change the billing method of data disks that are attached to subscription instances.\nHowever, the billing methods of system disks and data disks on pay-as-you-go instances change together with the billing methods of the instances.\nChange the billing method of a disk\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nPublic bandwidth\nYou can change the billing method for network usage by upgrading or downgrading instance configurations for instances that have system-assigned public IP addresses.\nChange the billing method for network usage of an ECS instance that uses an auto-assigned IP address\nYou can view your bills and their details in the Expenses and Costs. For more information, see View billing details.\nSubscription instances stop providing services when they expire. You can renew an expired instance to continue using it. However, if you do not renew it within the grace period, the instance is released, and all data stored on the instance is lost and cannot be recovered. For more information, see Renewal overview.\nPayments become overdue if you do not have sufficient funds in your account when a bill is due. The total usable funds are calculated as the sum of your balance and applicable vouchers in your account. Overdue payments may result in service interruptions. We recommend that you regularly check your account balance and ensure that you have enough funds to ensure business continuity.\nSubscription resources: Subscription resources are not affected by overdue payments because you have already paid for the resources. You can use these instances up until they expire. However, you will be unable to perform payment-related activities, including purchasing new instances, upgrading instance configurations, or renewing resources.\nPay-as-you-go resources: Pay-as-you-go instances are automatically stopped when you have overdue payments. In this state, billing is stopped for some resources. You are required to settle the overdue payments before you can continue using your instances. If payment is not completed within the grace period, your instances are released and all data stored on the instances is lost and cannot be recovered.\nECS supports the following payment methods:\nBank card\nPayPal\nAlibaba Cloud performs a pre-authorization hold on your PayPal account when you create pay-as-you-go resources.\nYou can use coupons to obtain discounts and savings on your purchases.\nIf you want to purchase ECS resources in the Chinese mainland, you must first complete real-name verification for your Alibaba Cloud account. For more information, see the \"Why do I need to complete real-name registration when purchasing cloud products in Chinese mainland?\" section of Real-name registration FAQs.\nAlibaba Cloud provides multiple methods to view the detailed information about your bills. For more information, see View billing details.\nECS usage costs can be broken into ownership costs and O&M costs. We have prepared a selection of best practices for maximizing cost performance, including actions such as optimizing resources, upgrading resources, taking cost savings measures, and implementing automated O&M. For more information, see Best practices for cost optimization.\nFor answers to the questions that you may encounter when you purchase or use ECS resources, see Billing FAQ."
    },
    "85": {
        "title": "Elastic Compute Service:Overview",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-overview",
        "content": "This Product\nElastic Compute Service:Overview\nYou can choose an appropriate billing method based on the Elastic Compute Service (ECS) resource types. This topic describes all billing methods used in ECS, compares the subscription and pay-as-you-go billing methods, and elaborates the cost-effective billing methods such as preemptible instance and savings plans.\nAn ECS instance includes computing resources (vCPUs and memory), an image, and Elastic Block Storage (EBS) devices, and uses one of the following basic billing methods: subscription, pay-as-you-go, or preemptible instance. The following table describes the applicable resources and scenarios of each billing method.\nBilling method\nApplicable resources\nDescription\nReferences\nSubscription\nComputing resources (vCPUs and memory)\nImage\nDisk\nPublic bandwidth\nA billing method that allows you to use ECS resources only after you pay for them. Subscription is applicable to services that run for 24 hours a day and seven days a week, such as web services. You must pay for subscription resources before you can use them.\nSubscription\nPay-as-you-go\nComputing resources (vCPUs and memory)\nImage\nDisk\nPublic bandwidth\nSnapshot\nA billing method that allows you to use ECS resources and pay for them afterwards. Pay-as-you-go is applicable to applications or services that experience traffic spikes, such as temporary scaling, interim testing, and scientific computing. You can activate and use pay-as-you-go resources before you pay for them. The system generates bills in each billing cycle and deducts corresponding fees from your account.\nPay-as-you-go\nPreemptible instance\nComputing resources (vCPUs and memory)\nPreemptible instances are on-demand instances that you can use before you pay for them. Preemptible instances offer some discounts compared with pay-as-you-go instances and are charged based on the actual usage duration. Prices of preemptible instances fluctuate based on the changes in supply and demand.\nPreemptible Instance\nSubscription instances, pay-as-you-go instances, and preemptible instances support different features. The following table describes the differences.\nFeature\nSubscription instance\nPay-as-you-go instance\nPreemptible instance\nRelease instances\nTo release an instance before it expires, you must first change its billing method from subscription to pay-as-you-go.\nIf you do not renew an instance within the required period of time after the instance expires, the instance is automatically released.\nSupported.\nRelease pay-as-you-go instances that you no longer need at the earliest opportunity. If you do not release them, the ECS resources continue to incur charges until the instances are stopped and released due to overdue payments.\nSupported. The system may also release an instance when the market price exceeds your bid or when the resources of the instance are insufficient.\nChange instance types\nSupported.\nSupported.\nNot supported.\nChange bandwidth configurations\nSupported.\nSupported.\nNot supported.\nChange billing methods\nSupported.\nSupported.\nNot supported.\nUse subscription images from Alibaba Cloud Marketplace\nSupported.\nNot supported.\nNot supported.\nApply for ICP filings for websites that are deployed on ECS instances in the Chinese mainland\nSupported.\nYou can apply for ICP filings only for ECS instances that have a subscription period of at least three months.\nPublic bandwidth must be purchased for the ECS instances.\nNot supported.\nNot supported.\nCreate instances by calling API operations\nSupported.\nSupported.\nSupported.\nUse Security Center Basic and CloudMonitor Basic\nSupported.\nSupported.\nSupported.\nIn addition to subscription, pay-as-you-go and preemptible instance, Alibaba Cloud provides some combinations of billing methods for different ECS resources to reduce costs. You can use a proper combination of billing methods based on your business requirements.\nBilling method\nApplicable resources\nDescription\nReferences\nReserved instance\nCompute resources (vCPUs and memory)\nImage\nReserved instances are coupons that can be used to offset the bills of pay-as-you-go instances.\nReserved instances\nSCU\nDisk\nSnapshot\nStorage capacity units (SCUs) are storage resource plans that can be used to offset the bills of different pay-as-you-go storage resources.\nSCUs\nData transfer plan\nPublic bandwidth\nData transfer plans provide economical solutions designed to offset the fees of IPv4 data transfers from instances billed on a pay-by-traffic basis for network usage.\nData Transfer Plan\nYou can switch between billing methods for ECS instances as your business requirements change and evolve. The following table describes the resources whose billing methods can be changed.\nResource\nDescription\nReferences\nInstance\nWhen you change the billing method of ECS instances, the billing methods of their computing resources and system disks are changed to match the billing method of the instance.\nIf your workloads become intermittent or you no longer need the instance, you can change the billing method of an instance from subscription to pay-as-you-go. Then, you need to pay only for what you use and can release the instance at any time. This lets you recover a portion of the subscription costs.\nAlibaba Cloud determines whether you can switch the billing method of an instance based on usage metrics of the instance. Go to the ECS console and check for the button or menu item that is used to change the billing method of an instance. If the button or menu item does not exist, the billing method of the instance cannot be changed.\nIf your workloads shift towards long-term, sustained business, you can change the billing method of an instance from pay-as-you-go to subscription to save on costs in the long run.\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nCloud disks\nYou can freely change the billing method of data disks that are attached to subscription instances.\nHowever, the billing methods of system disks and data disks on pay-as-you-go instances change together with the billing methods of the instances.\nChange the billing method of a cloud disk\nChange the billing method of an instance from subscription to pay-as-you-go\nChange the billing method of an instance from pay-as-you-go to subscription\nPublic bandwidth\nYou can change the billing method for network usage by upgrading or downgrading instance configurations for instances that have system-assigned public IP addresses.\nChange the billing method for network usage of an ECS instance that uses a static public IP address"
    },
    "86": {
        "title": "Elastic Compute Service:Subscription",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-subscription",
        "content": "This Product\nElastic Compute Service:Subscription\nSubscription is a billing method that allows you to use Elastic Compute Service (ECS) resources only after you pay for the resources. You can purchase subscription ECS instances to reserve resources for long-term use and save on bills. ECS provides larger savings for longer subscriptions. This topic describes the scenarios for which subscription ECS resources are suitable, the impacts of subscription ECS instance expiration, and how to change the billing method of an ECS instance from subscription to pay-as-you-go.\nIf your business has the following characteristics, we recommend that you purchase subscription ECS resources:\nPredictable usage period of resources\nConsistent use of resources\nLong-term use of resources\nExamples: web services and database services that run 24/7.\nThe following resources support the subscription billing method:\nECS instance types\nImages that are used with subscription ECS instances\nCloud disks that re used with subscription ECS instances\nPublic bandwidth that is used with subscription ECS instances\nAfter a subscription instance expires, it may be stopped. You are notified to renew the instance. Renew the instance at your earliest convenience to ensure service continuity. If you have other questions, submit a ticket.\nIf the auto-renewal feature is not enabled for a subscription instance, the instance stops providing services at some point from 00:00:00 on the expiration date to 00:00:00 the next day.\nYou cannot enable the auto-renewal feature for an expired subscription instance.\nThe following table describes the resource states for an expired subscription instance for which the auto-renewal feature is not enabled.\nResource\nWithin 15 days after the instance expires\nMore than 15 days after the instance expires\nComputing resources (vCPUs and memory)\nThe computing resources (vCPUs and memory) are retained, but the instance stops providing services.\nAfter an instance is stopped, you cannot connect to the instance or access websites that are deployed on the instance, and service errors may occur.\nThe computing resources (vCPUs and memory) are released.\nImage\nThe image is unavailable.\nThe image is unavailable.\nBlock storage device\nCloud disks: If you disable the Release Disk with Instance feature for a cloud disk, the disk is automatically converted into a pay-as-you-go cloud disk and retained and continues to be billed, but the cloud disk is out of service.\nLocal disks: The local disks and their data are retained, but the local disks are out of service.\nCloud disks:\nSubscription cloud disks are released, and data on the disks is deleted.\nPay-as-you-go disks for which the Release Disk with Instance feature is enabled are released, and data on the disks is deleted.\nIf the Delete Automatic Snapshots While Releasing Disk feature is enabled for a cloud disk, the automatic snapshots of the disk are automatically deleted when the disk is released. For more information, see the Enable the Delete Automatic Snapshots While Releasing Disk attribute section of the \"Configure an automatic snapshot policy for a cloud disk\" topic.\nLocal disks: The local disks are released, and data on the disks is deleted.\nPublic IP address\nIf the instance resides in the classic network, the public IP address that is automatically assigned to the instance is retained.\nIf the instance resides in a virtual private cloud (VPC), the following rules apply:\nThe auto-assigned public IP address of the ECS instance is retained.\nThe elastic IP address (EIP) that is associated with the instance is not affected.\nIf the instance is deployed in the classic network, the auto-assigned public IP address of the ECS instance is released.\nIf the instance resides in a VPC, the following rules apply:\nThe auto-assigned public IP address of the ECS instance is released.\nThe EIP is disassociated from the instance.\nIf the auto-renewal feature is enabled for a subscription instance but the instance fails to renew, the instance stops providing services at some point from 00:00:00 on the 15th day after instance expiration to 00:00:00 on the 16th day after instance expiration.\nThe following table describes the resource states for an expired subscription instance for which the auto-renewal feature is enabled.\nResource\nWithin 15 days after the instance expires\nMore than 15 days after the instance expires\nMore than 30 days after the instance expires\nComputing resources (vCPUs and memory)\nThe computing resources (vCPUs and memory) are retained, and the instance works as expected.\nYou can start or stop an instance that works properly, and connect to the instance by using management terminals or other connection methods.\nThe computing resources (vCPUs and memory) are retained, but the instance stops providing services.\nAfter an ECS instance is stopped, you may be unable to connect to the instance or access the websites that are deployed on the instance. Service errors may also occur.\nThe computing resources (vCPUs and memory) of the instance are released.\nImage\nThe image is available.\nThe image is unavailable.\nThe image is unavailable.\nBlock storage device\nCloud disks: If you disable the Release Disk with Instance feature for a cloud disk, the disk is automatically converted into a pay-as-you-go cloud disk and retained and continues to be billed, and the cloud disk works as expected.\nLocal disks: The local disks and their data are retained. The local disks can work as expected.\nCloud disks: If you disable the Release Disk with Instance feature for a cloud disk, the disk is automatically converted into a pay-as-you-go cloud disk and retained and continues to be billed, but the cloud disk is out of service.\nLocal disks: The local disks and their data are retained, but the local disks are out of service.\nCloud disks:\nSubscription cloud disks are released and data on the disks is deleted.\nPay-as-you-go disks for which the Release Disk with Instance feature is enabled are released, and data on the disks is deleted.\nIf the Delete Automatic Snapshots While Releasing Disk feature is enabled for a cloud disk, the automatic snapshots of the disk are automatically deleted when the disk is released. For more information, see the Enable the Delete Automatic Snapshots While Releasing Disk attribute section of the \"Configure an automatic snapshot policy for a cloud disk\" topic.\nLocal disks: The local disks are released, and data on the disks is deleted.\nPublic IP address\nIf the instance resides in the classic network, the public IP address that is automatically assigned to the instance is retained.\nIf the instance resides in a VPC, the following rules apply:\nThe auto-assigned public IP address of the ECS instance is retained.\nThe EIP that is associated with the instance is not affected.\nIf the ECS instance is deployed in the classic network, the auto-assigned public IP address of the instance is retained.\nIf the instance resides in a VPC, the following rules apply:\nThe auto-assigned public IP address of the ECS instance is retained.\nThe EIP that is associated with the instance is not affected.\nIf the instance is deployed in the classic network, the auto-assigned public IP address of the ECS instance is released.\nIf the instance resides in a VPC, the following rules apply:\nThe auto-assigned public IP address of the ECS instance is released.\nThe EIP is disassociated from the ECS instance.\nAfter an instance expires, Data Storage is displayed in the Actions column corresponding to the instance on the Instance page. Before the instance is released, you can create a custom image from the instance or create snapshots for disks on the instance to back up disk data.\nYou can change the billing method of an instance from subscription to pay-as-you-go to recover some subscription costs and use the instance in a more flexible manner. For more information, see Change the billing method of an instance from subscription to pay-as-you-go.\nIf you have overdue bills, existing subscription instances are not affected. However, you will be unable to perform activities that incur charges, including purchasing instances, upgrading instance configurations, or renewing resources. For more information, see Overdue payments.\nFAQ about billing"
    },
    "87": {
        "title": "Elastic Compute Service:Pay-as-you-go",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-pay-as-you-go",
        "content": "This Product\nElastic Compute Service:Pay-as-you-go\nPay-as-you-go is a billing method that lets you use resources first and pay for them afterwards. You can create or release Elastic Compute Service (ECS) resources on demand with no long-term commitments or upfront payments, and pay only for what you use. This eliminates the need to plan, purchase, and maintain large amounts of resources, simplifying resource deployment and providing savings of 30% to 80% when compared to self-built data centers. This topic describes the billing rules for pay-as-you-go resources.\nApplications have short-term, bursty, variable, or unpredictable workloads.\nApplications require resources to be created and released on demand.\nCommon scenarios that the pay-as-you-go billing method is suitable for include temporary scaling, testing, and flash sales.\nThe following ECS resources support the pay-as-you-go billing method:\nECS instances, which include computing resources (vCPUs and memory)\nImages\nDisks\nPublic bandwidth (pay-by-bandwidth)\nSnapshots\nThe following table describes how the resources in a pay-as-you-go instance are billed, on the premise that the instance is not stopped due to an overdue payment. Billing durations vary based on resource types.\nResource\nBilling formula\nBilling duration\nBilling increment\nComputing resources (vCPUs and memory)\nUnit price of an instance type \u00d7 Usage duration\nFor an instance that resides in the classic network, billing begins when the instance is created and ends when the instance is released.\nFor an instance that resides in a virtual private cloud (VPC), the billing duration depends on whether the economical mode is enabled.\nIf the economical mode is disabled, billing begins when the instance is created and ends when the instance is released.\nIf the economical mode is enabled, billing begins when the instance is created, suspends when the instance is stopped by using the ECS console, resumes when the instance is started again by using the ECS console, and ends when the instance is released. For more information, see Economical mode.\n1 second\nWithin each billing cycle (1 hour), computing resources has a minimum billing duration that varies based on the number of vCPUs provided by the instance type:\n1 vCPU: 10 minutes, with a minimum of 10 minutes\n2 vCPUs: 5 minutes, with a minimum of 5 minutes\n4 or more vCPUs: 2 minutes, with a minimum of 2 minutes\nImage\nUnit price of an image \u00d7 Usage duration\nBilling begins when the instance is created and ends when the instance is released.\n1 second\nCloud disk used as the system disk\nUnit price of a cloud disk \u00d7 Disk capacity \u00d7 Usage duration\nBilling begins when the instance is created and ends when the instance is released.\n1 second\nWithin each billing cycle (1 hour), the system disk has a minimum billing duration that varies based on the number of vCPUs provided by the instance type:\n1 vCPU: 10 minutes, with a minimum of 10 minutes\n2 vCPUs: 5 minutes, with a minimum of 5 minutes\n4 or more vCPUs: 2 minutes, with a minimum of 2 minutes\nCloud disks used as data disks\nUnit price of a cloud disk \u00d7 Disk capacity \u00d7 Usage duration\nBilling begins when a data disk is created and ends when the data disk is released.\n1 second\nPublic bandwidth (pay-by-bandwidth)\nUnit price of public bandwidth \u00d7 Bandwidth value \u00d7 Usage duration\nBilling starts when public bandwidth is provisioned, and ends when you disable public bandwidth or when the instance is released.\n1 second\nWithin each billing cycle (1 hour), public bandwidth has a minimum billing duration that varies based on the number of vCPUs provided by the instance type:\n1 vCPU: 10 minutes, with a minimum of 10 minutes\n2 vCPUs: 5 minutes, with a minimum of 5 minutes\n4 or more vCPUs: 2 minutes, with a minimum of 2 minutes\nSnapshots\nUnit price of a snapshot \u00d7 Snapshot size \u00d7 Usage duration\nBilling begins when a snapshot is created and ends when the snapshot is deleted.\n1 hour, with a minimum of 1 hour\nBills for pay-as-you-go ECS resources are generated on an hourly basis. Fees for all pay-as-you-go resources in your account are consolidated. Fees become due once a month, or when the cumulative bills exceed a predefined limit, which is determined by the default payment method.\nIf your default payment method is bank card (credit or debit card), the limit is USD 1,000.\nIf your default payment method is PayPal, the limit varies based on your ECS usage.\nAlibaba Cloud makes up to three attempts to collect fees: on the due date, 7 days after the due date (T+7), and 14 days after the due date (T+14). If Alibaba Cloud fails to collect payment on the due date, the payment becomes overdue. Then, Alibaba Cloud makes two more attempts to collect payment on T+7 and T+14. During this time, the instance is not stopped and is still billed. If all three attempts fail, the instance is stopped 15 days after the due date (T+15). Billing for the instance also stops. For more information, see the \"Pay-as-you-go resources\" section in Overdue payments.\nIf the cumulative bills in each month do not exceed the settlement limit, Alibaba Cloud attempts to collect the fees due on the first day of the following month.\nIf your requirements shift towards long-term workloads, you can switch the billing method to subscription and benefit from a more cost-effective pricing schedule. For more information, see Change the billing method of an ECS instance from pay-as-you-go to subscription.\nIf you no longer need an ECS instance, you can release the instance to prevent unnecessary costs. For more information, see Release an instance.\nWhen your account has overdue payments, all pay-as-you-go resources in your account are suspended. Overdue payments may result in the stop of instances and even the release of resources. To prevent these consequences and ensure service continuity, we recommend that you regularly add funds to your account to prevent overdue payments. For information about changes in resource status after payments become overdue, see Overdue payments.\nCan I use coupons to pay for pay-as-you-go instances?\nHow is the billable time of a pay-as-you-go instance calculated? For example, if I created a pay-as-you-go ECS instance at 01:30:00 and released it at 02:00:00, was the instance billed for a 30-minute or 1-hour period?\nWhy am I still charged for an instance that has been stopped manually or due to an overdue payment?\nI am unable to place an order to change the billing method of an instance from pay-as-you-go to subscription. What can I do?"
    },
    "88": {
        "title": "Elastic Compute Service:Preemptible instances",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-preemptible-instances",
        "content": "This Product\nElastic Compute Service:Preemptible instances\nPreemptible instances use the pay-as-you-go billing method. The market price changes in real time based on the supply and demand. Compared with pay-as-you-go instances, preemptible instances can reduce costs by up to 90%.\nA preemptible instance is billed only based on the instance type. Charges do not include images, disks, public bandwidth (based on the pay-by-bandwidth metering method), or snapshots.\nBilling duration: the duration from when a preemptible instance is created to when the instance is released.\nMarket price: the price of the instance type, which does not include the prices of other resources, such as disks and public bandwidth.\nBid price: the highest price you are willing to pay for a preemptible instance.\nThe bid price is not the actual price. The actual billing price is calculated based on the market price.\nInstance usage duration\n1 hour\nUndefined (None)\nBilling diagram\nDescription\nAlibaba Cloud does not automatically release a preemptible instance within 1 hour after the instance is created. After the 1-hour protection period ends, the system compares the bid price with the real-time market price and checks the resource inventory to determine whether to retain or release the instance.\nIf you do not specify a protection period for the preemptible instance, the system immediately compares the bid price with the real-time market price and checks the resource inventory to determine whether to retain or release the instance.\nPrice used for the instance per hour\nUsage duration \u2264 1 hour: Market price at the time of purchase.\nUsage duration > 1 hour: Real-time market price in each period.\nReal-time market prices in different periods.\nBilling formulas\nUsage duration \u2264 1 hour: Market price at the time of purchase \u00d7 Usage duration.\nUsage duration > 1 hour: Market price at the time of purchase \u00d7 1 hour + \u2211 (Real-time market price in period 1 \u00d7 Period 1 + Real-time market price in period 2 \u00d7 Period 2 +\u2026+ Real-time market price in period N \u00d7 Period N)\n\n\u2211 (Real-time market price in period 1 \u00d7 Period 1 + Real-time market price in period 2 \u00d7 Period 2 +\u2026+ Real-time market price in period N \u00d7 Period N).\nIf the instance type is the same, the market price of a preemptible instance whose usage duration is None is lower than the price of a preemptible instance whose usage duration is 1 Hour, regardless of whether the specified usage duration is exceeded.\nFees are calculated by second. Bills are settled on an hourly basis.\nThe market price varies based on the supply and demand for the instance type. The following examples are provided only for reference.\nScenario 1: set the Instance Usage Duration to 1 hour.\nFor example, you bid USD 3 per hour as the maximum price per instance at 9:40 and bid for a preemptible instance at a market price of USD 2.5 per hour. You set the Instance Usage Duration to 1 hour. At 11:00, the bid price falls below the market price, and the instance is interrupted and reclaimed. After 5 minutes, the instance is released.\nBilling\nPreemptible instances are billed by second based on usage duration. If an hourly price is displayed, you can divide the price by 3,600 to obtain the price per second.\nThe actual usage duration is 5,100 seconds (9:40 to 11:05) and exceeds 1 hour. The billing price within 1 hour is the market price at the time of purchase, which is USD 2.5 per hour. After 1 hour, the market price in each period applies before the preemptive instance is interrupted and reclaimed. The fees are calculated by using the following formulas:\nFees for the first hour = Market price at the time of purchase \u00d7 Billing duration.\n9:40 to 10:40, during which the market price is 2.5 USD per hour and the usage duration is 3,600 seconds: (2.5/3,600) \u00d7 3,600 = USD 2.5.\nFees for a usage duration after the first hour = \u2211 (Real-time market price in period 1 \u00d7 Period 1 + Real-time market price in period 2 \u00d7 Period 2 +\u2026+ Real-time market price in period N \u00d7 Period N)\n10:40 to 11:00, during which the market price is USD 3 per hour and the usage duration is 1,200 seconds: (3/3,600) \u00d7 1,200 = USD 1.\n11:00 to 11:05, during which the market price is USD 4 per hour and the usage duration is 300 seconds: (4/3,600) \u00d7 300 = USD 0.33.\nTotal fees = 2.5 + 1 + 0.33 = USD 3.83.\nScenario 2: set the Instance Usage Duration to None.\nFor example, you bid on a preemptible instance at 9:40 by using automatic bidding based on a market price of USD 2 per hour. If you set the Instance Usage Duration parameter to None, the instance is interrupted and reclaimed due to insufficient inventory at 11:00. Then, the instance is released after 5 minutes.\nBilling\nPreemptible instances are billed by second based on usage duration. If an hourly price is displayed, you can divide the price by 3,600 to obtain the price per second.\nThe actual usage duration is 5,100 seconds (9:40 to 11:05), and the billing price is the market price in each period. The fees are calculated by using the following formulas:\nFees for a usage duration = \u2211 (Real-time market price in period 1 \u00d7 Period 1 + Real-time market price in period 2 \u00d7 Period 2 +\u2026+ Real-time market price in period N \u00d7 Period N)\n9:40 to 10:00, during which the market price is USD 2 per hour and the usage duration is 1,200 seconds: (2/3,600) \u00d7 1,200 = USD 0.67.\n10:00 to 11:00, during which the market price is 2.5 USD per hour and the usage duration is 3,600 seconds: (2.5/3,600) \u00d7 3,600 = USD 2.5.\n11:00 to 11:05, during which the market price is USD 3 per hour and the usage duration is 300 seconds: (3/3,600) \u00d7 300 = USD 0.25.\nTotal fees = 0.67 + 2.5 + 0.25 = USD 3.42.\nFor more information about how to view the bills of preemptible instances, see the Example: View the bills for preemptible ECS instances section of the \"View billing details\" topic.\nIf you have overdue payments within your Alibaba Cloud account, you cannot use preemptible instances. Overdue payments cause instances to stop or resources to be released. To prevent the preceding issues and ensure service continuity, we recommend that you regularly add funds to your account to prevent overdue payments.\nOverview\nCreate a preemptible instance\nBest practices for preemptible instances\n"
    },
    "89": {
        "title": "Elastic Compute Service:Reserved instances",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-reserved-instances",
        "content": "This Product\nElastic Compute Service:Reserved instances\nA reserved instance serves as a paid membership card for pay-as-you-go Elastic Compute Service (ECS) instances (excluding preemptible instances). Similar to other membership cards, a reserved instance can offset the fees of the pay-as-you-go ECS instances whose attributes match the attributes of the reserved instance. After you purchase reserved instances, you commit to using pay-as-you-go instances for a specific period of time. The reserved instances can provide benefits to your business. For example, you can significantly reduce the costs of the computing resources of pay-as-you-go instances and achieve instance flexibility, resource assurance, and business continuity.\nWe recommend that you use savings plans instead of reserved instances. Savings plans provide more flexibility and discounts than reserved instances. For more information, see Savings plans.\nReserved instances are classified into regional and zonal reserved instances.\nRegional reserved instances\nYou need to only specify a region when you purchase a reserved instance.\nA regional reserved instance can be used to offset eligible pay-as-you-go instances across zones within a single region and across different instance types within the same instance family.\nResource reservation is not supported.\nZonal reserved instances\nYou must specify the region and zone when you purchase a zonal reserved instance.\nOnly the fees of pay-as-you-go instances of the same instance type in a single zone can be offset by a zonal reserved instance.\nResource reservation is supported. A specific number of instances of a specified instance type are reserved within the validity period. This ensures that pay-as-you-go instances can be created in the specified zone at any time.\nThe type of the reserved instance affects the matching conditions. For more information, see Usage rules for reserved instances. After you purchase a reserved instance, you can change the zone based on your business requirements. For more information, see Change the zone of a reserved instance of the \"Split, merge, or modify reserved instances\" topic.\nThe following table describes the scenarios in which you can purchase reserved instances to offset the bills of pay-as-you-go instances to ensure business flexibility and reduce costs.\nScenario\nBenefit\nYou use Auto Scaling to manage ECS instances and have a large number of pay-as-you-go instances. You want to reduce your costs.\nAfter you purchase reserved instances, you commit to using pay-as-you-go instances for a specific period of time. Reserved instances provide significant discounts compared with pay-as-you-go instances.\nYou want to pay for resources in installments to mitigate financial pressure.\nYou can pay by hour by selecting the Partial Upfront or No Upfront payment option to relieve the financial pressure caused by all upfront payments.\nIf you want to change the region for your business, you must release ECS instances in the original zone and create ECS instances in the zones of the destination region.\nYou can split or merge reserved instances to offset the bills of pay-as-you-go instances of different instance types.\nYou can change the zone of a reserved instance at any time. A regional reserved instance can be used to offset the bills of pay-as-you-go instances across zones.\nDuring automated O&M, the number of instances can be automatically adjusted.\nPurchased reserved instances deliver computing power instead of specific instances. Reserved instances can be matched to eligible pay-as-you-go instances and provide more flexibility than subscription instances.\nReserved instances support the following payment options:\nAll Upfront: Full payment is required at the time of purchase. No additional costs or hourly fees are charged within the term of the reserved instance.\nPartial Upfront: Partial payment (approximately 50% of the full amount) is required upfront at the time of purchase. The remainder is paid at a discounted hourly rate throughout the term.\nNo Upfront: No upfront payment is required at the time of purchase. You are billed a discounted hourly rate every hour throughout the term.\nTo use the Partial Upfront or No Upfront payment option, make sure that the term of the reserved instance is longer than one year.\nYour ECS usage determines whether you can use the No Upfront payment option. If you cannot find the No Upfront payment option and you want to use the option, submit a ticket.\nYou are charged based on the payment option that you selected, regardless of whether the reserved instance is matched to pay-as-you-go instances. The All Upfront option is the most cost-effective.\nIf the Partial Upfront or No Upfront option is selected, the hourly fee is calculated on a per-second basis, and the bill is generated on an hourly basis and paid on a monthly basis. For information about the pricing of reserved instances, see the Pricing tab of the Elastic Compute Service product page. If the total payable amount on the monthly bill reaches USD 1,000, USD 1,000 is automatically deducted from your account balance. Fees less than USD 1,000 are included in the monthly bill.\nA reserved instance immediately takes effect after it is purchased, and matches eligible pay-as-you-go instances on an hourly basis to offset the bills of the pay-as-you-go instances. For information about how a reserved instance is matched to pay-as-you-go instances, see Usage rules for reserved instances.\nA reserved instance takes effect and is billed starting on the hour of purchase. The reserved instance expires at 24:00:00 on the expiration date. For example, if you purchase a reserved instance with a one-year term at 22:45:00 on May 1, 2024, the reserved instance takes effect and is billed starting 22:00:00 on May 1, 2024. The reserved instance expires at 00:00:00 on May 2, 2025. If you purchase a reserved instance and have pay-as-you-go instances that match the attributes of the reserved instance, the reserved instance is applied to offset the bills of the matching pay-as-you-go instances starting from 22:00 to 23:00 on May 1, 2024 until the reserved instance expires.\nConfigure the Specify Effective Time parameter. Billing for a reserved instance starts at the effective time that you specify for the reserved instance.\nTo continue benefiting from the billing discounts provided by reserved instances, we recommend that you renew reserved instances to extend the related terms before the reserved instances expire. Reserved instances support the following renewal methods: manual renewal and auto-renewal. Select a renewal method based on the lifecycle state of your reserved instance.\n\nYou can manually renew a reserved instance in the ECS console at any time before the reserved instance expires.\nGo to the Reserved Instances page.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Deployment & Elasticity >  > Reserved Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind the reserved instance that you want to renew and click Renew.\nOn the Renew page, set Renewal Duration to 1 month, 1 year, or 3 years, select Enable Auto-renewal based on your business requirements, and then complete the renewal as prompted.\nThe availability of one-month Renewal Duration depends on your ECS usage. If you cannot see this option and need to use it, please submit a ticket.\nIf auto-renewal is enabled for a reserved instance, the reserved instance is automatically renewed before it expires. You can enable this feature for reserved instances to prevent the reserved instances from being automatically released.\nIf you manually renew a reserved instance before it is automatically renewed, the auto-renewal operation is not performed during the current billing cycle.\nIf you manually renew a reserved instance before the auto-renewal payment is deducted, the system renews the reserved instance based on the new expiration date.\nStarting on the ninth day before the instance expires, Alibaba Cloud attempts to deduct the renewal payment from your account. Make sure that your account balance is sufficient.\nIf the first deduction attempt fails, the system attempts to deduct the renewal payment once every day until the payment is deducted or until the reserved instance expires.\nGo to the Reserved Instances page.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Deployment & Elasticity >  > Reserved Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind the reserved instance that you want to renew and click Auto-renewal in the Actions column.\nRead the notes, turn on Enable Auto-renewal, select a value for the Renewal Period parameter, and then click OK.\nItem\nDescription\nMaximum number of reserved instances\nThe maximum number of reserved instances varies based on the type of reserved instances.\nMaximum number of regional reserved instances: Each account can have up to 20 regional reserved instances across all regions.\nMaximum number of zonal reserved instances: Each account can have up to 20 zonal reserved instances in each zone.\nIf you require more reserved instances, submit a ticket.\nInstance type\nThe gn6i and t5 instance families do not support regional reserved instances. The gn6i and t5 reserved instances cannot be split or merged.\nThe instance types that you can select when you purchase a reserved instance are displayed on the page.\nEligible resources\nReserved instances can match only pay-as-you-go instances, except for preemptible instances.\nOnly the fees of computing resources such as vCPUs and memory can be offset. The fees of resources such as network and storage resources cannot be offset. For information about the billing of ECS instances, see Billing overview.\nWindows reserved instances can be applied to offset the image fees of pay-as-you-go Windows instances.\nWindows reserved instances already include Windows images at no additional cost.\nBefore you purchase reserved instances, we recommend that you understand the deduction rules for reserved instances and pay-as-you-go instances. For more information, see Usage rules for reserved instances.\nFor information about how to purchase reserved instances, see Purchase reserved instances.\nIf your workloads change, you can split or merge reserved instances or change the zones of reserved instances to match pay-as-you-go instances of different instance types and zones. For more information, see Split, merge, or modify reserved instances.\nYou can view information about a reserved instance, such as the ECS instances whose bills can be offset by the reserved instance and the normalization factor of the reserved instance. You can also view the billing details, utilization, and coverage rate of the reserved instance. For more information, see View reserved instances.\nFor information about frequently asked questions about reserved instances, see Instance FAQ."
    },
    "90": {
        "title": "Elastic Compute Service:Savings plans",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-savings-plans",
        "content": "This Product\nElastic Compute Service:Savings plans\nA savings plan is a discount plan that can be applied to offset the bills of pay-as-you-go resources, including pay-as-you-go Elastic Compute Service (ECS) instances and elastic container instances, excluding preemptible instances. Savings plans allow you to use resources in a more flexible manner at low prices. This topic describes savings plans and how to purchase, use, and maintain savings plans.\nA savings plan is a discount plan that provides savings on the usage of pay-as-you-go resources, including pay-as-you-go ECS instances and elastic container instances, excluding preemptible instances. Savings plans provide significant savings over pay-as-you-go rates in exchange for a commitment to an hourly spend over a one- or three-year period. Compared with reserved instances, savings plans are more cost-effective and offer flexibility in choices of instance types, instance families, regions, and operating systems.\nIf you use pay-as-you-go resources for an extended period of time, you can purchase savings plans, which are automatically applied to eligible resources, to receive discounts and reduce resource costs.\nIf you use subscription resources, you can change the resources to pay-as-you-go resources and purchase savings plans. Then, you can change the resources between instance types, instance families, and regions in a flexible manner at no additional costs to meet your changing business requirements.\nSavings plans do not affect the status of your resources and can help reduce your bills only when the savings plans are applied to eligible pay-as-you-go instance usage. A purchased saving plan does not create instances for you, and you must create pay-as-you-go instances. Savings plans can help save you up to 83% off pay-as-you-go rates on eligible resource usage.\nAlibaba Cloud provides two types of savings plans that provide different degrees of flexibility in resource usage: ECS compute savings plans and general-purpose savings plans. The following figure shows the differences between the savings plans and other pricing models (billing methods) that have long-term commitments.\nAfter you purchase a savings plan, the savings plan does not provide resources that are eligible for the savings plan but can be applied to eligible pay-as-you-go resources to provide billing discounts. If you use pay-as-you-go resources, you can purchase savings plans to reduce costs. After you purchase a savings plan, you are charged based on the hourly spend commitment that is associated with the savings plan, as shown in the following figure. Savings plans are automatically matched to eligible resources within the duration of the savings plans. After a savings plan is matched to eligible resources, the savings plan is applied to offset the fees for the resources at discounted pay-as-you-go rates (also known as Savings Plan rates) every hour in the order of time when the resources are billed. The savings plan can cover your pay-as-you-go resource usage up to the hourly spend commitment. Usage beyond the hourly spend commitment is billed based on regular pay-as-you-go rates. For information about the rules based on which savings plans offset fees, see Eligible resources and deduction rules of savings plans.\nIf the hourly discounted spend of all your pay-as-you-go resources that are matched to a savings plan does not exceed the hourly spend commitment associated with the savings plan, you are still charged the hourly spend commitment. Make sure that you properly calculate and evaluate potential savings plan purchases before you purchase a savings plan to better reduce costs. You can purchase savings plans based on the recommendations provided by Alibaba Cloud. For more information, see Purchase savings plan.\n\n\nBefore you purchase savings plans, you can learn about the benefits of savings plans from the perspectives of business type characteristics, resource costs, and bill O&M management, to determine whether savings plans are suitable for your business.\nSavings plans require an hourly spend commitment and are suitable for business models that have relatively consistent resource demands. If your business model requires flexibility in resource usage and meets the following characteristics, we recommend that you purchase savings plans, which provide savings on long-term pay-as-you-go resource usage, and use pay-as-you-go resources in response to short-term demand changes to reduce resource costs. If your business workloads continuously increase, you can purchase a savings plan, make a small hourly spend commitment, and then upgrade the savings plan as your business workloads increase to facilitate O&M and management.\nLinked business\nAll business segments are closely linked. When the traffic loads of one business segment increase, the traffic loads of other business segments also increase.\nHybrid business\nMultiple types of business are deployed online and have different resource demands in different periods of time.\nStable business\nBusiness is relatively stable and has similar resource demands in different periods of time.\nPeriodically growing business\nThe overall business workload steadily grows and the business has stable resource demands in different periods of time.\n\n\n\n\nIf you want to change resources as your business requirements vary and maintain relatively stable usage costs for cloud resources, you can use savings plans to reduce the risk of additional fees.\nChange of resources\nIf you change the configurations or regions of unexpired subscription instances, you may be charged additional fees, which may amount to out-of-budget expenses.\nWhen you change the configurations or regions of pay-as-you-go instances, you may be charged significantly higher rates, which may increase the total cost.\nTo obtain discounts and significantly reduce the costs of instance configuration or region changes, we recommend that you use pay-as-you-go instances and apply savings plans to the instances. This way, you can maintain a stable total cost over an extended period of time and reduce long-term usage costs. The following figure shows how the total cost varies when you change the configurations or regions of instances.\nChange of resource types\nIf your business loads fluctuate and the instances of multiple instance types asynchronously change in loads, the subscription pricing model that you use may be unable to provide the required cost-effectiveness due to idle resource usage and result in an increase in the unit-time usage cost for individual instance types and an increase in the total cost.\nIn this case, you can use savings plans to offset the fees for pay-as-you-go resources to obtain discounts provided by the savings plans regardless of the instance family and reduce the total cost.\n\n\nSubscription and pay-as-you-go instances are independently billed at the instance level. Therefore, cloud budget management is complex. Savings plans can be applied to eligible resource usage regardless of the instance type and operating system. This helps simplify cloud budget management.\n\nBefore you purchase savings plans, determine your required savings plans based on your actual resource usage. You can refer to Purchase savings plan to purchase savings plans based on the recommendations of Alibaba Cloud or calculate potential savings plan purchases and then purchase on the savings plan buy page. When you calculate potential savings plan purchases, you must consider the discounts provided by each savings plan based on various conditions, such as your budget, the billing method of resources, and the usage duration of resources. Then, determine the type, resource configuration, hourly spend commitment, payment option, and duration of the savings plans that you want to purchase based on the calculation results and go to the savings plan buy page to purchase savings plans.\nYou can upgrade existing savings plans. For more information, see Upgrade a savings plan.\nOn the savings plan buy or upgrade page, the total payable amount for the savings plan is determined based on the hourly commitment amount (Committed Amount) and the duration (Duration) parameters, and the resource usage that the savings plan can cover per hour is determined based on the other parameters. We recommend that you purchase a savings plan based on the recommendations of Alibaba Cloud or the results of manual purchase calculation and evaluation. If you have other discounts, the discounts may apply. The payable amount displayed on the savings plan buy or upgrade page shall prevail.\nThe following limits apply when you purchase and use savings plans:\nLimits on purchase:\nYou can purchase up to 200 savings plans for each Alibaba Cloud account.\nLimits on use:\nSavings plans can be applied only to pay-as-you-go ECS instances and elastic container instances, excluding preemptible instances. For information about the eligible resources and deduction rules of savings plans, see Eligible resources and deduction rules of savings plans.\nFor ECS instances, savings plans can be used to offset the fees for computing resources (vCPUs and memory), images, system disks, and public bandwidth. Savings plans can also be used to offset capacity fees, performance provision fees, and performance burst fees for data disks on the ECS instances. For information about the billing of ECS instances, see Billing overview.\nFor elastic container instances, savings plans can be used to offset the fees for only computing resources (vCPUs and memory). For information about the billing of elastic container instances, see Billing of elastic container instances.\nIf you set the Activation Type parameter to Immediately Activate when you purchase a savings plan, the savings plan takes effect on the hour (zero minutes and zero seconds past the hour) when you complete the payment.\nIf you set the Activation Type parameter to Activated at Specified Point in Time, you must specify a point in time at which you want the savings plan to take effect. The specified point in time is an on-the-hour time and can be up to one year after the point in time when you place the order.\nFor example, if you purchase a one-year savings plan that immediately takes effect at 13:45 on October 29, 2024, the savings plan takes effect at 13:00 on October 29, 2024 and expires at 13:00 on October 29, 2025. If you have eligible pay-as-you-go instances, the savings plan is applied to offset the fees for the instances starting from 13:00:00 on October 29, 2024 until the savings plan expires.\nTo view the expiration time of a savings plan, log on to the Expenses and Costs console, choose Savings Plan > Overview in the left-side navigation pane, and then search for the savings plan.\nThe expiration times of savings plans are on-the-hour points in time. After a savings plan expires, the discount provided by the savings plan is no longer available and the pay-as-you-go instances to which the savings plan was applied are billed at regular pay-as-you-go rates. The instances are not released, and your business is not affected.\nIf your account has overdue payments, Partial Upfront or No Upfront savings plans are suspended. After a savings plan is suspended due to an overdue payment, the savings plan cannot be applied to offset the fees for pay-as-you-go resources starting from the next hour of the suspension. After you complete the overdue payment, the savings plan resumes.\nIf a savings plan is suspended multiple times or for an extended period of time due to overdue payments, you may be unable to use the No Upfront payment option. To prevent this issue, make sure that your account balance is sufficient.\nAfter a savings plan is suspended due to an overdue payment, you are still billed for the hourly spend commitment.\n\nView the billing details of savings plans on the Bill Details page in the Expenses and Costs console.\nLog on to the Expenses and Costs console. In the left-side navigation pane, choose Bills > Bill Details.\nClick the Billing Details tab. On the Billing Details tab, set the Product Details parameter to Saving Plan, configure other parameters, and then click Search to search for the billing details of savings plans. Export the billing details. For more information, see How to query savings plan bills.\nBy default, the bills of the logon account are displayed. If you log on to the Expenses and Costs console by using a main financial account, you can also specify a linked financial account or a linked account to view the bills of the specified account.\nTo request a refund for a savings plan that you no longer require, submit a ticket.\nBefore a savings plan expires, you can manually renew or enable auto-renewal for the savings plan to extend the duration of the savings plan. You can renew a savings plan on the Overview tab of Savings Plan page in the Expenses and Costs console. You can also manually renew or enable auto-renewal for a savings plan on the Renewal page in the Expenses and Costs console.\nThe renewal duration must be the same as the purchase duration of the savings plan that you want to renew. For example, if the duration of a savings plan is one year, you can renew the savings plan for only one year.\nTo maximize cost savings, we recommend that you monitor the usage of savings plans and adjust savings plan configurations at the earliest opportunity based on your business requirements. Alibaba Cloud provides a utilization report and a coverage report for your savings plans. You can optimize the usage of savings plans based on the reports by following the suggestions in the View and optimize the usage of savings plans topic or the recommendations on the Recommended page in the Expenses and Costs console.\nFor the answers to the frequently asked questions that you have when you use savings plans, see FAQ about billing."
    },
    "91": {
        "title": "Elastic Compute Service:Resource assurance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/resource-assurance-bill",
        "content": "This Product\nElastic Compute Service:Resource assurance\nResource Assurance helps you query, reserve, purchase, and use resources. Resource Assurance provides you with real-time insights into resource provision and allows you to make resource reservations and plans by using private pools. This topic describes the billing methods of resource assurances and provides examples on how resource assurances are billed.\nYou can purchase elasticity assurances, immediate capacity reservations, or scheduled capacity reservations to reserve resources that match specific attributes in private pools for different scenarios. For more information, see Overview.\nThe following table describes the billing methods that are supported by resource assurances.\nReservation type\nBilling method\nDescription\nReferences\nImmediate or Scheduled Elasticity Assurance\nElasticity Assurance\nPurchased elasticity assurances cannot be released manually. You are charged the following fees for an elasticity assurance:\nAssurance fee. This fee is charged when you purchase an elasticity assurance. An elasticity assurance reserves resources in a private pool. During the term of the elasticity assurance, you can create pay-as-you-go instances from the reserved resources (reserved capacity) in the private pool at any time.\nInstance fees. You are charged for the pay-as-you-go instances that are created in the reserved capacity on an hourly basis.\nYou can also apply existing savings plans or regional reserved instances that have matching attributes to offset pay-as-you-go instance fees.\nOverview of Elasticity Assurance\nImmediate Capacity Reservation\nImmediate Capacity Reservation\nAn immediate capacity reservation is billed at the pay-as-you-go rate of the specified instance type regardless of whether you create pay-as-you-go instances in the reserved capacity. Billing starts when the capacity reservation is created, and continues until the capacity reservation is manually released or automatically released on expiration.\nBefore you use an immediate capacity reservation to create pay-as-you-go instances, you are charged only for the reserved capacity of the specified instance type. After you use an immediate capacity reservation to create pay-as-you-go instances, you are charged based on the instance configurations, including computing resources, disks, and public bandwidth.\nAfter a private pool is configured for a purchased instance, the fees for the storage capacity of the instance immediately start being deducted by the fees of the compute resources (vCPU and memory capacity). For more information, see Configure a private pool for existing instances.\nOverview of Immediate Capacity Reservation\nScheduled Capacity Reservation\nCapacity Reservation with Savings Plan\nWhen you purchase a capacity reservation with Savings Plan, you can select only the No Upfront payment option for the savings plan. No upfront payment is required.\nWhen you use a capacity reservation with Savings Plan to create pay-as-you-go instances:\nYou are charged for the No Upfront savings plan.\nThe savings plan is applied to reduce your bills for the pay-as-you-go instances and the unused reserved capacity.\nIf the pay-as-you-go instances include non-computing resources such as system disks and public bandwidth, the savings plan is applied only to the computing resources (vCPUs and memory) of the instances and cannot be applied to other resources. You are charged for the other resources based on the actual rates.\nOverview of Scheduled Capacity Reservation\nCapacity Reservation for Subscription Resources\nWhen you purchase a capacity reservation for subscription resources, you do not need to pay upfront.\nWhen you use a capacity reservation for subscription resources:\nFor unused reserved capacity, you are charged only at the pay-as-you-go rate of the instance type.\nWhen you create subscription instances in the reserved capacity of the capacity reservation, you are charged subscription instance fees.\nOverview of Scheduled Capacity Reservation\nThis section provides examples on how elasticity assurances and capacity reservations are billed. The prices on this page are provided only for reference. The actual prices are displayed on the Pricing tab of the Elastic Compute Service (ECS) product page.\nScenario: You purchased an elasticity assurance for one instance and created an instance in the reserved capacity for a promotion event.\nAssurance fee for the elasticity assurance: USD 100\nTerm of the elasticity assurance: one month\nQuantity of instances: 1\nPay-as-you-go instance price: USD 10 per hour\nInstance usage (in hours): 6 hours\nBilled amount: Total fee = Assurance fee for the elasticity assurance + Fee for pay-as-you-go resources\nAssurance fee for the elasticity assurance: USD 100\nFee for pay-as-you-go resources: USD 10 per hour \u00d7 6 hours = USD 60\nTotal fee: USD 100 + USD 60 = USD 160\nDuring the term of an elasticity assurance, you can infinitely create or release pay-as-you-go instances in the reserved capacity.\nElasticity assurances are automatically released when they expire, but instances that are created in the reserved capacity are not released.\nThe instances continue to work as expected and are billed at pay-as-you-go rates.\nScenario: You purchased an immediate capacity reservation for two instances. The capacity reservation was provisioned for 4 hours. You created Instance A in the reserved capacity, used the instance for 3 hours, and then released the instance. Then, you created Instance B in the reserved capacity, used the instance for 1 hour, and then released the instance.\nPay-as-you-go instance price: USD 10 per hour\nTerm of the immediate capacity reservation: 4 hours\nUsage of Instance A (in hours): 3 hours\nUsage of Instance B (in hours): 1 hour\nBilled amount: Total fee = Fee for the immediate capacity reservation + Fee for pay-as-you-go resources\nFee for the immediate capacity reservation = Fee for unused reserved capacity + Fee for used reserved capacity. You are not charged for the used reserved capacity.\nFee for the pay-as-you-go resources of Instance A: USD 10 per hour \u00d7 3 hours = USD 30\nFee for unused reserved capacity for Instance A: USD 10 per hour \u00d7 1 hour = USD 10\nFee for the pay-as-you-go resources of Instance B: USD 10 per hour \u00d7 1 hour = USD 10\nFee for unused reserved capacity for Instance B: USD 10 per hour \u00d7 3 hours = USD 30\nFee for the immediate capacity reservation = USD 10 + USD 30 = USD 40\nFee for pay-as-you-go resources: USD 30 + USD 10 = USD 40\nTotal fee: USD 40 + USD 40 = USD 80\nScenario: You purchased a capacity reservation with Savings Plan for one instance and created a pay-as-you-go instance in the reserved capacity.\nFee for the No Upfront savings plan: USD 1,000\nFee for data disks: USD 500\nBilled amount: Total fee = Fee for the No Upfront savings plan + Fee for resource usage that is not covered by the savings plan\nFee for the No Upfront savings plan: USD 1,000\nFee for resource usage that is not covered by the savings plan: USD 500\nTotal fee: USD 1,000 + USD 500 = USD 1,500\nThe effective time of the capacity reservation with Savings Plan must be at least three days later than the creation time and can be up to one year later than the creation time.\nThe savings plan can be applied to reduce bills for the unused reserved capacity and the created pay-as-you-go instance.\nIf you release the capacity reservation before the savings plan expires, you can continue to apply the savings plan to eligible pay-as-you-go instances or immediate capacity reservations.\nScenario: You purchased a 7-day capacity reservation for subscription resources for 10 instances and created eight subscription instances in the reserved capacity.\nPay-as-you-go instance price: USD 10 per hour\nSubscription instance price: USD 4,800 per month\nUsage of the instances: 1 month\nTerm of the capacity reservation for subscription resources: seven days\nBilled amount: Total fee = Fee for the capacity reservation for subscription resources + Fee for subscription resources\nFee for the capacity reservation for subscription resources: (10 - 8) \u00d7 7 \u00d7 24 hours \u00d7 USD 10 per hour = USD 3,360\nFee for subscription resources: USD 4,800 per month \u00d7 8 \u00d7 1 month = USD 38,400\nTotal fee: USD 3,360 + USD 38,400 = USD 41,760\nYou cannot cancel effective capacity reservations for subscription resources.\nIf you create subscription instances only in a part of the reserved capacity during the term of the capacity reservation for subscription resources, you are charge for the unused reserved capacity at the pay-as-you-go rate. You are not charged for the used reserved capacity.\nScenario: You cannot purchase a subscription instance due to insufficient inventory of the specified instance type, and then you created an authorized pending order.\nSubscription price: USD 100 per month\nSubscription period: 2 months\nBilled amount: Fee for subscription resources = Subscription price \u00d7 Subscription period = USD 100 per month \u00d7 2 months = USD 200. The authorized pending order is free of charge.\nYou are not charged additional fees for the authorized pending order. You are charged for the purchased resources when the authorized pending order is fulfilled. Maintain a sufficient balance in your Alibaba Cloud account to ensure that Alibaba Cloud can place an order on your behalf.\nPurchase a resource reservation\nUse a private pool to create instances\n"
    },
    "92": {
        "title": "Elastic Compute Service:SCUs",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/billing-methods-storage-capacity-units",
        "content": "This Product\nElastic Compute Service:SCUs\nStorage capacity units (SCUs) are subscription storage resource plans that can be used to offset capacity fees for various storage resources, such as cloud disks, snapshots, and Object Storage Service (OSS) resources. This topic describes the billing methods, offset rules, and refund rules of SCUs.\nSCUs use the subscription billing method and are billed based on their capacity and validity periods. SCUs support only the All Upfront payment option. You must make a full payment at purchase. The following formula is used to calculate the amount that you need to pay upfront for an SCU:\nAmount = SCU price \u00d7 Validity period\nSCU price: Go to the Pricing tab of the Elastic Compute Service product page to view the SCU price schedule.\nValidity period: You select a period of one month, two months, three months, six months, one year, three years, or five years as the validity period for an SCU. You can receive some discounts for SCUs with a validity period of one or more years.\nFor example, to purchase a 2-month, 100 GB SCU in the China (Beijing) region at a price of USD 23 per month, you must pay USD 46 upfront, which is calculated by using the following formula: Amount = USD 23 per month \u00d7 2 months = USD 46.\nFor information about how to purchase an SCU, see Purchase an SCU.\nAfter you purchase an SCU in a region, the SCU is automatically applied to offset pay-as-you-go fees for eligible cloud disks and snapshots in the region. If the capacity of the cloud disks and snapshots exceeds the capacity of the SCU, you are charged for the overage at the pay-as-you-go rates.\nThe following table describes the deduction factors that apply when SCUs are used to offset storage fees for different categories of cloud disks and snapshots in the China (Beijing) region. You can go to the Pricing tab of the Elastic Compute Service product page to view the deduction factors for other Alibaba Cloud storage services and in other regions.\nCategory\nDeduction factor\nDescription\nBasic disk\n1\nEach GiB of basic disk capacity consumes 1 GB of SCU capacity.\nUltra disk\n1\nEach GiB of ultra disk capacity consumes 1 GB of SCU capacity.\nStandard SSD\n1\nEach GiB of standard SSD capacity consumes 1 GB of SCU capacity.\nPL0 Enterprise SSD (ESSD)\n0.5\nEach GiB of PL0 ESSD capacity consumes 0.5 GB of SCU capacity.\nPL1 ESSD\n1\nEach GiB of PL1 ESSD capacity consumes 1 GB of SCU capacity.\nPL2 ESSD\n2\nEach GiB of PL2 ESSD capacity consumes 2 GB of SCU capacity.\nPL3 ESSD\n4\nEach GiB of PL3 ESSD capacity consumes 4 GB of SCU capacity.\nStandard snapshot\n0.08\nEach GB of standard snapshots consumes 0.08 GB of SCU capacity.\n\nCloud disks\nOnly SCUs can offset pay-as-you-go storage fees for cloud disks to reduce usage costs. Cloud disks are first matched to SCUs for fee offsets. The capacity of the cloud disks that is not covered by the SCUs is billed at pay-as-you-go rates. For more information about billing for cloud disks, see Block storage devices.\nSnapshots\nYou can use SCUs to offset pay-as-you-go storage fees for snapshots to reduce usage costs. Snapshots are first matched to SCUs for storage fee offsets. The capacity of the snapshots that is not covered by the SCUs is billed at pay-as-you-go rates. For more information about billing for snapshots, see Snapshots.\nExample 1: You have 10 TiB of PL1 ESSDs and a 10 TB SCU.\nThe PL1 ESSDs require 10 TB (= 10 TB \u00d7 1) of SCU capacity. The SCU can offset all pay-as-you-go fees for the PL1 ESSDs.\nExample 2: You have 10 TiB of PL0 ESSDs, 5 TiB of PL1 ESSDs, and a 10 TB SCU.\nThe ESSDs require 10 TB (= 10 TB \u00d7 0.5 + 5 TB \u00d7 1) of SCU capacity. The SCU can offset all pay-as-you-go fees for the ESSDs.\nExample 3: You have 1 TiB of PL3 ESSDs, 2 TiB of PL2 ESSDs, 2 TiB of PL1 ESSDs, and a 10 TB SCU.\nThe ESSDs require 10 TB (= 1 TB \u00d7 4 + 2 TB \u00d7 2 + 2 TB \u00d7 1) of SCU capacity. The SCU can offset all pay-as-you-go fees for the ESSDs.\nExample 4: You have 12 TiB of standard SSDs and a 10 TB SCU.\nThe standard SSDs require 12 TB (= 12 TB \u00d7 1) of SCU capacity. The SCU can offset the pay-as-you-go fees for 10 TiB of standard SSDs, and you are charged for the remaining 2 TiB of standard SSDs at the pay-as-you-go rate.\nAssume that in January 2022, you had 500 GB of snapshots and a 35 GB SCU.\nThe 35 GB SCU can offset storage fees for 437.5 GiB (= 35 GB/0.08) of snapshots.\nYou are charged for the remaining 62.5 GB (= 500 GB - 437.5 GB) of snapshots at the pay-as-you-go rate.\nAfter an SCU expires, you cannot use it to offset pay-as-you-go fees for storage resources. If you have no other SCUs in the same region as the expired SCU, the pay-as-you-go storage resources are billed on a pay-as-you-go basis.\nSCUs cannot be renewed or upgraded. You can purchase multiple SCUs based on your storage usage.\nIf an SCU cannot cover all the bills of pay-as-you-go storage resources, you can purchase more SCUs.\nIf an SCU is about to expire, you can purchase more SCUs and specify a time for them to take effect.\nPurchaseStorageCapacityUnit: purchases one or more SCUs.\nModifyStorageCapacityUnitAttribute: changes the name or modifies the description of an SCU.\nDescribeStorageCapacityUnits: queries the details of one or more SCUs, including the capacity and state of SCUs.\nRefer to FAQ about billing and find the answers to frequently asked questions about SCUs.\n"
    },
    "93": {
        "title": "Elastic Compute Service:Create a Linux instance on the Custom Launch tab in the ECS console and deploy Apache on the instance",
        "url": "https://www.alibabacloud.com/help/en/ecs/getting-started/create-and-manage-an-ecs-instance-by-using-the-ecs-console",
        "content": "This Product\nElastic Compute Service:Create a Linux instance on the Custom Launch tab in the ECS console and deploy Apache on the instance\nThis topic describes the main steps to create a Linux Elastic Compute Service (ECS) instance on the Custom Launch tab of the instance buy page in the ECS console and set up a web service on the instance. You can use this topic to get started with ECS.\nAn Alibaba Cloud account is created and real-name verification is completed for the account. For information about how to create an Alibaba Cloud account and complete real-name verification, see Create an Alibaba Cloud account and FAQ about real-name verification of Alibaba Cloud accounts.\nThe following diagram shows the basic resources that are required to create an ECS instance.\nRegion: Multiple Alibaba Cloud regions are available where you can create and deploy ECS instances. In most cases, we recommend that you choose a region in close proximity to your users to achieve lower network latency and higher access speed. For more information, see Regions and Zones.\nVirtual private cloud (VPC): A VPC is a virtual network dedicated to your Alibaba Cloud account, in which you can deploy ECS instances. VPCs are mutually isolated and cannot directly access each other. All ECS instances that are deployed in the same VPC can communicate with each other. For more information, see VPCs and vSwitches.\nvSwitch: A vSwitch is a basic network device in a VPC. For more information, see VPCs and vSwitches.\nInstance type: Different instance types offer different compute, memory, and storage capabilities and vary in terms of specifications, such as the CPU models, number of vCPUs, and memory size. For example, some instance types have 2 vCPUs and 4 GiB of memory. For information about the ECS instance families available for purchase, see Overview of instance families.\nImage: An image is a basic template for creating an ECS instance, containing an operating system. For more information, see Overview of images.\nStorage: System disks and data disks are attached to ECS instances to store images and business data. For more information, see Overview of Block Storage.\nPublic IP address: In this topic, you need to access the ECS instance by using a public IP address. Therefore, associate a public IP address with the instance.\nSecurity group: A security group serves as a virtual firewall that can control inbound and outbound traffic for ECS instances. For more information, see Overview of security groups.\nKey pair: You can bind an SSH key pair to an ECS instance and use the key pair to authenticate when you log on to the instance for O&M purposes. For more information, see Overview of SSH key pairs.\nThis section describes how to create an ECS instance that runs a Linux operating system on the Custom Launch tab of the instance buy page in the ECS console. For information about other methods of creating ECS instances, see Create instances.\nEntry point for instance creation: Go to the Custom Launch tab of the instance buy page in the ECS console. Perform the following steps to create or select the basic resources required to create an ECS instance. Configure the other parameters based on your business requirements. For more information, see Create an instance on the Custom Launch tab.\nSelect a billing method based on your business requirements. In this example, the pay-as-you-go billing method is selected, which offers greater flexibility in terms of instance usage. For more information, see Billing overview.\nSelect a region based on the network latency requirements of your business. To achieve low network latency and high access speed, we recommend that you select a region in close proximity to your users. In this example, the China (Hangzhou) region is selected.\n\nWhen you create a VPC, select the region in which you want to create an ECS instance and specify a CIDR block to associate with the VPC based on your business requirements. When you create a VPC, you must create a vSwitch for the VPC. In this example, a VPC and a vSwitch are created in the China (Hangzhou) region. After you create a VPC, go back to the Custom Launch tab of the instance buy page in the ECS console, refresh the VPC and vSwitch drop-down lists, and then select the VPC and vSwitch that you created.\nWhen you create a VPC, you can create a vSwitch at the same time.\n\n\n\nSelect an instance type and an image. The operating system version included in the image is installed on the instance during instance creation. In this example, the cost-effective ecs.e-c1m1.large instance type and the Alibaba Cloud Linux 3.2104 LTS 64-bit public image are selected.\nYou can use ECS Purchase Assistant or the Add to Comparison feature in the lower part of the Instance > All Instance Types tab in the Instances & Images section to select an instance type that best fits your business requirements.\n\nConfigure a system disk and data disks for the ECS instance based on your business requirements. This topic describes how to set up a simple web service on the ECS instance, which requires only a system disk to store the operating system of the instance without the need for data disks.\nSystem Disk: System disks are the boot disks of ECS instances and are used to store system-related data, such as operating systems and program files.\nData Disk: Data disks are used to store data that is not related to the system, such as user data, logs, and applications.\nFor more information about storage, see Overview of Block Storage.\n\nTo provide Internet connectivity to the ECS instance, select Assign Public IPv4 Address to assign a public IP address to the instance. Alternatively, associate an elastic IP address (EIP) with the ECS instance after the instance is created. For more information, see Associate an EIP with an ECS instance.\nIf you do not assign a public IP address to or associate an EIP with the ECS instance, you cannot access the instance over SSH or Remote Desktop Protocol (RDP) or test the web service that is deployed on the instance over the Internet.\nAfter you select Assign Public IPv4 Address, set Bandwidth Billing Method to specify a billing method for network usage. In this example, the Bandwidth Billing Method parameter is set to Pay-by-traffic (CDT). In the pay-by-traffic billing method, you are charged based on the amount of data transferred over the Internet. For more information, see Public bandwidth.\n\nCreate a security group for the ECS instance. A security group serves as a virtual firewall that can control inbound and outbound traffic for ECS instances. When you create a security group, open the following ports to allow access to the ECS instance:\nOpen IPv4 Ports/Protocols: select SSH (TCP:22), RDP (TCP:3389), HTTP (TCP:80), and HTTPS (TCP:443).\nIn the Open IPv4 Ports/Protocols section, select the ports that must be open for the applications that will run on the ECS instance.\nBy default, a rule that references 0.0.0.0/0 as a source address is created in the new security group. 0.0.0.0/0 represents all IP addresses. The rule allows access to the ECS instance from all IP addresses on the specified ports. After you create the instance, we recommend that you modify the rule to allow access to the instance from only specific IP addresses. For more information, see Modify a security group rule.\n\nYou can bind key pairs to ECS instances and use the key pairs as security credentials to authenticate your identity when you log on to the instances. After you create a key pair, download the private key of the key pair in order to subsequently connect to an ECS instance. After you create a key pair, go back to the Custom Launch tab of the instance buy page, refresh the Key Pair drop-down list, and select the key pair that you created.\nroot is the highest-privileged account in the operating system. If you select root as the logon username, this can create security risks. We recommend that you select ecs-user as the logon username.\nWhen the key pair is created, the private key of the key pair is automatically downloaded. Pay attention to the download records of your browser and save the private key file that is in the .pem format.\n\nAfter you create or select the required basic resources, read and select ECS Terms of Service, Product Terms of Service, and CDT Terms of Service (which is available if you set Bandwidth Billing Method to Pay-by-traffic (CDT). Then, click Create Order. In the Success message, click Console to view the created ECS instance on the Instance page. Make note of the following data for later use:\nInstance ID: You can search for the ECS instance by instance ID.\nRegion: You can search for the ECS instance in the region.\nPublic IP address: You can use the public IP address of the ECS instance to check whether a web service is deployed on the instance.\n\nAfter you create an ECS instance, you can use a connection tool to log on to the instance. Before you can use the instance, you must log on to the instance.\nOn the Instance page in the ECS console, find the ECS instance that you created based on the region and instance ID. In the Actions column, click Connect.\nIn the Remote connection dialog box, click Sign in now in the Workbench section.\nThis topic demonstrates only how to connect to an instance by using the Workbench tool. For more information about different ways and tools to connect to instances, see Methods for connecting to an ECS instance.\nIn the Instance Login dialog box, set Authentication to SSH Key Authentication, set Username to ecs-user, enter or upload the private key file that you downloaded when you created the key pair, and then click OK.\nThe private key file was automatically downloaded to your on-premises computer when you created the key pair. Check the download records of your browser to find the private key file in the .pem format.\n\nThe page shown in the following figure indicates that you are logged on to the ECS instance.\nAfter you are logged on to the ECS instance, you can use the ECS instance based on your business requirements. This section describes how to deploy Apache on the ECS instance and use a browser to access Apache on the instance.\nInstall Apache.\nRun the following command on the ECS instance to install Apache:\nIf Apache is installed, Complete! appears in the command output, as shown in the following figure.\nStart Apache. Run the following command on the ECS instance to start Apache. The command does not return an output.\nCheck whether Apache is started.\nRun the following command on the ECS instance:\nIf Apache is running, active (running) appears in the command output, as shown in the following figure.\nVerify the result. In the address bar of a browser on your on-premises computer, enter http://<Public IP address of the ECS instance> and press the Enter key to access Apache on the ECS instance. The page shown in the following figure indicates that Apache is deployed on the ECS instance.\nReplace <Public IP address of the ECS instance> with the public IP address that you recorded in the 8. Create and view an ECS instance section. If you cannot find the public IP address of the ECS instance in your records, go to the Instance page in the ECS console, find the instance based on its region and instance ID, and then view the public IP address of the instance. If you did not assign a public IPv4 address to the instance during instance creation, you can associate an EIP with the instance. For more information, see EIPs.\n\nThis topic describes only how to deploy a web service on an ECS instance and does not go into the procedure of building a website. For information about how to build a website on an ECS instance, see Build a website.\nIf you no longer require the ECS instance that you created, you can release the instance. After the ECS instance is released, billing for the instance stops, and data of the instance is lost and cannot be restored. Perform the following operations:\nGo to the Instance page in the ECS console, find the ECS instance based on its region and instance ID, and then click the  icon in the Actions column.\nChoose Instance Status > Release.\nIn the Release dialog box, set Release Mode to Release Now and click Next.\nConfirm the associated resources that you want to release, read the notes about the data risks, select \"I am aware of the instances and their associated resources to be released and understand the data risks\", and then click OK.\nWhen the ECS instance is released, the system disk of the instance is released. If a public IP address was assigned to the instance, the IP address is also released.\nWhen the ECS instance is released, the associated security group, vSwitch, and VPC are not released. You are not charged for the security group, vSwitch, or VPC. You can retain or release them based on your business requirements.\nIf an EIP is associated with the ECS instance, the EIP is retained when the instance is released. You are charged for the EIP. You can retain or release the EIP based on your business requirements. For information about the billing for EIPs, see Billing overview.\nYou can view the billing details of the ECS instance for a certain period of time. Billing details are updated with a one-day delay. Perform the following operations:\nGo to the Expenses and Costs console, choose Bills > Bill Details in the left-side navigation pane, and then click the Billing Details tab.\nSpecify the ID of the ECS instance as a filter condition and click Search to view the billing details of the ECS instance.\nYou can refer to the following topics to learn more about ECS.\nFor information about common operations on ECS resources, see Quick reference.\nFor information about how to programmatically integrate ECS, see Integration overview."
    },
    "94": {
        "title": "Elastic Compute Service:Create instances",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/creation-methods",
        "content": "This Product\nElastic Compute Service:Create instances\nThis topic describes several methods of creating Elastic Compute Service (ECS) instances and the use scenarios of each method. You can choose a method based on your business requirements.\nMethod\nScenario\n\nCreate a subscription instance on the Quick Launch tab\nCreate subscription instances with a few clicks. This method simplifies the instance creation process and allows you to create a subscription instance within minutes.\nCreate an instance on the Custom Launch tab\nCustomize instance configurations, such as the image type, instance type, storage, bandwidth, and security groups, based on your business requirements when you create an instance.\nCreate an instance by using a custom image\nIf you require an instance that has custom configurations such as a specific operating system and pre-installed applications, you can create a custom image that includes the configurations and use the custom image to quickly create an instance that meets your requirements.\nCreate an instance by using a community image\nYou can use a community image to quickly deploy instances whose operating systems, applications, and data suit your business needs.\nPurchase an instance that has the same configurations as an existing instance\nIf you need a new instance that has the same configuration as an existing instance, you can this method to quickly create an instance similar to the existing instance, improving the efficiency of horizontal scaling in specific scenarios.\nClone an instance\nThe instance cloning feature helps you quickly create instances that are the same as or similar to the source instances. The instance cloning feature can be used in scenarios such as replication and test environments, application extensions, disaster recovery, backup, migration, and upgrade. This feature can improve service reliability, scalability, and efficiency.\nCreate an instance by using a launch template\nA launch template contains the configuration information required to create an instance. You can use a launch template to create an instance with a few clicks.\nUse auto provisioning group-related API operations to batch create ECS instances\nIf you want to create a large number of pay-as-you-go instances, you can call API operations to batch create the instances in a more efficient manner.\n"
    },
    "95": {
        "title": "Elastic Compute Service:Create an empty data disk",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/create-a-disk",
        "content": "This Product\nElastic Compute Service:Create an empty data disk\nYou can create an empty subscription or pay-as-you-go data disk and attach the disk to an Elastic Compute Service (ECS) instance to increase the storage space of the instance. This topic describes how to create an empty data disk.\nThe following table describes the limits that are imposed on cloud disks that use different billing methods.\nCloud disk\nLimits\nPay-as-you-go disk\nFor information about the pay-as-you-go billing method, see Pay-as-you-go.\nSubscription cloud disk\nWhen you create a subscription disk, you must attach the disk to a subscription ECS instance. You cannot separately create subscription disks.\nYou cannot separately detach or release subscription disks. Subscription disks expire and are released together with the ECS instances to which the disks are attached. If you want to release a subscription disk, you can convert the disk into a pay-as-you-go disk and then detach and release the pay-as-you-go disk.\nYou cannot merge block storage devices after you create them. Block storage devices are independent of each other. You cannot merge the storage space of multiple block storage devices by formatting the devices. Before you create block storage devices, we recommend that you determine the required number and capacity of block storage devices based on your business requirements.\nYou can create system disks only together with ECS instances. You cannot separately create system disks.\nTo create an empty data disk on the cloud disk buy page, click Create Cloud Disk on the Cloud Disk tab of the Block Storage page or on the Block Storage tab of the Instance Details page of an ECS instance. Alternatively, click Add Data Disk in the Data Disk section on the instance buy page to create data disks together with ECS instances. This section describes how to create an empty data disk on the cloud disk buy page.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Storage & Snapshots > Block Storage.\nOn the Cloud Disk tab, click Create Cloud Disk.\nOn the cloud disk buy page, configure the parameters. The following table describes the parameters.\nParameter\nDescription\nAttach\nSpecify whether to attach the cloud disk to an ECS instance.\nNot Attach: creates a cloud disk without attaching the disk to an ECS instance.\nIf you select this option, you can create only pay-as-you-go cloud disks. If you create a cloud disk that is not a Regional Enterprise SSD (ESSD), you can attach the cloud disk only to an ECS instance that resides in the same zone. Proceed with caution when you configure the Region and Zone parameters.\nAttach to ECS Instance: creates a cloud disk and attaches the disk to a specific ECS instance. If the cloud disk is not a Regional ESSD, you can attach the disk only to an ECS instance that resides in the same zone. If the cloud disk is a Regional ESSD, you can attach the disk to an ECS instance in the same region regardless of the zone. For information about the limits of Regional ESSDs, see Limits.\nIf you select this option, you must select a region and then select an ECS instance from the ECS Instance drop-down list.\nBilling Method\nSpecify the billing method of the cloud disk.\nPay-as-you-go: A pay-as-you-go cloud disk can be attached to a subscription or pay-as-you-go ECS instance.\nSubscription: A subscription cloud disk can be attached only to a subscription ECS instance.\nCloud Disk\nSelect a disk category and specify the disk capacity.\nTake note of the following parameters:\nPerformance Level: You can specify performance levels only for ESSDs. You can select a performance level based on the capacity of the ESSD. The performance of an ESSD varies based on the capacity and performance level of the ESSD. For more information, see ESSDs.\nCreate from Snapshot: Select a snapshot to create cloud disks. The created cloud disks contain data from the selected snapshot. For more information, see Create a data disk from a snapshot.\nMulti-attach: You can select this option to enable the multi-attach feature for ESSD-series disks. This way, you can attach each ESSD-series disk to multiple ECS instances in the same zone. For more information, see Multi-attach for cloud disks.\nEncryption: Specify whether to encrypt the cloud disk. If you select this option, data stored on the created cloud disk is automatically encrypted. For more information, see Encrypt cloud disks.\nEnable Performance Provision and Enable Performance Burst: You can select these options to enable the performance provision and performance burst features when you create ESSD AutoPL disks. For more information, see ESSD AutoPL disks.\nRelease settings: If you set the Attach parameter to Attach to ECS Instance and the Billing Method parameter to Pay-as-you-go, you can select the release options to automatically release the created cloud disk when the associated ECS instance is released and automatically delete the automatic snapshots of the created cloud disk when the disk is released.\nConfirm the configurations and fees and then follow the on-screen instructions to create the cloud disk.\nAfter a cloud disk is created, you can view the disk on the Cloud Disk tab. The cloud disk cannot be directly used on ECS instances.\nPerform operations on the cloud disk.\nTo use the created cloud disk, you must attach or initialize the disk based on your business scenario.\nScenario\nWhat to do next\nYou set the Attach parameter to Attach to ECS Instance when you created the cloud disk.\nTo initialize the disk, perform the following operations:\nIf the disk is attached to a Linux ECS instance, perform the operations described in Initialize a data disk (Linux).\nIf the disk is attached to a Windows ECS instance, perform the operations described in Initialize a data disk on a Windows instance.\nYou set the Attach parameter to Not Attach when you created the cloud disk.\nTo attach and initialize the disk, perform the following steps:\nStep 1: Attach the disk to an ECS instance. For more information, see Attach a data disk.\nStep 2: Initialize the disk.\nIf the disk is attached to a Linux ECS instance, perform the operations described in Initialize a data disk (Linux).\nIf the disk is attached to a Windows ECS instance, perform the operations described in Initialize a data disk on a Windows instance.\nYou can call the CreateDisk operation to create a data disk.\nYou can call the DescribeDisks operation to query the information of disks that you created.\n"
    },
    "96": {
        "title": "Elastic Compute Service:Create a snapshot for a cloud disk to back up disk data",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/create-a-snapshot-for-a-disk",
        "content": "This Product\nElastic Compute Service:Create a snapshot for a cloud disk to back up disk data\nBefore you perform operations, such as rolling back cloud disks, modifying critical system files, and replacing operating systems, we recommend that you create snapshots for system disks or data disks to back up data. If issues or data loss occurs, you can use the snapshots to restore data and ensure service continuity. This topic describes how to create a snapshot for a cloud disk.\nElastic Compute Service (ECS) Snapshot is activated. For more information, see Activate ECS Snapshot.\nThe cloud disk for which you want to create a snapshot is in the In Use or Unattached state. Take note of the following items:\nIf the disk is in the In Use state, make sure that the ECS instance to which the disk is attached is in the Running or Stopped state.\nIf the disk is in the Unattached state, make sure that the disk was attached to an ECS instance at least once. Snapshots cannot be created for disks that were not attached to an ECS instance at least once.\nWhen you create a snapshot for a cloud disk, take note of the following items:\nDo not perform operations that change the status of the associated ECS instance, such as stopping or restarting the instance. Otherwise, snapshot creation fails.\nWe recommend that you create snapshots during off-peak hours because snapshot creation degrades disk I/O performance by up to 10% and slows down data reads and writes.\nIf operations are performed on the disk and incremental data is generated while a snapshot is being created, the incremental data is not included in the snapshot.\nYou cannot resize the cloud disk when a snapshot is being created for the disk. Wait until the snapshot is created before you resize the cloud disk.\nAfter you create snapshots, you are charged snapshot storage fees per region based on the total size of the snapshots stored in the region. For more information, see Snapshots.\nWhen you use a cloud disk to create a dynamic extended volume or a RAID array, we recommend that you create a snapshot-consistent group and enable the application-consistent snapshot feature to ensure a consistent write order and crash consistency of data. For more information, see Create a snapshot-consistent group and Create application-consistent snapshots.\nThis section describes how to create a snapshot for a cloud disk on the Snapshots page in the ECS console. You can also create a snapshot for a cloud disk on the Block Storage page.\nGo to the Snapshots page.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Storage & Snapshots > Snapshots.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nOn the Disk Snapshots tab, click Create Disk Snapshot.\nIn the Create Snapshot dialog box, configure the parameters. The following table describes the parameters.\nParameter\nDescription\nResource Type\nValid values: Instance and Cloud Disk. Default value: Cloud Disk. If you set the Resource Type parameter to Cloud Disk, select a cloud disk for which you want to create a snapshot.\nIf you set the Resource Type parameter to Instance, select one or more ECS instances for which you want to create a snapshot-consistent group. Then, select the cloud disks for which you want to create snapshots from the ECS instances to ensure data consistency for the disks. For more information, see Create a snapshot-consistent group.\nDisk\nThe cloud disk for which you want to create a snapshot. You can select a system disk or a data disk.\nSnapshot Name\nThe name of the snapshot.\nRetention Period\nThe number of days for which you want to retain the snapshot. Valid values: Permanently (Until Deleted) and Retained for.\nPermanently (Until Deleted): The snapshot does not expire. After the maximum number of snapshots is reached, new snapshots cannot be created. To prevent unnecessary snapshot costs, you can delete snapshots based on your business requirements. For information about how to delete a snapshot, see Delete a snapshot.\nRetained for: After the retention period of the snapshot ends, the snapshot expires and is automatically deleted.\nIf the remaining retention period of a snapshot is a few days, such as three days, Released After {days} Days appears in the Retention Period column corresponding to the snapshot on the Disk Snapshots tab. You can extend the retention period of a snapshot before the snapshot expires. For more information, see Extend the retention period of a snapshot.\nAdvanced Settings\nInstant Access\nBy default, the instant access feature is enabled for Enterprise SSD (ESSD) series disks (ESSDs, ESSD AutoPL disks, ESSD Entry disks, and Regional ESSDs). Cloud disks of other categories do not support this parameter. For more information, see Use the instant access feature.\nTag\nThe tag key-value pairs that you want to add to the snapshot to facilitate management.\nResource Group\nThe resource group to which you want to assign the snapshot. You can use resource groups to manage snapshots at different levels.\nClick OK.\n(Optional) View the creation progress of the snapshot on the Disk Snapshots tab.\n\nAfter you create the snapshot, the snapshot is automatically stored in an Object Storage Service (OSS) bucket. For more information, see Overview.\nView the upload progress of the snapshot to OSS in the Progress column. When you move your pointer over Progress of Upload to OSS: xx%, the estimated remaining amount of time required to upload the snapshot is displayed.\nThe estimated remaining amount of time required to upload a snapshot to OSS dynamically varies in real time based on multiple factors, including the size of the snapshot and the number and size of snapshots that are being created by other users.\nA longer period of time is required to upload a larger snapshot to OSS.\nThe first snapshot of a cloud disk is a full snapshot. An extended period of time is required to create the first snapshot. Subsequent snapshots are incremental snapshots and do not require the same amount of time to be created as the first snapshot. The amount of time required to create an incremental snapshot varies based on the amount of data changed since the previous snapshot.\nThe peak periods of creating automatic snapshots are the early morning hours. The number and size of uploaded snapshots increase during peak periods, and the bandwidth that is allocated to each snapshot may decrease. The initial estimated amount of time required to upload each snapshot may increase. The number of snapshots that are being uploaded decreases over time. In this case, more bandwidth can be allocated to each snapshot, the transfer speed increases, and the estimated remaining amount of time required to upload each snapshot is reduced. To accelerate uploads, we recommend that you do not create manual snapshots during the peak periods.\nIf Progress of Upload to OSS: 100% is displayed, the snapshot is uploaded to OSS.\nYou can call the following API operations:\nCreateSnapshot: creates a snapshot.\nDescribeSnapshots: queries the details of cloud disk snapshots.\nDeleteSnapshot: deletes a snapshot.\nAfter you create a snapshot for a cloud disk, you can perform the following operations:\nIf data loss occurs due to accidental operations and ransomware, use the snapshot to roll back the cloud disk to the state when the snapshot was created. For more information, see Roll back a disk by using a snapshot.\nCreate a cloud disk from the snapshot. The data stored on the new disk is the same as the data stored on the source disk when the snapshot was created. This allows you to quickly replicate cloud disks. For more information, see Create a disk from a snapshot.\nCreate a custom image based on the snapshot and use the custom image to create ECS instances that have identical system environments. For more information, see Create a custom image from a snapshot.\nTo prevent unnecessary snapshot costs, periodically delete snapshots that you no longer require. For information about how to delete a snapshot, see Delete a snapshot.\n"
    },
    "97": {
        "title": "Elastic Compute Service:Create a custom image from an instance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/create-a-custom-image-from-an-instance",
        "content": "This Product\nElastic Compute Service:Create a custom image from an instance\nAfter you create an Elastic Compute Service (ECS) instance, you can customize the instance by performing operations, such as installing software and deploying application environments, based on your business requirements and then create a custom image from the instance. Instances created from the custom image contain all of the customized items, which eliminates the need to configure these items for each new instance. This topic describes how to create a custom image from an existing instance.\nAn ECS instance is created. For information about how to create an ECS instance, see Create an instance on the Custom Launch tab.\nSensitive data is deleted from the instance to enhance data security.\nBefore you create a custom image from a Linux instance, the following items are checked:\nNetwork configurations of the instance. If network errors occur, troubleshoot the errors by performing the operations that are described in How to solve unreachable network errors when a VPC-type instance is created from a custom image.\nFree space on the system disk. The system disk must have sufficient free space.\nWhen you create a custom image from an instance, a snapshot is automatically created for each disk on the instance. All the snapshots together constitute a complete custom image, as shown in the following figure.\nIf the instance has data disks, the custom image contains the snapshots of both the system disk and data disks of the instance.\n\nBefore you create a custom image from an instance, take note of the items that are described in the following table.\nItem\nDescription\nRegion\nA custom image resides in the same region as the instance from which the image was created. For information about how to use images across regions, see Copy an image.\nBilling\nA snapshot is automatically generated for each disk when you create a custom image. You are charged for the snapshots. For information about the billing of snapshots, see Snapshots.\nCustom images are billed independently of the ECS instances that were used to create the images or created from the images. For example, custom images created from subscription instances can be used to create pay-as-you-go instances.\nInstance type\nYou cannot create images that contain snapshots of system disks and data disks from instances that use local SSDs. For more information, see Instance families with local SSDs.\nInstance status\nWhen you create a custom image from an instance, you do not need to stop the instance.\nHowever, when you create a custom image from an instance that is in the Running state, real-time data may not be saved to the image. To ensure data integrity, we recommend that you stop the instance before you use it to create a custom image. If you do not want to stop your instance, you can create a snapshot-consistent group from the instance and then use the snapshot-consistent group to create a custom image. For more information, see Create a snapshot-consistent group.\nWhen a custom image is being created from an instance, do not change the status of the instance. For example, if you stop, start, or restart an instance while a custom image is being created from the instance, the image cannot be created.\nYou cannot create images from released instances. If you retained system disk snapshots of the instances, you can create custom images from the snapshots. For more information, see Create a custom image from a snapshot.\nLinux instance\nWhen you create a custom image from a Linux instance, take note the following additional items:\nDo not load data disk information to the /etc/fstab file. Otherwise, instances created from the image cannot be started.\nDo not update the kernel or operating system version.\nDo not adjust the system disk partitions. Only system disks with a single root partition are supported.\nDo not modify critical system files, such as /sbin, /bin, and /lib.\nDo not modify the logon username root.\nAmount of time required to create an image\nThe amount of time that is required to create an image from an instance depends on the disk size of the instance. Wait until the snapshot for each disk is created before you can use the image.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind the instance from which you want to create a custom image. Choose  > Disk and Image > Create Custom Image in the Actions column.\nIn the Create Custom Image dialog box, configure the parameters that are described in the following table.\nParameter\nDescription\nReferences\nImage Name\nEnter a name for the custom image.\nN/A\nImage Check\nOptional. The image check feature checks whether imported custom images are valid and whether the images can be used to create full-featured ECS instances.\nBy default, Check After Creation is selected, and the image check feature checks the custom image immediately after the image is created. After the image check is completed, you can view the check result in the Check Result column corresponding to the image on the Custom Images tab. If you need to repair an item, you can use the ACS-ECS-RepairImage public template of CloudOps Orchestration Service (OOS) or manually repair the item based on the solutions in the check result.\nOnly specific operating systems support the image check feature. For information about the operating systems that do not support the image check feature, see Operating system limits for image check.\nOverview of image check\nImage Family\nOptional. Select an image family for the custom image. Custom images that belong to an image family can be deprecated or restored to allow smooth image updates and rollbacks.\nOverview of image families\nImage Description\nOptional. Enter a description for the custom image.\nN/A\nTag\nSelect one or more tags.\nTag is an optional parameter in most scenarios.\nTag is a required parameter when you log on as a Resource Access Management (RAM) user and a policy attached to the RAM user requires that tags be added. In this case, if you do not specify the Tag parameter, an error that indicates insufficient permissions is reported.\nOverview of tags\nResource Group\nOptional. Select a resource group to manage the custom image based on usage and permissions.\nResource groups\nClick OK.\nYou can call an API operation to create a custom image or create a custom image from an ECS instance. For more information, see CreateImage or Create a custom image from an instance.\nAfter a custom image is created, you can use the custom image to perform the following operations:\nCreate an instance by using a custom image\nReplace the operating system (system disk) of an instance\nShared images\nCopy a custom image\nSpecific ECS instances that are created from a custom image and reside in virtual private clouds (VPCs) may not have network connectivity due to the configurations in the /etc/sysconfig/network file. For more information, see How to solve unreachable network errors when a VPC-type instance is created from a custom image.\n"
    },
    "98": {
        "title": "Elastic Compute Service:Manage security group rules",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/add-security-group-rules",
        "content": "This Product\nElastic Compute Service:Manage security group rules\nYou can use security group rules to manage inbound and outbound traffic of Elastic Compute Service (ECS) instances. Security group rules are suitable for various scenarios, such as to allow or deny specific network traffic, close unnecessary ports, restrict traffic of specific protocols, and configure access permissions on applications. This topic describes how to add, modify, query, delete, import, and export security group rules.\nBefore you manage security group rules, take note of the following items:\nYou can configure inbound rules for a security group to control traffic to ECS instances in the security group and outbound rules to control traffic from the instances. The rules of multiple security groups to which an ECS instance belongs are sorted in order. The security group rules are used to allow or reject the inbound or outbound network traffic of the ECS instance.\nFor more information about security group capabilities and usage suggestions, see Overview.\nIn addition to custom security group rules, security groups contain default access control rules that take effect but are invisible. For more information, see Basic security groups and advanced security groups.\nFor information about the composition of a security group rule and sorting policy of security group rules, see Security group rules.\nA security group can contain only a limited number of rules. We recommend that you add the minimum number of rules. For more information, see the Security group limits section in the \"Limits\" topic.\nIf your ECS instance needs to provide external services, you can add inbound security group rules that allow inbound access.\nWhen your ECS instance is under attacks, you can add inbound security group rules to deny inbound access.\nIf you want the ECS instance to actively connect to external networks, you must determine whether to add outbound security group rules that allow outbound access based on the security group type and internal connectivity policy.\nIf you no longer want to control outbound or inbound traffic, you can delete security group rules in the corresponding direction.\nIf you want to quickly copy rules in a security group to other security groups, you can export and import security group rules. For more information, see the Import and export security group rules section of this topic.\nFor information about more scenarios for which security groups are suitable, see Security groups for different use cases.\nA security group rule is defined by attributes such as the action, priority, protocol type, port range, and authorization object. If traffic matches the authorization object, port range, and protocol type of a security group rule, the traffic matches the security group rule. Then, the system determines whether the traffic is allowed based on the priority and action defined in the security group rule. If traffic does not match a security group rule, the default security group rule is used.\nAuthorization object: the source of traffic for inbound rules or the destination of traffic for outbound rules. You can configure multiple IP addresses, security groups, and prefix lists.\nIf you specify security groups and prefix lists as authorization objects in a security group rule, the security group rule takes effect on all IP addresses in the specified security groups and prefix lists.\nIf you want to allow resources in different security groups to communicate with each other, you must configure security group rules to allow mutual access between the security groups. To allow access over the internal network, you must specify security groups as authorization objects, instead of CIDR blocks.\nBy default, no inbound security group rules allow access to the internal network for ECS instances that reside in the classic network. For security reasons, we recommend that you do not enable access based on CIDR blocks.\nPort range: the ports used to match traffic. For more information, see Common ports.\nProtocol type: the protocol type of traffic.\nTCP is mainly suitable for applications that require high reliability, such as web browsing, e-mail transmission, remote logon, and file uploading and downloading.\nUDP is mainly suitable for applications that have higher requirements for speed than for accuracy, such as online games and video conferencing.\nInternet Control Message Protocol (ICMP) is mainly used to transmit control information between network devices in scenarios, such as the use of ping commands and transmission of error reports and diagnostic information.\nGeneric Routing Encapsulation (GRE) is mainly suitable for applications that require high security and whose data is transmitted across different networks, such as IP over IP.\nPriority: the priority of the matching traffic. A value of 1 indicates the highest priority.\nFor rules that have different priorities, traffic is matched against the rule that has a higher priority. If the rule that has a higher priority matches the traffic, the action specified in the rule is executed on the traffic, and the rule that has a lower priority is not applied to the traffic.\nFor rules that have the same priority but different actions, the deny rule is applied. If the deny rule does not match traffic, the allow rule is applied.\nAction: specifies whether to allow or reject traffic.\nMake sure that the applications corresponding to the ports specified in a security group rule are started and the ports are configured to listen on 0.0.0.0. For information about how to view the current port status, see the Check the status of the service and the listening status of the port of the service section of the \"What do I do if I cannot access a service deployed on an instance?\" topic.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Security Groups.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nOn the security group list page, find the security group that you want to manage and click Manage Rules in the Operation column.\nMethod 1: Quickly add a security group rule\nThis method is suitable for configuring common TCP rules. Click Quick Add. In the Quick Add dialog box, configure Action and Authorization Object and select one or more ports.\n\nIf the port range in the Quick Add dialog box does not include the ports that you want to allow or deny, you can select a port to create a security group rule and modify the port range of the rule. You can also use Method 2: Manually add a security group rule to specify the required ports.\nMethod 2: Manually add a security group rule\nConfigure parameters such as Action, Priority, Protocol Type, Port Range, and Authorization Object to add a security group rule. Perform the following steps:\nClick Add Rule.\nIn the rule list, configure the new security group rule and click Save in the Actions column.\nFor information about how to configure a security group rule, Security group rules.\n\nYou can use quintuple rules to control the inbound and outbound traffic of ECS instances. A quintuple rule includes the source IP address, source port, destination IP address, destination port, and protocol type. Quintuple rules are fully compatible with existing security group rules. You can call API operations to configure security group quintuple rules. For more information, see the Security group trituple and quintuple rules section of the \"Security group rules\" topic.\nCall the AuthorizeSecurityGroup operation to add an inbound security group rule.\nCall the AuthorizeSecurityGroupEgress operation to add an outbound security group rule.\nAfter you modify security group rules, the new security group rules immediately take effect. You may need to monitor network traffic and network connections to ensure that the modified security group rules meet your business requirements and help ensure network security. For more information, see What is CloudMonitor?\nIn the left-side navigation pane, choose Network & Security > Security Groups. On the security group list page, find the security group whose security group rules you want to modify and click Manage Rules in the Operation column.\nFind the security group rule that you want to modify and click Edit in the Actions column. Modify the rule and click Save.\nCall the ModifySecurityGroupRule operation to modify an inbound security group rule.\nCall the ModifySecurityGroupEgressRule operation to modify an outbound security group rule.\nYou can perform health checks on security groups to identify redundant rules. This helps simplify security group configurations, reduce administrative workloads, facilitate network management, and mitigate risks posed by security vulnerabilities.\nMethod 1: View the rules of a single security group\nIn the left-side navigation pane, choose Network & Security > Security Groups. On the security group list page, find the security group whose security group rules you want to view and click Manage Rules in the Operation column.\nClick the Inbound or Outbound tab based on the type of rule that you want to view.\nIn the search box above the rule list, enter ports or authorization objects to search for security group rules.\nMethod 1: View all rules in multiple security groups to which an ECS instance is added\nIn the left-side navigation pane, choose Instances & Images > Instances. Find the instance on which you want to view security group rules and click the instance ID to go to the instance details page.\nOn the Security Groups tab, view all security groups to which the instance is added.\nClick Manage Rules in the Operation column that corresponds to each security group to view rules in all security groups.\nCall the DescribeSecurityGroupAttribute operation to query one or more security group rules.\nBefore you delete security group rules, make sure that you understand the impacts of this deletion operation to prevent unnecessary network security issues caused by accidental deletions of security group rules. If you want to use a deleted security group rule, create an identical rule.\nIn the left-side navigation pane, choose Network & Security > Security Groups. On the security group list page, find the security group whose security group rules you want to delete and click Manage Rules in the Operation column.\nFind the security group rule that you want to delete and click Delete in the Actions column.\nIn the Delete Security Group Rule message, confirm that the rule information is correct and click OK.\nCall the RevokeSecurityGroup operation to delete one or more inbound security group rules.\nCall the RevokeSecurityGroupEgress operation to delete one or more outbound security group rules.\nYou can perform a health check on a security group to identify redundant rules in the security group. If rule A has a lower priority than rule B and rule B contains all conditions of rule A, rule A is considered to be a redundant rule. If a redundant rule exists, we recommend that you delete the rule to prevent the number of rules from reaching the upper limit.\nEach security group can contain a limited number of rules, and each elastic network interface (ENI) on an ECS instance can be associated with a limited number of security group rules. For more information about the limits and quotas of security group rules, see the Security group limits section in the \"Limits\" topic.\nIn the left-side navigation pane, choose Network & Security > Security Groups. On the security group list page, find the security group whose security group rules you want to query and click Manage Rules in the Operation column.\nIn the Access Rule section, click .\nIn the Health Check dialog box, check whether redundant rules exist.\nThe following figure shows that the security group contains two duplicate rules.\nSelect the redundant rules and click OK to delete the rules.\nThe ECS console allows you to export and import security group rules. This feature is suitable for scenarios such as backup, restoration, and migration of security group rules.\nBefore you import security group rules, make sure that the following limits are met to prevent an import failure:\nThe priority of a security group rule ranges from 1 to 100. If the priority of a security group rule is greater than 100, you must delete the rule from the rules that you want to import, import the remaining rules, and then create the deleted rule in the ECS console.\nYou can export security group rules as JSON or CSV files in the ECS console to your computer for backup. Make sure that the file format is correct and the files follow the naming conventions of Alibaba Cloud security group rule files.\nWe recommend that you import no more than 200 rules at a time.\nWhen you import rules across regions, the authorization objects in security group rules cannot be security groups or prefix lists.\nIn the left-side navigation pane, choose Network & Security > Security Groups. On the security group list page, find the security group whose security group rules you want to export and click Manage Rules in the Operation column.\nIn the Access Rule section, import or export security group rules.\nImport security group rules\nClick . In the Import Security Group Rule dialog box, click Select a file, and then select the JSON or CSV file that you want to import. Then, click Start.\nIf a security group rule fails the import check, you can move the pointer over the Warning icon to view the details of the failure.\nExport security group rules\nClick  and select a file format to export the security group rules as a file in the selected format to your computer.\nJSON format\nThe exported JSON file complies with the following naming convention: ecs_${regionID}_${groupID}.json.\nIf regionID is cn-qingdao and groupID is sg-123, the name of the exported JSON file is ecs_cn-qingdao_sg-123.json.\nCSV format\nThe exported CSV file complies the following naming convention: ecs_sgRule_${groupID}_${regionID}_${time}.csv.\nIf regionID is cn-qingdao, groupID is sg-123, and time is 2020-01-20, the name of the exported CSV file is ecs_sgRule_sg-123_cn-qingdao_2020-01-20.csv.\nFor information about security group configurations, security group rules, host penalties and unblocking procedures, and resource quota management, see Security FAQ.\nFor information about how to configure the Protocol Type and Port Range parameters, see Common ports and Change the default port used by an instance to accept connections.\nYou can add cloud resources, such as ECS instances or ENIs, to a new security group. For more information, see Manage ECS instances in security groups and Manage ENIs in security groups.\nFor information about how to modify the internal access control policy of a security group, see Modify the internal access control policy of a basic security group.\nBest practices and use cases for configuring security group rules:\nSecurity groups for different use cases\nBest practices of the security group (inbound rules)\nBest practices for ECS security groups (security group authorization)\nBest practices for ECS security groups (security group settings)\nIf you enable a firewall for an ECS instance and configure security group rules to block external access, you may be unable to connect to the instance. Best practices for enabling and disabling the system firewall:\nManage the system firewall of a Windows instance\nEnable or disable the system firewall on a Linux ECS instance\nOther best practices:\nEnable or disable SELinux\nProhibit a RAM user from creating high-risk security group rules\nConnect ECS instances through an internal network\nBest practices for configuring internal network-based interconnection between instances that belong to different security groups in the classic network"
    },
    "99": {
        "title": "Elastic Compute Service:Create a command",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/create-a-command",
        "content": "This Product\nElastic Compute Service:Create a command\nYou can create Cloud Assistant commands to perform routine tasks on Elastic Compute Service (ECS) instances. These tasks include running automated O&M scripts, polling processes, resetting user passwords, installing or uninstalling software, updating applications, and installing patches. The Cloud Assistant commands can be batch or PowerShell commands for Windows instances and shell commands for Linux instances. You can specify custom parameters as variables in the Cloud Assistant commands.\nYou can retain 500 to 50,000 Cloud Assistant commands in an Alibaba Cloud region. This quota may increase based on your ECS usage. You can apply for a quota increase. For information about how to view and increase resource quotas, see Manage quotas. The commands that you create are counted against the Cloud Assistant command quota of your account.\nEnter a detailed reason for the quota increase application to increase the approval rate.\nThe maximum size of a Base64-encoded command script is 18 KB.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Maintenance & Monitoring > Cloud Assistant.\nIn the top navigation bar, select a region and resource group in which to create a Cloud Assistant command.\nAfter you select a resource group to which you want to add the command, you can manage permissions on the command at the resource group level. You can attach required Resource Access Management (RAM) policies to resource groups to manage permissions at the resource group level. For information about RAM policies and how to manage permissions at the resource group level, see the Cloud Assistant command-specific sample custom policies section of the \"Use RAM to implement permission control\" topic and Classify resources into resource groups and grant permissions on the resource groups.\n\nIn the upper-right corner, click Create/Run Command.\nIn the Command Information section of the Create Command panel, configure the parameters. The following table describes the parameters.\nParameter\nDescription\nCommand Source\nSelect a command source.\nEnter Command Content: Create a command.\nSelect Saved Command: Select an existing command.\nCommand Type\nSelect a command type.\nFor Linux instances, select Shell, Python, or Perl.\nFor Windows instances, select Bat or PowerShell.\nCommand content\nEnter or paste the command content.\nFor information about shell commands, see View the system configurations of ECS instances.\nWhen you create a command, make sure that the syntax, logic, and algorithm of the command are correct.\nFor example, to archive a file to the /backup directory (mkdir /backup) that you created on an instance, enter the following shell command:\nIn the preceding sample command, {{file}} is a custom parameter. When you run the command, you can set the custom parameter to the name of the file that you want to archive. Example: /app/usrcredential. You can use custom parameters in scenarios in which dynamic values and values that are shared across multiple commands are required. We recommend that you specify custom parameters for sensitive data or data that changes together with the environment, such as AccessKey pairs, instance IDs, authorization codes, time parameters, and critical system files.\nUse Parameters\nSpecify whether to use parameters.\nIf you turn on Use Parameters, specify custom parameters in the {{key}} format in the Command content field.\nYou can specify up to 20 custom parameters in a single Cloud Assistant command.\nYou can specify built-in environment parameters as custom parameters. When you run the command, the parameters are automatically specified by Cloud Assistant. You can specify the following built-in environment parameters:\n{{ACS::RegionId}}: the ID of the region.\n{{ACS::AccountId}}: the unique identifier (UID) of the Alibaba Cloud account.\n{{ACS::InstanceId}}: the ID of the instance.\nIf you want to run the command on multiple instances and specify the {{ACS::InstanceId}} parameter as a built-in environment parameter, make sure that the version of Cloud Assistant Agent is not earlier than the following versions. For more information, see Install Cloud Assistant Agent.\nLinux: 2.2.3.309\nWindows: 2.1.3.309\n{{ACS::InstanceName}}: the name of the instance.\nIf you want to run the command on multiple instances and specify the {{ACS::InstanceName}} parameter as a built-in environment parameter, make sure that the version of Cloud Assistant Agent is not earlier than the following versions. For more information, see Install Cloud Assistant Agent.\nLinux: 2.2.3.344\nWindows: 2.1.3.344\n{{ACS::InvokeId}}: the ID of the command task.\nIf you want to specify the {{ACS::InvokeId}} parameter as a built-in environment parameter, make sure that the version of Cloud Assistant Agent is not earlier than the following versions. For more information, see Install Cloud Assistant Agent.\nLinux: 2.2.3.309\nWindows: 2.1.3.309\n{{ACS::CommandId}}: the ID of the command.\nIf you want to specify the {{ACS::CommandId}} parameter as a built-in environment parameter when you call the RunCommand operation, make sure that the version of Cloud Assistant Agent is not earlier than the following versions. For more information, see Install Cloud Assistant Agent.\nLinux: 2.2.3.309\nWindows: 2.1.3.309\nExecution Plan\nSelect a command execution plan.\nImmediate execution: The command is immediately run after you click Run or Run and Save.\nAfter the next startup of the system: The command is run the next time the associated instances are started after you click Run or Run and Save.\nAfter each system startup: The command is run each time the associated instances are started after you click Run or Run and Save.\nRun on Schedule: The command is run at a specific interval, at a specific time, or on a schedule after you click Run or Run and Save. The following execution schedule options are available:\nRun at Fixed Interval: Use a rate expression to specify an interval at which you want to run the command. You can specify the interval in seconds, minutes, hours, or days. This option is suitable for scenarios in which you want to execute command execution tasks at a fixed interval.\nWhen you specify an interval, take note of the following limits:\nThe specified interval can range from 60 seconds to 7 days and must be longer than the timeout period of the scheduled task.\nThe interval is the amount of time that elapses between two consecutive executions. The interval is irrelevant to the amount of time that is required to run the command once. For example, you set the interval to 5 minutes, and the command requires 2 minutes to run once. Each time the command is run, the system waits for 3 minutes before it reruns the command.\nAfter you create a task, the task does not immediately run. For example, you set the interval to 5 minutes and create a task to run the command. The task runs 5 minutes after it is created.\nRun Only Once at Specified Time: Specify a point in time and a time zone to run the command only once.\nFor example, if you set the Execution time parameter to May 17, 2022, 17:30:50 and the Time Zone parameter to (GMT+08:00) Asia/Shanghai, the command was run only once at 17:30:50 on May 17, 2022 (UTC+8).\nRun on Clock-based Schedule Cron Expression: Use a cron expression to specify a schedule on which you want to run the command. Specify a schedule that is accurate to seconds, minutes, hours, day of the month, month, day of the week, or year, and select a time zone from the Time Zone drop-down list. The system calculates the schedule based on the cron expression and the time zone and runs the command as scheduled. This option provides flexibility and is suitable for scenarios in which you want to execute command tasks on a schedule. For more information about cron expressions, see Cron expressions.\nThe minimum interval must be 10 seconds or longer and cannot be shorter than the timeout period of scheduled executions.\nFor example, if you set the Execution Frequency parameter to 0 0 12 ? * WED 2022 and the Time Zone parameter to (GMT+08:00) Asia/Shanghai, the system runs the command at 12:00:00 every Wednesday in 2022 (UTC+8).\nCommand Name\nEnter a name for the command.\nCommand Description\nEnter a description for the command. We recommend that you enter identifiable information, such as the purpose of the command, to facilitate management and maintenance.\nUsername\nSpecify a username that you want to use to run the command on ECS instances.\nFor security reasons, we recommend that you run Cloud Assistant commands as a regular user based on the principle of least privilege. For more information, see Run Cloud Assistant commands as a regular user.\nBy default, Cloud Assistant commands are run by the root user on Linux instances and by the system user on Windows instances.\nExecution Path\nSpecify an execution path for the command. Different default execution paths are provided based on the operating system of instances on which the command is run.\nFor Linux instances, the default execution path is the /home directory of the root user.\nFor Windows instances, the default execution path is C:\\Windows\\system32.\nTimeout\nSpecify a timeout period for running the command on instances. If a task that runs the command times out, Cloud Assistant forcefully terminates the task process.\nUnit: seconds. Default value: 60. Minimum value: 10. If you set the Timeout parameter to a value that is smaller than 10, the system changes the value to 10 to ensure that the command can be run.\nTag\nSpecify a tag that you want to add to the command for subsequent classification and management. Tag key: the key of the tag. Tag value: the value of the tag.\nIf you select instances and click Run and Save, the system adds the tag to the command and the command execution task.\nIf you select instances and click Run, the system adds the tag only to the command.\nIn the Select Instance and Select Managed Instances sections, select the instances on which you want to run the command.\nA managed instance is an instance that is not provided by Alibaba Cloud but is managed by Cloud Assistant. For more information, see Alibaba Cloud managed instances.\nClick Save.\nCall the CreateCommand operation to create a Cloud Assistant command named update that is used to update the operating system of instances.\nThe values that are enclosed in single quotation marks ('') are sample values of the parameters. Specify the parameters based on actual conditions.\nThe following table describes the main parameters. For more information about the parameters, see CreateCommand.\nParameter\nExample\nDescription\nRegionId\ncn-hangzhou\nThe ID of the region in which you want to create the command.\nName\nupdate\nThe name of the command.\nType\nRunShellScript\nThe type of the command.\nFor Linux instances, set this parameter to RunShellScript.\nFor Windows instances, set this parameter to RunBatScript or RunPowerShellScript.\nCommandContent\neXVtIHVwZGF0ZSAteQ==\nThe Base64-encoded content of the command.\nDescription\nupdate\nThe description of the command.\nAfter you create a command, you can view the details of the command on the My Commands tab. You can run a command on specific instances. For more information, see Run a command.\nIf you turn on Use Parameters when you create a command, you must enter parameter values in the Command Parameters fields when you run the command.\nYou can call an API operation to create a Cloud Assistant command. For more information, see CreateCommand."
    },
    "100": {
        "title": "Elastic Compute Service:Guidelines for using security groups and use cases",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/security-groups-for-different-use-cases",
        "content": "This Product\nElastic Compute Service:Guidelines for using security groups and use cases\n\n\n\n\nThis topic describes how to configure security group rules based on the characteristics of security groups in Elastic Compute Service (ECS) to ensure the security and reliability of network traffic for cloud resources in common scenarios, such as deploying a website on an ECS instance to provide external web services and managing remote access to an ECS instance.\nIdentify your business characteristics and security requirements. For example, you must know which services can be exposed to the Internet and which services are only for internal use.\nCreate different security groups for ECS instances that provide Internet-facing services and ECS instances that provide internal network-facing services.\nExcess open ports may allow your applications to be accessed over the Internet, which can cause security issues. The security groups to which you want to assign ECS instances must adhere to strict rules. We recommend that you preferentially configure Deny rules in the security groups. You can close all ports and protocols except for the ports and protocols required by the services deployed on the ECS instances.\nThe security group that contains Internet-facing ECS instances must have clear and simple rules to ensure that the instances provide only primary services. For example, for MySQL and Redis applications, we recommend that you deploy the applications on ECS instances that do not have Internet access and configure security group rules to allow access only from specific security groups (specified as authorization objects).\nAssign different applications to different security groups.\nIn most cases, different operating systems in a production environment do not belong to the same application group for load balancing. To provide different services, operating systems must have different ports exposed and blocked. We recommend that you assign different operating systems to different security groups.\nFor example, for a Linux operating system, you may need to expose TCP port 22 to allow SSH connections. For a Windows operating system, you may need to expose TCP port 3389 to allow Remote Desktop Protocol (RDP) connections.\nIf instances that use the same image but provide different services do not need to communicate with each other over the internal network, we recommend that you assign the instances to different security groups. This helps decouple image types from security groups, simplify subsequent changes to security group rules, and ensure that instances have simple responsibilities.\nWhen you plan and add new applications, you must properly plan security groups in addition to using vSwitches to define subnets. Use CIDR blocks and security groups to define your role as a service provider or consumer.\nUse different security groups in production and test environments.\nTo better isolate systems, you may build multiple test environments and a single production environment in actual development. You may need to configure different security group rules for different environments to properly isolate networks. This way, you can prevent changes made for test purposes from being uploaded to the production environment and affecting the stability of the production environment.\nYou can use security groups to confine access domains of applications and prevent communication between production and test environments. You can also assign different security groups to different test environments to block traffic between the environments and improve development efficiency.\nDo not assign public IP addresses to resources that do not require Internet access.\nIf you want to connect to an ECS instance, you can use a method that does not require a public IP address, such as Workbench, Session Manager, or a jump server, to minimize Internet exposure. If you want to directly access a service deployed in an environment that does not have Internet access or in a private network, you can use the port forwarding feature. For more information, see Connect to an instance without Internet connection by using the port forwarding feature of Session Manager CLI.\nMost distributed applications have different layers and groups. For ECS instances that do not have Internet access, we recommend that you do not assign public IP addresses. If multiple instances provide Internet access, we recommend that you configure Server Load Balancer (SLB) to distribute Internet traffic to improve system availability and prevent single points of failure. For more information, go to the Server Load Balancer page.\nIn virtual private clouds (VPCs), if your ECS instances do not have public IP addresses but require Internet access, we recommend that you use NAT gateways to provide Internet proxy services for the instances. You need to only configure Source Network Address Translation (SNAT) entries to enable Internet access for specific CIDR blocks or subnets. This way, you do not need to expose services to the Internet after public IP addresses are assigned when only outbound Internet access is required. For more information, see Create and manage SNAT entries.\nUse a security group as a whitelist\nUse a security group as a whitelist. By default, a security group denies all inbound access. You can add Allow inbound rules to the security group to allow access from specific authorization objects on specific ports. We recommend that you minimize the number of open ports and public IP addresses for ECS instances. You can associate elastic IP addresses (EIPs) with online ECS instances to allow easy access for task log queries and troubleshooting. However, this operation exposes the instances to the Internet.\nA security group serves as a virtual firewall to control inbound and outbound traffic for ECS instances. You must open only the required ports and restrict the allowed source IP address ranges.\nThe default actions of basic and advanced security groups are different.\nBy default, basic and advanced security groups deny all inbound access. By default, a basic security group allows all outbound access and an advanced security group denies all outbound access.\nInstances in different security groups are isolated from each other over the internal network, and the default internal access control policy differs for instances in different types of security groups.\nInstances in different security groups of the same account are inaccessible to each other over the internal network. By default, instances in a basic security group can communicate with each other over the internal network and instances in an advanced security group are isolated from each other over the internal network.\nThe control objects of security group rules vary based on the network type.\nIn a VPC, each security group rule controls access to or from the Internet and the internal network. You can configure a security group rule to deny or allow traffic to or from the Internet and the internal network.\nIn the classic network, public rules (Internet ingress and Internet egress rules) control access to and from the Internet and internal rules (inbound and outbound rules) control access to and from the internal network.\nAdd security group rules based on the principle of least privilege.\nFor example, if you want to open port 22 on a Linux instance for remote logon, we recommend that you allow access only from specific IP addresses.\nIf you specify 0.0.0.0/0 as the authorization object in an inbound rule of a security group, all IPv4 addresses are allowed to access the instances in the security group and all ports are exposed. This increases security risks. To improve security, we recommend that you deny external access on all ports and then configure security group rules to open ports based on your business requirements. For example, if you want to expose web services, you can open common TCP ports, such as ports 80, 8080, and 443, and close other ports.\nTo ensure security, we recommend that you specify IP addresses or CIDR blocks as authorization objects (traffic sources or destinations) based on your business requirements and the principle of least privilege. Exercise caution when you specify 0.0.0.0/0 or ::/0 as authorization objects to allow access from all IPv4 or IPv6 addresses. For information about the types of authorization objects supported by security groups, see the Composition of each security group rule section of the \"Security group rules\" topic.\nConfigure internal isolation based on the principle of least privilege.\nFor example, if you do not require intra-group connectivity between the ECS instances in a security group, change the internal access control policy of the security group from intra-group connectivity to internal isolation.\nMake sure that the purpose of the rules in each security group is consistent.\nAdd security group rules to security groups based on the purposes of the security groups and assign ECS instances to the security groups. Adding a large number of rules to a single security group increases management complexity.\nExercise caution when you specify authorization objects for each security group rule.\nThe authorization objects of security group rules can be IP addresses, security groups, or CIDR blocks.\nIf you want to allow resources in different security groups to communicate with each other, you must configure security group rules to allow mutual access between the security groups. For example, you can create different security groups for distributed applications. The security groups may not be accessible to each other. In this case, you can add security group rules that reference security groups (instead of IP addresses or CIDR blocks) as authorization objects to allow mutual access between the security groups so that resources in the security groups can access each other. For example, you create the sg-web security group for the web layer and the sg-database security group for the database layer of your applications. In the sg-database security group, you can add a rule that references the sg-web security group to allow all resources in the sg-web security group to access the resources in the sg-database security group on MySQL port 3306.\nTo allow access over the internal network, you must specify security groups as authorization objects instead of CIDR blocks.\nBy default, no inbound security group rules allow access to the internal network for ECS instances that reside in the classic network. To ensure security, we recommend that you do not enable access based on CIDR blocks.\nIn most cases, common applications use the default ports.\nApplications deployed on ECS instances use ports of the instances to provide external services. For more information, see Common ports.\nAs your business grows, security groups and security group rules may no longer meet your business requirements. You must regularly check the existing security groups and security group rules and modify security group settings based on the most recent security posture. When you modify a security group, we recommend that you clone the security group to a test environment and modify and debug the security group rules in the test environment to ensure that the traffic of the instances in the security group can be correctly forwarded. Then, you can modify the security group rules in the online environment to prevent service interruptions caused by accidental modifications.\nYou can configure inbound rules in a security group to allow only specific users to access the services deployed on the ECS instances that belong to the security group. By default, a security group denies all inbound access. You need to only configure Allow security group rules. The following use cases describe how to control inbound traffic to ECS instances:\nCase 1: Allow websites deployed on ECS instances to provide web services\nCase 2: Allow only specific users to connect to ECS instances\nCase 3: Control access to databases deployed on ECS instances\nCase 4: Allow only traffic of specific protocols to access ECS instances\nCase 5: Allow instances in different security groups to communicate with each other over the internal network\nYou can configure outbound rules in a security group to prohibit ECS instances in the security group from accessing specific external resources. By default, a basic security group allows all outbound access. You need to only configure Deny security group rules. The following use case describes how to control outbound traffic from ECS instances:\nCase 6: Restrict access from ECS instances to external websites\nA website is deployed on an ECS instance and is accessible to any user over the Internet. To ensure instance security, you can configure security group rules to allow inbound traffic from any source only on TCP ports 80 (HTTP) and 443 (HTTPS). This ensures that the website can be accessed from the Internet but restricts direct access to other services on the instance.\nThe following table describes a sample security group rule.\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nInbound\nAllow\n1\nCustom TCP\nOpen ports:\nHTTP(80)\nHTTPS(443)\nOther custom ports: Enter the range of ports that you want to open.\nSource: 0.0.0.0/0\nIf the website remains inaccessible after you add the preceding rule, check whether all required ports are open and available. For more information, see What do I do if I cannot access a service deployed on an instance?\nIf you want to deploy services on an ECS instance, you must configure rules in the security groups to which the instance belongs to allow only specific users such as administrators or servers at specific IP addresses to connect to the instance on a connection port, such as TCP port 22 (default SSH port) or a custom SSH port. This reduces the risk of malicious attacks.\nThe following table describes a sample security group rule.\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nInbound\nAllow\n1\nCustom TCP\nTo open port 22, which is the default port, on a Linux instance, select SSH (22).\nTo open port 3389, which is the default port, on a Windows instance, select RDP (3389).\nTo open other ports on a Linux or Windows instance, specify a port range.\nSource: 192.168.XX.XX\nThe IP address of a specific user or a specific server. Enter a public or private IP address based on whether the connection is over the Internet or a private network.\nYou can access an IP address search website, such as IP Search, to obtain the public IP address of your local network.\nWhen you use Alibaba Cloud Workbench to connect to an ECS instance, you need to allow only specific authorization objects. The following table describes a sample inbound security group rule.\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nAllow\n1\nCustom TCP\nTo open port 22, which is the default port, on a Linux instance, select SSH (22).\nTo open port 3389, which is the default port, on a Windows instance, select RDP (3389).\nTo open other ports on a Linux or Windows instance, specify a port range.\nTo connect to the instance by using the static public IP address (also called auto-assigned or system-assigned public IP address) or the EIP that is associated with the instance, specify 161.117.0.0/16.\nTo connect to the instance by using the private IP address of the instance, specify 100.104.0.0/16.\nFor information about how to configure security group rules for connecting to an ECS instance that resides in the classic network by using Workbench, see the Security group settings related to Workbench section of the \"Connect to an instance by using Workbench\" topic.\nIn most cases, databases require strict security policies. You can configure security group rules to allow inbound connections only on specific ports from specific IP addresses or security groups, such as the security group to which an application server belongs. This ensures the privacy and security of database access.\nIf an inbound security group rule includes 0.0.0.0/0, review the ports and services that your applications must expose. If you do not want specific ports to directly provide external services, you can add a Deny rule for the ports. For example, if you deploy MySQL database services on your instance, port 3306 cannot be exposed to the Internet. In this case, you can add a Deny rule and set the priority of the rule to 100, which specifies the lowest priority.\nThe following table describes sample security group rules for common databases that use default ports.\nDatabase type\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nMySQL\nInbound\nAllow\n1\nCustom TCP\nDestination: 3306/3306\nSource: 172.16.XX.XX.XX\nOracle\nInbound\nAllow\n1\nCustom TCP\nDestination: 1521/1521\nSource: 192.168.XX.XX\nMS SQL\nInbound\nAllow\n1\nCustom TCP\nDestination: 1433/1433\nSource: 192.168.XX.XX/16\nPostgreSQL\nInbound\nAllow\n1\nCustom TCP\nDestination: 5432/5432\nSource: sg-bp1hv6wvmegs036****\nRedis\nInbound\nAllow\n1\nCustom TCP\nDestination: 6379/6379\nSource: 160998252992****/sg-bp174yoe2ib1sqj5****\nThe IP addresses, CIDR block, Alibaba Cloud account ID, and security group IDs provided in the preceding table are only for reference. Replace the information with actual values.\nYou may need to restrict the network protocols that can be used to access ECS instances based on your business requirements. For example, you may need to allow traffic only over specific TCP or UDP. ports The Internet Control Message Protocol (ICMP) is used to transfer control messages between IP hosts and routers. Before you can perform specific test operations, such as running the ping command on a client to ping your ECS instance, you must add security group rules to allow inbound ICMP access. The following table describes a sample security group rule.\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nInbound\nAllow\n1\nIPv4 network environment: All ICMP (IPv4)\nIPv6 network environment: All ICMP (IPv6)\nDestination: -1/-1\nThe IP address of the client.\nEnter an IPv4 address or an IPv6 address based on the network environment.\nIf you want to share data between ECS instances from different security groups within the same VPC, such as when you want instances in Security Group A to access shared files on instances in Security Group B over FTP, you can add rules to allow mutual access between the security groups over the internal network. The preceding method is more convenient than adding rules to allow access to or from individual IP addresses or CIDR blocks. You do not need to separately configure access control for each instance in each security group.\nThis method is not supported for ECS instances that reside within different VPCs. You can use Cloud Enterprise Network (CEN) to connect instances in a VPC to instances in another VPC. For more information, see Get started with CEN.\nScenario 1:\nIf Security Group A and Security Group B belong to the same Alibaba Cloud account, you must specify the ID of Security Group A as the authorization object when you add a rule to Security Group B to allow inbound access from Security Group A. The following table describes a sample security group rule.\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nInbound\nAllow\n1\nCustom TCP\nDestination: 21/21\nSource: sg-bp1hv6wvmegs036****\nThe security group ID provided in the preceding table is only for reference. Replace the security group ID with the actual security group ID.\nScenario 2:\nIf Security Group A and Security Group B do not belong to the same Alibaba Cloud account, you must specify the ID of Security Group A and the ID of the Alibaba Cloud account to which Security Group A belongs as the authorization object when you add a rule to Security Group B to allow inbound access from Security Group A. The following table describes a sample security group rule.\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nInbound\nAllow\n1\nCustom TCP\nDestination: 21/21\nSource: 160998252992****/sg-bp174yoe2ib1sqj5****\nThe Alibaba Cloud account ID and the security group ID provided in the preceding table are only for reference. Replace the IDs with the actual IDs.\nBy default, a basic security group allows all outbound access. To allow ECS instances in a basic security group to access only specific websites, you can use the security group as a whitelist and add a Deny rule that denies all outbound access and then Allow rules that allow outbound access to the IP addresses of the websites.\nTake note of the following items:\nAfter multiple rules match a request based on the corresponding protocols, port ranges, and authorization objects, the request is matched against the priorities and actions of the rules to determine a single rule to apply. No session is established until an Allow rule is matched and applied.\nA smaller priority value specifies a higher priority for a security group rule. If two security group rules have the same priority and differ only in the action, the Deny rule takes effect. The priority of the Deny rule must be lower than the priority of the Allow rule. This ensures that the Allow rule takes effect to allow outbound access to the IP addresses of the specified websites.\nThe following table describes sample security group rules.\nRule direction\nAction\nPriority\nProtocol type\nPort range\nAuthorization object\nOutbound\nDeny\n2\nAll\nDestination: -1/-1\nDestination: 0.0.0.0/0\nOutbound\nAllow\n1\nCustom TCP\nDestination: 80/80\nDestination: 47.96.XX.XX\nOutbound\nAllow\n1\nCustom TCP\nDestination: 443/443\nDestination: 121.199.XX.XX\nThe preceding rules indicate that the ECS instances in the security group are allowed to access the HTTP service at 47.96.XX.XX on port 80 and the HTTPS service at 121.199.XX.XX on port 443. Other outbound access requests are denied."
    },
    "101": {
        "title": "Elastic Compute Service:Copy a custom image",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/copy-custom-images",
        "content": "This Product\nElastic Compute Service:Copy a custom image\nYou can copy images to deploy Elastic Compute Service (ECS) instances across regions or change the encryption status of encrypted and unencrypted images in the same region or across regions within the public cloud. After you copy an image (source image) to a destination region, an image copy that has a different ID is generated in the region. The image copy has the configurations, such as the resource groups, tags, and encryption attributes, that you specified when you copied the source image. This topic describes how to copy an encrypted or unencrypted custom image.\nA custom image is created. For more information, see Create a custom image from a snapshot or Create a custom image from an instance.\nKey Management Service (KMS) is activated if you want to copy an image to create an encrypted image copy. For more information, see the Activate KMS section in the \"Overview\" topic.\nCopy scenarios\nScenario\nDescription\nProcedure\nDeploy ECS instances across regions in the same account\nAfter you copy an image to a destination region, you can obtain the image copy that has a different ID in the region. Configurations such as tags, resource groups, and encryption attributes of the image copy are defined when you copy the source image. Then, you can use the image copy to deploy ECS instances.\nSet the Copy Mode parameter to Copy and select a destination region. You can follow the steps described in this topic.\nCreate an instance by using a custom image\nDeploy ECS instances across regions and accounts\nAfter you copy an image to a destination region, you can share the image copy with other Alibaba Cloud accounts. Then, the accounts can use the image copy to deploy ECS instances.\nSet the Copy Mode parameter to Copy and select a destination region. You can follow the steps described in this topic.\nShare a custom image\nCreate an instance by using a custom image\nDeploy ECS instances across accounts in the same region\nYou can share an image to other Alibaba Cloud accounts. This way, the Alibaba Cloud accounts can use the image to deploy ECS instances.\nShare a custom image\nCreate an instance by using a custom image\nCopy and encryption scenarios\nScenario\nDescription\nProcedure\nChange the encryption status of a custom image, which requires a longer period of time than copying a custom image without changing the encryption status of the image\nCopy an encrypted image to create an encrypted image that has a different encryption key\nCopy an unencrypted image to create an encrypted image\nAfter you copy an image in a region or across regions, you can use the encrypted image copy to deploy ECS instances.\nAfter a custom image is encrypted, the system and data disks of an ECS instance that is created from the image are automatically encrypted. The system and data disks use the same encryption key as the custom image.\nSet the Copy Mode parameter to Copy and Encrypt, select a destination region, and then select an encryption key. The destination region can be the region of the source image or a different region.\nCreate an instance by using a custom image\nBefore you copy an image, take note of the following items:\nFees for image replication\nSnapshot fees: When you copy an image to a region, a corresponding snapshot is automatically created in the region and consumes snapshot storage capacity. You are charged for the amount of the actual snapshot storage capacity that you use. For more information, see Snapshots.\nSnapshots created for image copies are retained indefinitely regardless of the retention period of the snapshots of the source images.\nFees for cross-region data transfer: Alibaba Cloud does not charge you for cross-region data transfer. For information about the most recent billing details, see the official Alibaba Cloud website for announcements.\nReplication duration\nThe amount of time that is required to copy an image varies based on the size of the image, the network transmission speed, and the number of concurrent tasks in the queue.\nYou can copy a snapshot faster than you can copy an image, and you can use snapshot copying to bypass capacity limits. To copy a large image across regions, such as an image larger than 2 TiB in size, you can first copy the snapshots of the image to the destination region and then create an image from the snapshots in the destination region. For more information, see Copy a snapshot and Create a custom image from a snapshot.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Images.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nOn the Images page, click the Custom Images tab.\nFind the image that you want to copy and click Copy Image in the Actions column.\nIn the Copy Image dialog box, configure the parameters based on the copy scenario.\nParameter\nRequired\nDescription\nCopy Mode\nYes\nSelect Copy.\nDestination Region\nYes\nSelect different regions from the region of the source image.\nIf you use an Alibaba Cloud account to copy an image, you can select up to five destination regions.\nCustom Image Name\nYes\nEnter a name for the image copy to display in the destination region. Example: Image_m_bp1f_from_hangzhou.\nDescription\nNo\nEnter a description for the image copy to display in the destination region.\nResource Group\nNo\nSpecify the resource group to which you want to add the image copy to facilitate management.\nTag\nNo\nAdd tags to the image copy. You can use tags to classify images to facilitate search and batch operations.\nYou can only add tags to the image copy. You cannot modify the custom tags of the source image. The image copy inherits the custom tags of the source image.\nParameter\nRequired\nDescription\nCopy Mode\nYes\nSelect Copy and Encrypt.\nIf you want to encrypt image copies, you must select Copy and Encrypt.\nEncryption Settings\nYes\nSelect destination regions and encryption keys.\nDestination Region: Select the region in which you want to create the image copy. The region can be the region of the source image or a different region.\nEncryption Key: Select the service key of the destination region or a customer master key (CMK) that is created in KMS from the drop-down list. For more information about encryption keys, see the Encryption keys section of the \"Encrypt cloud disks\" topic.\nIf you use an Alibaba Cloud account to copy an image, you can select up to five destination regions.\nIf you select a CMK, make sure that the CMK meets the region and permission requirements. For more information, see the Limits section of the \"Encrypt cloud disks\" topic.\nCustom Image Name\nYes\nEnter a name for the image copy to display in the destination region. Example: Image_m_bp1f_from_hangzhou.\nDescription\nNo\nEnter a description for the image copy to display in the destination region.\nResource Group\nNo\nSpecify the resource group to which you want to add the image copy to facilitate management.\nTag\nNo\nAdd tags to the image copy. You can use tags to classify images to facilitate search and batch operations.\nYou can only add tags to the image copy. You cannot modify the custom tags of the source image. The image copy inherits the custom tags of the source image.\nMake sure that the information is correct and click OK. The system copies the source image.\nYou can view the results of the image copy task and manage the task in the image list in the destination region.\nIf you use an Alibaba Cloud account, a message indicating that the image copy task is submitted appears in the upper-right corner of the page. You can go to the Resource Orchestration Service (ROS) console to check the progress of the image copy task. After the image is copied, the corresponding stack is deleted.\nIn the upper-left corner of the top navigation bar, select the destination region from the drop-down list and view the copy progress of the custom image.\nWhen the image copy task is completed, the progress reaches 100% and the image enters the Available state. The image copy is generated in the destination region and has a unique image ID.\n(Optional) When Creating is displayed in the Status column of the image copy, you can click Cancel Copying in the Actions column to cancel the image copy task.\nAlternatively, you can call the CancelCopyImage API operation to cancel the image copy task.\nYou can call an API operation to copy a custom image. For more information, see CopyImage.\nAfter you copy a custom image, you can use the image copy to create an ECS instance or replace the operating system of an ECS instance. For more information, see the following topics:\nCreate an instance by using a custom image\nReplace the operating system (system disk) of an instance\n"
    },
    "102": {
        "title": "Elastic Compute Service:Overview of ECS instance configuration changes",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/overview-of-instance-upgrade-and-downgrade",
        "content": "This Product\nElastic Compute Service:Overview of ECS instance configuration changes\nIf the configurations of an Elastic Compute Service (ECS) instance do not meet your business requirements, you can change the configurations, including the instance type (vCPUs and memory), public bandwidth configurations, and billing methods of data disks. This topic describes the methods that you can use to change the configurations of an ECS instance.\nAn instance type is a predefined combination of vCPUs and memory. When you change the instance type of an instance, you must change the number of vCPUs and memory size. You cannot individually change the number of vCPUs or memory size.\nBefore you can change the instance type of an instance, you must identify the compatible instance types and learn about the instance types. The compatible instance types are displayed on the configuration change page.\nFor information about instance types, see Overview of instance families.\nFor information about instance families that support instance type changes, see Instance families that support instance type changes.\nThe method for changing the instance type of an instance varies based on the billing method of the instance. The following table describes the most suitable methods for different billing methods of instances.\nBilling method\nChange time\nEffective time\nReference\nSubscription\nBefore the instance expires\nAfter the instance is restarted\nUpgrade the instance types of subscription instances\nDowngrade the instance types of subscription instances\nWithin 15 days before the instance expires\nAfter the instance is restarted within the first seven days of the new billing cycle\nDowngrade the configurations of an instance during renewal\nPay-as-you-go\nN/A\nAfter the instance is restarted\nChange the instance type of a pay-as-you-go instance\nYou can use different methods to change the billing method for network usage of an instance based on the public IP address type. The following table describes the methods.\nPublic IP address type\nEffective time\nReference\nSystem-assigned public IP address\nImmediately\nChange the billing method for network usage\nElastic IP address (EIP)\nImmediately\nModify the bandwidth of an EIP\nYou can use different methods to modify the public bandwidth of an instance based on your business requirements and the billing method of the instance. The following table describes the methods.\nIf you change the public bandwidth from a non-zero value to 0 Mbit/s, whether the system-assigned public IP address of the instance is retained varies based on the network type of the instance.\nIf the instance resides in a virtual private cloud (VPC), the public IP address of the instance is immediately released.\nIf the instance resides in the classic network, the instance can no longer access the Internet, but the public IP address of the instance is retained.\nIf you change the public bandwidth from 0 Mbit/s to a non-zero value, the system assigns a public IP address to the instance.\nThe first time you change the public bandwidth of an ECS instance that resides in the classic network from 0 Mbit/s to a non-zero value, you must restart the instance in the ECS console or by calling the RebootInstance operation for the new configuration to take effect.\nPublic IP address type\nApplicable scope\nEffective time\nReference\nSystem-assigned public IP address\nModify the base public bandwidth of a subscription instance\nImmediately\nModify the bandwidth configurations of subscription instances\nModify the base public bandwidth of a subscription instance during renewal\nAfter the new billing cycle starts\nDowngrade the configurations of an instance during renewal\nModify the base public bandwidth of a pay-as-you-go instance\nImmediately\nModify the bandwidth configurations of pay-as-you-go instances\nEIP\nModify the bandwidth of an EIP for a subscription or pay-as-you-go instance\nImmediately\nModify the bandwidth of an EIP\nYou can attach only pay-as-you-go data disks to pay-as-you-go instances. As a result, you can change the billing methods of data disks only on subscription instances. The following table describes the methods.\nChange time\nEffective time\nReference\nBefore the workspace expires\nImmediately\nChange the billing method of a disk\nWithin 15 days before the instance expires or when the instance has expired but not been released\nImmediately\nDowngrade the configurations of an instance during renewal\nThe following section provides answers to some frequently asked questions about upgrading and downgrading the configurations of instances. For more information, see Instance FAQ.\nHow is the fee for an instance configuration upgrade calculated?\nYou are charged for upgrading the instance type and configurations of a subscription ECS instance. The fee is the difference between the price of the new configurations and the remaining price of the original configurations.\nAfter you upgrade a pay-as-you-go ECS instance, you are periodically charged for the instance based on the new instance type.\nThe actual fee is displayed on the corresponding page in the ECS console when you upgrade the instance type or configurations of an instance. You can also go to the Account Overview page in the Expenses and Costs console to view the fee.\nAre my cloud service configurations affected if I upgrade the configurations of ECS instances?\nPay-as-you-go instances must be stopped before their configurations can be upgraded. After you upgrade the configurations of a subscription instance, you must restart the instance for the new configurations to take effect. The upgrade operation interrupts services that are running on the instance for a short period of time. We recommend that you upgrade instances during off-peak hours. Instances can seamlessly resume services after upgrades without the need to reconfigure environments.\nAfter I place an order to upgrade the configurations of an instance, can I cancel the order to restore the instance to its original configurations?\nNo, after an order to upgrade the configurations of an instance takes effect, the order cannot be canceled and the configurations of the instance are upgraded. If you want to restore the instance to its original configurations, you can downgrade its configurations. You are charged for the configuration downgrade."
    },
    "103": {
        "title": "Elastic Compute Service:Resize cloud disks",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/resize-cloud-disks",
        "content": "This Product\nElastic Compute Service:Resize cloud disks"
    },
    "104": {
        "title": "Elastic Compute Service:Secondary private IP addresses",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/assign-secondary-private-ip-addresses",
        "content": "This Product\nElastic Compute Service:Secondary private IP addresses\nYou can assign one or more secondary private IP addresses to a primary or secondary elastic network interface (ENI) that is attached to an Elastic Compute Service (ECS) instance. This meets your business requirements for multiple private IP addresses in multi-application, failover, and Server Load Balancer (SLB) scenarios. This topic describes how to assign secondary private IP addresses to and configure secondary private IP addresses for an ECS instance and how to unassign the secondary private IP addresses.\nIf the primary ENI or a secondary ENI on your instance requires more than one IP address, in addition to the primary private IP address, you can assign multiple secondary private IP addresses to the ENI. In this case, a single ECS instance has multiple private IP addresses. The following figure shows the private IP address assignment to the primary and secondary ENIs.\nSecondary private IP addresses are suitable for the following scenarios:\nScenarios that involve multiple applications: If multiple applications are deployed on an ECS instance, you can assign secondary private IP addresses to the applications. This way, each application can use a separate IP address for communication and a single instance can provide multiple services to maximize instance utilization.\nFailover scenarios: If an instance fails, you can unbind secondary ENIs from the instance and bind the ENIs to another instance. Traffic destined for the secondary private IP addresses of the failed instance can be diverted to the normal instance to ensure service continuity.\nSLB scenario: After multiple secondary private IP addresses are assigned to each instance, the SLB mechanism can evenly distribute traffic to different private IP addresses across instances. This improves system scalability and performance.\nThe maximum number of private IP addresses that can be assigned to an ENI varies based on the status of the ENI.\nFor an ENI in the Available state, you can assign up to 10 private IP addresses.\nFor an ENI in the InUse state, the maximum number of private IP addresses that you can assign varies based on the instance type of the instance to which the ENI is bound. For more information, see the Private IPv4 addresses per ENI column in the instance type table of each instance family in Overview of instance families.\nA limited number of private IP addresses can be contained in a security group that belongs to a virtual private cloud (VPC). For more information, see the Security group limits section in the \"Limits\" topic.\nIn the following steps, both steps 1 and 3 are mandatory. Please read carefully the steps before you perform operations.\nYou can add or delete secondary private IP addresses in the Manage ENI IP Addresses dialog box of the primary ENI or a secondary ENI bound to an ECS instance in the ECS console. Perform the following steps.\nYou can call an API operation to assign secondary private IPv4 or IPv6 addresses to an ENI. For more information, see AssignPrivateIpAddresses or AssignIpv6Addresses.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Elastic Network Interfaces.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nOn the Elastic Network Interfaces page, find the ENI to which you want to assign secondary private IP addresses and click Manage ENI IP Addresses in the Operation column.\nIn the Manage ENI IP Addresses dialog box, click Increase in the Secondary Private IPv4 Address or IPv6 section.\nIf you leave the fields empty, random IP addresses are automatically assigned from within the private IPv4 or IPv6 CIDR blocks of the vSwitch to which the ENI is connected.\nIf you enter IP addresses, make sure that the IP addresses are within the private IPv4 or IPv6 CIDR blocks of the vSwitch to which the ENI is connected.\nClick Confirm to complete the assignment of the secondary private IP addresses.\nCheck whether the secondary private IP addresses are assigned to the ENI as expected.\nGo to the instance details page of the instance to which the ENI is bound, click the ENIs tab, and then view the address assignment information. The following figure shows an example.\n\nIf you want to add a secondary private IP address to a secondary ENI, make sure that the secondary ENI is bound to an ECS instance and configured. For more information, see Bind ENIs to instances and Configure ENI to take effect within the instance.\nIn this example, a secondary private IP address is assigned to the primary ENI that is already bound to an ECS instance. Therefore, you do not need to perform this step.\nAfter you assign a secondary private IP address to an instance, you must configure the secondary private IP address for the instance based on the operating system type and IP address type. The operations that you must perform vary based on the operating system type and IP address type.\nConfiguration example\nIn this example, secondary private IPv4 addresses are configured. For information about how to configure IPv6 addresses, see IPv6 communication.\nThe following table describes the assignment of secondary private IPv4 addresses to the primary ENI. Replace the IPv4 addresses with actual IPv4 addresses.\nENI\nPrimary private IPv4 address\nSecondary private IPv4 address 1\nSecondary private IPv4 address 2\nPrimary ENI\n192.168.1.201\n192.168.1.202\n192.168.1.203\nBefore you perform operations, make sure that the instance to which the ENI is bound is in the Running (Running) state. For information about how to start an instance, see Start an instance.\nThe following configuration operations in the following operating systems are only for reference. The configuration operations may vary based on the operating system type.\nConnect to the Linux ECS instance.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nView the current network configurations and routing information, and obtain the default gateway and subnet mask.\nRun the following command to query the network configurations:\nThe following figure shows the sample command output.\n\nThe command output indicates the network configurations of the ENI named eth0.\neth0 is activated and is dynamically assigned 192.168.1.201 as the primary private IPv4 address.\nRun the following command to query the routing information:\nThe sample command output shown in the following figure indicates the routing information of the instance.\nThe subnet mask (Genmask) is 255.255.255.0.\nThe default gateway (Gateway) is 192.168.1.253.\n\nThe following table describes the network configurations of the instance.\nENI\nStatus\nDefault gateway\nSubnet mask\nPrimary private IP address\nSecondary private IPv4 address 1\nSecondary private IPv4 address 2\neth0 (serves as the primary ENI)\nUP\n192.168.1.253\n255.255.255.0\n192.168.1.201 (is automatically configured)\n192.168.1.202 (cannot be recognized and must be manually configured)\n192.168.1.203 (cannot be recognized and must be manually configured)\nUse one of the following methods to configure secondary private IPv4 addresses based on your business requirements.\nNetworkManager is a daemon process used to manage network connections and network settings in Linux operating systems. NetworkManager provides the nmcli command-line tool to help you easily manage network connections.\nnmcli is suitable for all operating systems that manage network services by using NetworkManager, including but not limited to Fedora, CentOS, Red Hat Enterprise Linux (RHEL), Ubuntu, Debian, and their distributions.\nIn this example, eth0 is used as the connection name. Replace the connection name with the actual connection name.\nRun the following command to create a file to disable the network configuration feature of cloud-init. This prevents configuration failures caused by instance restart. For more information, see the cloud-init automatically initializes network configurations section of this topic.\nAdd the following configuration to the file:\nRun the following command to check the current network connection:\nThe names of network connections vary based on the Linux distribution. The following figure shows a sample network connection.\n\nRun the following commands to configure the secondary private IPv4 addresses, default gateway, and IPv4 configuration method (manual or DHCP) of eth0:\nRun the following command to allow the configurations to take effect:\nIf a message similar to \"Connection successfully activated\" is returned, the configurations take effect.\nThe network configuration file varies based on the Linux operating system distribution and version.\nWe recommend that you back up the network configuration file before you modify the file.\nMake sure that you correctly modify the network configuration file. Incorrect configurations may cause an instance connection failure.\nThe following procedure applies to the following operating system distributions: Alibaba Cloud Linux 2, Alibaba Cloud Linux 3, CentOS 6, CentOS 7, CentOS 8, Red Hat 6, Red Hat 7, Red Hat 8, Red Hat 9, Anolis 7, Anolis 8, Fedora 33, Fedora 34, and Fedora 35.\nIn this example, Alibaba Cloud Linux 3.2 is used.\nIn this example, the eth0 ENI is used. Replace the ENI name with the actual ENI name.\nRun the following command to check whether the main configuration file of the ENI exists. Each ENI has a corresponding configuration file that identifies the ENI.\nIn specific operating systems, such as Alibaba Cloud Linux 3.2, the main configuration file of an ENI is automatically generated by cloud-init.\nIn other operating systems, such as CentOS 8.5, you must create the main configuration file of an ENI and configure ENI parameters in the file.\nIf the main configuration file exists, proceed to Step b.\nIf the main configuration file does not exist, create the main configuration file and configure basic ENI parameters in the file.\nSpecify the ENI name, use Static as the method to obtain an IP address, and then configure the primary private IPv4 address, subnet mask, and gateway information of the ENI.\nIn this example, the main configuration file of eth0 does not exist. You must configure the required parameters. Sample code snippet:\nRun the following command to open the network configuration file of eth0 and configure Secondary private IPv4 address 1 for eth0:\nSample code snippet:\nConfigure Secondary private IPv4 address 2 for eth0\nThe operations for configuring Secondary private IP address 2 are similar to the operations for configuring Secondary private IP address 1. Take note of the following items:\nReplace the serial number of the secondary private IP address with the actual serial number. Serial numbers are unique to each secondary private IP address.\nReplace the DEVICE parameter with the actual device name. The device names cannot be identical. The device name must contain the same serial number of the secondary private IP address as the serial number specified in the configuration file.\nSample code snippet:\nRun the following command to disable the network configuration feature of cloud-init.\nThe /etc/netplan/50-cloud-init.yaml network configuration file is automatically generated by cloud-init when the instance starts. Before you can modify the file, you must disable the network configuration feature of cloud-init. For more information, see the cloud-init automatically initializes network configurations section of this topic.\nAdd the following configuration to the configuration file:\nRun the following command to open the network configuration file and configure the ENI:\nSample code snippet:\nRestart the network service to allow the new configurations to take effect.\nIf you run the nmcli con commands, you do not need to restart the network service. NetworkManager monitors the network configuration file and automatically applies the new configurations.\nOperating system\nCommand to restart the network service\nAlibaba Cloud Linux 2\nCentOS 7\nRed Hat 7\nAnolis 7\nSUSE Linux 11, SUSE Linux 12, and SUSE Linux 15\nopenSUSE 15 and openSUSE 42\nsudo service network restart\nor sudo systemctl restart network\nCentOS 6\nRed Hat 6\nsudo service network restart\nAlibaba Cloud Linux 3\nCentOS 8\nRed Hat 8\nAnolis 8\nFedora 33, Fedora 34, and Fedora 35\nsudo systemctl restart NetworkManager or sudo reboot\nUbuntu 18, Ubuntu 20, and Ubuntu 22\nDebian 12\nsudo netplan apply\nUbuntu 14 and Ubuntu 16\nDebian 8, Debian 9, Debian 10, and Debian 11\nsudo systemctl restart networking or sudo reboot\nRepeat Step 2 to check whether the configurations take effect.\n\nThe procedure applies to the Windows operating system.\nIn this example, Windows Server 2022 is used.\nIn this example, the primary ENI named Ethernet is used. If you use a secondary ENI, replace the ENI name with the actual ENI name. Example: Ethernet 2.\nConnect to the Windows ECS instance.\nFor more information, see Use Workbench to connect to a Windows instance over RDP.\nView the current network configurations and routing information to obtain the default gateway and subnet mask of the ENI.\nOpen Command Prompt or Windows PowerShell.\nRun the following command to view information about the current ENI and its IP addresses:\nThe following command output indicates information about the current ENI and its IP addresses.\n\nThe following table describes the network configuration and routing information of the ENI.\nENI\nSubnet mask\nDefault gateway\nPrimary private IP address\nSecondary private IPv4 address 1 to be configured\nSecondary private IPv4 address 2 to be configured\nEthernet (serves as the primary ENI)\n255.255.255.0\n192.168.1.253\n192.168.1.201 (is automatically configured)\n192.168.1.202 (cannot be recognized and must be manually configured)\n192.168.1.203 (cannot be recognized and must be manually configured)\nOpen Network and Sharing Center.\nClick Change adapter settings.\nDouble-click the primary ENI named Ethernet. Then, click Properties in the Ethernet Status dialog box.\n\nIn the Ethernet Properties dialog box, double-click Internet Protocol Version 4 (TCP/IPv4).\n\nIn the Internet Protocol Version 4 (TCP/IPv4) Properties dialog box, select Use the following IP address and click Advanced.\nThe policy of automatically obtaining IP addresses is changed to manual configuration. Configure the following parameters, including the primary private IP address. Otherwise, you cannot connect to the instance by using the primary private IP address.\n\nIn the Advanced TCP/IP Settings dialog box, configure IP addresses.\nIn the IP addresses section, click Add. Then, enter the primary and secondary private IP addresses that are assigned to Ethernet and the subnet mask that you queried.\nIn this example, enter the two secondary private IP addresses of Ethernet.\nIn the Default gateways section, click Add and enter the obtained default gateway that you queried in the Gateway field.\n\nClick OK to save the settings in each dialog box to complete the configuration of the secondary private IPv4 addresses. Repeat Step 2 to check whether the configurations take effect.\n\nRun the following command to open the network configuration file and configure the ENI:\nStarting some releases of Debian 10, the /etc/network/interfaces file contains symbolic links to the network interface configuration files that are stored in the /etc/network/interfaces.d/ directory, but does not contain network interface configurations.\nYou can configure the following configuration items in a network interface configuration file instead of in the /etc/network/interfaces file based on your business scenario.\nExample:\nRestart the network service to allow the new configurations to take effect.\nThe following procedure applies to the following operating systems: SUSE Linux 11, SUSE Linux 12, SUSE Linux 15, and openSUSE 15.\nIn this example, SUSE Linux 15 SP5 is used.\nIn this example, the eth0 ENI is used. Replace the ENI name with the actual ENI name.\nRun the following command to open the configuration file of eth0, in which you can specify the secondary private IPv4 addresses and their subnet masks:\nSample configuration file:\nTo view help information about the template configuration file, run the sudo cat /etc/sysconfig/network/ifcfg.template command.\nRun the following command to check whether the default gateway information exists in the global network configuration file:\nIf the default gateway information does not exist in the global network configuration file, add the default gateway information to the file. Example:\nRestart the network service to allow the new configurations to take effect.\nWhen an ENI no longer requires secondary private IP addresses, you can unassign the secondary private IP addresses from the ENI. You can perform the following steps to unassign secondary private IP addresses.\nBefore you unassign secondary private IP addresses from an ENI, make sure that the following prerequisites are met:\nOne or more secondary private IP addresses are assigned to the ENI.\nThe ENI is in the Available (Available) or InUse (InUse) state.\nWhen you unassign secondary private IP addresses from a primary ENI, the ECS instance to which the primary ENI is bound is in the Running (Running) or Stopped (Stopped) state.\nYou can call an API operation to unassign one or more secondary private IPv4 or IPv6 addresses from an ENI. For more information, see UnassignPrivateIpAddresses or UnassignIpv6Addresses.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Elastic Network Interfaces.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nOn the Elastic Network Interfaces page, find the ENI from which you want to unassign secondary private IP addresses and click Manage ENI IP Addresses in the Operation column.\nIn the Manage ENI IP Addresses dialog box, find the secondary private IP addresses that you want to unassign in the Secondary Private IPv4 Address section and click the  icon on the right side of the IP addresses.\nClick OK.\nRefresh the ENI list. If the IP Address column of the ENI no longer displays the secondary private IP addresses that you unassigned, the secondary private IP addresses are unassigned from the ENI.\ncloud-init is an open source initialization tool that automates initialization operations for Linux operating systems, such as generating an initial password, configuring the hostname, and running user data scripts. cloud-init is pre-installed on all Alibaba Cloud public images. When an ECS instance starts, cloud-init automatically generates network configurations for the instance.\nView the description of the network configuration file to check whether the file is automatically generated by cloud-init.\nYou can view information about whether cloud-init automatically generates a network configuration file. In this example, the description of the /etc/sysconfig/network-scripts/ifcfg-eth0 configuration file for Alibaba Cloud Linux 3.2 is viewed.\n\nDisable the network configuration feature of cloud-init.\nScenarios in which the network configuration feature of cloud-init can be disabled: In the following scenarios, you may disable the network configuration feature of cloud-init. Otherwise, if the instance restarts, the network configurations automatically generated by cloud-init may overwrite your custom network configurations.\nManually configure the network by modifying the network configuration file automatically created by cloud-init.\nManage the network by using other network management services, such as NetworkManager.\nMethod used to disable the network configuration feature of cloud-init: Create the /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg file and add the network: {config: disabled} configuration to the file.\nFor more information about cloud-init, log on to the Linux instance operating system and view information in the /etc/cloud/cloud.cfg.d/README file.\nThe methods used to configure IP addresses in the operating system include DHCP (default) and static. When you configure secondary private IP addresses, select a configuration method based on your business scenario.\nStatic configuration: You must manually configure necessary network parameters, such as subnet masks, default gateways, and DNS server addresses.\nDHCP dynamic acquisition: DHCP is a network protocol that allows devices in a network to automatically acquire network configurations, such as IP addresses, subnet masks, default gateways, and DNS server addresses. You can also configure secondary private IP addresses for Linux instances when DHCP dynamic acquisition is enabled.\nAfter you assign secondary private IP addresses, you may need to use SLB. For more information, see Getting Started.\nYou may want to configure security groups for the assigned secondary private IP addresses to ensure that only authorized network traffic can access the IP addresses. For information about how to add a security group rule, see Add a security group rule.\nAfter you unassign secondary private IP addresses, you may need to reconfigure security group rules for the associated ECS instance. For more information, see Modify a security group rule.\nYou can configure event notifications in EventBridge or CloudMonitor to receive notifications about IP address events. After you assign private IP addresses to or unassign private IP addresses from an ENI, you are notified of the results by emails or DingTalk chatbots. You can obtain information, such as the IDs of ENIs and the secondary private IP addresses that are assigned to the ENIs, from the notifications and configure operations to be automatically performed in response to the notifications. For more information, see Use CloudMonitor to subscribe to ECS system event notifications, ECS events, and the Notifications for private IPv4 address assignment events section of the \"IP address event notifications\" topic.\nIf a Windows instance cannot access the Internet after you configure secondary private IP addresses for the instance, troubleshoot the issue by following the instructions in the After I configure a secondary private IP address for a Windows ECS instance, the instance cannot access the Internet. Why? section of the \"Network FAQ\" topic."
    },
    "105": {
        "title": "Elastic Compute Service:Replace the operating system (system disk) of an instance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/change-the-operating-system",
        "content": "This Product\nElastic Compute Service:Replace the operating system (system disk) of an instance\nIf the operating system of an Elastic Compute Service (ECS) instance does not meet your business requirements, you can replace the operating system. When you replace the operating system, you must replace both the image and system disk, but you cannot replace only the image. This topic describes how to replace the operating system of an instance.\nA snapshot is created for the system disk of the ECS instance whose operating system you want to replace to back up disk data. For more information, see Create a snapshot.\nThe operating system replacement operation replaces the system disk and image. After the operating system of an ECS instance is replaced, the original system disk is released and all data stored on the disk is cleared. Before you replace the operating system, create snapshots for the system disk to back up data.\nThe ECS instance whose operating system you want to replace is in the Stopped state. If the ECS instance is not in the Stopped state, stop the instance. For more information, see Stop Instance.\nIf an ECS instance uses the pay-as-you-go billing method and resides in a VPC, you must enable the standard mode when you stop the instance. If you enable the economical mode, you may be unable to start the instance after you replace the operating system of the instance.\nA subscription ECS instance is locked if the instance expires. Before you change the operating system on an expired subscription ECS instance, renew your instance. For more information, see Renew a subscription instance.\nIf you replace the operating system of an ECS instance, risks may occur. Before you perform this operation, take note of the items that are described in the following table.\nAfter you replace the operating system of an ECS instance, all data stored on the original system disk is cleared, and you must redeploy environments on the new system disk to run services. This may interrupt your business for an extended period of time. If the operating systems meet the following conditions, you can use Server Migration Center (SMC) to migrate the operating system instead of replacing it: The ECS instance runs an operating system, you want to retain data stored on the original system disk and reduce service downtime, and the source and destination operating systems meet the requirements described in Migration and upgrade scenarios. For more information, see Migrate and upgrade the operating system of an ECS instance.\nItem\nDescription\nImpacts on the system disk\nAfter you replace the operating system of an ECS instance, Alibaba Cloud assigns a new system disk to the instance. Take note of the following items:\nThe original system disk is released, and all data and partition information of the disk are cleared.\nThe system disk ID changes. However, the category of the system disk, the IP addresses of the instance, and the media access control (MAC) addresses of the elastic network interfaces (ENIs) on the instance remain unchanged.\nImpacts on the data disks\nIf the replacement involves the same operating system type, such as Windows or Linux, the replacement operation replaces the system disk but does not affect the data disks attached to the instance. Take note that the disks must be re-attached to the instance.\nIf the replacement involves different operating system types, such as Windows and Linux,  the replacement operation replaces the system disk and causes an issue that the new operating system cannot recognize the file system format on the data disks. You must re-initialize the data disks or install software to recognize the file system format on the data disks. For more information, see the What to do next section of this topic.\nIf the custom image that you use to replace the operating system of an ECS instance contains data from data disks, make sure that no business dependency exists between the original system disk and the data disks attached to the instance or no issues occur when the new system disk performs operations on the data disks. For example, if the original system disk read data from and wrote data to the data disks, exceptions may occur when the new system disk reads data from and writes data to the data disks.\nImpacts on snapshots\nSnapshots of the original system disk cannot be used to roll back the new system disk but can be used to create custom images.\nManual snapshots of the original system disk are not released.\nIf you enable Delete Automatic Snapshots While Releasing Disk for the original system disk, the automatic snapshots of the disk are automatically released together with the disk. If you disable Delete Automatic Snapshots While Releasing Disk for the original system disk, the automatic snapshots of the disk are retained until they expire.\nThe automatic snapshot policy applied to the original system disk becomes invalid, and you can configure an automatic snapshot policy for the new system disk based on your business requirements.\nLimits that apply when you replace an operating system with a Windows operating system\nMake sure that the system disk has at least 1 GiB of free space. Otherwise, the ECS instance may fail to start after the operating system is replaced.\nStarting January 14, 2020, Microsoft no longer provide support for Windows Server 2008 and Windows Server 2008 R2. Starting October 10, 2023, Microsoft no longer provides support for Windows Server 2012 R2. Alibaba Cloud no longer provides technical support for ECS instances that run the preceding operating systems. If your ECS instances run the preceding operating systems, we recommend that you upgrade to Windows Server 2016 or later at the earliest opportunity. For more information, see Windows Server EOL guidance.\nLimits that apply when you replace a Windows operating system with a Linux operating system or replace a Linux operating system with a Windows operating system\nOperating systems of ECS instances can be replaced between Windows and Linux operating system families only in regions in the Chinese mainland. In regions outside the Chinese mainland, the operating systems of ECS instances can be replaced only within the same operating system family.\nCheck whether the hostname of the ECS instance meets the requirements of the replacement operating system. For example, if the replacement operating system is a Windows operating system, the instance hostname cannot exceed 15 characters in length. For information about how to change the hostname, see Modify the attributes of an instance or ModifyInstanceAttribute.\nCharges\nYou are not charged for replacing the operating system of an ECS instance, but you are charged for the resources that are used in the following scenarios:\nIf you use a paid image as the replacement image, you are charged for the image. For more information, see Images.\nIf you extend the system disk when you replace the operating system of an ECS instance, you are charged for the additional disk capacity. For more information, see Block storage devices.\nTime required to replace the operating system\nApproximately 10 minutes is required to replace the operating system of an ECS instance. The actual amount of time varies based on the operating system.\nAfter the operating system is replaced, you may be unable to log on to the ECS instance by using Virtual Network Computing (VNC) for specific reasons, such as slow boot. In this case, log on to the instance again later.\nThis section describes how to use an image to replace the operating system of a single ECS instance in the ECS console. To replace the operating systems of multiple ECS instances at a time, use the ACS-ECS-BulkyReplaceSystemDisk public template provided by OOS. For more information, see ACS-ECS-BulkyReplaceSystemDisk.\nOpen the Replace Operating System dialog box.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nIn the top navigation bar, select the region where the ECS instance resides.\nFind the ECS instance whose operating system you want to replace and choose  > Disk and Image > Replace Operating System in the Actions column.\nPerform a precheck on the ECS instance.\nIn the Replace Operating System dialog box, select Replace System Disk.\nA precheck is automatically performed on the ECS instance and requires approximately 10 seconds to complete.\nIf the ECS instance passes the precheck,  is displayed in the Precheck column.\nIf the ECS instance fails the precheck,  is displayed in the Precheck column. Follow the on-screen instructions to resolve the issue and then try again.\nRead the precautions, select I am aware of the preceding risks and want to continue, and then click Continue to Replace Operating System.\nOn the Change Operating System page, configure the parameters.\n\n\u2460: In the Image section, select an image type. Then, select an image and an image version from the drop-down lists.\n(Optional) \u2461: In the System Disk section, specify the capacity of the new system disk based on your business requirements or select Encryption to encrypt the new system disk.\nYou cannot replace the system disk with a disk from a different category.\nIf you renewed the ECS instance and downgraded its configurations, you cannot change the system disk capacity until the next billing cycle starts.\nYou can specify a capacity that is greater than the capacity of the current system disk. If you extend the system disk, you are charged for the additional disk capacity. For more information, see Block storage devices.\nIf you extend the system disk during the operating system replacement, the partitions on the system disk may fail to be extended due to a timeout error. For information about how to resolve the issue, see the What do I do if partitions on the system disk of an instance fail to be extended when I extend the disk by replacing the operating system of the instance? section in the \"FAQ about replacing the operating system of an instance\" topic.\n\u2462: In the Security Settings section, configure an authentication method. The following table describes the authentication methods.\nAuthentication method\nDescription\nKey Pair\nYou can use key pairs to log on only to Linux instances.\nSelect a username that you want to use to log on to the ECS instance. Then, select an existing key pair or click Create SSH Key Pair to create a key pair. For more information, see Create an SSH key pair. After you create a key pair, go to the Change Operating System page and click the  icon next to the Key Pair field to obtain the most recent key pair list.\nSet Username to root or ecs-user.\nroot is the highest-privileged account in the operating system. If you set Username to root, security risks may occur. We recommend that you set Username to ecs-user.\nUse Predefined Password\nThis authentication method is supported only if you select the Custom Image or Shared Image image type in the Image section.\nYou can select this option to use the preset password in the selected image to log on to the ECS instance. If you select this authentication method, make sure that your selected image has a preset password.\nPassword\nSpecify a username and a password.\nFor a Linux instance, you can set Username to root or ecs-user.\nroot is the highest-privileged account in the operating system. If you set Username to root, security risks may occur. We recommend that you set Username to ecs-user.\nFor a Windows instance, Username is automatically set to administrator.\nSet after Change\nAfter you replace the operating system, bind a key pair or use the Reset Password feature to specify a password for the instance. For more information, see Bind an SSH key pair and Reset the logon password of an instance.\nCheck the fees, read and select ECS Service Terms, and then click Create Order.\n(Optional) Complete the payment (if any) as prompted.\nApproximately 10 minutes is required to replace the operating system. Go to the ECS console and verify that the state of the ECS instance changes to Running. Check whether the operating system of the instance changes.\n(Conditionally required) If the replaced and replacement operating systems are Linux operating systems and the data disk partitions of the ECS instance are configured to automatically mount on instance startup, the mounting information of the data disk partitions is lost. You must rewrite the mounting information of the data disk partitions to the /etc/fstab file. For more information, see Configure UUIDs in the fstab file to automatically mount data disks.\nYou can redeploy environments on the new operating system to run services, such as installing software, APT repositories, and YUM repositories, and configuring environment variables.\nAfter the operating system is replaced, the original system disk is released and all data stored on the disk is cleared. You can use a snapshot of the original system disk to create a pay-as-you-go disk and then attach the new disk to the ECS instance to restore data. After the data is restored, we recommend that you release the new disk at the earliest opportunity. For more information, see Create a disk from a snapshot, Attach a data disk, and Release a disk.\nHow do I reuse the data disks of an ECS instance after I replace the instance operating system between Windows and Linux operating system families?\nAfter you replace the Linux operating system of an ECS instance with a Windows operating system, the Windows operating system cannot recognize Ext3, Ext4, or XFS file systems on the data disks of the instance. To resolve the preceding issue, we recommend that you perform one of the following operations on the data disks:\nIf the data disks do not contain important data, re-initialize the disks and format the disks into a file system that can be recognized by the Windows operating system. For more information, see Re-initialize a data disk and Initialize a data disk on a Windows instance.\nIf the data disks contain important data, separately install software that allows the Windows operating system to recognize Ext3, Ext4, or XFS file systems, such as Ext2Read and Ext2Fsd.\nAfter you replace the Windows operating system of an ECS instance with a Linux operating system, the Linux operating system cannot recognize New Technology File System (NTFS) file systems on the data disks of the instance. To resolve the preceding issue, we recommend that you perform one of the following operations on the data disks:\nIf the data disks do not contain important data, re-initialize the disks and format the disks into a file system that can be recognized by the Linux operating system. For more information, see Re-initialize a data disk and Initialize a data disk whose size does not exceed 2 TiB on a Linux instance.\nIf the data disks contain important data, separately install software that allows the Linux operating system to recognize NTFS file systems, such as ntfsprogs.\nIf you use ntfsprogs, run the following commands in sequence to allow the Linux operating system to access the NTFS file systems:\nReplace <Data disk partition name> and <Mount directory> with the actual names and mount directories of the data disk partitions.\nFor more information, see How do I move an NTFS disk between a Linux instance and a Windows instance?\n\nFor information about the operating systems that support graphical desktops, see the Which operating systems support graphical desktops? section of the \"FAQ about images during instance creation\" topic.\nAfter you replace the operating system of an ECS instance, the automatic snapshot policy applied to the original system disk becomes invalid. You can configure an automatic snapshot policy for the new system disk based on your business requirements. For more information, see Configure an automatic snapshot policy for a cloud disk.\nAfter you replace the operating system of an ECS instance, you can delete the snapshots of the original system disk to reduce snapshot costs. For information about how to delete a snapshot, see Delete a snapshot.\nTo obtain the answers to frequently asked questions about replacing the operating system of an ECS instance, see FAQ about replacing the operating system of an instance.\nYou can call the ReplaceSystemDisk operation to replace the operating system of an ECS instance. For more information, see ReplaceSystemDisk."
    },
    "106": {
        "title": "Elastic Compute Service:Control access to ECS using RAM users",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/control-access-to-resources-by-using-ram-users",
        "content": "This Product\nElastic Compute Service:Control access to ECS using RAM users\nAlibaba Cloud provides Resource Access Management (RAM), which offers powerful granular access control. It is suitable for enterprise scenarios where multiple departments or roles require access to Elastic Compute Service (ECS) resources. By assigning different access permissions based on departmental or role-specific duties, you can ensure the security of sensitive information and key business processes. Implementing a strategy where duties are separated not only improves management efficiency but also mitigates the risk of data breaches. This topic describes how to manage RAM user permissions for controlling access to ECS resources.\nAssume that your company uses ECS for hosting applications and services. Managers oversee IT architecture planning, with full control over ECS resources, including resource creation, resource allocation adjustments, and security policy configurations. Developers focus on continuous project iteration and feature development, deploying projects to ECS. Operators ensure system stability by creating snapshots, generating images, and executing maintenance scripts.\nFor these roles, we recommend the following permission schemes:\nManagers are granted full ECS operational permissions, such as instance creation, instance release, and security group rule modifications.\nDevelopers can view all ECS instance details but cannot change the settings. They are authorized to log on to instances to perform operational tasks.\nOperators are permitted to create certain resources but cannot delete them. These permissions include generating snapshots and images, and executing scripts.\nLog on to the RAM console with your Alibaba Cloud account and create three RAM users: manager, developer, and operator. Assign them appropriate permissions. Ensure console logon is enabled for these users. For more information, see Create a RAM user.\nCreate three custom policies for fine-grained access control and management. For more information, see Create custom policies.\nThis policy is defined for managers, with full ECS operational permissions granted.\nThis policy specifies view-only permissions for developers for certain resources and allows remote ECS login by using Workbench. Developers do not have permission for creation or modification.\nThis policy grants operators permission to view resources, create images and snapshots, and execute commands.\nAttach the custom policies to RAM users to manage their access to specific resources. When a RAM user performs unauthorized actions, you can revoke their authorization or reduce the scope of their permissions, so that you can mitigate risks. For more information, see Grant permissions to a RAM user.\nRAM User\nPolicy to Grant\nManager\nManager_Policy\nDeveloper\nDeveloper_Policy\nOperator\nOperator_Policy\nGo to the RAM user logon page and sign in with the created RAM users.\nLog on to the ECS console and perform operations such as viewing ECS instances, creating instances, and generating images to check whether the access control takes effect.\nYou can view the ECS instance list.\n\nYou can create ECS instances.\n\nYou can release ECS instances.\n\nYou can create images.\n\nYou can view the ECS instance list.\n\nYou cannot create ECS instances.\n\nYou cannot create images.\n\nYou can log on to an ECS instance by using Workbench and deploy projects with commands on the instance.\n\nYou can view the ECS instance list.\n\nYou cannot create ECS instances.\n\nYou can create images.\n\nRAM is a service provided by Alibaba Cloud that allows you to manage user identities and resource access permissions. For more information, see What is RAM?\nYou can check usage notes and limits of multi-factor authentication (MFA) in RAM. For more information, see What is multi-factor authentication?\nECS offers various custom policies. For more information, see Custom policies for ECS.\nFor information about how to connect to an ECS instance by using Workbench, see Connect to an instance by using Workbench."
    },
    "107": {
        "title": "Elastic Compute Service:Identities",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/ram-overview",
        "content": "This Product\nElastic Compute Service:Identities\nTo ensure the security of your accounts and resources on Alibaba Cloud, do not use your Alibaba Cloud account to access Elastic Compute Service (ECS) unless required. We recommend that you use your Resource Access Management (RAM) identities instead, including RAM users and RAM roles.\nRAM users can be created by Alibaba Cloud accounts, or RAM users or RAM roles that have administrative rights. RAM users are allowed to log on to consoles or access Alibaba Cloud resources within the Alibaba Cloud accounts only if the RAM user has the required permissions.\nWe recommend that you take note of the following items:\nUse your Alibaba Cloud account to create a RAM user and grant the RAM user the administrative rights. Then, you can use the RAM user to create and manage other RAM users.\nSeparate RAM users for individuals from RAM users for programs.\nYou can use the RAM console or call API operations to create RAM users. If you use the RAM console, you must provide the username and password of your Alibaba Cloud account. If you call API operations, you must provide your AccessKey pair. We recommend that you separate RAM users for individuals from RAM users for programs to prevent human errors. If you use the RAM console, we recommend that you enable multi-factor authentication (MFA) to increase security.\nGrant permissions to RAM users based on the principle of least privilege.\nLeast-privilege permissions refer to the minimum permissions that are required to perform an operation. Least-privilege permissions improve data security and prevent permission abuse.\nDo not embed your AccessKey ID or AccessKey secret in code. Otherwise, your AccessKey pair may be leaked, which causes security risks for all resources within your account. We recommend that you use Security Token Service (STS) tokens or configure environment variables to obtain access permissions.\nEnable single sign-on (SSO) for RAM users to allow the RAM users to log on to and access Alibaba Cloud resources from the identity management systems of their enterprises.\nOverview of RAM users\nAccessKey security solution\nOverview of user-based SSO\nIf you use your Alibaba Cloud account to create multiple RAM users, you can group the RAM users to facilitate permission management. For example, you can grant the same permissions to RAM users in the same RAM user group. We recommend that you take note of the following items:\nGrant permissions to RAM user groups based on the principle of least privilege.\nRemove a RAM user from the RAM user group if the work duties of the RAM user change.\nRemove a RAM user from the RAM user group if the RAM user no longer needs the permissions of the RAM user group.\nOverview of a RAM user group\nA RAM role is a virtual identity to which policies can be attached. A RAM role does not have permanent identity credentials, such as a logon password or an AccessKey pair. A RAM role can be used only after the role is assumed by a trusted entity. After a RAM role is assumed by a trusted entity, the trusted entity can obtain a Security Token Service (STS) token. Then, the trusted entity can use the STS token to access Alibaba Cloud resources as the RAM role.\nWe recommend that you take note of the following items:\nDo not frequently change the trusted entity of a RAM user after the RAM user is created. If you change the trusted entity of a RAM user, permission loss may occur, which affects your business. If you add a trusted entity, security risks may arise due to privilege escalation. Make sure that the changes are fully tested before you apply them to a RAM user.\nAfter a trusted entity is granted a permission, the trusted entity can call the AssumeRole operation to obtain an STS token, which can be used to assume a RAM role. For more information, see AssumeRole. An STS token is valid only for a limited period of time. We recommend that you set the validity period to an appropriate value to reduce security risks.\nThe maximum validity period of an STS token is the longest session duration specified for the RAM role. We recommend that you specify an appropriate session duration for a RAM role to reduce security risks.\nEnable SSO for RAM roles to allow the RAM roles to log on to and access Alibaba Cloud resources from the identity management systems of their enterprises.\nRAM role overview\nAssume a RAM role\nSpecify the maximum session duration for a RAM role\nRole-based SSO"
    },
    "108": {
        "title": "Elastic Compute Service:Manage ECS quotas",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/view-and-increase-instance-quotas",
        "content": "This Product\nElastic Compute Service:Manage ECS quotas\nA quota is the maximum number of operations or cloud resources an Alibaba Cloud account can use. Through the Quota Center, you can check ECS-related quota limits and usage, or request quota increases and set usage alerts based on business requirements. This topic explains how to manage ECS-related quotas.\nThe system dynamically adjusts quotas based on actual usage. You need not worry about insufficient quotas or request increases if you maintain many instances over time, unless you anticipate a surge in usage.\nWhen managing ECS-related quotas in the Quota Center, pay attention to the following resource types:\nGeneral Quotas: These are limits on cloud resources under an account, such as the maximum number of security groups.\nElastic Compute Service Instance Type Quotas: The maximum number of vCPUs for an ECS instance family, GPU cards, or vGPU instances that a single Alibaba Cloud account can hold in a specific region and billing method.\nElastic Compute Service: Quota limits for resources such as images and security groups.\nElastic Block Storage: Quota limits on different types of disks for a single Alibaba Cloud account in a specific region and zone.\nAPI Rate Quotas: These are limits on the frequency of OpenAPI calls. For instance, the quota for RunInstances is 100/60(s).\nElastic Compute Service: API rate limits for images, security groups, and block storage with the API version 2014-05-26.\nThe API rate quotas for Elastic Compute Service do not support requests for increases.\nElastic Block Storage: API rate limits for advanced features of block storage with the API version 2021-07-30.\nGeneral quotas are limits on cloud resources under an account, such as the maximum number of security groups.\nElastic Compute Service instance type quotas are the maximum number of vCPUs for an ECS instance family, GPU cards, or vGPU instances that a single Alibaba Cloud account can hold in a specific region and billing method.\nNavigate to the Elastic Compute Service instance type quota list.\nSelect the desired region.\n\nIn the quota list, view or request an increase for the quota.\nTo view the quota: The Quota column shows the upper limit for the quota item, and the Used column displays the current usage.\nYou can find the quota item by looking for the instance family you are interested in. For the relationship between quota items and instance families, refer to vCPU quota items and GPU card and vGPU quota items.\nTo request a quota increase:\nClick Apply in the Action column.\nIf the Action column indicates Not Adjustable, the quota cannot be increased.\nIn the dialog box, enter the Requested Quota and Reason For Request, and leave Notify Adjustment Result as the default.\nFor a higher chance of approval, provide a reasonable requested quota and a detailed reason for your application.\nYou will receive notification of the application result via text message and email.\nClick Confirm Adjustment.\nIn the left-side navigation pane, select Application History to check the status of your quota increase request.\nIf the application status is Approved, the increase has been successful.\nElastic Compute Service quotas include limits for resources such as images and security groups.\nNavigate to the Elastic Compute Service quota list.\nSelect the desired region.\n\nIn the quota list, view or request an increase for the quota.\nTo view the quota: The Quota column shows the upper limit for the quota item, and the Used column displays the current usage.\nIf you know the  Quota ID for a quota item, you can locate it using the  Quota ID. If you are unfamiliar with the  Quota ID, you can also find the quota item by its name and description.\nTo request a quota increase:\nClick Apply in the Action column.\nIf the Action column indicates Not Adjustable, the quota cannot be increased.\nIn the dialog box, enter the Requested Quota and Reason For Request, and leave Notify Adjustment Result as the default.\nFor a higher chance of approval, provide a reasonable requested quota and a detailed reason for your application.\nYou will receive notification of the application result via text message and email.\nClick Confirm Adjustment.\nIn the left-side navigation pane, select Application History to check the status of your quota increase request.\nIf the application status is Approved, the increase has been successful.\nElastic Block Storage quotas are limits on different types of disks for a single Alibaba Cloud account in a specific region and zone.\nNavigate to the Elastic Block Storage quota list.\nSelect the desired region and zone.\n\nIn the quota list, view or request an increase for the quota.\nTo view the quota: The Quota column shows the upper limit for the quota item, and the Used column displays the current usage.\nIf you know the Quota ID of a quota item, you can locate it using the Quota ID. If you are unaware of the Quota ID, you can still find the quota item by its name and description.\nTo request a quota increase:\nClick Apply in the Action column.\nIf the Action column indicates Not Adjustable, the quota cannot be increased.\nIn the dialog box, enter the Requested Quota and Reason For Request, and leave Notify Adjustment Result as the default.\nFor a higher chance of approval, provide a reasonable requested quota and a detailed reason for your application.\nYou will receive notification of the application result via text message and email.\nClick Confirm Adjustment.\nIn the left-side navigation pane, select Application History to check the status of your quota increase request.\nIf the application status is Approved, the increase has been successful.\nAPI rate quotas are the limits on the frequency of OpenAPI calls. For example, the quota for RunInstances is 100/60(s).\nElastic Compute Service API rate quotas include API rate limits for images, security groups, and block storage with the API version 2014-05-26. The API rate quotas for Elastic Compute Service do not support requests for increases.\nNavigate to the Elastic Compute Service API rate quota list.\nSelect the desired region.\n\nIn the quota list, view the quota. The Quota column shows the rate limit for the corresponding API.\nYou can find the quota item by looking for the API Name and viewing its quota.\nAPI rate limits for advanced features of block storage with the API version 2021-07-30.\nNavigate to the Elastic Block Storage API rate quota list.\nSelect the desired region.\n\nIn the quota list, view or request an increase for the quota.\nTo view the quota: The Quota column shows the rate limit for the corresponding API.\nYou can find the quota item by looking for the API Name and viewing its quota.\nTo request a quota increase:\nClick Apply in the Action column.\nIf the Action column indicates Not Adjustable, the quota cannot be increased.\nIn the dialog box, enter the Requested Quota and Reason For Request, and leave Notify Adjustment Result as the default.\nFor a higher chance of approval, provide a reasonable requested quota and a detailed reason for your application.\nYou will receive notification of the application result via text message and email.\nClick Confirm Adjustment.\nIn the left-side navigation pane, select Application History to check the status of your quota increase request.\nIf the application status is Approved, the increase has been successful.\nYou can use the DescribeAccountAttributes API to query the quotas available in a region, including the number of security groups, ENIs, pay-as-you-go vCPU cores, preemptible instance vCPU cores, the total capacity quota of pay-as-you-go disks, the number of dedicated hosts, network type, and whether real-name authentication is complete.\nQuota alerts: Set up alerts for quota items to be notified when usage approaches the specified threshold. This enables you to request an increase in your quota promptly.\nQuery the list and details of quota increase applications: After initiating a quota increase application, you can retrieve the list and details of your applications to check the approval status.\nFor additional quota operations, refer to the Quota Center document."
    },
    "109": {
        "title": "Elastic Compute Service:Execute commands using SDK",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/use-python-to-manage-ecs-instances-without-logging-on-to-the-instances",
        "content": "This Product\nElastic Compute Service:Execute commands using SDK\nCloud Assistant facilitates the simultaneous execution of commands across multiple Elastic Compute Service (ECS) instances. This topic details how to use the ECS SDK to run Cloud Assistant commands and verify their outcomes.\nYour ECS instance must be in the Running state (Running) and must have the Cloud Assistant Agent installed. If the agent is not installed, please see Install Cloud Assistant Agent.\nEnsure the runtime environment is set with the environment variables ALIBABA_CLOUD_ACCESS_KEY_ID and ALIBABA_CLOUD_ACCESS_KEY_SECRET. For configuration details, see Configure environment variables in Linux, macOS, and Windows.\nTo avoid security risks from primary account AccessKey exposure, it's advisable to create a Resource Access Management (RAM) user and grant it the necessary ECS access privileges. Use the RAM user's AccessKey for SDK operations. For more information, see RAM users.\nGrant the RAM user the required permissions for Cloud Assistant. For more information, see Authorize RAM users to use Cloud Assistant.\nPrepare the Shell, Bat, or PowerShell commands for execution by Cloud Assistant.\nIncorporate the ECS SDK into your project. For more information, see  and ECS_SDK.\nIn today's cloud computing environments, operations and maintenance (O&M) management systems are essential for business continuity. Regular monitoring of resource usage, including CPU, memory, and disk space, is vital for the performance and stability of ECS instances. Imagine developing an automated O&M system using Cloud Assistant's password-free feature, which allows remote execution of user-defined commands on ECS instances to meet various O&M requirements. This system can perform tasks such as resource monitoring, log collection, and troubleshooting, thereby enhancing O&M efficiency and supporting effective business operations."
    },
    "110": {
        "title": "Elastic Compute Service:Use CloudMonitor to subscribe to ECS system event notifications",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/set-event-notifications",
        "content": "This Product\nElastic Compute Service:Use CloudMonitor to subscribe to ECS system event notifications\nTo ensure the stability of your business running on Elastic Compute Service (ECS) instances and implement automated O&M, we recommend that you subscribe to event notifications to monitor system changes. This topic describes how to subscribe to ECS system events on the CloudMonitor console.\nIf your business requires fast response to events or may involve a large number of events, we recommend that you subscribe to ECS events through EventBridge. For more information, see Use EventBridge to quickly subscribe to ECS events.\nCloudMonitor is a monitoring service that allows you to query, manage, and monitor the system events of Alibaba Cloud services in an integrated manner. For more information about CloudMonitor, see What is CloudMonitor?\nYou can use CloudMonitor to configure alert rules so that you are notified when system events occur. CloudMonitor supports the following notification methods:\nSends SMS, emails, or DingTalk messages.\nDistributes the notifications to your Message Queue, Log Service, Function Compute, or Webhook services, so that you can handle the events in an automated manner.\nIn this topic, a subscription policy is created for the Instance:StateChange system event.\nLog on to the CloudMonitor console.\nIn the left-side navigation pane, choose Event Center > Event Subscription.\nYou can also perform the following steps to create a subscription policy by using the System Event menu:\nIn the left-side navigation pane, choose Event Center > System Event.\nIn the Welcome to the New Event Center section, click Create Immediately to create a subscription policy.\nOn the Subscription Policy tab, click Create Subscription Policy.\nOn the Create a subscription policy page, configure the parameters.\nBasic information: Enter a name for the subscription policy.\nAlert Subscription:\nSubscription Type: Select System events.\nSubscription Scope:\nProducts: Select Elastic Compute Service (ECS) from the drop-down list.\nEvent Type: Select Abnormal.\nEvent name: Select Instance:StateChange.\nEvent Level: Select Notification (Info).\nApplication grouping, Event Content, and Event Resources: Leave these parameters empty, which indicates that notifications will be sent for the Instance:StateChange events that occur on all ECS instances under all application groups of the account.\nFor a list of the system events supported by ECS, see System Event - Elastic Compute Service (ECS).\nCombined noise reduction: Use the default settings.\nNotification: Create a notification configuration. Use the default settings for Custom notification method.\nWhen you create a notification configuration, enter a notification configuration name, set the Notification settings parameter to Set the notification group directly, select an alert contact group from the Contact Group drop-down list, and then click OK.\nFor more information about how to create a notification configuration, see the Create a notification configuration policy section of the \"Manage notification configurations\" topic.\nCloudMonitor automatically sends alert notifications based on the notification methods for the alert contacts in the specified alert contact group. For example, if you specify a mobile number and an email address for an alert contact and use the default notification method as the custom notification method, the alert contact receives only alert phone calls, text messages, and emails.\nPush and Integration: Leave this section empty.\nFor information about how to create a push channel, see Create a push channel.\nFor information about event notifications, see the following topics:\nInstance event notifications\nEBS event notifications\nSnapshot event notifications\nENI operation event notifications\nvSwitch event notifications\nIP address event notifications\nAfter you subscribe to system event notifications, you can use the debugging feature to check whether notifications can be sent to Message Queue, Log Service, Function Compute, and Webhook services as expected.\nOn the Subscription Policy tab, click Debug event subscription.\nIn the Create event debugging panel, set Products to Elastic Compute Service (ECS) and Name to Instance:StateChange.\nCloudMonitor automatically generates the debugging content in the JSON format.\nSample JSON content for the Instance:StateChange event\nClick OK.\nAn Operation successful message appears. CloudMonitor automatically sends a test alert notification to the alert contacts based on the notification methods specified in the subscription policy.\nYou can specify follow-up actions for event notifications, so as to handle status change events of ECS instances in an automated manner. For example, you can specify a Message Service (MNS) queue in the policy. For more information about the operations, see Automate O&M based on status change events of ECS instances.\n"
    },
    "111": {
        "title": "Elastic Compute Service:Use deployment sets to improve service availability or reduce communication latency between ECS instances",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/deployment-sets-overview",
        "content": "This Product\nElastic Compute Service:Use deployment sets to improve service availability or reduce communication latency between ECS instances\nA deployment set provides a deployment strategy for deploying Elastic Compute Service (ECS) instances on physical servers. For cluster services that require high availability, you can deploy ECS instances on different physical servers based on the high availability strategy or the high availability group strategy. This prevents single points of failure (SPOFs) and improves service availability. For applications that are highly sensitive to network latency, such as high-frequency transactions and real-time data analytics, you can deploy ECS instances within the same network based on the low latency strategy. This shortens the communication latency between ECS instances. This topic describes the deployment strategies and limits of deployment sets, and how to use deployment sets.\nA deployment strategy determines how to deploy ECS instances on physical servers. You can select a deployment strategy based on your business requirements, such as high availability, network latency, and deployment scale.\nStrategy\nDescription\nHigh availability strategy (Availability)\nDeploys ECS instances in a deployment set on different physical servers to effectively reduce the risks of SPOF-induced service interruptions.\nSuitable scenarios: The systems that are deployed on a small scale and require high service continuity and isolation, such as Hadoop distributed computing clusters and SQL database clusters.\nZone scope: ECS instances in a deployment set can be deployed in different zones.\nMaximum number of instances: Up to 20 ECS instances can be deployed per zone.\nHigh availability group strategy (AvailabilityGroup)\nProvides finer-grained control in a single zone by dividing a deployment set into up to seven deployment set groups and allocating ECS instances to the groups to achieve higher fault isolation.\nECS instances allocated to the deployment set groups are strictly distributed on different physical servers within a specific region to prevent SPOFs. In addition, multiple ECS instances in the same deployment set group may be deployed on the same physical server. This reduces the latency of mutual access.\nTo query the deployment set groups (DeploymentSetGroupNo) to which ECS instances are allocated in a deployment set, call the DescribeInstances operation.\nSuitable scenarios: Large-scale applications that require high isolation, especially applications that have built-in high availability mechanisms, such as master-replica replication mechanism of ApsaraDB for Redis and NGINX load balancing mechanism.\nZone scope: ECS instances in a deployment set can be deployed in different zones.\nMaximum number of instances: Up to 20 ECS instances can be deployed per deployment set group per zone. Up to seven deployment groups are supported per zone.\nLow latency strategy (LowLatency)\nDeploys all ECS instances within the same network in the same zone, which reduces communication latency.\nMultiple ECS instances may be deployed on the same physical server, which cannot guarantee high availability.\nSuitable scenarios: Applications that are highly sensitive to network response speeds, especially applications that have built-in high availability mechanisms and require rapid data exchanges, such as high-performance computing, real-time data analytics, and AI inference.\nZone scope: ECS instances of a deployment set must reside in the same zone.\nMaximum number of instances: Up to 20 ECS instances can be deployed in a zone.\nIf a resource shortage occurs in a specific region, you may be unable to create ECS instances or restart pay-as-you-go instances that were stopped in economical mode in the region. In this case, wait a period of time and try again. For more information, see Economical mode.\nDedicated hosts: cannot be created in deployment sets.\nMaximum number of deployment sets: To query the quota of deployment sets that an Alibaba Cloud account can create, go to the General Quotas page of ECS in the Quota Center console.\nRegion and zone limits: ECS instances and the deployment sets to which the instances belong must be in the same region. ECS instances in a deployment set that uses the low latency strategy must be deployed in the same zone.\nInstance family limits\nDeployment strategies that can be used may vary based on the instance family. The following table describes the deployment strategies that are supported by different instance families.\nTo query the instance families that support a specific deployment strategy, call the DescribeDeploymentSetSupportedInstanceTypeFamily operation.\nDeployment strategy\nInstance families that support the deployment strategy\nHigh availability strategy or high availability group strategy\n\ng8a, g8i, g8y, g7se, g7a, g7, g7h, g7t, g7ne, g7nex, g6, g6e, g6a, g5, g5ne, sn2ne, sn2, and sn1\nc8a, c8i, c8y, c7se, c7, c7t, c7nex, c7a, c6, c6a, c6e, c5, ic5, and sn1ne\nr8a, r8i, r8y, r7, r7se, r7t, r7a, r6, r6e, r6a, re6, re6p, r5, re4, se1ne, and se1\nhfc8i, hfg8i, hfr8i, hfc7, hfg7, hfr7, hfc6, hfg6, hfr6, hfc5, and hfg5\nd3c, d2s, d2c, d1, d1ne, d1-c14d3, and d1-c8d3\ni3g, i3, i2, i2g, i2ne, i2gne, and i1\nebmg5, ebmc7, ebmg7, ebmr7, sccgn6, scch5, scch5s, sccg5, and sccg5s\ne, t6, xn4, mn4, n4, e4, n2, and n1\ngn6i\nLow latency strategy\ng8a, g8i, g8ae, and g8y\nc8a, c8i, c8ae, and c8y\nebmc8i, ebmg8i, and ebmr8i\nr8a, r8i, r8ae, and r8y\nebmc7, ebmg7, and ebmr7\nDeployment sets cannot be merged.\nYou can use deployment sets free of charge. However, you are charged for the creation and usage of resources, such as ECS instances, disks, snapshots, images, and public bandwidth, in deployment sets. For more information, see Billing overview.\nIn the ECS console, choose Deployment & Elasticity >  > Deployment Sets to go to the Deployment Sets page.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nIn the Create Deployment Set dialog box, configure the Deployment Set Name, Description, and Strategy parameters. For information about how to select a deployment strategy, see the Deployment strategies section of this topic.\nCall the CreateDeploymentSet operation to create a deployment set in a specific region and specify a deployment strategy.\nIf the Strategy parameter is set to AvailabilityGroup, you can configure the GroupCount parameter to specify the number of deployment set groups.\nMake sure that the instance types, regions, and quantity of ECS instances meet the limits. For more information, see the Limits section of this topic.\nCreate an ECS instance in a deployment set.\nOn the Deployment Sets page, find the deployment set in which you want to create an ECS instance and click Create Instance in the Actions column to go to the ECS instance buy page.\n\nAdd an existing ECS instance to a deployment set. For more information, see the Change the deployment set to which an ECS instance belongs section of this topic.\nTo create an ECS instance in a deployment set, call the RunInstances operation and specify the DeploymentSetId parameter.\nSpecify the number of deployment set groups in the deployment set.\nTo add an existing ECS instance to a deployment set, call the ModifyInstanceDeployment operation and specify the InstanceId and DeploymentSetId parameters.\nIf you set the Strategy parameter to AvailabilityGroup, you can configure the DeploymentSetGroupNo parameter to specify the number of the deployment set group to which to deploy the ECS instance.\nYou can move an ECS instance from an existing deployment set to a different deployment set or add an ECS instance that does not belong to a deployment set to a deployment set based on your business requirements.\nGo to the Instance page in the ECS console.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind an ECS instance that you want to manage and choose  > Deployment & Elasticity > Change Deployment Set in the Actions column.\nIn the Change Deployment Set dialog box, select the destination deployment set and configure the Force Change parameter.\nYes: allows the instance to be moved to a different physical server. A forced change may cause the instance to restart. Proceed with caution.\nNo: adds the instance to the destination deployment set and does not allow the instance to be moved to a different physical server. This prevents an instance restart. If the current instance does not meet the requirements of the destination deployment set, the instance cannot be added to the destination deployment set.\nCall the ModifyInstanceDeployment operation and specify the following parameters to change the deployment set of an ECS instance:\nRegionId: The ID of the region to which the instance belongs. Example: cn-hangzhou.\nInstanceId: The instance ID. Example: i-bp67acfmxazb4ph***.\nDeploymentSetId: The ID of the destination deployment set. Example: ds-bp67acfmxazb4ph****.\nForce: specifies whether to forcefully move the instance to a different physical server. Valid values:\ntrue: allows the instance to be moved to a different physical server. A forced change may cause the instance to restart. Proceed with caution.\nfalse (default): adds the instance to a specific deployment set and does not allow the instance to be moved to a different physical server. This prevents an instance restart. If the current instance does not meet the requirements of the destination deployment set, the instance cannot be added to the destination deployment set.\nTo retain an ECS instance in a deployment set that you want to delete, you can remove the instance from the deployment set and then delete the deployment set. This allows the instance to remain in the original state.\nMake sure that the instance whose deployment set you want to delete is in the Running or Stopped state. For more information, see Start an instance and Stop an instance.\n\nCall the ModifyInstanceDeployment operation and specify the following parameters to remove the instance from the deployment set:\nRegionId: The ID of the region to which the instance belongs. Example: cn-hangzhou.\nInstanceId: The instance ID. Example: i-bp67acfmxazb4ph***.\nDeploymentSetId: The ID of the deployment set. Example: ds-bp67acfmxazb4ph****.\nRemoveFromDeploymentSet: specifies whether to remove the instance from the deployment set. Set the parameter to true.\nCheck whether the instance is removed as expected. If the operation is called as expected and the status code 200 is returned, the instance is removed as expected.\nOn the Deployment Sets page, find the deployment set that you want to manage and click Modify Information or Delete in the Actions column.\nModify the deployment set by changing the name or description of the deployment set.\nDelete the deployment set. If you no longer require a deployment set, delete the deployment set to prevent unnecessary resource usage.\nWhen you delete a deployment set, make sure that no instances exist in the deployment set. If an instance exists, remove the instance before you delete the deployment set. For more information, see the Change the deployment set to which an ECS instance belongs or Remove an ECS instance from a deployment set section of this topic."
    },
    "112": {
        "title": "Elastic Compute Service:View the monitoring information of an ECS instance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/query-monitoring-information-of-an-instance",
        "content": "This Product\nElastic Compute Service:View the monitoring information of an ECS instance\nYou can monitor the health status of your Elastic Compute Service (ECS) instances to ensure that your users can always access your websites and applications, process data, or render videos. Alibaba Cloud allows collection and visualization of monitoring data, and provides real-time alerts to help ensure that your ECS instances run as expected.\nYou can monitor your ECS instances in the ECS or CloudMonitor console.\nECS console: You can monitor vCPU utilization, network traffic, and disk I/O operations.\nCloudMonitor console: You can monitor resources in a more fine-grained manner.\nThe following section describes the monitoring metrics for ECS instances:\nvCPU utilization: the percentage of allocated compute units that are in use on an ECS instance. A higher percentage indicates a higher vCPU load on the instance. You can view the monitoring data of an ECS instance in the ECS or CloudMonitor console or by calling ECS API operations. You can also connect to an ECS instance to view the monitoring data of the instance.\nTo view the vCPU utilization of an ECS instance after you connect to the instance, you can use one of the following methods:\nWindows instance: View the vCPU utilization in Task Manager. You can sort processes by vCPU utilization to identify processes that consume the vCPUs of the instance.\nLinux instance: Run the top command on the instance to view the vCPU utilization of the instance. Press Shift+P to sort processes by vCPU utilization and identify processes that consume the vCPUs of the ECS instance.\nNetwork traffic-related metrics: the inbound and outbound bandwidth usages of the ECS instance in Kbit/s.\nECS monitors public bandwidth usage. CloudMonitor monitors public and internal bandwidth usage. If an outbound public bandwidth of 1 Mbit/s is allocated to an ECS instance and the outbound public bandwidth usage by the instance reaches 1,024 Kbit/s, the allocated outbound public bandwidth is considered to be fully utilized.\nThe monitoring data of public bandwidth over the classic network does not include back-to-origin traffic. You can view the complete monitoring data in the CloudMonitor console.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind the ECS instance whose monitoring data you want to view and click the instance ID.\nOn the Instance Details page, click the Monitoring tab.\nSpecify a time range to query the monitoring data of the instance, such as vCPU utilization and memory usage.\nThe granularity of the displayed data varies based on the length of the specified time range. A shorter time range indicates a higher resolution of displayed data. For example, the aggregation interval is different for a 1-hour period and a 6-hour period, which results in different average values. You can specify a time range based on your business requirements.\n\nYou can also call ECS API operations, such as DescribeInstanceMonitorData, DescribeDiskMonitorData, and DescribeEniMonitorData, to query monitoring data.\nThe monitoring data of an ECS instance that you can view in the ECS console varies based on whether the CloudMonitor agent is installed on the instance.\nIf the CloudMonitor agent is installed on the ECS instance, the operating system metrics from CloudMonitor are displayed in the ECS console, and the data of the other metrics displayed in the ECS console is the same as the data of basic metrics displayed in the CloudMonitor console. CPU utilization, memory usage, and system load are operating system metrics for which data is obtained from instance operating systems.\nIf the CloudMonitor agent is not installed on the ECS instance, the data of metrics in the ECS console is the same as the data of basic metrics in the CloudMonitor console.\nOperating system metrics are collected every 15 seconds. Basic metrics are collected every 1 minute. For more information, see Operating system monitoring.\nThe following table describes the metrics of ECS instances on which the CloudMonitor agent is not installed. The data collection interval is 1 minute.\nMetric\nDescription\nUnit\nMetricName\nDimensions\nStatistics\n(ECS) CPU Utilization\nCPU utilization\n%\nCPUUtilization\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)InternetInRate(Classic Network)\nAverage rate of inbound traffic over the Internet\nbit/s\nInternetInRate\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)IntranetInRate\nAverage rate of inbound traffic over the internal network\nbit/s\nIntranetInRate\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)InternetOutRate(Classic Network)\nAverage rate of outbound traffic over the Internet\nbit/s\nInternetOutRate\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)IntranetOutRate\nAverage rate of outbound traffic over the internal network\nbit/s\nIntranetOutRate\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)DiskReadBPS\nNumber of bytes that are read from the system disk per second\nByte/s\nDiskReadBPS\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)DiskWriteBPS\nNumber of bytes that are written to the system disk per second\nByte/s\nDiskWriteBPS\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)DiskReadIOPS\nNumber of read operations that are performed on the system disk per second\nCount/s\nDiskReadIOPS\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)DiskWriteIOPS\nNumber of write operations that are performed on the system disk per second\nCount/s\nDiskWriteIOPS\nuserId and instanceId\nAverage, Minimum, and Maximum\n(ECS)InternetInRate_IP\nInbound bandwidth over the Internet\nbit/s\nVPC_PublicIP_InternetInRate\nuserId, instanceId, and ip\nMaximum, Minimum, and Average\n(ECS)InternetOutRate_IP\nOutbound bandwidth over the Internet\nbit/s\nVPC_PublicIP_InternetOutRate\nuserId, instanceId, and ip\nMaximum, Minimum, and Average\n(ECS)InternetOutRatePercent_IP\nUtilization of the outbound bandwidth over the Internet\n%\nVPC_PublicIP_InternetOutRate_Percent\nuserId, instanceId, and ip\nAverage\n(ECS)InternetIn(Classic Network)\nInbound traffic over the Internet\nByte\nInternetIn\nuserId and instanceId\nAverage, Minimum, Maximum, and Sum\n(ECS)InternetOut(Classic Network)\nOutbound traffic over the Internet\nByte\nInternetOut\nuserId and instanceId\nMaximum, Minimum, and Average\n(ECS)IntranetInRate\nInbound traffic over the internal network\nByte\nIntranetInRate\nuserId and instanceId\nMaximum, Minimum, and Average\nCloudMonitor provides end-to-end and out-of-the-box monitoring solutions for enterprises in the cloud. CloudMonitor provides the host monitoring service to monitor ECS instances. For more information about the host monitoring service, see Overview. For information about the host monitoring metrics, see Operating system monitoring.\nTo monitor the utilization of various cloud resources, create alert rules in the CloudMonitor console. If resource metrics meet specific alert conditions, alerts are triggered and CloudMonitor sends alert notifications. This way, you can identify and handle monitoring data exceptions at the earliest opportunity. For more information, see Create an alert rule.\nLog on to the CloudMonitor console.\nIn the left-side navigation pane, click Host Monitoring.\n(Optional) On the Host Monitoring page, find and select the ECS instance whose monitoring data you want to view. In the lower part of the page, click Batch Install and then click OK.\nIf the CloudMonitor agent is not installed on the ECS instance, you can install the agent on the instance. For more information, see Install and uninstall the CloudMonitor agent.\nIf the CloudMonitor agent is not installed on the ECS instance, you can view only basic metrics in the CloudMonitor console.\nIf the CloudMonitor agent is installed on the ECS instance, you can view basic metrics and operating system metrics in the CloudMonitor console.\nOn the Host Monitoring page, click the ID of the ECS instance whose monitoring data you want to view. On the Basic Monitoring and OS Monitoring tabs, view monitoring data.\nMonitoring data can be retained for up to 30 days.\nDescribeInstanceMonitorData\nDescribeDiskMonitorData\nDescribeEniMonitorData\n"
    },
    "113": {
        "title": "Elastic Compute Service:Migrate ECS instances from the classic network to a VPC",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/migrate-ecs-instances-from-the-classic-network-to-a-vpc",
        "content": "This Product\nElastic Compute Service:Migrate ECS instances from the classic network to a VPC\nCompared with the classic network, virtual private clouds (VPCs) provide higher security, higher isolation, and more flexible network configuration capabilities. This topic describes how to use a migration plan to migrate one or more Elastic Compute Service (ECS) instances from the classic network to VPCs.\nThe classic network type is an early traditional network type supported by Elastic Compute Service (ECS) instances in Alibaba Cloud. In 2014, Alibaba Cloud released the Virtual Private Cloud (VPC) network type. Over several years, the VPC network type increasingly became the default choice for Alibaba Cloud users. Compared with the classic network type, the VPC network type provides a higher level of security from multiple aspects. The VPC network type is suitable for enterprises and organizations that require a high level of data security.\nFor information about VPCs and the classic network, see Network types.\nAs an increasing number of users successfully migrate business to VPCs and VPC features are continuously improved, Alibaba Cloud gradually reduces the support for the classic network.\nStarting July 2024, Alibaba Cloud restricts operations related to renewal and purchase of ECS instances of the classic network type. For more information, see EOL notice for Alibaba Cloud ECS instances in the classic network.\nOn February 28, 2025, ECS instances in the classic network are expected to reach the end of life (EOL). We recommend that you migrate ECS instances in the classic network to VPCs by following the procedure in this topic.\nThe Migration Plan feature is supported in the following regions: China (Qingdao), China (Beijing), China (Hangzhou), China (Shanghai), China (Shenzhen), China (Hong Kong), US (Silicon Valley), and Singapore. In the China (Hangzhou) region, you cannot migrate specific ECS instances in Hangzhou Zone C from the classic network to a VPC.\nThe ECS instances that you want to migrate from the classic network to a VPC meet the following requirements:\nThe ECS instance is created and not attached with a local disk.\nCheck whether local disks are attached to an ECS instance\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nOn the Instance page, find the ECS instance that you want to check and view the Specifications column for local disk information.\nIf Local Storage is displayed in the Specifications column, local disks are attached to the instance. If Local Storage is not displayed in the Specifications column, local disks are not attached to the instance.\nIf local disks are attached to the instance, submit a ticket to contact Alibaba Cloud technical support to migrate the instance.\nThe ECS instance does not expire. If an ECS instance in the classic network expires and cannot be renewed and migrated, submit a ticket.\nThe classic network-to-VPC migration affects the status, network type, and IP addresses of ECS instances. Before you migrate ECS instances, make sure that you are familiar with the migration impacts that are described in the following table.\nItem\nDescription\nPeriod of time that is required to migrate an ECS instance\nApproximately 15 minutes are required from the time when an ECS instance in the classic network is stopped until the time when the instance is migrated to and started in a specific VPC.\nIf an ECS instance is started in the VPC, the computing and network resources of the instance are migrated to the VPC, and you can use the instance as expected.\nIf an ECS instance is migrated across zones, the system continues to migrate disk data of the instance after the instance is started. In most cases, approximately 4 hours are required to migrate 100 GiB of disk data. During the migration of disk data, the I/O performance of disks degrades and snapshot-related and disk-related operations cannot be performed. The disk data migration does not affect your business. The I/O performance degradation is imperceptible to the business that is not highly sensitive to I/O performance degradation.\n\nInstance status\nDuring the migration, the ECS instance that is migrated is stopped and then restarted. We recommend that you migrate your instance during off-peak hours.\nNetwork type\nAfter an ECS instance is migrated, the network type of the instance changes from classic network to VPC. For information about VPCs, see What is a VPC?\nAfter you migrate an ECS instance from the classic network to a VPC, you cannot migrate the instance back to the classic network.\nSoftware authorization codes\nAfter an ECS instance is migrated, the authorization codes of software on the instance may change.\nSolutions to issues related to software authorization code changes\nProblem description: The software vendor did not approve the migration certificate issued by Alibaba Cloud. Solution: We recommend that you contact the software vendor or channel partner to submit a verification form for re-authorization.\nProblem description: If specific software was associated with a MAC address to register to an ECS instance, authorization errors may occur after you migrate the instance to a VPC. Cause: After you migrate the ECS instance from the classic network to a VPC, only the public or private MAC address of the instance is retained. If the MAC address with which the software is associated for registration is deleted, authorization errors occur. Solution: We recommend that you contact the software vendor to check whether the software is associated with a MAC address to register to your ECS instance. If the software is associated with a MAC address to register to your instance, you must re-associate the MAC address of the instance with the software. For information about elastic network interfaces (ENIs), see Overview.\nPublic and private IP addresses\nPublic IP address: After an ECS instance is migrated, the public IP address of the instance remains unchanged.\nCompared with ECS instances in the classic network, ECS instances in the VPC do not have network interface controllers (NICs) to which public IP addresses are assigned. In a VPC, a public IP address is assigned to a gateway device connected to an ECS instance. The public IP address of the gateway cannot be viewed, but the internal IP address of the instance can be viewed in the operating system of the ECS instance.\nIf your applications require the public IP address in the operating system of the instance, you must configure the public IP address after instance migration.\nScenario 1: Change the public IP address configured in the application, such as the IP address of the website of Internet Information Services (IIS) Manager. For more information, see the FAQ section of this topic.\nScenario 2: If an application deployed on an instance require a public IP address that can be viewed in the operating system of the instance, you can convert the auto-assigned public IP address into an EIP in the ECS console, and then expose an EIP on a NIC by adding a secondary CIDR block to a VPC.\nInternal IP address: You can specify whether to retain the internal IP address of an ECS instance when you create a migration plan to migrate the instance. You can also change the internal IP address of the instance after the instance is migrated. For more information, see Primary private IP address.\nWe recommend that you retain the internal IP address of the ECS instance that you want to migrate. If you do not retain the internal IP address of an ECS instance, you must configure the files, business programs, and cloud service whitelists that use the original internal IP address to use the new internal IP address after the migration. For example, you must modify the /etc/hosts file of a Linux ECS instance.\nDevice names of disks\nLinux instances: The underlying virtualization technology of specific ECS instances is upgraded when the instances are migrated from the classic network to VPCs. This may result in changes to the device names of the disks on the instances. On Linux instances, disks are assigned device names within the vd[a-z] range, which serve as unique identifiers for the disks.\nIf the disks of a Linux instance are assigned device names in the vd? format before the instance is migrated, the device names of the disks remain unchanged after the instance is migrated.\nIf the disks of a Linux instance are assigned device names in the xvd? format before the instance is migrated, the device names of the disks are converted into the vd? format after the instance is migrated. For example, xvda, xvdb, and xvdc are converted into vda, vdb, and vdc. Alibaba Cloud updates the /etc/fstab file for Linux instances. You must check whether your applications are dependent on the original device names of the disks.\nWindows instances: The device names of disks are not affected.\nBilling\nYou are not charged for the migration, and the migration process does not incur additional fees. The unit price of an ECS instance type does not change before and after the migration.\nAfter you migrate ECS instances from the classic network to VPCs, all ineffective or unpaid orders related to the instances that were placed when the instances were in the classic network are canceled.\nRegions and zones\nThe regions of ECS instances remain unchanged after the migration. ECS instances cannot be migrated across regions.\nBased on the limits on the number of ECS resources per zone, select a destination zone that provides sufficient instance resources, which may be different from the source zone.\nHostname\nBy default, the hostname does not change. However, if you changed the hostname on the instance and the hostname displayed in the ECS console is different from the hostname on the instance, we recommend that you change the hostname on the instance to be the same as the hostname displayed in the ECS console before the migration. For more information, see the Configure a hostname for an ECS instance section of the \"Hostnames\" topic.\nDNS\nThe Domain Name System (DNS) server address is reset after the migration because the DNS server address used in the classic network is different from the DNS server address used in a VPC. If you use a custom DNS server address, you must restore the custom DNS server address after the migration.\nOthers\nThe ID, username, and logon password of an ECS instance remain unchanged after you migrate the instance to a VPC.\nIf an ECS instance is added to the vServer group of a Server Load Balancer (SLB) instance before the ECS instance is migrated, the ECS instance is not automatically associated with the SLB instance after the migration. You must add the ECS instance to the vServer group of the SLB instance. For more information, see the Modify a vServer group section of the \"Create and manage a vServer group\" topic.\nYou can no longer add ECS instances in the classic network to the vServer group of an SLB instance.\nCreate snapshots for the disks on the ECS instances to be migrated to back up data.\nFor more information, see Create a snapshot.\nYou are charged for the snapshots. For more information, see Snapshots.\nIf an ECS instance that you want to migrate is associated with an ApsaraDB service and requests access to the private IP address of the ApsaraDB service, use one of the following methods to allow the instance to access the ApsaraDB service after the migration.\nIf the ECS instance accesses the ApsaraDB service by using the public IP address of the ApsaraDB service, the access is not affected by the instance migration.\nTemporarily access the ApsaraDB service in hybrid mode:\nBefore you migrate the ECS instance, set the ApsaraDB service to the hybrid access mode to allow simultaneous access from ECS instances in the classic network and VPCs. For more information, see Hybrid access to ApsaraDB services and Configure the hybrid access solution.\nPerform the following follow-up operations after instance migration:\nAfter you migrate the ECS instance, migrate the ApsaraDB service to the same VPC to which the ECS instance is migrated. During this process, a 30-second disconnection occurs and you cannot access an ApsaraDB RDS instance until the migration is complete. For more information, see the Migrate an ApsaraDB RDS instance from the classic network to a VPC section of this topic.\nIf an ECS instance that you want to migrate is associated with an ApsaraDB service (such as ApsaraDB RDS) that provides the whitelist feature, you must add the CIDR block of the destination vSwitch to a whitelist of the database service before you migrate the instance.\nFor more information, see Configure a whitelist.\n(Optional) To ensure that services can be rapidly restored after migration, we recommend that you configure application services to run on instance startup and monitor service availability.\nDisable or uninstall server security software on the ECS instances to be migrated.\nThe device drivers of ECS instances are updated when the instances are migrated. You must disable or uninstall security software such as Safedog, Huweishen, and Yunsuo on the instances before you migrate the instances.\nReserve at least 500 MiB of free space on the system disk of each ECS instance that you want to migrate. If less than 500 MiB of free space is available on the system disk of each ECS instance that you want to migrate, virtualization drivers may fail to be installed and the instances may be unable to start.\nMake sure that the destination vSwitch has sufficient internal IP addresses available. The number of available internal IP addresses must be greater than the number of ECS instances to be migrated.\nIf an ECS instance that you want to migrate has a public IP address and a public bandwidth of 0 Mbit/s, you must increase the public bandwidth to a value more than 0 Mbit/s before you migrate the instance. A public bandwidth of 0 Mbit/s results in the loss of the public IP address after you migrate the instance. For more information, see the Modify the maximum public bandwidth section of the \"Overview of instance configuration changes\" topic.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Maintenance & Monitoring >  > Migration Plans.\n\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nClick Create Migration Plan.\nIn the Precautions dialog box, select I have read and understood the precautions and click Create Migration Plan.\n\nIn the Configure Migration Plan step, configure the destination zone and VPC, network properties, and network connectivity settings, and click Next.\nIn the Destination Zone and VPC section, configure the parameters. The following table describes the parameters.\n\nParameter\nDescription\nPlan Name\nEnter a name for the migration plan.\nSelect a destination zone\nSelect a destination zone from the drop-down list. The available zones are automatically planned and displayed based on the resource availability. If ECS resources in a zone are sold out, the zone is not displayed. Select one of the available zones from the drop-down list. You can also submit a ticket.\nOnly one zone can be specified in each migration plan. If you want to migrate multiple ECS instances to different zones, you must create multiple migration plans.\nDestination VPC or Create a VPC\nSelect a destination VPC from the drop-down list. The CIDR block of the selected VPC determines whether the internal IP addresses of the ECS instances from the classic network can be retained.\nIf you want to retain the internal IP addresses of the ECS instances, you must select a VPC that is associated with the 10.0.0.0/8 CIDR block. You can select the default option or a VPC that you created.\nIf you have not created VPCs that are associated with the 10.0.0.0/8 CIDR block, select (Default) Automatically create a VPC, CIDR block: 10.0.0.0/8. Then, a VPC that is associated with the 10.0.0.0/8 CIDR block is automatically created.\nIf you already created a VPC that is associated with the 10.0.0.0/8 CIDR block, select the VPC.\nIf you do not need to retain the private IP addresses of the ECS instances, select a VPC that is associated with a CIDR block other than 10.0.0.0/8.\nIn the Instance Network Properties section, configure the parameters. The following table describes the parameters.\n\nParameter\nDescription\nDestination Security Group\nSpecify destination security groups. Valid values:\n(Default) Clone Security Groups of Classic Network-type Instances: The security groups of the ECS instances are automatically cloned from the classic network to the destination VPC. The rules of the new security groups (clone security groups) in the VPC are the same as the rules of the original security groups in the classic network.\nIf the original security groups in the classic network are referenced by managed security groups or contain rules that reference a managed security group, the original security groups cannot be cloned to the destination VPC.\nIf you set Destination VPC or Create a VPC to (Default) Automatically create a VPC, CIDR block: 10.0.0.0/8, Destination Security Group is automatically set to (Default) Clone Security Groups of Classic Network-type Instances and cannot be modified.\nSpecify Security Groups: Select one or more existing security groups from the drop-down list.\nImproper security group settings affect the connectivity of ECS instances. Make sure that your security group rules meet your connectivity requirements.\nMac Address Retention Policy\nSelect the media access control (MAC) address that you want to retain for each ECS instance from the classic network. In the classic network, an ECS instance that is assigned a public IP address has a public MAC address and a private MAC address. In a VPC, each ECS instance has only a private MAC address and can use a NAT device to map the internal IP address of the instance to a public IP address for Internet access.\nYou can select (Default) Private Mac Address or Public Mac Address based on your business requirements.\nIf your business system is associated with a MAC address, retain the MAC address. For example, this situation applies when your software is associated with a MAC address for registration.\n(Default) Private Mac Address: The private MAC addresses of the ECS instances are retained regardless of whether the instances have public MAC addresses.\nPublic Mac Address: If the ECS instances have public MAC addresses, the public MAC addresses are retained. If the ECS instances do not have public MAC addresses, the private MAC addresses of the instances are retained.\nIf your business system is not associated with a MAC address, select (Default) Private Mac Address or Public Mac Address.\nIn the Instance Network Connectivity section, configure the parameters. Then, click Next. The following table describes the parameters.\n\nParameter\nDescription\nRetain Internal IP Address\nSpecify whether to retain the internal IP addresses of the ECS instances from the classic network. If you want to retain the internal IP addresses of the ECS instances, you must specify how to create a vSwitch. If you do not want to retain the internal IP addresses of the ECS instances, you must select a vSwitch from the drop-down list.\n(Default) Yes: retains the internal IP addresses of the ECS instances from the classic network. If you select (Default) Yes, you must configure vSwitch Creation Policy.\nIf you set vSwitch Creation Policy to Automatic, a vSwitch is automatically created and associated with a CIDR block based on the internal IP addresses of the ECS instances. Make sure that the CIDR block corresponding to the internal IP addresses of the ECS instances is not used by other vSwitches. If the CIDR block is used by other vSwitches, the vSwitch cannot be created.\nIf you set Destination VPC or Create a VPC to (Default) Automatically create a VPC, CIDR block: 10.0.0.0/8, Retain Internal IP Address is automatically set to (Default) Yes, and vSwitch Creation Policy is automatically set to Automatic and cannot be modified.\nIf you set vSwitch Creation Policy to Manual, you must create a vSwitch in the specified destination zone based on the internal IP addresses of the ECS instances.\nYou can set vSwitch Creation Policy to Manual only when you select a user-created VPC that is associated with the 10.0.0.0/8 CIDR block for Destination VPC or Create a VPC.\nNo: does not retain the internal IP addresses of the ECS instances from the classic network. You must select a vSwitch from the drop-down list.\nIf you cannot find the vSwitches that you created in the drop-down list, the reason may be that the vSwitches do not reside in the specified destination zone. Create a vSwitch in the destination zone. For more information, see Create and manage a vSwitch.\nEnsure interconnections between the migrated instances and the classic network-type instances\nSpecify whether to allow mutual access over the internal network between migrated instances and unmigrated instances that are included in the migration plan. Configure this parameter based on the value of Retain Internal IP Address.\nRetain Internal IP Address set to (Default) Yes:\nIf you do not want to allow mutual access over the internal network between migrated instances and unmigrated instances that are included in the migration plan, select (Default) No.\nIf you want to allow mutual access over the internal network between migrated instances and unmigrated instances that are included in the migration plan, select Yes. Then, select all ECS instances in the classic network that require mutual access over the internal network in the Select Instances step. You can schedule different migration times for the instances to specify the order in which to migrate the instances.\nECS instances in the classic network that are not included in the migration plan cannot communicate with the ECS instances that are migrated to the specified VPC over the internal network. After this migration plan is created, ECS instances cannot be added to the plan.\nRetain Internal IP Address set to No:\nIf you do not want to allow mutual access over the internal network between migrated instances and unmigrated instances that are included in the migration plan, proceed to the Select Instances step.\nIf you want to allow mutual access over the internal network between migrated instances and unmigrated instances that are included in the migration plan, configure ClassicLink to link the instances to the specified VPC before you migrate the instances. For more information, see Connect an instance in a classic network to a VPC.\nIn the Select Instances step, select ECS instances and click Next.\nIf you set Retain Internal IP Address to (Default) Yes and want to allow mutual access over the internal network between migrated instances and unmigrated instances that are included in the migration plan, you must select all ECS instances in the classic network that require mutual access over the internal network. You can schedule different migration times for the instances to specify the order in which to migrate the instances. After the migration plan is created, you cannot add ECS instances to the plan.\nIn the following figure, the section that is labeled \u2460 indicates the instances that you want to migrate in the first batch, and the section that is labeled \u2461 indicates the instances that you want to migrate in subsequent batches.\n\nIn the Scheduled Migration step, specify the migration time for the instances and click Verify.\nThe instances are stopped and then started again during the migration process. We recommend that you schedule the migration task for your instances during off-peak hours. A unique migration time can be specified for each instance.\nTo specify a migration time for only a single instance, click Schedule Migration Time in the Actions column corresponding to the instance.\nTo specify a migration time for multiple instances that you want to migrate in a batch, select the instances and click Batch Schedule Migration Time.\nFor ECS instances that need to remain in the classic network and communicate with the ECS instances that are migrated by this migration plan, specify a later migration time. Before the migration time, you can reevaluate whether to migrate the ECS instances from the classic network.\nThe following limits apply to the migration time that can be specified for each instance:\nThe migration time cannot be earlier than the local time.\nThe migration time cannot be later than the expiration time of the instance.\nAfter the migration plan is created, the replicas of some disks are checked. The period of time that is required by the check is determined based on the disk size and the number of disks that are queued for the check. The migration starts after the check is complete. Set migration times as prompted.\nIn the Verify dialog box, read the migration considerations and verify whether your migration plan meets the specified requirements.\nIf your migration plan meets the specified requirements, select options and click Confirm and Create.\nIf your migration plan does not meet the requirements, error messages are displayed. You can troubleshoot the errors based on the error messages and modify the relevant parameters to create the migration plan again.\nAfter the migration plan is created, the system migrates the specified ECS instances from the classic network to the destination VPC at the specified times.\nIf an ECS instance is migrated across zones, the system continues to migrate disk data of the instance after the instance is started. In most cases, approximately 4 hours are required to migrate 100 GiB of disk data. During the migration of disk data, the I/O performance of disks degrades and snapshot-related and disk-related operations cannot be performed. The disk data migration does not affect your business. The I/O performance degradatione is imperceptible to the business that is not highly sensitive to I/O performance degradation.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nFind the migrated ECS instances and click the ID of each of these instances.\nOn the Instance Details page, check whether the network type of the instance is VPC.\nIf the instance is migrated to the specified VPC, the network type of the instance changes to VPC.\nCheck the internal network and business runtime environments.\n\nScenario\nMigration plan\nWhat to do next\nMigrate all ECS instances from the classic network to a VPC\nSet Destination VPC or Create a VPC to (Default) Automatically create a VPC, CIDR block: 10.0.0.0/8.\nSet Ensure interconnections between the migrated instances and the classic network-type instances to (Default) No.\nCheck whether your business system runs as expected.\nMigrate some ECS instances to a VPC and retain other ECS instances in the classic network\nSet Destination VPC or Create a VPC to (Default) Automatically create a VPC, CIDR block: 10.0.0.0/8.\nSet Ensure interconnections between the migrated instances and the classic network-type instances to Yes.\nCheck whether your business system runs as expected.\nOther scenarios\nSet Destination VPC or Create a VPC to a VPC that is associated with a CIDR block other than 10.0.0.0/8.\nCheck network connectivity.\nIn this scenario, Retain Internal IP Address is unsupported. If your business is connected by using internal IP addresses, you must configure new internal IP addresses.\nCheck whether your business system runs as expected.\nIf you do not retain the internal IP addresses of ECS instances, but the associated services use domain names that were bound to the original internal IP addresses, modify the /etc/hosts file on the corresponding instances and change the original internal IP addresses to the new internal IP addresses.\nIf you have set Retain Internal IP Address to No in the migration plan, remove the internal IP addresses that are no longer used from the whitelists of other cloud services after the migration.\nThe cloud services include AparaDB RDS, SLB, and Object Storage Service (OSS).\nIf an ECS instance is migrated across zones, its connectivity with other Alibaba Cloud services, such as ApsaraDB RDS, Tair (Redis OSS-compatible), and ApsaraDB for MongoDB, may be affected. Adjust application configurations at the earliest opportunity. For example, you can migrate the corresponding RDS instances to the same zone as the ECS instance to ensure connectivity. For more information, see Migrate an ApsaraDB RDS for MySQL instance across zones.\nIf you have not restarted an ECS instance or upgraded its kernel for an extended period of time, issues may occur after the instance is migrated. For example, a file system check (fsck) may be performed, configuration changes may become invalid, or the instance may be unable to start.\nIf you have not restarted an ECS instance for an extended period of time or after the kernel is upgraded, the system checks the file systems of the instance and updates the configurations of the instance when the instance is restarted. If your ECS instance cannot be started, submit a ticket at the earliest opportunity to contact Alibaba Cloud.\nIf a NAS file system is mounted on an ECS instance, you must replace classic network mount targets with VPC mount targets. For more information, see Replace a classic network mount target with a VPC mount target for a NAS file system.\nIf your ECS instance is associated with an ApsaraDB RDS instance, you must perform the following operations to migrate the ApsaraDB RDS instance to the destination VPC of the ECS instance by using the Switch Network Type feature. For more information, see Change the network type of an ApsaraDB RDS for MySQL instance.\nMigrate an ApsaraDB RDS instance from the classic network to a VPC\nObtain the VPC information of the ECS instance that you migrated.\nIn the left-side navigation pane of the ECS console, choose Instances & Images > Instances.\nClick the ID of the ECS instance that you migrated.\nOn the Instance Details tab, record the VPC ID and vSwitch ID. Then, click the vSwitch ID to obtain information about the zone in which the vSwitch resides.\n\nParameter\nExample\nVPC ID\nvpc-wz9avqy2c3fw8w4******\nvSwitch ID\nvsw-wz98loggfq88msu******\nZone\nShenzhen Zone B\nObtain the network information of the RDS instance in the classic network.\nLog on to the ApsaraDB RDS console.\nIn the left-side navigation pane, click Instances.\nIn the upper-left corner of the top navigation bar, select the region where the RDS instance resides.\nClick the ID of the RDS instance.\nView the region and zone of the RDS instance.\n\nIf the zone of the RDS instance is the same as that of the vSwitch obtained in the previous step, proceed to the next step.\nIf the zone of the RDS instance is different from that of the vSwitch obtained in the previous step, create a vSwitch in the zone of the RDS instance and then proceed to the next step. For information about how to create a vSwitch, see Create and manage a vSwitch.\nIn this example, the vSwitch and the RDS instance both reside in Shenzhen Zone B. You do not need to create a vSwitch.\nIn the left-side navigation pane of the page that appears, click Database Connection.\nClick Switch to VPC.\nIn the dialog box that appears, select the VPC and vSwitch that you obtained and enable the Reserve Original Classic Network Endpoint feature. Then, click OK.\nParameter\nDescription\nSelect a VPC\nSelect the VPC ID that you obtained in Step 1. Example: vpc-wz9avqy2c3fw8w4******.\nSelect a vSwitch\nSelect the vSwitch ID that you obtained in Step 1. Example: vsw-wz98loggfq88msu******.\nIf you created a vSwitch because the RDS instance does not reside in the same zone as the vSwitch that you obtained, select the ID of the vSwitch that you created.\nSpecify whether to select Retain Classic Network\nClear the option. The classic network endpoint is not retained and changes to a VPC endpoint.\nWhen you change the network type from classic network to VPC, a transient connection that lasts approximately 30 seconds occurs and ECS instances that reside in the classic network are immediately disconnected from the RDS instance.\nCheck whether the RDS instance is migrated to the VPC.\nAfter the RDS instance is migrated, you can click Database Connection in the left-side navigation pane. On the Database Connection page of the RDS instance, the network type changes to VPC and the internal endpoint also changes.\n(Conditionally required) If the internal IP address of the ECS instance changes, you must add the CIDR block of the new vSwitch to which the ECS instance connects to the whitelist of the RDS instance.\nThis issue may occur because traffic is not allowed on the required communication ports in the new security groups of the ECS instance. We recommend that you clone the original security group rules of the instance from the classic network. For more information, see Clone a security group.\nYou cannot view the public IP address of the ECS instance from within the operating system in the VPC. If you configured the public IP address of the ECS instance that was assigned before the migration for your IIS website, you must change the status of the IP address of the website to unassigned in IIS Manager after the instance is migrated.\n\nAfter the ECS instance is migrated, the public network interface of the instance is deleted and the FTP service becomes unavailable. We recommend that you perform the following operations:\nConvert the system-assigned public IP address of the instance to an EIP.\nExpose an EIP on an NIC by adding a secondary CIDR block to a VPC.\nSome retired instance types and entry-level instance types of the previous generation do not support ENIs. If the instance type of your instance does not support ENIs, upgrade the instance to an instance type that supports ENIs before you perform the preceding operations. For more information, see Overview of instance configuration changes.\nAfter the Windows instances are migrated, the disks that are attached to the instances are disconnected. We recommend that you perform the following steps to configure the disks to automatically reconnect. For more information, see How do I handle offline disks attached to a Windows ECS instance and configure the SAN policy of the instance?\nLog on to the ECS console.\nIn the left-side navigation pane, choose Maintenance & Monitoring > Cloud Assistant.\nClick Create/Run Command to create and run a Cloud Assistant command.\nIn the Create Command panel, configure the parameters. The following table describes the parameters. For the parameters that are not described in the table, use the default values. For information about more parameters, see Create and run a command.\nParameter\nDescription\nCommand Type\nPowerShell\nCommand content\nSelect Instance\nOne or more Windows instances.\nClick Run and Save.\nECS instances in the classic network have both public network interfaces and private network interfaces. ECS instances in VPCs have only private network interfaces. If your applications are configured to recognize only public IP addresses, you must reconfigure the applications.\nMost FTP clients access FTP servers in passive mode. In passive mode, FTP servers must communicate their IP addresses to FTP clients. In VPCs, public IP addresses cannot be recognized and FTP servers send their internal IP addresses to FTP clients. When the clients use the internal IP addresses to access the servers, errors occur.\nWhen you use an ECS instance that resides in a VPC as an FTP server, we recommend that you communicate the public IP address of the instance to the FTP server program. The procedures that are required to communicate the public IP addresses of ECS instances vary based on the types of FTP server programs. Select a procedure that is suitable for your FTP server program. In the following example, vsftpd is used. Open the configuration file of vsftpd and add the following content to the file:\nReplace <PublicIP> with the static public IP address (also called auto-assigned or system-assigned public IP address) or EIP of your instance. If an EIP is associated with the instance, we recommend that you use the EIP.\nSwitch the network type from classic network to VPC\nChange the network type\nConfigure the hybrid access solution\n"
    },
    "114": {
        "title": "Elastic Compute Service:Connect an instance in the classic network to a VPC",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/connect-a-classic-network-to-a-vpc",
        "content": "This Product\nElastic Compute Service:Connect an instance in the classic network to a VPC\nYou can establish ClassicLink connections to allow Elastic Compute Service (ECS) instances in a classic network to communicate with resources in a virtual private cloud (VPC) over private IP addresses. You can establish ClassicLink connections in scenarios such as during a transition from a classic network to a VPC and when resources in a classic network need to communicate with resources in a VPC over private IP addresses. This topic describes how to connect an instance in a classic network to a VPC by using ClassicLink.\nThe ClassicLink feature of Alibaba Cloud allows you to establish private connections between Alibaba Cloud classic networks and VPCs. Classic networks and VPCs are two types of networks on Alibaba Cloud. By default, classic networks are isolated from VPCs. You can use the ClassicLink feature to connect classic networks to VPCs. This way, resources in the classic networks can communicate with resources in the VPCs. For more information, see Overview of ClassicLink.\nIf you want to associate an ECS instance of Account A with a VPC of Account B, you must first transfer the ECS instance from Account A to Account B.\nLog on to the VPC console.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nIn the list of VPCs, find the VPC to which you want to connect and click the ID of the VPC.\nOn the Basic Information tab, click Enable ClassicLink in the upper-right corner.\nIn the Enable ClassicLink message, click OK.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nAdd a ClassicLink rule to a security group of an ECS instance that resides in a classic network.\nFind the ECS instance that resides in the classic network. In the Actions column, choose  > Network and Security Group > Set VPC Connection Status.\nIn the dialog box that appears, select the VPC to which you want to connect the instance and click Confirm.\nYou can call the AttachClassicLinkVpc API operation to link an instance that is deployed in the classic network to a VPC by establishing a ClassicLink connection between the instance and the VPC.\nClick Go to the instance security group list and add ClassicLink rules.\n\n\nFind a security group of the ECS instance. In the Actions column, click Add Rules.\nOn the Security Group Rules page, click Add ClassicLink Rule in the upper-right corner. In the dialog box that appears, configure the parameters that are described in the following table.\nParameter\nDescription\nClassic Security Group\nThe name of the classic-network security group is displayed.\nSelect VPC\nThe VPC to which to connect the instance.\nVPC-type Security Groups\nThe security groups from the selected VPC that you want to associate with the instance. You can select up to five security groups.\nMode\nThe access mode.\nClassic Network <=> VPCs (recommended): allows mutual access between resources in the classic network and resources in the VPC.\nClassic Network => VPCs: allows resources in the classic network to access resources in the VPC.\nVPCs => Classic Network: allows resources in the VPC to access resources in the classic network.\nProtocol\nThe communication protocol. Example: Custom TCP.\nPort Range\nThe port range. Specify a port range in the <Start port number>/<End port number> format. Example: 80/80, which indicates port 80.\nPriority\nThe priority of the rule. A smaller value indicates a higher priority. Example: 1.\nDescription\nThe description of the rule.\nClick OK.\nPerform the following steps to test the connectivity between the instance and the VPC:\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nView the Network Type column of the ECS instance.\nIf the ECS instance in the classic network is connected to the VPC, the connection status is Connected.\n"
    },
    "115": {
        "title": "Elastic Compute Service:Create and manage ENIs",
        "url": "https://www.alibabacloud.com/help/en/ecs/user-guide/create-an-eni",
        "content": "This Product\nElastic Compute Service:Create and manage ENIs\nENIs can be used to deploy high-availability clusters, perform low-cost failover, and achieve fine-grained network management. If your business requires more detailed network classification and isolation, or if you need to address single point of failure issues with a single network card, you can bind multiple ENIs to an ECS instance to extend the network card capabilities.\nYou can create ENIs when you purchase an instance or create them separately after the instance is created and bind them to the instance.\nThere is a limit on the number of ENIs you can create in a single region. You can visit the Quota Center to view the limits, or you can request to increase the total number of ENIs based on your business needs. For specific operations, see ECS Quota Management.\nWhen purchasing an ECS instance, you can choose to add ENIs that are created with the instance. These ENIs are automatically assigned IP addresses and bound to the instance without additional binding operations. For specific operations, see Custom Purchase Instance.\nSome ECS instance types do not support binding secondary ENIs when creating instances. You can bind them separately after the instance is created. For more information, see ECS Instance Types That Do Not Support Hot Swapping of ENIs.\nENIs created in this manner are automatically released when the associated instance is released. However, you can prevent this by disabling the automatic release feature within the instance settings to keep the ENI after the instance is released.\n\nAfter creating an instance, if you need to better manage and extend the network capabilities of ECS instances, such as adding private IP addresses, building high-availability network environments, creating dedicated network traffic, or isolating different network environments, you can separately create secondary ENIs to meet your needs. ENIs created separately are secondary ENIs and can be bound to instances.\nYou can also create ENIs by calling CreateNetworkInterface.\nLog on to the ECS console.\nIn the left-side navigation pane, select Network & Security > Enis.\nIn the upper-left corner of the page, select the resource group and region where the target resource resides.\nClick Create ENI.\nOn the Create ENI page, complete the relevant settings.\nParameter\nDescription\nENI Name\nCustom. Enter the ENI name as prompted.\nVPC\nSelect the VPC to which the instance is bound. After an ENI is created, its VPC cannot be changed.\nAn ENI can be bound to only an instance that is in the same VPC.\nvSwitch\nSelect a vSwitch in the zone where the instance is located. After an ENI is created, its vSwitch cannot be changed.\nAn ENI and the instance to which it is bound must be in the same zone but can be connected to different vSwitches.\nSecurity Group\nSelect the security group in the specified VPC. You can select one to five security groups.\nYou cannot select basic security groups or advanced security groups at the same time.\nAdd Elastic RDMA Interface\n(Optional) This feature enables the ENI to support eRDMA capabilities. ENIs with this capability can only be attached to instance types that support eRDMA capabilities. For more information, see Elastic RDMA Interface (ERI).\nPrimary Private IP\n(Optional) Enter the primary private IP address of the ENI. This IPv4 address must be an idle IP address within the CIDR block of the vSwitch. If you do not specify an address, an idle private address is automatically assigned to the ENI when it is created. For more information, see Primary Private IP.\nSecondary Private IPv4\n(Optional) Set the secondary private IPv4 address.\nDo Not Assign: The ENI temporarily does not require a secondary private IPv4 address.\nAuto-assign: Manually enter the number of secondary private IPv4 addresses, which can be an integer from 1 to 9. The system automatically assigns the specified number of idle IPv4 addresses from the vSwitch.\nSpecify Address: Manually add secondary private IPv4 addresses. You can add up to nine secondary private IPv4 addresses.\nSpecify Ipv4 Prefix: Assign an IPv4 CIDR block to the ENI. For more information, see IP Prefix.\nFor more information, see Secondary Private IP.\nIPv6\n(Optional) Set the secondary private IPv6 address.\nDo Not Assign: The ENI temporarily does not require a secondary private IPv6 address.\nAuto-assign: Manually enter the number of secondary private IPv6 addresses, which can be an integer from 1 to 10. The system automatically assigns the specified number of idle IPv6 addresses from the vSwitch.\nSpecify Address: Manually complete the last four digits of the secondary private IPv6 address. You can add up to ten secondary private IPv6 addresses.\nSpecify Ipv6 Prefix: Assign an IPv6 CIDR block to the ENI. For more information, see IP Prefix.\nTo set an IPv6 address for the ENI, you need to select a vSwitch that supports IPv6 addresses. If the selected vSwitch does not have the IPv6 address assignment feature enabled, you can click Enable Vswitch Ipv6 to enable it.\nSESSION Timeout\nConfiguration and management of the timeout for established TCP connections, TCP wait and close timeout, and UDP stream timeout. For more information, see Connection Timeout Management.\nDescription\n(Optional) Enter a description for the ENI for easy management.\nResource Group\n(Optional) Select a resource group for multi-user and multi-project hierarchical resource management. For more details about resource groups, see Resource Group.\nTag\n(Optional) Select one or more tags for easy search and resource aggregation. For more details about tags, see Tag.\nClick Create ENI.\nWhen the status of the newly created ENI in the ENI list shows Pending, it indicates that the secondary ENI has been successfully created.\nAn ENI can be bound to only one ECS instance at a time, but an ECS instance can have multiple ENIs bound to it simultaneously. For the number of ENIs that can be bound to each instance type, see Instance Family.\nThe primary ENI is bound when the instance is created. If you want to extend the network interface for an instance, you need to bind the secondary ENI in the Pending state to the target instance.\nThe ENI to be bound must belong to the same VPC and be in the same zone as the target ECS instance.\nThe ECS instance to be bound must be an I/O optimized instance type (see Instance Family or call DescribeInstanceTypes to view the performance data of the target instance type, or see Instance Type Selection Guide for how to select an instance type), and be in the Stopped or Running state.\nSome instance types do not support hot swapping and only support binding secondary ENIs in the Stopped state.\nList of ECS instance types that do not support hot swapping of ENIs\nInstance Family\nInstance Type\nShared Standard Instance Family s6\necs.s6-c1m1.small, ecs.s6-c1m2.large, ecs.s6-c1m2.small, ecs.s6-c1m4.large, ecs.s6-c1m4.small\nEconomy Instance Family e\necs.e-c1m1.large, ecs.e-c1m2.large, ecs.e-c1m4.large\nBurstable Instance Family t6\necs.t6-c1m1.large, ecs.t6-c1m2.large, ecs.t6-c1m4.large, ecs.t6-c2m1.large, ecs.t6-c4m1.large\nBurstable Instance Family t5\necs.t5-c1m1.large, ecs.t5-c1m2.large, ecs.t5-c1m4.large, ecs.t5-lc1m1.small, ecs.t5-lc1m2.large, ecs.t5-lc1m2.small, ecs.t5-lc1m4.large, ecs.t5-lc2m1.nano\nPrevious-generation Shared Instance Families xn4, n4, mn4, e4\necs.xn4.small\necs.n4.small, ecs.n4.large\necs.mn4.small, ecs.mn4.large\necs.e4.small, ecs.e4.large\nIf the ECS instance was last started before April 1, 2018 (including but not limited to starting a newly purchased instance, restarting, or rebooting), you must restart the instance before you can bind ENIs to it.\nYou must restart the ECS instance in the console or by calling RebootInstance. Restarting within the operating system is ineffective.\nWhen purchasing an instance, you can bind up to two ENIs, one as the primary ENI and the other as a secondary ENI.\nWhen purchasing an ECS instance, you can choose to bind ENIs that are already created and in the pending state within the same VPC and zone to the instance as the primary or secondary ENI without additional creation. For specific operations, see Custom Purchase Instance.\n\nAfter the instance is created, only secondary ENIs can be bound.\nBind through the console\nLog on to the ECS console.\nIn the left-side navigation pane, select Network & Security > Enis.\nIn the upper-left corner of the page, select the resource group and region where the target resource resides.\nFind the available secondary ENI, and in the operation column, click Bind Instance.\nIn the Bind Instance dialog box, select the instance and click Confirm.\nRefresh the list. When the status of the ENI shows Bound, it indicates that the ENI has been successfully bound.\nBind through API\nYou can also bind ENIs by calling AttachNetworkInterface, specifying NetworkInterfaceId as the target ENI ID and InstanceId as the instance ID to attach the ENI to an instance of the VPC type.\nSpecify the physical network card index through NetworkCardIndex in the API\nTo support higher network performance, some instance types support physical network card mapping. When attaching ENIs through AttachNetworkInterface, you can specify the NetworkCardIndex parameter to map to the network card on the physical machine, thereby avoiding bandwidth contention and improving the bandwidth capability of the instance. For more information, see Physical Network Card Mapping.\nAfter the ENI is bound to the instance, you need to configure the ENI to take effect within the instance.\nThe primary ENI usually takes effect automatically after the instance is created, and you do not need to configure it. When you attach multiple secondary ENIs to an ECS instance, you need to confirm within the instance whether the ENIs have taken effect.\nIf the bound secondary ENI is not correctly configured within the instance, the ENI cannot communicate normally. Follow the steps below to confirm that the ENI has taken effect.\nSample operating system: Alibaba Cloud Linux 3.2.\nConnect to the Linux instance remotely.\nFor specific operations, see Log on to a Linux instance by using the SSH protocol through Workbench.\nRun the following command to view and confirm the ENI information of the instance.\nThe returned information shows the ENI information of the current instance:\nENI identifier: eth0, eth1. In this example, the instance has two ENIs, one primary ENI eth0 and one secondary ENI eth1.\nENI status: state UP, indicating that the ENI status is normal and the ENI has taken effect within the instance.\n\nIf you see state DOWN as shown in the following figure, it indicates that the ENI has not been successfully loaded and cannot be used normally. You need to configure the Linux operating system to recognize the ENI to ensure that the ENI status is normal.\n\nPrimary private IP address of the ENI: After the ENI status is normal, you can see the primary private IP address of each ENI. For more information, see Primary Private IP.\nIf your ENI is assigned a secondary private IP address but is not recognized within the operating system, you can refer to configure the operating system to recognize the secondary private IP address for reconfiguration.\nRun the following command to view the routing information of the ENI.\n\nUsually, the system configures two routes for the secondary ENI eth1:\nRoute with Destination 192.168.xx.xx: Specifies the route within a specific subnet. This route ensures that the local machine can correctly identify and directly communicate with other hosts within the subnet without additional routers.\nRoute with Destination 0.0.0.0: This route is used to handle packets destined for external networks or other remote networks. When the destination of a packet is not within the local subnet, the packet is sent to the gateway address 192.168.xx.xx for further forwarding.\nBy default, the priority of the default route of the attached ENI is usually lower than that of the default route of eth0, which means that data is preferentially sent from the primary ENI eth0.\nIf you want to specify that packets with private IPs corresponding to the attached ENI eth1 are sent from eth1, you can configure policy-based routing for the secondary ENI to ensure that the data is sent and received from the same source. For more information, see Configure policy-based routing for the ENI.\nSome earlier operating systems, such as Ubuntu16, may not automatically configure the default route for the secondary ENI. After checking the route, it appears as follows. This situation may cause abnormal ENI usage. It is recommended to use a newer version of the operating system distribution, or you can configure it yourself. For specific operations, see Configure the default route for the ENI.\n\nSample operating system: Windows Server 2022.\nConnect to the Windows instance remotely.\nFor specific operations, see Log on to a Windows instance by using the RDP protocol through Workbench.\nOpen Network and Sharing Center.\nClick Change Adapter Settings.\nIn this example, the instance has two ENIs bound (one primary ENI and one secondary ENI). The following information indicates that the ENIs have taken effect within the instance, and no additional configuration is required.\n\nIf the secondary ENI is not correctly recognized due to other reasons, you may see the following information. You can refer to Handling method for ENI configuration failure on Windows instances.\n\nView the status and details of the ENI.\nDouble-click the ENI name to view the ENI status.\nTake the primary ENI Ethernet as an example:\n\nClick Details to view the ENI property information.\nIn the dialog box that appears, you can view the primary private IPv4 address, subnet mask, and default gateway of the ENI:\n\nOpen the Command Prompt page.\nUse the keyboard shortcut Win+R to open the Run dialog box, enter the command cmd, and click OK.\nRun the following command to view the routing information of the ENI.\n\nAfter confirming that the ENI has not taken effect, you can configure it within the system in two ways to activate the ENI.\nMost Windows operating systems automatically recognize ENIs. If you encounter an ENI failure, see Handling method for ENI configuration failure on Windows instances.\nThe multi-nic-util tool is only applicable to the following operating systems: Alibaba Cloud Linux 2, CentOS 6 (CentOS 6.8 and later), CentOS 7 (CentOS 7.3 and later), RedHat.\nAlibaba Cloud strongly recommends avoiding using the multi-nic-util tool in Docker or other containerized environments.\nUsing the multi-nic-util tool will overwrite the original network configuration of the ECS instance. Please be aware of this risk.\nIf you cannot use this tool to configure the ENI for the reasons mentioned above, refer to Method 2: Manually Configure Through Network Configuration Files.\nRun the following command to download and install the multi-nic-util tool (public network access is required).\nRun the following command to restart the ENI service.\nRefer to Step 1: Confirm within the instance whether the ENIs have taken effect again to ensure the ENI status is normal.\nNetwork configuration files vary depending on the Linux distribution and version, along with the management methods and tools for network configuration.\nIt is recommended to back up the original network configuration file before editing it.\nIf you accidentally modify the network configuration file and cannot connect to the instance through Workbench, you can connect to the instance through VNC to review and correct the network configuration file.\nIn this example, we configure the network management protocol as Dynamic Host Configuration Protocol (DHCP) by default. The network interface will automatically obtain the primary private IP address. If you want to configure the network interface with a static IP, see Configure the operating system to recognize the secondary private IP address.\nEnsure that the IP address, MAC address, gateway, and other information in the network configuration file are accurate. Incorrect network configuration may prevent your instance from communicating normally.\nConnect to the ECS instance remotely.\nFor specific operations, see Log on to a Linux instance by using the SSH protocol through Workbench.\nCreate and edit the network configuration file for the ENI based on different Linux distributions and versions.\nThe primary ENI configuration file is usually generated automatically. The following example explains how to configure a secondary ENI.\nApplicable operating systems: Alibaba Cloud Linux 2/3, CentOS 6/7/8, Red Hat 6/7/8/9, Anolis 7/8, Fedora 33/34/35, etc.\nNetwork interface configuration file: /etc/sysconfig/network-scripts/ifcfg-*\nEach network interface has a corresponding configuration file, such as ifcfg-eth0, ifcfg-eth1, ifcfg-eth2, etc.\nSample configuration: Run the following command to create and edit the configuration file for the secondary ENI eth1, and configure the network interface settings.\nDEVICE: Specifies the network interface identifier, such as eth1, eth2, etc.\nTYPE: The type of network interface. Ethernet indicates an Ethernet-type interface.\nBOOTPROTO: Sets the method for obtaining an IP address. When set to dhcp, the interface will automatically obtain an IP address from the DHCP server on the network. If set to static, you need to manually set the static IP address, subnet mask, etc.\nONBOOT: Controls whether this network interface is activated when the system starts. A value of yes means the network interface will be automatically enabled when the system starts; if no, it will not be automatically enabled unless started manually.\nDEFROUTE: Whether to configure the current network interface as the default route exit.\nFor the primary ENI eth0, you do not need to configure this parameter. The system usually automatically generates the highest priority default route for the primary ENI.\nTo avoid changing the active default route of the ECS instance when starting the secondary ENI, it is recommended not to set eth1 as the default route (after setting, eth1 may replace eth0 as the default route exit, causing communication issues with your primary ENI). In a multi-ENI environment, you can control the traffic forwarding path of the ENI by configuring policy-based routing for the ENI.\nNetplan is a newer network configuration framework that has become the default network configuration method for Ubuntu since Ubuntu 18.04 LTS.\nApplicable operating systems: Ubuntu 18/20/22/24\nNetwork interface configuration file: /etc/netplan/*.yaml\nThe system recognizes YAML files in the /etc/netplan directory, and each network interface can have a separate YAML file.\nThe default primary ENI network configuration file 50-cloud-init.yaml is automatically generated by cloud-init when the system starts.\nSample configuration: Run the following command to create and edit the configuration file for the secondary ENI eth1, and configure the network interface settings.\nBy default, the network configuration file for the primary ENI already exists. To ensure the YAML file format is correct, you can generate the network interface configuration file for the secondary ENI by using cp 50-cloud-init.yaml ethX-netcfg.yaml , and then modify the corresponding information as shown below.\ndhcp4: Whether to enable DHCP for IPv4 on this interface, with values of true or false.\nmatch: Matches the attributes of the network interface, such as macaddress.\nYou can view the MAC address of the ENI in the console or through the API.\nApplicable operating systems: Debian, early versions of Ubuntu, such as Ubuntu 14/16, Debian 8/9/10, etc.\nNetwork interface configuration file: /etc/network/interfaces\nBy editing this file, users can manually configure the IP address, subnet mask, gateway, DNS, and other information of the network interface, along with set static IP or DHCP modes.\nWith the popularity of Systemd and its network management tools, this method has gradually been replaced in newer versions of Ubuntu and some other distributions.\nMain configuration items:: The file contains configurations for the type of interface, IP address, subnet mask, gateway, DNS information, etc.\nSample configuration: Run the following command to edit the network configuration file and configure the network interface settings.\nThe configurations for the primary ENI (eth0) and the secondary ENI (eth1) are maintained in the same configuration file. Be careful not to omit the information for the primary ENI.\nauto <interface>: Automatically activates the network interface when the system starts.\niface <interface> inet <method>: Defines the configuration method for the network interface.\ninet: Indicates the definition of IPv4-related configurations.\nmethod: Sets the method for obtaining an IP address. When set to dhcp, the interface will use the Dynamic Host Configuration Protocol (DHCP) to automatically obtain an IP address, subnet mask, default gateway, and other necessary network parameters. If set to static, you need to manually set the static IP address, subnet mask, etc.\nApplicable operating systems: SUSE Linux 11/12/15, OpenSUSE 15, etc.\nNetwork interface configuration file: /etc/sysconfig/network/ifcfg-*\nEach network interface has a corresponding configuration file, such as ifcfg-eth0, ifcfg-eth1, ifcfg-eth2, etc.\nSample configuration: Run the following command to create and edit the configuration file for the secondary ENI eth1, and configure the network interface settings.\nBOOTPROTO: Specifies how to obtain the IP address. dhcp means that the interface will automatically obtain an IP address and other related network configuration information (such as subnet mask, default gateway, and DNS server address) from the DHCP server on the network.\nSTARTMODE: Defines how this network interface is handled when the system starts. Setting it to 'auto' means that as long as the system starts and detects that this interface is available, it will attempt to activate this network interface.\nRun the following command to restart the network service.\nRestart the network service to allow the new configurations to take effect.\nOperating system\nCommand to restart the network service\nAlibaba Cloud Linux 2\nCentOS 7\nRed Hat 7\nAnolis 7\nSUSE Linux 11, SUSE Linux 12, and SUSE Linux 15\nopenSUSE 15 and openSUSE 42\nsudo service network restart\nor sudo systemctl restart network\nCentOS 6\nRed Hat 6\nsudo service network restart\nAlibaba Cloud Linux 3\nCentOS 8\nRed Hat 8\nAnolis 8\nFedora 33, Fedora 34, and Fedora 35\nsudo systemctl restart NetworkManager or sudo reboot\nUbuntu 18, Ubuntu 20, and Ubuntu 22\nDebian 12\nsudo netplan apply\nUbuntu 14 and Ubuntu 16\nDebian 8, Debian 9, Debian 10, and Debian 11\nsudo systemctl restart networking or sudo reboot\nRefer to Step 1: Confirm within the instance whether the ENIs have taken effect again to ensure the ENI status is normal.\nUpon assignment to a specific VPC and subnet (vSwitch), an ENI receives a primary private IPv4 address from within the subnet by default. ECS instances utilize this private IP address for internal network communication.\nFor business needs that require multiple IP addresses, such as multi-application hosting, failover, and load balancing, you can assign additional private IP addresses within the subnet to the ENI. For detailed instructions, see Add Secondary Private IP Addresses to an ENI.\nIn a single primary ENI scenario, you can assign a static public IP to the instance (primary ENI) for public network communication. For more information, see Static Public IP.\nFor multi-ENI or more flexible management scenarios, you can bind an Elastic IP Address (EIP) to the ENI for public network communication. EIPs offer greater flexibility than static public IPs as they can be easily bound and unbound. For more information, see Bind an EIP to an ENI.\nYou can also bind an ECS instance to one or more ENIs and assign EIPs to multiple private IPs of the ENI, allowing the ECS instance to have multiple public IP addresses. For detailed instructions, see Bind Multiple EIPs to an ECS Instance in Normal Mode.\nAfter binding an EIP to a secondary ENI, ensure that the ENI is attached to the instance and has taken effect, so the EIP functions properly. For more information, see Configure the ENI to Take Effect Within the Instance.\nWhen using a secondary ENI with an EIP or NAT Gateway, the default routing priority is lower than that of the primary ENI. By default, outbound traffic uses the primary ENI, which may lead to communication issues if inbound traffic uses the secondary ENI. To ensure consistent traffic flow, configure policy-based routing to direct traffic to return via the same path it arrived. For more information, see Configure Policy-Based Routing for the ENI.\nIf the ENI and routing are correctly configured but you are unable to ping the public IP, further investigation into the security group, firewall, and other configurations may be necessary. For more information, see Troubleshooting Methods for Failing to Ping the Public IP of an ECS Instance.\nENIs are associated with security groups to provide network-layer security control.\nThe security group associated with an ECS instance governs the primary ENI of that instance. This primary ENI is automatically part of the same security group as the ECS instance, and its associated security group cannot be modified independently. To change the security group for the primary ENI, you must modify the security group of the ECS instance itself. For more information, see Add, remove, or change the security group of an instance.\nSecondary ENIs attached to an ECS instance can be linked to different security groups within the same VPC and zone as the instance. You can specify the security group for an ENI during its creation, or change the security group for an ENI after it has been created.\nSetting multiple secondary IPv4 or IPv6 addresses for an ENI means these addresses will also be governed by the ENI's associated security group. You can establish detailed security group rules based on source IP addresses, application-layer protocols, ports, and more to enable fine-grained access control for each ENI. For more information, see Manage security group rules."
    },
    "116": {
        "title": "Elastic Compute Service:Configure IPv6 communication for an ECS instance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/configure-ipv6-addresses",
        "content": "This Product\nElastic Compute Service:Configure IPv6 communication for an ECS instance\nIf you want to implement IPv6 communication over the Internet or between private networks in a virtual private cloud (VPC), you can create an Elastic Compute Service (ECS) instance that is assigned IPv6 addresses in the VPC. Make sure that the VPC and the vSwitch that you want to connect to the instance are assigned IPv6 CIDR blocks. This topic describes how to configure an ECS instance to communicate over IPv6, assign an IPv6 address to an ECS instance, and configure an IPv6 address for an ECS instance.\nDue to the depletion of IPv4 addresses, network engineers spend a large amount of time and effort resolving issues such as address conflicts in an IPv4 environment. Compared with IPv4 addresses, more IPv6 addresses are available and allow more types of devices to access the Internet.\nIPv6 gateways route IPv6 traffic to and from VPCs. By default, an IPv6 address is used only for communication within a VPC. You can enable IPv6 Internet bandwidth for an IPv6 address of an IPv6 gateway in the VPC console. In this way, the IPv6 address can be used for communication over the Internet. For more information, see What is an IPv6 gateway?\nArea\nRegions\nAsia Pacific - China\nChina (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Hangzhou), China (Shanghai), China (Fuzhou - Local Region), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), and China (Hong Kong)\nAsia Pacific - Others\nPhilippines (Manila), Singapore, Japan (Tokyo), South Korea (Seoul), Indonesia (Jakarta), Malaysia (Kuala Lumpur), and Thailand (Bangkok)\nEurope & Americas\nUS (Virginia), US (Silicon Valley), Germany (Frankfurt), and UK (London)\nMiddle East\nSAU (Riyadh - Partner Region)\nThe SAU (Riyadh - Partner Region) region is operated by a partner.\nic5, compute-intensive instance family\nse1, memory-optimized instance family\nd1, big data instance family\ni2g, instance family with local SSDs, and i1, instance family with local SSDs\nhfc5, compute-optimized instance family with high clock speeds, and hfg5, general-purpose instance family with high clock speeds\nebmg5, general-purpose ECS Bare Metal Instance family, and ebmr5s, network-enhanced memory-optimized ECS Bare Metal Instance family\nxn4, n4, mn4, and e4, previous-generation shared instance families\nscch5, SCC instance family with high clock speeds\ngn5, GPU-accelerated compute-optimized instance family\nn1, n2, and e3, shared instance families\nsn2, general-purpose instance family, and sn1, general-purpose instance family\nYou can click Quick Deploy to perform the following operations.\nMake sure that IPv6 is enabled for the VPC in which the ECS instance that you want to manage resides and for the vSwitch to which the instance is connected. For more information, see Enable IPv6 for a VPC and Enable IPv6 for a vSwitch.\n\n\nAssign an IPv6 address to an ECS instance to allow the instance to communicate with other instances or the Internet over IPv6.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Instances & Images > Instances.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind the ECS instance that you want to manage and choose  > Network and Security Group > Manage IPv6 Addresses in the Actions column.\nIn the Manage Secondary Private IP Address dialog box, assign an IPv6 address as prompted.\n\nClick Confirm.\nWhen you create an ECS instance, take note of the following parameters. For information about other parameters, see Create an instance on the Custom Launch tab.\nNetwork and Zone: Select a VPC and a vSwitch that are assigned IPv6 CIDR blocks.\nInstance: Search for instance types that support IPv6 and select an instance type from the search results.\n\nBandwidths & Security Groups: Click ENI\uff5cIPv6(Optional) and select Assign IPv6 Address Free of Charge.\n\nAfter you assign the IPv6 address to the ECS instance, you can view information about the IPv6 address in the ECS console. For more information, see View IP addresses.\nYou can configure an IPv6 address for a network interface card (NIC) of an ECS instance. This way, the IPv6 address can be identified and takes effect in the operating system of the instance.\nSpecific images support automatic configuration and recognition of IPv6 addresses. Perform the following steps to check whether the operating system of the ECS instance can recognize IPv6 addresses.\nConnect to the Linux instance.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nRun the ip -6 addr show or ifconfig command.\nThe following command output contains a global unicast IPv6 address and a link-local IPv6 address, which indicates that the IPv6 address that you assigned to the ECS instance is automatically recognized by the operating system. In this case, skip this step for configuring an IPv6 address. If the IPv6 address is not recognized by the operating system, proceed with the following operations.\n\nConnect to the Windows instance.\nFor more information, see Connect to a Windows instance by using a password.\nOpen the Command Prompt window and run the ipconfig command.\nThe following command output contains a global unicast IPv6 address and a link-local IPv6 address, which indicates that the IPv6 address that you assigned to the ECS instance is automatically recognized by the operating system. In this case, skip this step for configuring an IPv6 address. If the IPv6 address is not recognized by the operating system, proceed with the following operations.\n\nConfigure an IPv6 address.\nTo automatically configure an IPv6 address, you must install Cloud Assistant Agent. If your instance does not support Cloud Assistant Agent or Cloud Assistant Agent is not installed on your instance, manually configure an IPv6 address.\nCloud Assistant Agent is installed on the ECS instance. If Cloud Assistant Agent is not installed on the ECS instance, install Cloud Assistant Agent as described in Install Cloud Assistant Agent.\nThe ECS instance runs one of the following operating systems: Alibaba Cloud Linux 2, Alibaba Cloud Linux 3, CentOS 6, CentOS 7, CentOS 8, Red Hat 6, Red Hat 7, Anolis OS, Fedora, Ubuntu 14, Ubuntu 16, Ubuntu 18, Ubuntu 20, Debian 8, Debian 9, Debian 10, Debian 11, SUSE 11, SUSE 12, SUSE 15, openSUSE 15, openSUSE 42, and FreeBSD 11.\nDuring the configuration, Cloud Assistant is used, and NICs and the network service are restarted. This may cause a brief network interruption. Proceed with caution.\nConnect to the Linux instance.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nRun the following command to configure an IPv6 address.\nBy default, the following command automatically checks whether the ecs-utils-ipv6 plug-in is installed or whether the latest version of the plug-in is installed. If the plug-in is not installed or runs an earlier version, the system automatically downloads and installs the latest version of the plug-in. Make sure that the ECS instance can access the Internet.\nConnect to the Linux instance.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nRun the ip addr | grep inet6 or ifconfig | grep inet6 command to check whether IPv6 is enabled for the instance.\nIf the command output does not contain inet6 information, IPv6 is disabled for the instance. Perform the following operations to enable IPv6.\nEnable IPv6\nRun the following command to modify the /etc/sysctl.conf configuration file:\nPress the I key to enter Insert mode, find the following content, and replace 1 at the end of each line with 0:\nTo enable IPv6 for a specific NIC, use the following setting:\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command to check whether the configurations in the /etc/sysctl.conf file are consistent with the configurations in the /etc/sysctl.conf file in the initram file system (initramfs):\nAn initramfs is configured for Alibaba Cloud Linux 2. If the configurations in the /etc/sysctl.conf file in the initramfs are inconsistent with the configurations in the /etc/sysctl.conf file, the system may accept the configurations in the /etc/sysctl.conf file in the initramfs.\nIf the configurations are inconsistent, run the following command to generate a new initramfs:\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nRun the ip addr | grep inet6 or ifconfig | grep inet6 command to check whether IPv6 is enabled.\nIf the command output contains inet6 information, IPv6 is enabled.\nRun the following command to modify the /etc/modprobe.d/disable_ipv6.conf configuration file:\nPress the I key to enter Insert mode and replace options ipv6 disable=1 with options ipv6 disable=0.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command to modify the /etc/sysconfig/network configuration file:\nPress the I key to enter Insert mode and replace NETWORKING_IPV6=no with NETWORKING_IPV6=yes.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\n(Optional) Run the following commands in sequence to reload the IPv6 module.\nIf the ECS instance runs a CentOS 6 operating system, perform this step. Otherwise, skip this step.\nIf the IPv6 module is loaded, the following content is returned:\nThe parameter value in the third column of the returned content cannot be 0. If the parameter value is 0, you must re-enable IPv6.\nRun the following command to modify the /etc/sysctl.conf configuration file:\nPress the I key to enter Insert mode, find the following content, and then replace 1 at the end of each line with 0:\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command for the configurations to take effect:\nRun the following command to modify the /etc/default/grub configuration file:\nPress the I key to enter Insert mode and delete ipv6.disable=1 from the file.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command to modify the /boot/grub/grub.cfg configuration file:\nPress the I key to enter Insert mode and delete ipv6.disable=1 from the file.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRestart the Linux instance. For more information, see Restart an instance.\nRun the following command to modify the /etc/sysctl.conf configuration file:\nPress the I key to enter Insert mode, find the following content, and then replace 1 at the end of each line with 0.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command for the configurations to take effect:\nRun the following command to modify the /etc/sysctl.conf configuration file:\nPress the I key to enter Insert mode, find the following content, and then replace 1 at the end of each line with 0.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command for the configurations to take effect:\nRun the following command to modify the /etc/rc.conf configuration file:\nPress the I key to enter Insert mode and add ipv6_activate_all_interfaces=\"YES\" to the file.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command to restart the network service for the configurations to take effect:\nRun the following command to modify the /etc/modprobe.d/50-ipv6.conf configuration file:\nPress the I key to enter Insert mode and delete install ipv6 /bin/true from the file.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command to modify the /etc/sysctl.conf configuration file:\nPress the I key to enter Insert mode, find the following content, and then replace 1 at the end of each line with 0.\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRun the following command for the configurations to take effect:\nIf the command output contains inet6 information, IPv6 is enabled for the ECS instance. You can configure an IPv6 address.\nConfigure an IPv6 address.\nRun the following command to open the NIC configuration file:\nReplace eth0 with the actual NIC name. After you modify the configuration file, save the changes and close the file.\nPress the I key to enter Insert mode. Add the following configurations based on the actual information in the file:\nPress the Esc key, enter :wq, and then press the Enter key to save the changes and close the file.\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nCheck whether the NIC configuration file contains the IPV6INIT=yes and DHCPV6C=yes configurations. If the configuration file contains the configurations, proceed to the next step. If the configuration file does not contain the configurations, add the configurations to the file.\nIn this example, eth0 is used. Replace eth0 with the actual NIC name. After you modify the configuration file, save the changes and close the file.\nDisable the feature that allows cloud-init to modify the NIC files in the /etc/sysconfig/network-scripts/ directory.\nYou do not need to manually configure the assigned IPv6 addresses. However, the IPv6 addresses may be lost when the ECS instance is restarted. You must disable the feature that allows cloud-init to modify NIC files.\nRun the vi /etc/cloud/cloud.cfg command to open the NIC configuration file.\nAdd the following content before Example datasource config:\nAfter you modify the configuration file, save the changes and close the file.\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nRun the vi /etc/network/interfaces command to open the NIC configuration file and add the following content to the file based on the actual information:\nReplace eth0 with the actual NIC name. After you modify the configuration file, save the changes and close the file.\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nDisable the feature that allows cloud-init to modify the NIC files in the /etc/sysconfig/network-scripts/ directory.\nYou do not need to manually configure the assigned IPv6 addresses. However, the IPv6 addresses may be lost when the ECS instance is restarted. You must disable the feature that allows cloud-init to modify NIC files.\nRun the vi /etc/cloud/cloud.cfg command to open the NIC configuration file.\nAdd the following information before Example datasource config:\nAfter you modify the configuration file, save the changes and close the file.\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nRun the vi /etc/network/interfaces command to open the NIC configuration file and add the following content to the file based on the actual information:\nReplace eth0 with the actual NIC name. After you modify the configuration file, save the changes and close the file.\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nRun the vi /etc/rc.conf command to open the NIC configuration file and add the following content to the file based on the actual information:\nReplace vtnet0 with the actual NIC name. After you modify the configuration file, save the changes and close the file.\nApply the following changes to the NIC configuration file. Then, save the changes and close the file.\nAfter you apply the changes, the NIC configuration file contains the following content:\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nCheck whether the NIC configuration file contains the IPV6INIT=yes and DHCPV6C=yes configurations. If the configuration file contains the configurations, no additional operations are required. If the configuration file does not contain the configurations, add the configurations to the file.\nReplace eth0 with the actual NIC name. After you modify the configuration file, save the changes and close the file.\nRestart the ECS instance for the configurations to take effect. For more information, see Restart an instance.\nConnect to the Windows instance.\nFor more information, see Connect to a Windows instance by using a password.\nOpen the Command Prompt window and run the ipconfig command to check whether IPv6 is enabled for the ECS instance.\nIf the command output does not contain inet6 information, IPv6 is disabled for the ECS instance. Perform the following operations to enable IPv6.\nEnable IPv6\nChoose Control Panel > Network and Sharing Center > Network Connections.\nClick the name of the current network connection. In the dialog box that appears, click Properties.\nSelect Internet Protocol Version 6 (TCP/IPv6).\nTo enable IPv6 in Windows Server 2008, Windows Server 2012, Windows Server 2016, Windows Server 2019, or Windows Server 2022, perform the following operations:\nCheck whether the IPv6 option is selected. If the IPv6 option is not selected, select the option and click OK.\nTo enable IPv6 in Windows Server 2003, perform the following operations:\nThe operations vary based on whether IPv6 is installed.\nIf IPv6 is installed, select Internet Protocol Version 6 (TCP/IPv6) and click OK.\nIf IPv6 is not installed, perform the following operations:\nIn the Local Area Connection Properties dialog box, click Install. In the Select Network Component Type dialog box, choose Protocol > Add.\nIn the Select Network Protocol dialog box, select Microsoft TCP/IP Version 6 and click OK.\nSelect Internet Protocol Version 6 (TCP/IPv6) and click OK.\nIf the command output contains inet6 information, IPv6 is enabled for the ECS instance. You can configure an IPv6 address.\nConfigure an IPv6 address.\nOn the Instance Details page, obtain the generated IPv6 address.\nConfigure the IPv6 address.\nTo configure an IPv6 address in Windows Server 2008, Windows Server 2012, or Windows Server 2016, perform the following operations:\nChoose Control Panel > Network and Internet > Network and Sharing Center.\nClick the name of the current network connection. In the dialog box that appears, click Properties.\nChoose Internet Protocol Version 6 (TCP/IPv6) > Properties.\nSelect Use the Following IPv6 Address, enter the IPv6 address, subnet prefix length, and IPv6 gateway, and then click OK.\n(Optional) To associate multiple IPv6 addresses, perform the following operations: In the Internet Protocol Version 6 (TCP/IP) Properties dialog box, click Advanced. In the Advanced Settings dialog box, click Add to add multiple IPv6 addresses, and then click OK.\nTo configure an IPv6 address in Windows Server 2003, perform the following operations:\nChoose Control Panel > Network Connections to view the current network connection name. In this example, Local Area Connection 2 is displayed.\nOn the Windows desktop, press Win+R to open the Run dialog box. Then, enter cmd and click OK to open the Command Prompt window.\nAdd IPv6 addresses.\nRun the following command to add a single IPv6 address:\nRun the following commands to add multiple IPv6 addresses:\nRun the following command to add the default route:\n(Conditionally required) If your ECS instance runs a Linux operating system, perform this step. Otherwise, skip this step.\nRun the following command to check whether the multi-NIC configuration tool is installed on the ECS instance:\nIf the following information is returned, the multi-NIC configuration tool is pre-installed on the ECS instance. You need to modify the eni-function file of the multi-NIC configuration tool.\nBy default, the multi-NIC configuration tool does not support IPv6. If the tool is pre-installed on a Linux instance, the NICs in the Linux operating system cannot automatically identify IPv6 addresses, and the operating system cannot obtain IPv6 addresses after the ECS instance is restarted.\n\nModify the eni-function file\nRun the following command to modify the eni-function file:\nPress the I key to enter Insert mode, change IPV6INIT=no to IPV6INIT=yes, add the DHCPV6C=yes configuration, save the changes, and then close the file.\n\nCheck whether the configuration is successful. Run the ifconfig or ipconfig command. If the command output contains the result obtained in Step 1, the configuration is successful.\nVerify that the ECS instance can communicate with other Alibaba Cloud resources in the same VPC.\nTest VPC connectivity\nWhen you test the network connectivity of the IPv6 address, make sure that the server and client support IPv6 and are configured with IPv6 addresses. In this example, ECS01 and ECS02 must be assigned IPv6 addresses.\nRun the ping6 <Private IPv6 address of ECS02> command on the ECS01 instance to ping the IPv6 address of the ECS02 instance and check whether ECS01 can access ECS02 within the VPC.\nIf ECS01 can receive ICMPv6 echo reply packets, the connection is established. The test result shows that ECS01 can access ECS02 by using the IPv6 address.\nRun the ping6 command on the ECS02 instance to ping the IPv6 address of the ECS01 instance and check whether ECS02 can access ECS01 within the VPC.\nIf ECS02 can receive ICMPv6 echo reply packets, the connection is established. The test result shows that ECS02 can access ECS01 by using the IPv6 address.\nBy default, the IPv6 address of an ECS instance can be used only for communication within a VPC. To connect to the Internet by using the IPv6 address, enable IPv6 Internet bandwidth by performing the following steps:\nLog on to the VPC console.\nIn the left-side navigation pane, choose Access to Internet > IPv6 Gateway.\nOn the IPv6 Gateway page, find the IPv6 gateway that corresponds to the VPC in which the ECS instance resides and click the IPv6 gateway ID.\nOn the details page of the IPv6 gateway, click the IPv6 Internet Bandwidth tab, find the IPv6 address for which you want to enable Internet bandwidth, and then click Activate Internet Bandwidth in the Actions column.\nOn the IPv6 Internet Bandwidth (PostPay) page, specify the parameters described in the following table, click Buy Now, and then complete the payment.\nParameter\nDescription\nTraffic\nSelect a metering method for the Internet bandwidth.\nValid values: Pay-By-Bandwidth and Pay-By-Data-Transfer. For more information, see Billing.\nBandwidth\nSpecify a maximum value for the Internet bandwidth.\nBilling cycle\nSelect a billing cycle for the Internet bandwidth. Valid values: Day (By Day) and Hour (By Hour).\nIf you set Traffic to Pay-By-Bandwidth, you can select only Day (By Day).\nIf you set Traffic to Pay-By-Data-Transfer, you can select only Hour (By Hour).\nAfter you enable IPv6 Internet bandwidth, you can test the Internet connectivity of the IPv6 address.\nWhen you test the network connectivity of the IPv6 address, make sure that the server and client support IPv6 and are configured with IPv6 addresses.\nThe following command output indicates that the ECS instance can access the website.\nIn this example, the aliyun.com website supports IPv6. After your ECS instance is configured, you can access the aliyun.com website over IPv6 on the instance.\nIPv4 communication and IPv6 communication are independent of each other. If the current security group rules do not meet your business requirements, configure IPv6 security group rules for your instances to increase network security.\nAdd IPv6 security group rules\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Security Groups.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nFind the security group to which you want to add rules and click Manage Rules in the Operation column.\nOn the details page of the security group, click the Inbound or Outbound tab in the Access Rule section.\nAdd security group rules. For information about how to add a security group rule, see Add a security group rule.\nWhen you add an IPv6 security group rule, set Authorization Object to an IPv6 CIDR block. Example: 2001:db8:1234:1a00::***. For more information about security group rules, see Security group rules.\nYou can delete IPv6 addresses that you no longer require. After you delete the IPv6 address of an ECS instance, the instance can still use IPv4 addresses. This section describes how to delete an IPv6 address in the ECS console.\nMake sure that the ECS instance is in the Running or Stopped state.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Elastic Network Interfaces.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\nOn the Elastic Network Interfaces page, find the ENI that is bound to the instance and assigned an IPv6 address and click Manage ENI IP Addresses in the Operation column.\nIn the Manage ENI IP Addresses dialog box, click the  icon to the right of an IPv6 address in the IPv6 section.\nClick Confirm.\nIf an IPv6 address does not require access to the Internet, you can delete the Internet bandwidth of the IPv6 address. For more information, see the Delete IPv6 Internet bandwidth section of the \"Enable and manage IPv6 Internet bandwidth\" topic.\nYou can add and manage IPv6 routes in a routing table to manage IPv6 traffic in a VPC. For more information, see Create and manage IPv6 routes.\n"
    },
    "117": {
        "title": "Elastic Compute Service:Manage SSH key pairs",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/key-pairs",
        "content": "This Product\nElastic Compute Service:Manage SSH key pairs\nWhen you connect to an Elastic Compute Service (ECS) Linux instance over SSH, you can specify a key pair without the need to enter a password for authentication.\nAn SSH key pair is a credential used to connect to an ECS instance over SSH. An SSH key pair consists of a public key and a private key. The public key is automatically stored on the instance. You must securely keep the private key on your on-premises computer. Keys must be used in pairs. The public key is used to encrypt data and the private key is used to decrypt data. Data encrypted by using the public key can only be decrypted by using the private key.\nSecurity and reliability\nThe security strength of SSH key pairs is higher than that of regular passwords. The difficulty of reverse-engineering a private key from a public key is extremely high, which eliminates the threat of brute-force cracking.\nConvenience\nYou can use an SSH key pair to connect to an instance by using SSH commands or related tools, which is password free.\nYou can connect to multiple Linux instances at the same time by using an SSH key pair, which is a recommended logon method that allows you to batch manage Linux instances in a more convenient manner.\nThe following figure shows the simplified SSH key pair-based authentication process. The client initiates a logon request to the server. Upon receipt of the request, the server encrypts a random string by using the public key and replies the client with the encrypted string. Then, the client decrypts the string by using the private key and returns the string to the server. The server authenticates the client by checking whether the two strings are consistent.\nYou can manage key pairs on the Key Pairs page in the ECS console, as shown in the following figure. Perform the following steps to go to the Key Pairs page. On the Key Pairs page, you can view information about all key pairs in the current region and manage key pairs.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Key Pairs.\nIn the top navigation bar, select the region and resource group to which the resource belongs.\n\nTo query all key pairs in a specific region, call the DescribeKeyPairs operation. For more information, see DescribeKeyPairs.\nYou can create a key pair in the ECS console. After you create a key pair, the private key of the key pair is automatically downloaded. You must securely store and ensure the confidentiality of the private key. ECS stores the public key, but not the private key. To connect to an ECS instance to which an SSH key pair is bound, you must provide the private key.\nYou can have up to 500 SSH key pairs in a region.\nPerform the following steps to automatically create a key pair in the ECS console:\nOn the Key Pairs page, click Create SSH Key Pair.\nIn the Create SSH Key Pair dialog box, configure the following parameters:\nName: The name of the key pair must be 2 to 128 characters in length and can contain letters, digits, periods (.), underscores (_), hyphens (-), and colons (:). The name cannot start with a special character or a digit.\nCreation Type: Select Auto-create. The system automatically creates a key pair. The private key is automatically downloaded after the key pair is created. The private key can be downloaded only once. You must securely store the private key file.\nResource Group: You can assign the key pair to a resource group to facilitate management. For more information, see Resource groups.\nTags: You can add one or more tags to a key pair to facilitate resource search and aggregation. For more information, see Tags.\nClick OK.\nAfter the key pair is created, your browser downloads the private key file (<Key pair name>.pem) to your computer.\n\nYou can call the CreateKeyPair operation to create an SSH key pair. For more information, see CreateKeyPair .\nTo view information about the public key of a key pair, perform the following steps to obtain the public key from the private key.\nRun the ssh-keygen command and specify the path in which the .pem file is stored.\nExample of the returned public key information:\nIf the command fails, run the chmod 400 my-key-pair.pem command to change the permissions to ensure that only you can view the public key file.\nTo view public key information, perform the following operations:\nStart PuTTYgen.\nClick Load.\nSelect the .ppk or .pem file.\nPuTTYgen displays the public key information.\nConnect to a Linux instance.\nFor more information, see Connect to a Linux instance by using Workbench with an SSH key pair in a VPC.\nRun the following command to view the public key information of an SSH key pair:\nThe public key information is stored in the ~/.ssh/authorized_keys file. Open the file on the instance to view the public key information.\nPublic keys that you want to import to ECS must be encoded in Base64 and support one of the following encryption methods:\nrsa\ndsa\nssh-rsa\nssh-dss\necdsa\nssh-rsa-cert-v00@openssh.com\nssh-dss-cert-v00@openssh.com\nssh-rsa-cert-v01@openssh.com\nssh-dss-cert-v01@openssh.com\necdsa-sha2-nistp256-cert-v01@openssh.com\necdsa-sha2-nistp384-cert-v01@openssh.com\necdsa-sha2-nistp521-cert-v01@openssh.com\nPerform the following steps to automatically create a key pair in the ECS console.\nOn the Key Pairs page, click Create SSH Key Pair.\nIn the Create SSH Key Pair dialog box, configure the following parameters:\nName: The name of the key pair must be 2 to 128 characters in length and can contain letters, digits, periods (.), underscores (_), hyphens (-), and colons (:). The name cannot start with a special character or a digit.\nCreation Type: Select Import. If you select this option, you must provide the public key file.\nPublic Key: Enter the content of the public key file that you want to import.\nResource Group: You can add the key pair to a resource group to facilitate management. For more information, see Resource groups.\nTags: You can add one or more tags to a key pair to facilitate resource search and aggregation. For more information, see Tags.\nClick OK.\n\nYou can call the ImportKeyPair operation to import an existing key pair by importing the public key of the key pair. For more information, see ImportKeyPair.\nYou can bind an SSH key pair to an ECS instance when or after you create the ECS instance. You can use SSH key pairs to securely connect to ECS instances and manage multi-user access, which facilitates automated and batch operations.\nYou can perform the operations in this section to bind a key pair only to the initial logon user of an ECS instance. The initial logon user of the instance is the logon user whom you selected when you created the instance. For more information about how to bind a key pair to another user, see Bind a key pair to an instance for password-free logon over SSH.\nYou must restart an instance after you bind a key pair to the instance for the binding to take effect. To prevent the instance restart from affecting your business, you can perform the operations described in Bind a key pair to an instance for password-free logon over SSH to bind the key pair to the instance.\nIn the ECS console, you can bind only one SSH key pair to an instance and bind the same SSH key pair to multiple instances. If you bind an SSH key pair to an instance to which another SSH key pair was bound, the new key pair replaces the original key pair.\nThe binding changes the logon method. If SSH password-based logon is used for an ECS instance before you bind a key pair to the instance, SSH password-based logon is disabled after you bind a key pair to the instance.\nPerform the following steps to bind a key pair to instances in the ECS console:\nFind the SSH key pair that you want to bind and click Bind in the Actions column.\nIn the Select ECS Instance column, select the instances to which you want to bind the SSH key pair and click the > icon to move the instances to the Selected column. Click Next.\nYou cannot select Windows instances. An SSH key pair can be bound to Linux instances, not Windows instances.\nSelect a method to restart the instances as prompted, or wait for an appropriate time to restart the instances. After the instances are restarted, the new key pair can take effect.\n\nYou can call the AttachKeyPair operation to bind a key pair to Linux instances. For information, see AttachKeyPair.\nIf you no longer require an SSH key pair, you can unbind the SSH key pair from the related ECS instances to improve the instance security or restrict access permissions. For example, you can unbind an SSH key pair if the SSH key pair has expired or is rotated or a user no longer needs to access an ECS instance to which the SSH key pair is bound.\nAfter you use this method to unbind a key pair from ECS instances, you must restart the instances for the unbinding to take effect. If you do not want to restart an ECS instance, unbind the key pair from the instance as described in Bind a key pair to an instance for password-free logon over SSH.\nUnbind a key pair in the ECS console\nPerform the following steps to unbind a key pair from instances in the ECS console:\nFind the SSH key pair that you want to unbind and click Unbind in the Actions column.\nIn the Select ECS Instance column, select the instances from which you want to unbind the SSH key pair and click the > icon to move the instances to the Selected column. Click Next.\nSelect a method to restart the instances as prompted, or wait for an appropriate time to restart the instances. After the instances are restarted, the key pair is unbound from the instances.\n\nYou can call the DetachKeyPair operation to unbind an SSH key pair from Linux instances. For more information, see DetachKeyPair.\nIf a key pair is bound to an instance, you cannot delete the key pair.\nTo delete a key pair in the ECS console, perform the following steps:\nOn the Key Pairs page, find the SSH key pair that you want to delete and click Delete in the Actions column.\nDelete the key pair as prompted.\n\nYou can call the DeleteKeyPairs operation to delete an SSH key pair. For more information, see DeleteKeyPairs.\n"
    },
    "118": {
        "title": "Elastic Compute Service:Common ports",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/typical-applications-of-commonly-used-ports",
        "content": "This Product\nElastic Compute Service:Common ports\nAfter you get familiar with the default ports that are used by typical applications, you can add or modify security group rules in a more accurate manner. This way, applications hosted on Elastic Compute Service (ECS) instances can provide external services over the required ports, to meet your business requirements in different scenarios, such as connecting to an ECS instance over SSH and using the Simple Mail Transfer Protocol (SMTP) service to send emails. This topic describes the common ports of ECS instances and the corresponding usage scenarios.\nWhen you add security group rules to a security group, you must specify communication ports or port ranges. The security group allows or denies traffic to or from ECS instances based on the security group rules.\nFor example, when you connect to a Linux instance in a security group by using an Xshell client, the security group detects an SSH request from the Internet or internal network. Then, the security group matches the request against each inbound rule to check whether the rule contains the IP address of the request sender and whether port 22 is open. A connection is not established to the instance until an inbound rule that allows the request is matched.\nSpecific carriers mark ports 25, 135, 139, 444, 445, 5800, and 5900 as high-risk ports, and traffic over the ports is blocked by default. Even if the ports are opened by security group rules, ECS instances remain inaccessible over the ports in specific regions. We recommend that you do not use the ports.\nFor information about the ports that are used by applications on Windows Server operating systems, see Service overview and network port requirements for Windows in Microsoft documentation.\nThe following table describes the default ports that are used by typical applications.\nPort\nService\nDescription\n21\nFTP\nThe FTP port. The port is used to upload and download files.\n22\nSSH\nThe SSH port. The port is used to log on to Linux ECS instances by using a CLI tool or remote connection software such as PuTTY, Xshell, and SecureCRT. For more information, see Connect to a Linux instance by using a username and password.\n23\nTelnet\nThe Telnet port. The port is used to log on to ECS instances.\n25\nSMTP\nThe SMTP port. The port is used to send emails.\nBy default, port 25 is disabled on ECS instances to ensure security. We recommend that you use the SSL port to send emails. In most cases, the SSL port is port 465.\n53\nDNS\nThe Domain Name Server (DNS) port.\nIf a security group denies all outbound access by default and allows specific outbound access based on security group rules, you must add security group rules that open the default UDP port 53 for outbound traffic to resolve domain names.\n80\nHTTP\nThe HTTP port. The port is used to access services such as IIS, Apache, and NGINX.\nFor information about how to troubleshoot issues related to port 80, see Check whether TCP port 80 is available.\n110\nPOP3\nThe POP3 port. The port is used to send and receive emails.\n143\nIMAP\nThe Internet Message Access Protocol (IMAP) port. The port is used to receive emails.\n443\nHTTPS\nThe HTTPS port. The port is used for access over HTTPS. The HTTPS protocol can provide encrypted and secure data transmission.\n1433\nSQL Server\nThe TCP port of SQL Server. The port is used for SQL Server to provide external services.\n1434\nSQL Server\nThe UDP port of SQL Server. The port is used to obtain the TCP/IP port and IP address that are used by SQL Server\nOpen UDP port 1434 only if you need to use the SQL Server Browser service. If you do not need to use the SQL Server Browser service, we recommend that you close UDP port 1434 or restrict traffic over the port to ensure security.\n1521\nOracle\nThe Oracle communication port. ECS instances that run Oracle SQL must have this port open.\n3306\nMySQL\nThe MySQL port. The port is used for MySQL to provide external services.\n3389\nWindows Server Remote Desktop Services\nThe Windows Server Remote Desktop Services port. The port is used to log on to Windows ECS instances. For more information, see Connect to a Windows instance by using a username and password.\n8080\nProxy service\nAn alternative to port 80. In most cases, port 8080 is used for WWW proxy services. If you use port 8080, you must add :8080 to the end of your IP address when you access websites or use proxy servers. If you install the Apache Tomcat service, port 8080 is used by default.\n137, 138, and 139\nNetBIOS\nIn most cases, the NetBIOS protocol is used to share Windows files and printers. The protocol is also used in Samba.\nIn most cases, UDP ports 137 and 138 are used for data transfer over NetBIOS.\nPort 139 is used to obtain services over NetBIOS or SMB.\nThe following table describes sample usage scenarios of specific common ports that are used by ECS instances and the security group rules that are used for the scenarios. For information about more usage scenarios, see Security groups for different use cases.\nUsage scenario\nNetwork type\nDirection\nAction\nProtocol\nPort range\nObject type\nAuthorization object\nPriority\nConnect to Linux ECS instances over SSH\nVirtual Private Cloud (VPC)\nInbound\nAllow\nCustom TCP\nSSH (22)\nCIDR block\n0.0.0.0/0\n1\nClassic network\nInternet ingress\nConnect to Windows ECS instances over Remote Desktop Protocol (RDP)\nVPC\nInbound\nAllow\nCustom TCP\nRDP (3389)\nCIDR block\n0.0.0.0/0\n1\nClassic network\nInternet ingress\nPing ECS instances over the Internet\nVPC\nInbound\nAllow\nAll ICMP\n-1/-1\nCIDR block or security group\nSubject to the authorization type\n1\nClassic network\nInternet ingress\nUse ECS instances as web servers\nVPC\nInbound\nAllow\nCustom TCP\nHTTP (80)\nCIDR block\n0.0.0.0/0\n1\nClassic network\nInternet ingress\nUpload and download files over FTP\nVPC\nInbound\nAllow\nCustom TCP\n20/21\nCIDR block\nSpecified CIDR blocks\n1\nClassic network\nInternet ingress"
    },
    "119": {
        "title": "Elastic Compute Service:ECS instance security",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/best-practices-for-security",
        "content": "This Product\nElastic Compute Service:ECS instance security\nThis topic describes measures that Alibaba Cloud takes to handle threats in cybersecurity and challenges and improve security when users use accounts, instances, operating systems (OSs), and Elastic Compute Service (ECS) resources.\nSecurity covers a broad spectrum. Alibaba Cloud provides secure services and is responsible for protecting the underlying infrastructure of Alibaba Cloud services, such as data centers and virtualization platforms. When you use Alibaba Cloud services, it is also important that you follow best security practices such as protecting your Alibaba Cloud accounts, keeping information confidential, and controlling permissions.\nIn recent years, we have seen a rapid increase in cybersecurity threats. State of Security 2022, an annual global research report released by Splunk Inc., reveals the following data:\n49% of organizations say that they have suffered data breaches over the last two years, compared to 39% a year ago.\n79% of respondents say that they have faced ransomware attacks. 35% admit that one or more of those attacks caused them to lose access to data and systems.\n59% of security teams say that they have devoted significant time and resources to taking remedial actions, compared to 42% a year ago.\nOn average, it takes 14 hours to recover from unplanned downtime. Respondents estimate that the average cost of this downtime amounted to USD 200,000 per hour.\nThe shift from traditional IT infrastructure to cloud-based architectures brings new challenges to security. A single accidental operation may expose your application to the Internet or disclose your key and result in a cybersecurity incident. Security and compliance are essential to digital transformation and are job one in your journey to the cloud.\nSecurity is extremely important and you must make it a priority. The security of systems and applications is an ongoing journey of incremental progress and maturity.\nMake a holistic security strategy and integrated protection policies, complete with security tools and controls.\nBuild security into DevOps.\nBuild an automated security defense system to protect your systems.\nDig into cloud security compliance standards.\nIn addition, you must take note of the following items:\nIdentify, define, and categorize all your information assets.\nDefine what asset data to protect.\nDefine who can access the asset data in protection and for what purposes the asset data can be accessed.\nCloud computing security, or cloud security, usually refers to the practice of using a set of policies, controls, and technologies to protect data, infrastructure, and applications within a cloud computing environment from both external and internal cybersecurity threats and vulnerabilities. An ever-growing number of enterprises attach greater importance to cloud security compliance. Security compliance in the cloud depends on a top-down top-level design. To ensure security compliance in the cloud, you must develop cloud-based applications with security in mind.\nIn light of current security trends, we recommend that you use the best security practices described in the following table to protect your information assets in the cloud.\nItem\nBest practice\nDescription\nAccount security\nProtect Alibaba Cloud accounts\nEnable multi-factor authentication (MFA) for accounts.\nUse Resource Access Management (RAM) users instead of Alibaba Cloud accounts and attach appropriate permissions policies to the users.\nUse instance RAM roles instead of AccessKey pairs to call API operations.\nPrevent AccessKey pair leaks.\nFollow the security suggestions for managing accounts and passwords.\nManagement of application resources\nManage information assets in bulk\nUse tags to manage resources in bulk\nUse Cloud Assistant to automate O&M on resource channels.\nUse Cloud Config to conduct compliance audits on resources.\nInformation and data security\nEnable security compliance when you create instances\nHost business that requires high security on security-enhanced instances.\nUse secure images.\nEncrypt data on disks.\nUse snapshots for disaster recovery purposes.\nAccess instance metadata in security hardening mode.\nNetwork environment security\nProperly separate permissions on network resources\nFollow the security suggestions for isolating network resources.\nBuild a secure network environment.\nApplication security\nUse security services to build a security defense system\nUse Anti-DDoS Origin Basic (free-of-charge), Anti-DDoS Pro, and Anti-DDoS Premium to mitigate DDoS attacks.\nUse Security Center Basic for free to protect against exploitation of system vulnerabilities.\nUse Web Application Firewall (WAF) to protect against exploitation of system vulnerabilities.\nSecurity of applications in the guest operating systems of instances\nProtect applications in instance guest operating systems\nConfigure security settings to ensure secure logons to ECS instances.\nEncrypt data in transit.\nMonitor and audit log exceptions.\nWe recommend that you enable MFA for your Alibaba Cloud account. MFA enhances security because it requires you to provide MFA security codes in addition to usernames and passwords when you access Alibaba Cloud services. MFA security codes are dynamically generated by MFA devices.\nMake sure that access permissions on ECS resources are granted to RAM users based on the principle of least privilege. Do not share account information to third parties or grant unnecessary permissions to RAM users. We recommend that you use your Alibaba Cloud account to create RAM users (or user groups) and attach specific permissions policies for fine-grained access control over accounts on ECS resources. For more information, see RAM users.\nRAM user\nIf you purchase multiple ECS instances that need to be accessed by different entities in your organization, such as employees, systems, and applications, you can create RAM users and attach permissions policies to the RAM users to grant only required permissions to prevent security risks.\nRAM user group\nYou can create multiple user groups and attach different permissions policies to the user groups. This way, you can manage user permissions by user group. For example, to enhance network security, you can configure a permission policy that denies access to specific ECS resources from IP addresses outside your corporate network and assign the policy to a specific user group.\nYou can create multiple user groups and attach different policies to manage permissions of personnel with different job responsibilities. For example, if a developer becomes a system administrator, you can move the developer account from the Developers group to the SysAdmins group.\nPolicy for a user group\nSysAdmins: This user group needs permissions to create and manage ECS instances. You can attach a permissions policy to allow members in the SysAdmins group to perform all operations on ECS resources such as instances, images, snapshots, and security groups.\nDevelopers: This user group needs only permissions to use ECS instances. You can attach a permissions policy to allow members in the Developers group to call the DescribeInstances, StartInstances, StopInstances, RunInstances, and DeleteInstance operations.\nTypically, applications that are deployed on ECS instances access the APIs of other Alibaba Cloud services by using the AccessKey pair of an Alibaba Cloud account or RAM user. Before the AccessKey pair can be used on an instance to call API operations, the AccessKey pair must be configured in the instance. For example, you can write the AccessKey pair to a configuration file of the instance. However, this method carries security risks such as information leaks and difficult maintenance. To address these risks, Alibaba Cloud provides instance RAM roles. By using instance RAM role, you can ensure the security of your AccessKey pairs and make use of RAM for fine-grained control and management of permissions.\nYou can attach an instance RAM role to an ECS instance and use a Security Token Service (STS) temporary credential to access the APIs of other Alibaba Cloud services. After you attach the role to the instance, we recommend that you access instance metadata in security hardening mode. The STS temporary credential is updated periodically. For more information, see Overview.\nAccessKey pairs are credentials for Alibaba Cloud accounts to access APIs and must be kept secure. Do not expose your AccessKey pairs to external channels such as GitHub to prevent security threats caused by malicious uses. If the AccessKey pair of your Alibaba Cloud account is disclosed, your resources are exposed to risks.\nSecurity suggestions on how to use AccessKey pairs:\nDo not embed AccessKey pairs in code.\nChange AccessKey pairs on a regular basis.\nRevoke unnecessary AccessKey pairs on a regular basis.\nUse RAM users based on the principle of least privilege.\nEnable log audit and deliver the logs to Object Storage Service (OSS) and Log Service for storage and audits.\nSet acs:SourceIp to control access from specific public IP addresses to Alibaba Cloud APIs.\nSet acs:SecureTransport to true, which indicates that the features and resources are accessed over HTTPS.\nCategory\nPolicy description\nAlibaba Cloud accounts\nMFA must be enabled for administrative accounts.\nConfigure permissions at different levels for accounts and abide by the principle of least privilege to grant permissions.\nDisable root access to APIs or common request methods.\nKeys and credentials\nDo not use expired certificates or credentials.\nDelete the access keys for root accounts.\nRemove the keys and credentials on a regular basis that have not been used for more than 30 days.\nMonitor the latest usage of keys and credentials.\nAutomatically scan your Git repository and historical records for potential key leaks on a regular basis.\nPassword\nChange passwords on a regular basis and make sure that passwords meet strength requirements.\nEnforce password complexity policies.\nSet complex account passwords that differ from those on other platforms to prevent security threats caused by password leaks to resources on multiple platforms.\nHost AccessKey pairs and other account password information in Key Management Service (KMS) securely. Do not store AccessKey pairs or password information in plaintext on disks.\nDo not use the same password or key pair for different accounts on a host.\nConfidential data securely hosted in KMS\nStoring confidential data in plaintext on disks poses leakage risks. We recommend that you activate KMS in advance. KMS allows you to enable data encryption in cloud services without the need to develop and maintain cryptographic infrastructure yourself. For example, you can enable disk encryption and trusted boot on ECS instances.\nAutomatically manage and audit cloud resources in bulk to prevent individual assets being left unprotected due to incorrect configurations. We recommend that you use uniform deployment and naming conventions for instances and security groups and periodically check for, be warned of, and delete security groups or instances that do not comply with the naming conventions. Use tags to manage resources in bulk, use Cloud Assistant to automate O&M on resource channels, and use Cloud Config to conduct compliance audits on resources.\nUse tags to identify, categorize, and find cloud resources in bulk. In the event of a security incident, you can use tags to quickly identify the scope and impact severity of the incident.\nYou can configure security policies with specific tags for resources, such as security groups, at a time.\nFor more information, see Tags.\nTraditional O&M channels depend on SSH to obtain keys and open relevant network ports. Cloud resources are exposed to risks in case of improper management of keys and exposure of network ports. Cloud Assistant is a native automated O&M tool developed for ECS. Cloud Assistant allows you to batch maintain ECS instances and batch execute scripts on and send files to ECS instances in a password-free, logon-free manner without the use of jump servers. Typically, you can use Cloud Assistant to install and uninstall software, start and stop services, distribute configuration files, and run common commands (or scripts), to help manage cloud resources in a secure and efficient manner. You can use Cloud Assistant to batch manage, run commands on, and send files to multiple ECS instances at a time. Cloud Assistant provides the session management feature that allows you to perform interactive O&M on ECS instances. You can perform all of the preceding operations without using passwords, logons, jump servers, or the public IP addresses of ECS instances. Cloud Assistant uses the following security mechanisms to ensure the security of O&M channels:\nAccess control: Cloud Assistant uses RAM policies to control user access to ECS instances based on multiple dimensions, such as instances, resource groups, tags, or source IP addresses. Only users that have the required permissions can use Cloud Assistant to manage ECS instances.\nEnd-to-end reliability: All resources involved in the use of Cloud Assistant interact over HTTPS, and data is encrypted in transit. ECS instances use an internal security mechanism to control inbound access without the need to open ports to users, and minimize intrusion risks. ECS instances communicate outbound over the internal network and become reachable without the need to expose their public IP addresses.\nSecure content: Commands transmitted by Cloud Assistant are encrypted and verified based on signatures to ensure that the commands are secure and not tampered with during transmission.\nLog audit: You can call API operations to audit commands and files that are transmitted by Cloud Assistant. You can query the execution times and results of command tasks or file sending tasks, command or file content, and usernames that are used to run commands or send files. You can also deliver the logs about tasks executed by Cloud Assistant to OSS or Simple Log Service for archiving or analysis purposes.\nFor more information, see Overview.\nCloud Config is a service that allows you to evaluate cloud resources. Cloud Config aggregates resources in different regions to accelerate the query of resources. Cloud Config takes snapshots to record configuration changes of each monitored resource and displays the configuration changes over time in a configuration timeline. Resource configuration changes can trigger compliance evaluation. Cloud Config generates alerts for non-compliant configurations. Cloud Config allows you to monitor the compliance of large amounts of cloud resources against internal and external compliance requirements. For more information, see What is Cloud Config?\nIf your business requires high security and enhanced trust, you can run the business on security-enhanced instances that can ensure trusted boot and the security of private data.\nThis instance family supports encrypted memory and confidential computing based on Intel\u00aeSoftware Guard Extensions (SGX) to protect the confidentiality and integrity of essential code and data from malware attacks.\nThis instance family implements trusted boot based on Trusted Cryptography Module (TCM) or Trusted Platform Module (TPM) chips. During a trusted boot, all modules in the boot chain from the underlying server to the ECS instance are measured and verified.\nExample: c6t instances. For more information about security-enhanced instances, see Overview.\n\nUse public images and enable security hardening for the images.\nUse public images provided by Alibaba Cloud.\nEnable security hardening that is free of charge for public images to obtain various security features, such as webshell detection, security configuration check, and alerting for unusual logons to servers.\n\n\nUse encrypted custom images.\nUse the AES-256 algorithm to encrypt custom images to prevent data leaks in case of image disclosure. You can create encrypted system and encrypted data disks and then create encrypted custom images based on these disks. You can also use the Copy and Encrypt feature when you copy an unencrypted custom image to encrypt the image copy. If you want to share encrypted custom images, we recommend that you create separate BYOK keys (custom keys imported by using Bring Your Own Key feature) for the images to prevent key leaks. For more information, see Copy a custom image.\nYou can encrypt disks to provide maximum protection for data stored on the disks without additional modifications to business or applications. Snapshots that are created from encrypted disks and disks that are created from these snapshots are encrypted. In scenarios that require data security and regulatory compliance, you can use the disk encryption feature to encrypt your data stored in Alibaba Cloud ECS. This way, you can protect the privacy, autonomy, and security of your data without the need to establish or maintain key management infrastructure. Both system disks and data disks can be encrypted. For more information, see Encrypt cloud disks.\n\nUse snapshots to back up data\nData backup is the foundation of disaster recovery and helps reduce the risk of data loss caused by system failures, accidental operations, and security issues. ECS provides the snapshot feature to meet the data backup requirements of most users. You can select a method of creating snapshots based on your needs. For more information, see Create a snapshot.\nWe recommend that you create automatic snapshots on a daily basis and retain the snapshots for at least seven days. This significantly improves disaster tolerance and minimizes potential data loss.\n\n\nUse encrypted snapshots\nECS uses the industry-standard AES-256 algorithm and keys to encrypt snapshots and prevent data leaks in case of snapshot disclosure. You can create encrypted disks and then create encrypted snapshots from the disks.\nECS instance metadata includes the information of ECS instances in Alibaba Cloud. You can view the metadata of running instances and configure or manage the instances based on their metadata. For more information, see Overview of ECS instance metadata.\nWe recommend that you access instance metadata in security hardening mode. In security hardening mode, a session can be established between an ECS instance and the instance metadata server. When you attempt to access the metadata of the instance, the instance metadata server authenticates your identity based on a token. When the token expires, the instance metadata server closes the session and deletes the token. The following limits apply to tokens:\nEach token can be used only for a single ECS instance. If you attempt to use the token of one instance to access a different instance, your access is denied.\nEach token must have a validity period that ranges from 1 second to 21,600 seconds (6 hours). Tokens can be reused until they expire to maintain an optimal balance between security and user experience.\nProxy access is not supported. If a request for creating a token contains the X-Forwarded-For header, the instance metadata server refuses to issue the token.\nAn unlimited number of tokens can be issued for each instance.\nCloud computing leverages Virtual Private Cloud (VPC) to abstract physical networks into isolated secure virtual networks and pool network resources to provide isolation at the data link layer. VPCs are completely isolated from each other and can be connected only by using elastic IP addresses or NAT IP addresses. You can configure IP address ranges or CIDR blocks, route tables, gateways within each VPC. You can connect on-premises data centers to VPCs or connect networks around the world to build a customized network environment so that you can smoothly migrate applications to the cloud or scale the data centers. To connect on-premises data centers to VPCs, you can use VPN Gateway, Express Connect, or Smart Access Gateway (SAG). To connect networks worldwide, you can use Cloud Enterprise Network (CEN).\nNetworks are the basis of cloud services. Networks are vulnerable to various severe cyberattacks and difficult to protect. Cloud computing platforms provide a mature cybersecurity architecture to defend against threats from the Internet. In Alibaba Cloud, you can use security groups, network access control lists (ACLs), routing policies, or Express Connect circuits to control access to VPCs. In addition, you must configure security protections such as Cloud Firewall, WAF, and Anti-DDoS to protect against external cyberthreats.\nConsider the following security suggestions for isolating network resources:\nCreate a network administrator account to manage security groups, network ACLs, and traffic logs in a centralized manner.\nUse network ACLs to restrict access to private data.\nIsolate network resources and preconfigure large subnets to prevent overlapping of subnets.\nConfigure security groups based on access points instead of resources.\nProperly configure security groups to isolate networks and reduce attack surface\nSecurity groups are an important component of network security isolation and are used to control network access to or from ECS instances. The rules of a security group control inbound traffic to and outbound traffic from the instances that are associated with the security group. You can configure security group rules to filter traffic based on port numbers and IP addresses so that you can reduce the attack surface and protect your instances.\nFor example, port 22 is used as the remote connection port on Linux instances by default. Security risks arise if this port is open to external access. You can configure security group rules to allow only specific local IP addresses access to the instances over port 22. If you have higher security requirements, you can use third-party virtual private network (VPN) products to encrypt logon data. Consider the security suggestions described in the following table.\nSuggestion\nDescription\nReferences\nPrinciple of least privilege\nSecurity groups are expected to work like whitelists. Therefore, open and expose as few ports as you need and allocate as few public IP addresses as you need. To query task logs or perform troubleshooting on an instance, log on to the instance by using a VPN or bastion host. Incorrect configurations may leave service ports or IP addresses exposed to the Internet and result in cybersecurity threats.\nYou can create security groups to prevent unauthorized access. You need to open only the ports required by business in security groups that govern Internet traffic and those that govern internal network traffic.\nFor high-risk service ports on ECS instances, you must allow access only from your computer or configure security group rules to allow access only from specific IP addresses.\nFor the management backend of HTTP services, you must configure security group rules to allow access only from specific IP addresses. Enable WAF features for the domain name of the HTTP service.\nSecurity groups for different use cases\nDo not set 0.0.0.0/0 as an authorization object in your security group rules.\nAllowing all inbound access is a common mistake. 0.0.0.0/0 indicates all IP addresses. If a security group rule includes 0.0.0.0/0 as an authorization object to allow inbound access, the rule opens all ports to external access. This poses high security risks. To improve security posture, we recommend that you deny external access over all ports and then configure security group rules to open ports based on your needs. For example, if you need to expose web services, you can open common TCP ports such as ports 80, 8080, and 443 and keep other ports closed.\nAdd a security group rule\nDisable inbound security group rules that are no longer needed.\nIf an inbound security group rule includes 0.0.0.0/0, review the ports and services that your applications must expose. If you do not want specific ports to directly provide external services, you can add a Deny (Forbid) rule for the ports. For example, if you deploy MySQL database services on your instance, port 3306 cannot be exposed to the Internet. In this case, you can add a Deny rule and set the priority of the rule to 100, which indicates the lowest priority.\nAdd a security group rule\nReference security groups as authorization objects in security group rules.\nRules must be added to security groups to allow access based on the principle of lease privilege. Different application layers must use different security groups with appropriate inbound and outbound rules.\nFor example, you can create different security groups for distributed applications. These security groups may not be accessible to each other. In this case, you can add security group rules that reference security groups (instead of IP addresses or CIDR blocks) as authorization objects to allow mutual access between the security groups so that resources in these security groups can access each other.\nFor example, assume that you create the sg-web security group for the web layer and the sg-database security group for the database layer of your applications. In sg-database, you can add a rule that references the sg-web security group to allow all resources in the sg-web security group access over port 3306.\nAdd a security group rule\nFor security groups of the classic network type, do not set CIDR blocks or IP addresses as authorization objects in rules that govern internal network traffic.\nBy default, no inbound rules for internal network traffic are enabled for ECS instances that reside in the classic network. Exercise caution when you configure security group rules that govern internal network traffic.\nSecurity group rule\nConfigure appropriate names and tags for security groups.\nAppropriate names and descriptions help you identify security groups. You can modify the names and descriptions of security groups.\nYou can add tags to security groups by using the ECS console or by calling API operations for easy search and management.\nModify a security group\nCreate or add a tag\nAdd ECS instances that require mutual access to the same security group.\nEach ECS instance can belong to up to five security groups. ECS instances within the same security group can communicate with each other over the internal network. If you have multiple security groups but do not want to configure multiple security group rules, you can create another security group and add the instances that require internal network communication to the new security group.\nWe recommend that you do not add all of your ECS instances to the same security group. For a large or medium-sized application that is distributed across multiple ECS instances, each of these instances plays a different role. You cannot add all the instances to the same security group and must properly configure inbound and outbound security group rules for each instance.\nManage ECS instances in security groups\nIsolate instances within a security group.\nSecurity groups act as virtual firewalls that provide Stateful Packet Inspection (SPI), also known as dynamic packet filtering. A security group contains instances that reside in the same region. These instances have the same security requirements and trust each other. Alibaba Cloud fine-tunes the internal access control policies (or internal network communication policies) of security groups to isolate instances within a security group.\nNetwork isolation within a basic security group\nUse security group quintuple rules.\nSecurity groups are used to control network access to or from one or more ECS instances. Security groups are an important component of security isolation and are used to logically isolate security domains in the cloud. Security group quintuple rules allow you to implement precise access control based on the following five elements: source IP address, source port, destination IP address, destination port, and transport layer protocol.\nSecurity group quintuple rules\nAdd ECS instances that provide Internet-facing services and those that provide internal network-facing services to different security groups.\nApplications hosted on an ECS instance may be accessible to the Internet in scenarios in which the instance provides Internet-facing services. These scenarios include those in which the instance proactively exposes specific ports (such as ports 80 and 443) for external access and in which the instance passively provides port forwarding rules (such as NAT port forwarding rules and forwarding rules that are based on the system-assigned public IP address or elastic IP address of the instance).\nIn the preceding scenarios, use the strictest security group rules for the instance. Add a rule to deny access over all protocols and all ports and then add rules to allow access only to ports required by external services, such as ports 80 and 443. If a security group contains only Internet-facing ECS instances, the rules in the security group are easy to adjust.\nInternet-facing ECS instances within the same security group must have clear and simple responsibilities to ensure that the instances provide no services other than their primary services. For example, for MySQL and Redis applications, we recommend that you deploy them on ECS instances that do not provide Internet access, and then configure security group rules to allow access from specific security groups to the instances.\nAdd a security group rule\nConfigure security domains to isolate services of different security levels within your organization\nYou can build private networks by using VPCs to separately host servers of different security levels in your organization and ensure that the servers do not interfere with each other over an interconnected network. We recommend that you create a VPC, assign a private IP address range in CIDR notation to the VPC, and configure route tables and gateways for the VPC. Then, you can store important data in this VPC, which is logically isolated from the Internet, and use an elastic IP address (EIP) or a jump server to manage data for daily O&M purposes. For more information, see Create and manage a VPC.\nUse jump servers or bastion hosts to protect against internal and external intrusions\nJump servers have a large set of permissions. If you use a jump server, you must use tools to thoroughly record and audit operations on it. We recommend that you use bastion hosts instead to prevent your networks and data from being hacked or disrupted by attackers. Use various technical methods to monitor and record the operations that your O&M personnel perform on servers, network devices, security devices, and databases in your networks, so that your troubleshooting or O&M personnel can be alerted in a centralized manner, handle the alerts in a timely manner, audit the operations, and determine who is responsible for accidental operations or faults.\nWe recommend that you assign the jump server to a dedicated vSwitch in a VPC and then associate the corresponding EIP or NAT port forwarding table with the jump server. Create a dedicated security group named SG_BRIDGE and open required ports. For example, open TCP port 22 for Linux operating systems and RDP port 3389 for Windows operating systems. To restrict inbound access, you can add security group rules to allow only specific public IP addresses of your organization to access the security group. This way, the probability that resources are scanned or accessed is reduced. Add the ECS instance that functions as a jump server to the security group. If you want the jump server to access ECS instances within another security group, you can configure a rule that allows the jump server access to that security group. For example, in a security group named SG_CURRENT, you can add a rule to allow access from the SG_BRIDGE security group over specific protocols and ports. When you use the jump server for SSH communication, we recommend that you use key pairs instead of passwords to log on to ECS instances. For information about key pairs, see SSH key pair overview.\nProperly assign public IP addresses to reduce Internet-exposed attack surface\nProper allocation of public IP addresses facilitates Internet access management and reduces attack surface regardless of whether ECS instances reside in the classic network or VPCs. For ECS instances that reside in a VPC, we recommend that you connect the instances that require Internet access to several specified vSwitches. This makes the instances easy to audit and distinguish and helps prevent accidental exposure of ECS instances to the Internet.\nMost distributed applications have different layers and groups. For ECS instances that do not provide Internet access, we recommend that you do not assign public IP addresses. For multiple instances that provide Internet access, we recommend that you configure Server Load Balancer (SLB) instances to distribute Internet traffic to improve system availability. For more information, see SLB overview.\nIf your ECS instances require Internet access but do not have public IP addresses, we recommend that you use NAT gateways to provide Internet proxy services for the instances. You need only to configure SNAT entries to provide Internet access for specific CIDR blocks or subnets. This way, you can prevent services from being exposed to the Internet after public IP addresses are assigned, when only outbound Internet access is required. For more information, see What is VPN Gateway?\nIn a DDoS attack, multiple compromised computer systems flood one or more targets with fraudulent traffic to deny service to legitimate users of the targets. Alibaba Cloud Security Center can defend against Layer 3 to Layer 7 DDoS attacks, including SYN flood, UDP flood, ACK flood, ICMP flood, DNS flood, and HTTP flood attacks. Anti-DDoS Origin Basic provides a DDoS mitigation capacity of up to 5 Gbit/s free of charge.\nBy default, Anti-DDoS Origin Basic is enabled on ECS instances. Anti-DDoS Origin Basic allows you to maintain normal access speeds in case of DDoS attacks without the need to purchase expensive traffic scrubbing devices. Anti-DDoS Origin Basic ensures the expected bandwidth, availability, and stability of your business. In this case, your business is not affected by other users. After an ECS instance is created, you can set scrubbing thresholds for it. For more information, see Configure a traffic scrubbing threshold.\nSecurity Center is a centralized security management system that identifies, analyzes, and warns of security threats in real time. Security Center provides multiple features to ensure the security of cloud resources and servers in data centers. The features include anti-ransomware, antivirus, web tamper proofing, and compliance check. You can use Security Center to automate security operations, responses, and threat tracing, and meet regulatory compliance requirements.\nSecurity Center Basic is available to you by default. Security Center Basic scans only for the following threats: unusual logons to servers, vulnerabilities, and configuration risks in cloud services. To use advanced features such as threat detection, vulnerability fixing, and virus detection and removal, go to the Security Center console to purchase a paid Security Center edition. For more information, see Introduction to Security Center Basic.\nWeb Application Firewall (WAF) depends on the big data capabilities of Alibaba Cloud Security Center to protect web applications against common attacks reported by the Open Web Application Security Project (OWASP) and HTTP flood attacks. The attacks include SQL injections, cross-site scripting (XSS) attacks, webshells, trojans, and unauthorized access. WAF blocks malicious visits to prevent data leaks and ensure the security and availability of your websites. For more information, see Getting started.\nWAF has the following benefits:\nWAF can handle various web application attacks to ensure the web security and availability of a website without the need to install software or hardware or modify website configurations and code. On top of powerful web protection capabilities, WAF can provide dedicated protection for specific websites and is a great fit for web application protection in fields such as finance, e-commerce, Online To Offline (O2O), Internet Plus, gaming, public services, and insurance.\nWithout WAF, you may be vulnerable to web intrusions in face of attacks such as data leak attacks, HTTP flood attacks, and trojans.\nFor more information about how to use WAF, see Getting started.\nBy default, a non-root account can be used to log on to an ECS instance. Before you can use a non-root account to log on to an ECS instance, you must run the su or sudo command on the instance to grant administrative permissions to the account. By default, you cannot use the root account with a key file in the PEM format to log on to the instance. We recommend that you use a secure access control protocol to access ECS instances and select different logon credentials based on image types. For Linux instances, we recommend that you configure the instances to support only RSA-encrypted key pairs as logon credentials and not to support passwords as logon credentials. For Windows instances, we recommend that you use complex passwords that are more than eight characters in length and contain special characters as logon credentials.\nLinux instance:\nBy default, non-root accounts are used to log on to Linux instances.\nIf you log on to a Linux instance with the root account, you have the highest permissions on the instance. This facilitates O&M operations. However, serious data security risks may arise if the instance is attacked. We recommend that you use the Anolis OS 8.4 or Ubuntu 20.04 public image, which supports logons that use the regular ecs-user account.\n\nUse temporary SSH key pairs to log on to Linux instances.\nYou can use the config_ecs_instance_connect plug-in to send an SSH public key to a specific instance for a specific user to use. The SSH public key is stored on the instance for 60 seconds. During these 60 seconds, you can use the SSH public key to connect to the instance as the specified user without a password. For more information, see Connect to a Linux instance by using the config_ecs_instance_connect plug-in with a public key instead of a password.\nAn SSH key pair consists of a public key and a private key that are generated based on an encryption algorithm. By default, the keys are encrypted by using the RSA-2048 algorithm. Key pair-based authentication has the following advantages over username- and password-based authentication:\nSSH key pairs provide higher security and reliability for logons.\nThe security strength of the key pair is much higher than that of the regular user password, which can prevent the threat of brute-force cracking.\nPrivate keys cannot be deduced even if the public keys are maliciously acquired.\nSSH key pairs are easy to use.\nIf you configure a public key on a Linux instance, you can use the corresponding private key to run SSH commands or other tools to log on to the instance without a password.\nYou can log on to a large number of Linux instances by using a key pair at the same time. If you want to batch manage multiple Linux instances, we recommend that you use an SSH key pair to log on to the instances. You can use an SSH key pair that is bound to a Linux instance to log on to the instance. You can specify an SSH key pair when you create an instance, or bind an SSH key pair to an instance after the instance is created. Then, you can use the private key to connect to the instance.\nWe recommend that you modify the sshd_config file to disable password-based logon and support only RSA key pair-based logon. You can modify the parameters related to password logon in the SSH configuration file.\nWindows instance:\nSet complex passwords and change passwords on a regular basis. Weak passwords are one of the leading vulnerabilities that lead to data breaches. To prevent security risks that arise from weak passwords, we recommend that you use complex passwords for servers. Server passwords must be at least eight characters in length and contain multiple character types such as uppercase letters, lowercase letters, digits, and special characters. We also recommend that you change the passwords on a regular basis.\nSet strong passwords for ECS instances. The passwords must be 8 to 30 characters in length and contain at least three of the following character types: uppercase letters, lowercase letters, digits, and special characters, including ( ) ` ~ ! @ # $ % ^ & * _ - + = | { } [ ] : ; ' < > , . ? /. For Windows instances, passwords cannot start with a forward slash (/).\nConfigure security groups or firewalls to allow communication only between ports used by network services that encrypt data. You can use encryption protocols such as Transport Layer Security (TLS) 1.2 and later to encrypt sensitive data in transit between clients and ECS instances.\nThe M-Trends 2018 report published by FireEye stated that most enterprises, especially enterprises in Asia Pacific, are vulnerable to cybersecurity attacks. The global median dwell time was 101 days. In Asia Pacific, the median dwell time was 498 days. The dwell time indicates a period from when an attack occurs to when the attack is detected. To shorten the dwell time, enterprises need reliable log data and audit services.\nWe recommend that you use CloudMonitor, ActionTrail, Log Audit Service, VPC flow log, and application logs to build a monitoring and alerting system for abnormal resource and permission access. This system is essential for timely detection of problems, stop loss, and optimization of the security defense system.\nUse CloudMonitor to configure resource usage thresholds for triggering alerts and prevent DDoS attacks. For more information, see What is CloudMonitor?\nUse ActionTrail to detect unauthorized access and identify incorrect security configurations and high-risk or accidental operations. You can also use ActionTrail to perform quality monitoring and compliance auditing, and detect and respond to threats. Use MFA to control access to ActionTrail. For more information, see What is ActionTrail?\nEnable the flow log feature provided by VPC and create flow logs to record information about inbound and outbound traffic of elastic network interfaces (ENIs) that reside in a VPC. This helps analyze the flow logs.\nUse Log Audit Service to collect, scrub, analyze, and virtualize data and generate alerts. You can use Log Audit Service in scenarios related to Simple Log Service, such as DevOps, operations, security, and audit scenarios. For more information, see Overview of Log Audit Service.\nTrace application event logs and API call logs.\nSynchronize all logs to Simple Log Service or OSS on a regular basis for storage and configure access permissions on the logs.\nAdd information such as instance IDs, regions, zones, and environments (test or production environments) to stored logs to facilitate troubleshooting."
    },
    "120": {
        "title": "Elastic Compute Service:List of operations by function",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/list-of-operations-by-function",
        "content": "This Product\nElastic Compute Service:List of operations by function"
    },
    "121": {
        "title": "Elastic Compute Service:CLI reference",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/api-reference-quick-start",
        "content": "This Product\nElastic Compute Service:CLI reference\nAlibaba Cloud CLI is a command-line tool that allows you to call Alibaba Cloud API operations in a terminal or a command-line interface to create, configure, and manage Alibaba Cloud resources. This topic describes how to call Elastic Compute Service (ECS) API operations by using Alibaba Cloud CLI to create and manage ECS instances and provides examples.\nFor more information about Alibaba Cloud CLI, see What is Alibaba Cloud CLI?\nInstall Alibaba Cloud CLI.\nYou can install Alibaba Cloud CLI on Windows, Linux, and macOS. Download an installation package that is suitable for the operating system that runs on your computer. For information about how to install Alibaba Cloud CLI in different operating systems, see the following topics:\nWindows\nLinux\nmacOS\nConfigure Alibaba Cloud CLI.\nConfigure the credentials, regions, and languages that are required to call Alibaba Cloud resources. For more information, see the Identity credential configuration methods section of the \"Configure credentials\" topic.\nTo ensure the security of your Alibaba Cloud account, we recommend that you create a Resource Access Management (RAM) user that is used for calling API operations and create an AccessKey pair for the RAM user. For information about how to use an AccessKey pair in a secure manner, see Credential security solutions.\nYou can directly use Alibaba Cloud CLI in Cloud Shell without the need for installation or configuration. Due to the fact that the virtual machine (VM) destruction feature of Cloud Shell may cause data loss, we recommend that you run commands on Alibaba Cloud CLI in Cloud Shell to perform simple and quick operations, such as debugging.\nDestruction on expiration: Each VM that is created by Cloud Shell is valid for only 1 hour. When the VM expires, Cloud Shell immediately destroys the VM. When you restart Cloud Shell, a new VM is created.\nDestruction due to no operations: If no interactive operation is performed on a VM for 30 minutes or all sessions are closed, the VM is destroyed in 15 minutes. When you restart Cloud Shell, a new VM is created. For more information, see Limits.\nLog on to the ECS console and click the Cloud Shell icon in the upper-right corner to go to the Cloud Shell console.\n\nFor information about the formats supported by the fields of different data types, see Parameter formats.\nFor information about the command syntax, see the Syntax section of the \"Generate and run CLI commands\" topic.\nBefore you call an API operation, we recommend that you read the usage notes of the API operation.\nAfter you install and configure Alibaba Cloud CLI, you can run commands in the following format to call ECS API operations:\nLog on to the OpenAPI Portal.\nSelect the API operation for which you want to generate a CLI command and specify parameters.\nClick the CLI Example tab in the right-side pane to view the CLI command that is generated with the specified parameters.\n\nThe following example describes how to use Alibaba Cloud CLI to call ECS API operations.\nThe following sample requests are only for reference. Modify the CLI commands based on your business requirements.\nThe following example describes how to create a subscription ECS instance from an Alibaba Cloud Linux image in the China (Hangzhou) region by using Alibaba Cloud CLI.\nMake preparations.\nBefore you create an ECS instance, create a virtual private cloud (VPC), a vSwitch, and a security group, and obtain the IDs of the preceding resources.\nIf you already created the preceding resources and the resources meet your business requirements, skip this step.\nCall the CreateVpc operation to create a VPC.\nIn this example, a VPC is created in the China (Hangzhou) region and associated with the CIDR block 192.168.0.0/16.\nSample command\nSample command output\nCall the CreateVSwitch operation to create a vSwitch in the VPC.\nIn this example, a vSwitch is created in the VPC whose ID is vpc-bp1d9v4763ym2hlzt**** and is associated with the CIDR block 192.168.0.0/24.\nSample command\nSample command output\nCall the CreateSecurityGroup operation to create a security group in the VPC.\nSample command\nSample command output\nCall the AuthorizeSecurityGroup operation to create a security group rule in the security group.\nIn this example, an inbound security group rule that allows TCP traffic on port 22 is added to the security group whose ID is sg-bp18z2q1jg4gq95t****.\nSample command\nSample command output\nCreate an ECS instance.\nCall the RunInstances operation to create a subscription ECS instance.\nExample scenario\nParameter\nDescription and example\nRegionId\nThe ID of the region in which you want to create the ECS instance. Example: cn-hangzhou.\nImageId\nThe ID of the image. We recommend that you select the Alibaba Cloud Linux image whose ID is aliyun_3_x64_20G_alibase_20240528.vhd.\nInstanceType\nThe instance type. Examples:\nFor personal applications, we recommend that you select the ecs.e-c1m1.large instance type that has 2 vCPUs and 2 GiB of memory.\nFor the applications of small and medium-sized enterprises, we recommend that you select the ecs.c7.large instance type that has 2 vCPUs and 4 GiB of memory.\nSecurityGroupId\nThe ID of the security group. Obtain the value from the response of the CreateSecurityGroup operation.\nExample: sg-bp18z2q1jg4gq95t****.\nVSwitchId\nThe ID of the vSwitch. Obtain the value from the response of the CreateVSwitch operation.\nExample: vsw-bp11hf5r945gewysp****.\nInstanceName\nThe name of the ECS instance.\nExample: ecs_cli_demo.\nInstanceChargeType\nThe billing method of the ECS instance. To create a subscription ECS instance, set the value to PrePaid.\nMake sure that your account balance is sufficient.\nPeriodUnit\nThe unit of the subscription duration. Example: Month.\nPeriod\nThe subscription duration. Example: 1.\nInternetMaxBandwidthOut\nThe maximum outbound public bandwidth. Example: 1.\nPassword\nThe logon password of the ECS instance. Example: <yourPassword>.\nTo ensure instance security, you must specify a complex password.\nSystemDisk.Category\nThe category of the system disk. Example: cloud_essd.\nSystemDisk.Size\nThe size of the system disk. Example: 40.\nSample command\nSample command output\nObtain the public IP address of an ECS instance.\nCall the DescribeInstances operation with the ID of an ECS instance to query the public IP address of the instance. In this example, the ID of the ECS instance is i-bp1ducce5hs1jm98****.\nSample command\nSample command output\nThe PublicIpAddresses parameter indicates the public IP address of the ECS instance.\n\nConnect to the ECS instance.\n\nCall the StartInstance operation to start an ECS instance.\nExample scenario: Start an ECS instance whose ID is i-bp1aq39j2yul5y01**** in the China (Hangzhou) region (cn-hangzhou) after a dry run, and do not perform troubleshooting during instance startup.\nSample command\nSample command output\nCall the DescribeInstances operation to query the details of one or more ECS instances.\nExample 1: Query an ECS instance by instance ID\nIn this example, the details of an ECS instance whose ID is i-bp14a7xie8erwsvo**** are queried.\nSample command\nSample command output\nExample 2: Query ECS instances by tag\nIn this example, the details of ECS instances to which owner:zhangsan tags are added are queried.\nSample command\nSample command output\nExample 3: Query ECS instances by image ID\nIn this example, the details of ECS instances whose images have the m-bp12qhgxbmp5eh02**** tag are queried.\nSample command\nSample command output\nExample 4: Query ECS instances in a specific VPC\nIn this example, the details of ECS instances that reside in a VPC whose ID is vpc-bp1vwnn14rqpyiczj**** and are connected to a vSwitch whose ID is vsw-bp1ddbrxdlrcbim46**** are queried.\nSample command\nSample command output\nExample 5: Query ECS instances by page\nCall the DescribeInstances operation to query ECS instances in the China (Hangzhou) region by page. Each page displays five entries.\nSample command\nSample command output\nCall the CreateSnapshot operation to create a snapshot for a disk.\nExample scenario: Create a snapshot for an Enterprise SSD (ESSD) whose ID is d-bp14bjlwo3t3owin****. Set the snapshot name to demoname, the description to demo, and the retention period to three days.\nSample command\nSample command output\nCall the CreateImage operation to create a custom image from an ECS instance.\nExample scenario\nParameter\nDescription and example\nInstanceId\nThe ID of the ECS instance. Example: i-bp1aq39j2yul5y01****.\nPlatform\nThe operating system distribution for the system disk in the custom image. Example: Aliyun, which indicates Alibaba Cloud Linux.\nRegionId\nThe ID of the region in which to create the custom image. Example: cn-hangzhou.\nSample command\nSample command output\nCall the StopInstance operation with ForceStop parameter set to false and StoppedMode set to KeepCharging to stop an ECS instance in the Running (Running) state after a dry run. The ECS instance is stopped in standard mode, and billing for the ECS instance continues.\nExample scenario: Stop an ECS instance whose ID is i-bp1aq39j2yul5y01**** in the China (Hangzhou) (cn-hangzhou) region.\nSample command\nSample command output\nThis topic describes specific API operations. For information about other API operations, see List of operations by function.\nIn Alibaba Cloud CLI, you can specify command line options to change the behaviors of commands or implement the extended features of commands based on your business requirements. For more information, see Command line options for API calls."
    },
    "122": {
        "title": "Elastic Compute Service:Call API operations over the internal network",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/call-api-operations-over-the-internal-network",
        "content": "This Product\nElastic Compute Service:Call API operations over the internal network\nYou cannot call API operations on VPC-type ECS instances that do not have public IP addresses. This topic describes how to call API operations on VPC-type ECS instances over the Alibaba Cloud internal network.\nECS provides public endpoints. If your ECS instance does not have a public bandwidth or a public IP address, you cannot make API requests by using tools such as Alibaba Cloud CLI or SDKs. You can use one of the following methods to call API operations over the Alibaba Cloud internal network:\nSDK: Use the SDK for Java core library v4.5.3 or later to call API operations over the internal network in a VPC.\nCLI: Use CLI to call API operations over the internal network by specifying the endpoint of a specific region.\nTake note of the following items:\nThese methods are applicable only in regions where VPC-type ECS instances are deployed. The endpoint of a region can be used to manage resources only within that region. Cross-region operations are not supported.\nWe recommend that you use custom images that have Alibaba Cloud CLI or SDKs deployed to create ECS instances. The ECS instances must load related dependencies with access to the Internet.\nThe following table describes the endpoints that support API calls over the internal network. Make sure that you use an endpoint listed in the table.\nAlibaba Cloud region\nRegion ID\nEndpoint\nChina (Hangzhou)\ncn-hangzhou\necs-vpc.cn-hangzhou.aliyuncs.com\nChina (Shanghai)\ncn-shanghai\necs-vpc.cn-shanghai.aliyuncs.com\nChina (Nanjing - Local Region)\ncn-nanjing\necs-vpc.cn-nanjing.aliyuncs.com\nChina (Fuzhou - Local Region)\ncn-fuzhou\necs-vpc.cn-fuzhou.aliyuncs.com\nChina (Qingdao)\ncn-qingdao\necs-vpc.cn-qingdao.aliyuncs.com\nChina (Beijing)\ncn-beijing\necs-vpc.cn-beijing.aliyuncs.com\nChina (Zhangjiakou)\ncn-zhangjiakou\necs-vpc.cn-zhangjiakou.aliyuncs.com\nChina (Hohhot)\ncn-huhehaote\necs-vpc.cn-huhehaote.aliyuncs.com\nChina (Ulanqab)\ncn-wulanchabu\necs-vpc.cn-wulanchabu.aliyuncs.com\nChina (Shenzhen)\ncn-shenzhen\necs-vpc.cn-shenzhen.aliyuncs.com\nChina (Heyuan)\ncn-heyuan\necs-vpc.cn-heyuan.aliyuncs.com\nChina (Guangzhou)\ncn-guangzhou\necs-vpc.cn-guangzhou.aliyuncs.com\nChina (Chengdu)\ncn-chengdu\necs-vpc.cn-chengdu.aliyuncs.com\nChina (Hong Kong)\ncn-hongkong\necs-vpc.cn-hongkong.aliyuncs.com\nSingapore\nap-southeast-1\necs-vpc.ap-southeast-1.aliyuncs.com\nMalaysia (Kuala Lumpur)\nap-southeast-3\necs-vpc.ap-southeast-3.aliyuncs.com\nIndonesia (Jakarta)\nap-southeast-5\necs-vpc.ap-southeast-5.aliyuncs.com\nPhilippines (Manila)\nap-southeast-6\necs-vpc.ap-southeast-6.aliyuncs.com\nThailand (Bangkok)\nap-southeast-7\necs-vpc.ap-southeast-7.aliyuncs.com\nJapan (Tokyo)\nap-northeast-1\necs-vpc.ap-northeast-1.aliyuncs.com\nSouth Korea (Seoul)\nap-northeast-2\necs-vpc.ap-northeast-2.aliyuncs.com\nGermany (Frankfurt)\neu-central-1\necs-vpc.eu-central-1.aliyuncs.com\nUK (London)\neu-west-1\necs-vpc.eu-west-1.aliyuncs.com\nUS (Silicon Valley)\nus-west-1\necs-vpc.us-west-1.aliyuncs.com\nUS (Virginia)\nus-east-1\necs-vpc.us-east-1.aliyuncs.com\nUAE (Dubai)\nme-east-1\necs-vpc.me-east-1.aliyuncs.com\nSimple configurations are required when you use SDKs to call API operations over the internal network. The following code provides an example on how to use SDK for Java to call an API operation over the internal network:\nThe DescribeRegions operation is used in this example. Sample command:"
    },
    "123": {
        "title": "Elastic Compute Service:ECS SDK V2.0 Overview",
        "url": "https://www.alibabacloud.com/help/en/ecs/developer-reference/ecs-v2-0-sdk-overview",
        "content": "This Product\nElastic Compute Service:ECS SDK V2.0 Overview\nThe Elastic Compute Service (ECS) SDK is a comprehensive dependency package that streamlines the development process. It encapsulates underlying API calls, enabling developers to easily manage ECS resources such as instances, security groups, and images. The ECS SDK handles complex tasks such as network communication, request formatting, and response parsing internally. It supports multiple programming languages and allows developers to focus on business logic rather than underlying infrastructure.\nThe ECS SDK includes the SDK V2.0 and the SDK V1.0. The SDK V2.0, as the latest version, supports a wider range of programming languages, addresses the thread safety issue found in the SDK V1.0, and enhances robustness and usability, thereby offering developers an improved development experience.\nThe SDK V2.0 is recommended. If you are currently using the SDK V1.0, consider upgrading to the SDK V2.0. For more information, see Upgrade Alibaba Cloud SDK V1.0 to V2.0.\nThe ECS SDK V2.0 supports multiple programming languages. You can view the installation methods on the OpenAPI portal or view the source code and installation guides on GitHub. For each programming language, we recommend that you use mainstream dependency management tools for installation.\nLanguage\nSDK Installation Method\nGitHub Address\nQuick Start\nJava\nSDK for Java\nSDK for Java (Asynchronous)\nalibabacloud-java-sdk/ecs-20140526\nalibabacloud-java-async-sdk/ecs-20140526\nUse Alibaba Cloud SDKs for Java in an IDE\nGo\n\nSDK for Go\nalibabacloud-go/ecs-20140526\nUse the Alibaba Cloud SDKs for Go in an IDE\nPython\n\nSDK for Python\nalibabacloud-python-sdk/ecs-20140526\nUse Alibaba Cloud SDKs for Python in an IDE\nNode.js\n\nSDK for TypeScript\nalibabacloud-typescript-sdk/ecs-20140526\nUse Alibaba Cloud SDKs for Node.js in an IDE\nC#\n\nSDK for C#\nalibabacloud-csharp-sdk/ecs-20140526\n/\nPHP\n\n\nalibabacloud-sdk-php/ecs-20140526\nUse Alibaba Cloud SDKs for PHP in an IDE\nC++\n\nSDK for C++\nalibabacloud-sdk-cpp/ecs-20140526\n/\nSwift\n\nSDK for Swift\nalibabacloud-sdk-swift/ecs-20140526\n/\nThe following examples demonstrate how to call the DescribeInstances API operation with the ECS SDK to query detailed information about ECS instances.\nUse SDK for Java\nUse SDK for Node.js"
    },
    "124": {
        "title": "Elastic Compute Service:Manually deploy a LAMP stack",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/deploy-the-lamp-environment-alibaba-cloud-linux-3",
        "content": "This Product\nElastic Compute Service:Manually deploy a LAMP stack\nLAMP is an acronym of the names of its original four components: the Linux operating system, Apache HTTP Server, MySQL relational database management system, and PHP programming language. In most cases, LAMP stacks are used to build websites. This topic describes how to manually deploy a LAMP stack on an Elastic Compute Service (ECS) instance.\nA public IP address is automatically assigned to the ECS instance. Alternatively, an elastic IP address (EIP) is associated with the ECS instance. For instructions on how to enable public bandwidth, see Enable public bandwidth.\nInbound rules are added to a security group of the ECS instance to open ports 22 and 80. For information about how to add a security group rule, see Add a security group rule.\nThe ECS instance has at least 4 GiB of memory.\nAll content is removed from the default CentOS 8 repository at the following address: http://mirror.centos.org/centos/8/. If you continue using the default CentOS 8 repository on Alibaba Cloud, an error is reported. You must change CentOS 8 repository addresses. For more information, see Change CentOS 8 repository addresses.\nInstall Apache.\nInstall MySQL.\nIf your instance runs Alibaba Cloud Linux 3, you must install compat-openssl10, which is compatible with earlier versions of OpenSSL libraries.\nQuery the default initial password of the root user.\nIf your instance runs Alibaba Cloud Linux 3, run the following command:\nIf your instance runs CentOS 8, the root user does not have an initial password.\nSpecify a new password for the root user of MySQL. In the following command, replace <oldpwd> with the initial password and <newpwd> with the new password. If your instance runs CentOS 8, replace <oldpwd> with an empty string and press the Enter key to skip to the next line when you are prompted to enter a password.\nThe password must be at least eight characters in length, and contain at least one uppercase letter, one lowercase letter, one digit, and one special character.\nInstall PHP.\nIn this example, PHP 8.4 is used. If you require another PHP version, change the module name based on the PHP version that you want to install. For example, if you want to install PHP 8.1, change the module name to php:remi-8.1.\nVerify the LAMP stack.\nQuery the default listening address of PHP-FPM in the configuration file.\nCreate the /etc/httpd/conf.d/php-fpm.conf configuration file and configure php-fpm rules in the file.\nIf the listening address of PHP-FPM is 127.0.0.1:9000, set the SetHandler parameter to proxy:fcgi://127.0.0.1:9000.\nRestart httpd for the configuration to take effect.\nCreate the test.php file in the /var/www/html/ directory and add the following content to the file. Replace <username> with the MySQL username and <password> with the corresponding password.\nEnter http://<Public IP address of the ECS instance>/test.php in the address bar of a web browser on your on-premises machine. If success is returned, you are connected to MySQL by using the PHP proxy.\nInstall Apache.\nInstall MySQL.\nQuery the default initial password of the root user.\nSpecify a new password for the root user of MySQL. In the following command, replace <oldpwd> with the initial password and <newpwd> with the new password.\nThe password must be at least eight characters in length, and contain at least one uppercase letter, one lowercase letter, one digit, and one special character.\nInstall PHP.\nVerify the LAMP stack.\nQuery the default listening address of PHP-FPM in the configuration file.\nIf the address of a socket file is returned, PHP-FPM listens to the socket file.\nIf 127.0.0.1:9000 is returned, PHP-FPM listens on local port 9000.\nCreate the /etc/httpd/conf.d/php-fpm.conf configuration file and configure php-fpm rules in the file.\nIf the listening address of PHP-FPM is the address of a socket file, change proxy:fcgi://127.0.0.1:9000 to proxy:unix:<path>;. Replace <path> with the address of your socket file.\nRestart httpd for the configuration to take effect.\nCreate the test.php file in the /var/www/html/ directory and add the following content to the file. Replace <username> with the MySQL username and <password> with the corresponding password.\nEnter http://<Public IP address of the ECS instance>/test.php in the address bar of a web browser on your on-premises machine. If success is returned, you are connected to MySQL by using the PHP proxy.\nInstall Apache.\nUpdate the software package list and install the MySQL server.\nChange the password and identity authentication plug-in used by the root user of the MySQL server. Replace <newpwd> in the following command with the actual password.\nThe default identity authentication plug-in used by the root user is auth_socket. After the command is run, you are prompted to enter a password. Press the Enter key to skip to the next line.\nInstall PHP.\nRun the sudo apt search php command to query all PHP versions that you can install. If you want to install a different PHP version, replace the version number in the following command with the actual version number. For example, if you want to install PHP 8.1, run the sudo apt install -y php8.1 php8.1-fpm php8.1-mysql command.\nVerify the LAMP stack.\nQuery the default listening address of PHP-FPM in the configuration file. Replace <version> with your actual PHP version. For example, if you use PHP 8.4, replace <version> with 8.4.\nIf the address of a socket file is returned, PHP-FPM listens to the socket file.\nIf 127.0.0.1:9000 is returned, PHP-FPM listens on local port 9000.\nCreate the /etc/apache2/conf-available/php-fpm.conf configuration file and configure PHP forwarding rules in the file. Replace <listen> with the actual listening address of PHP-FPM.\nIf the address of a socket file is used as the listening address of PHP-FPM, replace <listen> with unix:<path>; and <path> with the address of the socket file.\nTo listen to socket files, your account must have the read and write permissions on the socket files. You can run the sudo chmod 666 <path> command to grant the preceding permissions. Replace <path> with the actual address of a socket file.\nIf 127.0.0.1:9000 is used as the listening address of PHP-FPM, replace <listen> with fcgi://127.0.0.1:9000.\nCreate a symbolic link for the configuration file.\nEnable the proxy_fcgi and setenvif modules to allow Apache to forward PHP requests to PHP-FPM. Then, enable the configuration file of PHP-FPM.\nRestart httpd for the configuration to take effect.\nCreate the test.php file in the /var/www/html/ directory and add the following content to the file. Replace <username> with the MySQL username and <password> with the corresponding password.\nEnter http://<Public IP address of the ECS instance>/test.php in the address bar of a web browser on your on-premises machine. If success is returned, you are connected to MySQL by using the PHP proxy.\nPossible causes and solutions:\nPort 80 is not open in the security groups of the ECS instance, the system firewall is enabled on the ECS instance, or port 80 is used by a different service.\nFor information about how to troubleshoot the issue based on the preceding causes, see What do I do if I cannot access a service deployed on an instance?\nCreate a non-root account and allow remote access to MySQL by using the account. For more information, see Deploy MySQL on a Linux instance."
    },
    "125": {
        "title": "Elastic Compute Service:Deploy a Java web environment (Apache Tomcat)",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/manually-deploy-the-java-web-environment-alibaba-cloud-linux-3",
        "content": "This Product\nElastic Compute Service:Deploy a Java web environment (Apache Tomcat)\nJava Web is a technology stack that integrates the Java programming language and various technologies and frameworks to facilitate the development of dynamic web applications. Developers can use Java Web to develop complex, high-performance web applications that can be deployed across platforms. Apache Tomcat is the most popular web server environment used to deploy and run Java web applications. This topic describes how to deploy a Java web environment on an Elastic Compute Service (ECS) instance.\nYou can go to Terraform Explorer and view and run the Terraform code on the Code tab to automatically deploy an Apache Tomcat Java web environment on an ECS instance.\nBefore you deploy a Java web environment on an ECS instance, make sure that the instance meets the following requirements:\nA Java environment is deployed on the instance. For more information, see Deploy a Java environment.\nThe ECS instance is assigned a static public IP address (also called system-assigned or auto-assigned public IP address) or associated with an elastic IP address (EIP). For more information, see EIPs.\nIf your instance runs a Linux operating system, make sure that a rule is added to a security group of the instance to allow inbound traffic on ports 22 and 8080.\nIf your instance runs a Windows operating system, make sure that a rule is added to a security group of the instance to allow inbound traffic on ports 3389 and 8080.\nFor information about how to add a security group rule, see Add a security group rule.\nIf your instance runs a Linux operating system, make sure that the system firewall and Security-Enhanced Linux (SELinux) are disabled. For more information, see Enable or disable the system firewall on a Linux ECS instance and Enable or disable SELinux.\nIf your instance runs a Windows operating system, make sure that the system firewall is disabled. For more information, see Enable or disable the Windows firewall.\nPerform the following operations based on the operating system of your instance.\nIn this example, Apache Tomcat 9.0.91 is used. If you install another version of Apache Tomcat or use other directories, replace the version and directories in the following commands with the actual version and directories.\nConnect to your Linux instance. For more information, see Overview of ECS Remote Connection Methods.\nRun the following commands to download and decompress the Apache Tomcat 9.0.91 installation package.\nThe download URLs of Apache Tomcat may change. If the following download URL is invalid, visit the official Apache Tomcat website to obtain the latest download URL.\nIf you want to install another version of Apache Tomcat, visit the official Apache Tomcat website to obtain the download URL and replace the URL in the following wget command with the URL that you obtained.\nRun the following command to move the Apache Tomcat installation files to the /usr/local/tomcat/ directory:\n(Optional) Configure the server.xml file.\nIf you want to modify Apache Tomcat configurations, perform the following steps:\nRun the following command to open the /usr/local/tomcat/conf/server.xml file:\nPress the I key to enter Insert mode. In this example, the default Apache Tomcat configurations are used. You can also modify the Apache Tomcat configurations based on your business requirements. Examples:\nBy default, Apache Tomcat uses port 8080. If you want to change the port number, change the value of the port parameter.\nAfter you change the port number, you must allow the new port in a security group of the instance. For more information, see Add a security group rule.\n\nBy default, the website root directory of Apache Tomcat is webapps. When you transfer a web application, such as a WAR file or a folder that contains the WEB-INF directory, to the webapps directory, Apache Tomcat automatically deploys the application. If you want to change the website root directory of Apache Tomcat, change the value of the appBase parameter.\nPress the Esc key, enter :wq, and then press the Enter key to save and close the file.\n(Optional) Configure Java Virtual Machine (JVM) memory parameters.\nIf you want to configure the JVM memory parameters of Apache Tomcat based on your business requirements to optimize the performance and stability of Apache Tomcat, perform the following steps:\nRun the following command to create and open the /usr/local/tomcat/bin/setenv.sh file:\nPress the I key to enter Insert mode and add the following content.\nSpecify the JAVA_OPTS parameter to configure JVM memory information and the encoding format. In this example, the encoding format is UTF-8.\nYou can adjust the following content to configure JVM memory parameters based on your business requirements:\nPress the Esc key to exit Insert mode. Enter :wq and press the Enter key to save and close the file.\nRun the following command to grant the execute permissions on the file:\nConfigure a script that enables Apache Tomcat to automatically start on system startup.\nRun the following command to download the script:\nRun the following command to move and rename the Tomcat-init.sh file:\nRun the following command to grant the execute permissions on the /etc/init.d/tomcat file:\nObtain the path in which Java Development Kit (JDK) is installed. Run the following command to obtain the actual path in which the Java binary file is stored. The parent directory of the Java binary file is the path in which JDK is installed.\nFor example, if /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.432.b06-2.0.2.1.al8.x86_64/jre/bin/java is returned after the command is run, JDK is installed in the /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.432.b06-2.0.2.1.al8.x86_64 path.\nRun the following command to specify the JAVA_HOME parameter in the script.\nThe JDK path specified in the JAVA_HOME parameter must be the path in which JDK is installed. Otherwise, Apache Tomcat cannot start.\nRun the following commands in sequence to enable Apache Tomcat to automatically start on system startup and start Apache Tomcat:\nAfter Apache Tomcat is started, you can run the sudo systemctl status tomcat command to check the status of Apache Tomcat. If active (running) is returned, Apache Tomcat is started.\nCheck the environment configuration.\nIn the address bar of a web browser on your on-premises device, enter http://<Public IP address of the ECS instance>:8080. If the Apache Tomcat welcome page appears, the Java web environment is configured as expected.\nIf the Apache Tomcat welcome page does not appear after you enter http://<Public IP address of the ECS instance>:8080, check whether a security group of the instance allows inbound traffic on port 8080.\nIf you changed the Apache Tomcat port number, replace 8080 with the new Apache Tomcat port number that you specified and check whether a security group of the instance allows inbound traffic on the port.\nIf you want to upload an on-premises project to test the environment, upload a WAR package to the website root directory of Apache Tomcat. In this example, the /usr/local/tomcat/webapps directory is used. Then, enter http://<Public IP address of the ECS instance>:8080/<Package name> in the address bar of a web browser to access the project. For more information, see Upload a file to or download a file from a Linux instance.\n\nIn this example, Apache Tomcat 9.0.97 is used.\nConnect to your Windows instance. For more information, see Overview of ECS Remote Connection Methods.\nDownload the Apache Tomcat installation package.\nVisit the official Apache Tomcat website, select the version that you want to install, and then download the installation package.\n\nDecompress the Apache Tomcat installation package.\nDecompress the downloaded installation package to the directory in which you want to install Apache Tomcat. In this example, the C:\\Program Files directory is used.\nObtain the directory in which you want to install Apache Tomcat.\nAfter you decompress the installation package to the directory, go to the directory and obtain the installation directory of Apache Tomcat from the address bar.\n\nConfigure environment variable settings.\nRight-click This PC and select Properties.\nOn the About page, scroll down to the bottom and click Advanced system settings.\n\nClick Environment Variables.\n\nIn the System variables section, click New to create a system variable. Then, click OK. The variable name is CATALINA_HOME and the variable value is the installation directory of Apache Tomcat. In this example, the C:\\Program Files\\apache-tomcat-9.0.97 directory is used.\n\nIn the System variables section, select the Path variable and click Edit.\n\nIn the Edit environment variable dialog box, click New to add the %CATALINA_HOME%\\bin path.\n\nClick OK twice to save the environment variable.\n\nStart Apache Tomcat.\nGo to the bin folder in the installation directory of Apache Tomcat.\nEnter cmd in the path bar and press the Enter key to open the command prompt.\nRun the startup.bat command to start Apache Tomcat. After the command is run, a new command prompt window is opened by default to display the startup logs of Apache Tomcat. Do not close the window.\n\n\nTest Apache Tomcat.\nIn the address bar of a web browser on your on-premises device, enter http://<Public IP address of the ECS instance>:8080. If the Apache Tomcat welcome page appears, Apache Tomcat is deployed as expected.\nIf the Apache Tomcat welcome page does not appear after you enter http://<Public IP address of the ECS instance>:8080, check the following items:\nCheck whether security groups of the instance allow inbound traffic on port 8080.\nCheck whether the command prompt window that is opened by default after you run the startup.bat command to start Apache Tomcat is closed. If the window is closed, rerun the startup.bat command to open the window.\nIf you want to upload an on-premises project to test Apache Tomcat, upload a WAR package to the website root directory of Apache Tomcat. In this example, the C:\\Program Files\\apache-tomcat-9.0.97\\webapps directory is used. Then, enter http://<Public IP address of the ECS instance>:8080/<Package name> in the address bar of a web browser to access the project. For more information, see Upload a file to or download a file from a Linux instance.\n"
    },
    "126": {
        "title": "Elastic Compute Service:Build an FTP site on a Windows instance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/manually-build-an-ftp-site-on-a-windows-instance",
        "content": "This Product\nElastic Compute Service:Build an FTP site on a Windows instance\nYou can build an FTP site on a Windows Elastic Compute Service (ECS) instance so that you can transfer files to or from the instance after you connect to the instance. This topic describes how to build an FTP site on a Windows ECS instance.\nAn ECS instance that meets the following requirements is created:\nThe ECS instance is assigned a static public IP address (also called system-assigned or auto-assigned public IP address) or associated with an elastic IP address (EIP). For information about how to associate an EIP with an instance, see the Associate one or more EIPs with an instance section of the \"EIPs\" topic.\nThe ECS instance runs Windows Server 2012 R2 or later.\nMake sure that the IIS and FTP services are installed on the Windows ECS instance on which you want to build an FTP site. If you have not installed the IIS and FTP services on the instance, perform the following steps to install the services:\nConnect to the Windows ECS instance.\nFor more information, see Use Workbench to connect to a Windows instance over RDP.\nIn the lower-left corner of the Windows desktop, click the  icon. Then, find and click Server Manager.\nIn the top navigation bar, choose Manage > Add Roles and Features.\n\nIn the Before you begin step, click Next.\nSelect Role-based or feature-based installation and click Next.\n\nSelect Select a server from the server pool, select the Windows ECS instance on which you want to build an FTP site, and then click Next.\n\nSelect Web Server (IIS). In the dialog box that appears, click Add Features and then click Next.\n\n\nUse the default settings and click Next until you reach the Select role services step.\nSelect IIS Management Console and FTP Server and click Next.\n\nClick Install. After the IIS and FTP server roles are added, click Close.\nCreate a Windows user to access the FTP site to be built. If you want to access the FTP site as an anonymous user with the anonymous or ftp username, skip the steps described in this section.\nIn the Server Manager window, choose Tools > Computer Management.\n\nIn the left-side navigation pane, choose System Tools > Local Users and Groups > Users. Right-click the blank area in the middle pane and select New User.\n\nIn the dialog box that appears, configure the User name and Password parameters.\nConfigure the following parameters:\nUser name: Enter a username. In this example, the ftptest username is used.\nPassword and Confirm password: Enter a password.\nThe password must contain uppercase letters, lowercase letters, and digits. Store your password in a secure location to prevent data security risks caused by password leaks.\nPassword-related settings: Select Password never expires.\nClick Create and close the New User dialog box.\nCreate a folder for sharing files with the FTP site and grant the access and modification permissions on the folder. Subsequently, when clients access the FTP site, all files are transferred by using this folder. Perform the following operations:\nOn a disk of the Windows instance, create a folder for the FTP site to use.\nIn this example, a folder named work is created on Disk C.\nRight-click the work folder and select Properties.\nClick the Security tab, select Everyone, and then click Edit.\nIf the Everyone option is unavailable, add the option. For information about how to add the option, see the What do I do if the Everyone option is unavailable when I configure permissions on a folder? section of the \"FAQ about building an FTP site\" topic.\n\nIn the dialog box that appears, select Everyone, select permissions based on your business requirements, and then click OK.\nIn this example, all permissions in the Allow column are selected.\n\nIn the lower-left corner of the Windows desktop, click the  icon. Then, find and click Server Manager.\nIn the top navigation bar, choose Tools > Internet Information Services (IIS) Manager.\n\nIn the left-side navigation pane, choose <Hostname of the Windows instance> > Sites. Then, in the Actions pane in the right part, click Add FTP Site...\n\nIn the dialog box that appears, configure parameters and click Next.\nConfigure the following parameters:\nFTP site name: Enter a name for the FTP site. Example: ftptest.\nContent Directory: Specify the path to the shared folder required by FTP. In this example, the shared folder is the work folder created on Disk C.\nConfigure the IP address and SSL settings and click Next.\nConfigure the following parameters:\nIP Address: Use the default settings.\nSSL: In this example, No SSL is selected, which indicates that SSL encryption is not required. If you want to secure data transfers and already have an SSL certificate, select Allow SSL or Require SSL.\nNo SSL: SSL encryption is not required.\nAllow SSL: The FTP server is allowed to support both non-SSL and SSL connections with a client.\nRequire SSL: SSL encryption is required for communication between the FTP server and a client.\nUse the default settings for other parameters.\nIf you select Allow SSL or Require SSL, you must select an SSL certificate. You can select an existing SSL certificate or create a new SSL certificate. For information about how to create an SSL certificate, see the How do I create a server certificate? section of the \"FAQ about building an FTP site\" topic.\nConfigure authentication and authorization information and click Finish.\nConfigure the following parameters:\nAuthentication: In this example, only Basic is selected. Then, you can use the ftptest user that you created to access the FTP site. If you do not have security requirements on data transfers, you can select Anonymous so that you can access the FTP site as an anonymous user.\nAnonymous: allows users who provide the anonymous or ftp username to access content.\nBasic: requires users to provide valid usernames and passwords to access content. Basic authentication transmits unencrypted passwords across the network. We recommend that you use basic authentication only when you are certain that the connection between the client and the FTP server is secure, such as when SSL encryption is used.\nAuthorization: In this example, Allow access to is set to Specified users, and ftptest is entered.\nAll users: All users are allowed to access the shared folder corresponding to the FTP site.\nAnonymous users: Anonymous users can access the shared folder corresponding to the FTP site.\nSpecified roles or user groups: Only specified roles or members of specified groups can access the shared folder corresponding to the FTP site. Enter roles or groups in the corresponding field.\nSpecified users: Only specified users can access the shared folder corresponding to the FTP site. Enter usernames in the corresponding field. In this example, ftptest is entered.\nPermissions: Select both Read and Write.\nAfter you perform the preceding steps, you can view the built FTP site in the Internet Information Services (IIS) Manager window.\nConfigure the firewall of the FTP site.\nIn the Internet Information Services (IIS) Manager window, double-click the FTP site name ftptest to go to the ftptest Home page.\nDouble-click FTP Firewall Support in the list of features in the middle pane.\n\nOn the FTP Firewall Support page in the middle pane, configure the parameters and click Apply in the Actions pane.\nData Channel Port Range: Enter a port range for passive connections to the FTP service. Valid range for port numbers: 1024 to 65535. Specify a port range based on your business requirements.\nExternal IP Address of Firewall: Enter the public IP address of the Windows ECS instance.\n\nFor information about the reasons for opening specific ports and suggestions on how to open ports in passive mode, see the What suggestions can I obtain when I configure ports in FTP passive mode? section of the \"FAQ about building an FTP site\" topic.\nOpen the Command Prompt window of the Windows ECS instance and run the following commands to restart the FTP service:\nAfter you build the FTP site on the Windows ECS instance, add inbound rules to the security groups of the instance to allow traffic to port 21 and the passive port range of the FTP server. Valid port numbers for the passive port range: 1024 to 65535.\nSpecify the port range based on your business requirements. We recommend that you use ports with higher numbers. In this example, the port range of 40000 to 40100 is used.\nIn the security groups of the Windows ECS instance, add inbound rules to allow traffic to port 21 and ports in the range of 40000 to 40100.\nFor information about how to add a security group rule, see Add a security group rule.\n\nFor information about security groups, see Security groups for different use cases and Common ports.\n(Optional) Configure the firewall of the Windows ECS instance.\nBy default, the firewall of the Windows ECS instance is disabled. If your firewall is enabled, open TCP port 21 and ports in the range of 40000 to 40100 for the FTP service.\nFor more information about firewall settings, see Build an FTP Site on IIS.\nYou can use Windows File Explorer, command-line tools, browsers, or third-party FTP connection tools to test the FTP server. In this example, a Windows computer is used as an FTP client and Windows File Explorer is used to access the FTP site.\nOn the Windows computer, open Windows File Explorer and enter ftp://<Public IP address of the FTP site>:21 in the address bar.\nIn this example, Windows 10 is used.\nIn the Log On As dialog box, configure logon credentials and click Log On.\nIn this example, the ftptest username and its password are used as credentials to log on to the FTP site. When you use Windows File Explorer to access the FTP site, if Use Passive FTP is not enabled for the IE browser on Windows, you cannot access the FTP site and the 200 and 501 error codes are returned. You can perform the following steps to enable Use Passive FTP for the IE browser and then access the FTP site again:\nOn the Windows computer, open the IE browser.\nIn the upper-right corner, click the  icon and select Internet options.\nClick the Advanced tab. In the Settings section, select Use Passive FTP (for firewall and DSL modem compatibility).\nClick Apply and then click OK.\nAfter you access the shared work folder that corresponds to the FTP site, you can create a test folder named test. Then, you can relog on to the Windows ECS instance. If the FTP site is built and can be used for data transfers, you can find the test folder in the work folder on Disk C.\nIf you want to manage files stored in Object Storage Service (OSS) by using FTP, you can install ossftp. For more information, see ossftp.\nAfter ossftp receives a regular FTP request, ossftp maps operations on files and folders to operations on OSS objects.\n"
    },
    "127": {
        "title": "Elastic Compute Service:Build a WordPress website on a Linux instance",
        "url": "https://www.alibabacloud.com/help/en/elastic-compute-service/latest/manually-build-a-wordpress-website-on-an-ecs-instance-that-runs-centos-8",
        "content": "This Product\nElastic Compute Service:Build a WordPress website on a Linux instance\nWordPress is a free, open-source content management system (CMS) that allows you to easily create and manage websites, including blogs, news websites, e-commerce websites, and social media websites. WordPress has a rich library of themes and plug-ins that allows you to customize the appearance and functionality of your websites. This topic describes how to build a WordPress website on Elastic Compute Service (ECS) instances that run different Linux operating systems.\nTo build a WordPress website on an existing Linux ECS instance, make sure that the instance meets the following requirements:\nA public IP address is automatically assigned to the ECS instance. Alternatively, an elastic IP address (EIP) is associated with the ECS instance. For instructions on how to enable public bandwidth, see Enable public bandwidth.\nInbound rules are added to a security group of the Linux ECS instance to open ports 22 and 80. For information about how to add a security group rule, see Add a security group rule.\nFor security reasons, only ports that are required to deploy and test the LNMP stack and the WordPress website are open. LNMP is the acronym for the names of the following open source components: Linux operating system, NGINX web server, MySQL relational database management system, and PHP programming language. You can open other ports based on your business requirements. For example, if you want to connect to a MySQL database that is deployed on an ECS instance, you must add an inbound rule to a security group of the instance to open port 3306, which is the default port for MySQL.\nThe commands that you must use to build a WordPress website on a Linux ECS instance may vary based on the operating system of the instance. Use the commands that are suitable for the operating system of your Linux ECS instance. Otherwise, you may be unable to build the WordPress website. In this topic, ECS instances that run Alibaba Cloud Linux 2, Alibaba Cloud Linux 3, CentOS 7, and CentOS 8 are used to deploy WordPress 6.4.\nDeploy an LNMP stack. For more information, see Deploy an LNMP stack.\n\nFor information about the methods for deploying an LNMP stack, see Deploy an LNMP stack. Each WordPress version requires specific PHP and MySQL versions. If the PHP or MySQL version is incompatible with the WordPress version that you want to install, WordPress may fail to be installed. For information about PHP and MySQL versions that are compatible with each WordPress version, see WordPress Compatibility.\nIn this topic, NGINX is used, which is a web server. If Apache is installed on your Linux ECS instance, WordPress is inaccessible because port 80 is used by Apache.\nConnect to an ECS instance.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nConfigure a database for WordPress.\nLog on to MySQL.\nUse the root user and enter the password of the user to log on to MySQL. The password is the password you configured for MySQL when you built the LNMP stack.\nCreate a database named wordpress for the WordPress website that you want to build.\nCreate a user named user to manage the wordpress database and set the password of the user to PASSword123. to increase data security.\nYou can run the show variables like \"%password%\"; command to query the MySQL password strength rules. In this example, the following strength rules apply to MySQL passwords: The password must be 8 to 30 characters in length and contain uppercase letters, lowercase letters, digits, and special characters. Supported special characters include ( ) ` ~ ! @ # $ % ^ & * - + = | { } [ ] : ; \u2018 < > , . ? /\nBy default, the validate_password plug-in is installed in MySQL 5.7 and later versions to validate the strength of passwords.\nGrant the user named user all permissions on the wordpress database.\nApply the preceding settings.\nExit MySQL.\nDownload WordPress and save it to the root directory of the website that you want to build.\nGo to the root directory of the NGINX website and download the WordPress package.\nIn the example, the Chinese version of WordPress is installed by default. To install the English version of WordPress, run the wget https://wordpress.org/wordpress-6.4.4.zip command to download the package for the English version of WordPress. Replace wordpress-6.4.4-zh_CN.zip with wordpress-6.4.4.zip in commands used in subsequent steps.\n(Optional) Install the unzip command.\nRun the following command in Alibaba Cloud Linux 2, Alibaba Cloud Linux 3, CentOS 7, or CentOS 8:\nRun the following command in Ubuntu 20.04 or later:\nDecompress the WordPress package.\nCopy the content of the wp-config-sample.php file in the WordPress installation directory to the wp-config.php file and use the wp-config-sample.php file as a backup.\nModify the configuration file of WordPress.\nOpen the wp-config.php file.\nPress the I key to enter Insert mode.\nModify the MySQL-related settings based on the configured database for WordPress as shown in the following code snippet.\nThe name of the database for WordPress, MySQL database username, and MySQL database password that you specify in the WordPress configuration file must be the same as those that you configure in the Configure a database for WordPress step.\nThe data of the WordPress website is stored by the user named user in the wordpress database.\nPress the Esc key to exit Insert mode. Enter :wq and press the Enter key to save and close the configuration file.\nModify the NGINX configuration file.\nRun the following command to open the NGINX configuration file:\nPress the I key to enter Insert mode and modify the configuration file.\nWithin the server braces, replace the content after root with the root directory of the WordPress website.\nIn this example, the root directory of the WordPress website is /usr/share/nginx/html/wordpress.\nWithin the location ~ .php$ braces, replace the content that follows root with the root directory of the WordPress website.\nWhen you replace the content with the root directory of the WordPress website, append a semicolon (;) to the root directory. Otherwise, NGINX cannot be restarted.\nIn this example, the php-fpm listens on the /run/php-fpm/www.sock address. Refer to the actual display for details.\n\nWithin the server braces, replace the content after root with the root directory of the WordPress website.\nIn this example, the root directory of the WordPress website is /usr/share/nginx/html/wordpress.\nWithin the location ~ .php$ braces, replace the content that follows root with the root directory of the WordPress website.\nWhen you replace the content with the root directory of the WordPress website, append a semicolon (;) to the root directory. Otherwise, NGINX cannot be restarted.\nIn this example, the php-fpm listens on the /run/php/php8.4-fpm/www.sock address. Refer to the actual display for details.\n\nPress the Esc key to exit Insert mode. Enter :wq and press the Enter key to save and close the configuration file.\nRun the following command to restart NGINX:\nInstall WordPress and log on to the WordPress website.\nOn your on-premises computer, use a web browser to access http://<Public IP address of the ECS instance> to go to the WordPress installation page.\nConfigure basic information about the WordPress website and click Run the installation.\nConfigure the following parameters:\nSite Title: the name of the WordPress website. Example: demowp.\nUsername: the username that you want to use to log on to WordPress. Make sure that the username is secure. Example: testwp.\nPassword: the password that you want to use to log on to WordPress. We recommend that you specify a strong password. Example: Wp.123456.\nYour Email: the email address that you want to use to receive notifications. Example: username@example.com.\nClick Install Wordpress.\nEnter the testwp username and the Wp.123456 password that you specified when you installed WordPress, and click LOGIN.\nYou are logged on to your WordPress website. For more information about how to use WordPress, see the WordPress documentation.\nIf you allow users to access the WordPress website by using the public IP address of the ECS instance on which the WordPress website is built, the security of the instance is compromised. To improve security, configure a domain name for the WordPress website. If you have a domain name or want to register a domain name for the WordPress website, perform the following steps:\nRegister a domain name.\nYou can register a domain name on Alibaba Cloud. For more information, see Register a domain name on Alibaba Cloud.\nApply for an Internet Content Provider (ICP) filing for the domain name.\nIf the WordPress website is built on an ECS instance that is located in a region inside the Chinese mainland, apply for an ICP filing for the domain name before you use the domain name for the WordPress website. For more information, see ICP filing process.\nYou can apply for an ICP filing for the domain name of a website hosted on an ECS instance only if the instance is a subscription instance that has a subscription duration of at least three months. If the ECS instance on which the WordPress website is built does not meet the preceding requirements, perform one of the following operations:\nIf the ECS instance is a pay-as-you-go instance, change the billing method of the instance to subscription and set the subscription duration to at least three months. For more information, see Change the billing method of an instance from pay-as-you-go to subscription.\nIf the ECS instance is a subscription instance that has a subscription duration shorter than three months, renew the instance. For more information, see Renew a subscription instance.\nThe entire ICP filing process requires 1 to 22 business days to complete. The actual amount of time required may vary.\nFor the frequently asked questions about the ICP filing process, see FAQ.\nResolve the registered domain name\nto the public IP address of the ECS instance. For more information, see Get Started.\nFor the answers to frequently asked questions about the DNS resolution issues, see FAQ about DNS resolution issues.\nReplace the public IP address of the ECS instance with the registered domain name.\nConnect to the ECS instance on which the WordPress website is built.\nFor more information, see Overview of ECS Remote Connection Methods.\nLog on to MySQL.\nSwitch to the database for WordPress.\nConfigure the registered domain name for the WordPress website.\nReplace the following variables in the command with actual values:\nhttp://<Public IP address of the ECS instance>: Replace <Public IP address of the ECS instance> with the actual public IP address of the ECS instance on which the WordPress website is built.\nhttp://www.example.com: Replace this domain name with the registered domain name for the WordPress website.\nExit MySQL.\nThe registered domain name is configured for your WordPress website.\nPossible causes and solutions:\nPort 80 is not open in the security groups of the ECS instance, the system firewall is enabled on the ECS instance, or port 80 is used by a different service.\nFor information about how to troubleshoot the issue based on the preceding causes, see What do I do if I cannot access a service deployed on an instance?\nThe PHP or MySQL version is incompatible with the WordPress version.\nEach WordPress version requires specific PHP and MySQL versions. If the PHP or MySQL version is incompatible with the WordPress version, WordPress may fail to be installed. For information about PHP and MySQL versions that are compatible with each WordPress version, see WordPress Compatibility.\nYou can make a website static to help search engines index the website. Before you configure a permalink for the WordPress website, configure static rules in the NGINX server. Perform the following steps:\nLog on to the ECS instance on which the WordPress website is hosted.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nOpen the NGINX configuration file.\nPress the I key to enter Insert mode.\nWithin the location / code braces, add the following code snippet:\nPress the Esc key to exit Insert mode. Enter :wq and press the Enter key to save and close the configuration file.\nRestart NGINX.\nYou may not have the permissions to configure themes or plug-ins in the WordPress configuration file. To resolve the issue, perform the following steps:\nLog on to the ECS instance on which the WordPress website is hosted.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nOpen the WordPress configuration file.\nPress the I key to enter Insert mode.\nAdd the following code snippet to the end of the file:\nPress the Esc key to exit Insert mode. Enter :wq and press the Enter key to save and close the configuration file.\nReturn to the WordPress dashboard and refresh the page. Check whether the FTP logon credential issue is solved.\nIf the directory cannot be created, run the following command on the ECS instance to switch the user who has permissions on the website root directory to the NGINX user. In this example, the nginx user is used.\nConnect to the ECS instance that uses the WordPress image.\nFor more information, see Use Workbench to connect to a Linux instance over SSH.\nLog on to MySQL.\nEnter the default password of the root user of MySQL as prompted.\nLog on to the MySQL database.\nTo view the username of the MySQL database, run the select user from mysql.user; command.\nChange the default username and password of the MySQL database based on your business requirements.\nChange the default username of the MySQL database.\nIn this example, the following command is run to change the default username from root to admin:\nChange the password of the default username.\nIn this example, the following command is run to change the password of the root username to newpassword:\nReload the privilege tables and apply the changes.\nExit MySQL.\nYou can use Docker to deploy WordPress. For more information, see Use Docker Compose to deploy applications.\nIf you want to upload a theme or plug-in to WordPress by using FTP, you must first build an FTP server. For information about how to build an FTP server, see the following topics:\nBuild an FTP site on a Windows instance\nBuild an FTP site on a Linux instance\nYou can build multiple websites on an ECS instance. For more information, see the following topics:\nUse IIS to configure multiple websites\nUse NGINX to configure multiple websites\nIf a domain name is connected to the WordPress website, you can configure encrypted communication over HTTPS for the domain name. For more information, see Installation overview."
    },
    "128": {
        "title": "Object Storage Service:What is OSS?",
        "url": "https://www.alibabacloud.com/help/en/oss/what-is-oss",
        "content": "This Product\nObject Storage Service:What is OSS?\nAlibaba Cloud Object Storage Service (OSS) is a secure, cost-effective, and highly reliable cloud storage service that allows you to store large amounts of data. OSS is designed to provide 99.9999999999% (twelve 9's) data durability and 99.995% data availability. OSS provides multiple storage classes to help you manage and reduce storage costs.\nOSS provides platform-independent API operations, which allows you to upload and access your data from any application, anytime, and anywhere.\nAside from the API operations, OSS provides OSS SDKs and migration tools that you can use to easily transfer large amounts of data to and from OSS. OSS provides storage classes that are intended for different storage scenarios. For example, you can store images, audio files, and video files used in your apps and websites as Standard objects for frequent access and store infrequently accessed data as Infrequent Access (IA), Archive, Cold Archive, or Deep Cold Archive objects to reduce the total costs of storage over time.\nOSS as a cloud data lake can provide high bandwidth to download objects. In specific regions, a single Alibaba Cloud account can provide up to 100 Gbit/s of total download bandwidth over the internal network and Internet to meet the requirements of AI and large-scale data analysis. For more information about the bandwidth of each region, see Bandwidth.\nVideo introduction\nWatch the following video for a quick introduction to OSS.\n\nFAQ\nBrowse the FAQ to obtain answers to frequently asked questions about OSS.\nOSS stores data as objects within buckets. To store data in OSS, you must first create a bucket within a region and specify the access control list (ACL) and storage class for the bucket. When you upload an object to OSS, you must specify the name of the object (also referred to as an object key or a key). This name is the unique identifier of the object within a bucket.\nOSS provides region-specific endpoints through which you can access your data. Endpoints allow you to use OSS operations to manage your data. OSS authenticates a request by verifying the symmetric AccessKey pair (AccessKey ID and AccessKey secret) included in the request.\nOSS ensures atomic updates to all objects and provides strong consistency for operations on all objects.\nBucket\nA bucket is a container for objects that are stored in OSS. Every object in OSS is contained in a bucket. You can configure various properties for a bucket, including the region, access control list (ACL), and storage class. Storage classes are useful when you need to store data that have different access patterns.\nObject\nObjects are the smallest data unit in OSS. Files uploaded to OSS are called objects. Unlike typical file systems, objects in OSS are stored in a flat structure instead of a hierarchical structure. An object is composed of a key, metadata, and the data stored in the object. Each object in a bucket is uniquely identified by the key. Object metadata is a group of key-value pairs that define the properties of an object, such as the file type and encoding format. You can also specify custom user metadata for objects in OSS.\nObject key\nIn OSS SDKs for different programming languages, object key, key, and object name indicate the full path of the object. You must specify the full path of an object when you perform operations on the object. For example, when you upload an object to a bucket, ObjectKey indicates the full path that includes the extension of the object, such as abc/efg/123.jpg.\nRegion\nA region is a physical location from which OSS provides services. When you create a bucket, you can select a region based on the cost or location from which the bucket is most frequently accessed. In most cases, when you access OSS from a geographically closer location, the access speed is faster. For more information, see Regions, endpoints and open ports.\nEndpoint\nAn endpoint is a domain name used to access OSS. OSS provides region-specific endpoints that you can use to access your data. You can manage your data in different regions by using OSS API operations. A region has different endpoints for access over the internal network and for access over the Internet. For example, the public endpoint used to access OSS data in the China (Hangzhou) region is oss-cn-hangzhou.aliyuncs.com, and the internal endpoint is oss-cn-hangzhou-internal.aliyuncs.com. For more information, see Regions, endpoints and open ports.\nAccessKey pair\nAn AccessKey pair is used to authenticate a requester. An AccessKey pair consists of an AccessKey ID and an AccessKey secret. OSS uses an AccessKey pair to implement symmetric encryption and verify the identity of a requester. The AccessKey ID is used to identify a user. The AccessKey secret is used to encrypt and verify the signature string. The AccessKey secret must be kept confidential. OSS supports AccessKey pairs obtained by using the following methods:\nAccessKey pairs applied for by the bucket owner.\nAccessKey pairs granted by the bucket owner by using Resource Access Management (RAM).\nAccessKey pairs granted by the bucket owner by using Security Token Service (STS).\nFor more information, see Obtain an AccessKey pair.\nAtomicity and strong consistency\nObject operations in OSS are atomic. Operations are either successful or failed without intermediate states. When an object is uploaded, you can get either the data before or after the upload. You cannot obtain partial or corrupted data.\nObject operations in OSS are highly consistent. For example, when you receive an upload (PUT) success response, you can immediately read the uploaded object, and replicas of the object are created for redundancy. Therefore, there are no scenarios in which data is not obtained when you perform the read-after-write operation. Similarly, after you delete an object, the object and its replicas no longer exist.\nFor more information about the terms in OSS, see Terms.\nVersioning\nVersioning is a bucket-level data protection feature that you can use to protect objects in a bucket against unintended operations. After versioning is enabled for a bucket, existing objects in the bucket are stored as previous versions when they are overwritten or deleted. Versioning allows you to recover accidentally overwritten or deleted objects to any previous versions. For more information, see Overview.\nBucket policy\nA bucket policy is an access policy that provides flexible and fine-grained permission management. The owner of a bucket can configure bucket policies to grant users access permissions on the bucket and the objects in the bucket. For example, you can configure bucket policies to authorize other Alibaba Cloud accounts or anonymous users to access or manage all or specific resources in your bucket. You can also configure bucket policies to grant read-only, read/write, or full permissions to different RAM users of the same Alibaba Cloud account. For more information about how to configure bucket policies, see Configure bucket policies to authorize other users to access OSS resources.\nCRR\nCross-region replication (CRR) allows you to automatically and asynchronously (in near real-time) replicate objects in a bucket from one region to a bucket in a different region within the same account or a different account. CRR replicates operations, such as the creation, overwriting, and deletion of objects, from a source bucket to a destination bucket. CRR can help you meet compliance requirements for cross-region disaster recovery and data replication. For more information, see CRR overview.\nData encryption\nServer-side encryption: OSS encrypts objects uploaded to a bucket for which server-side encryption is configured and stores the encrypted objects. When you download an object, OSS decrypts and returns the object. The x-oss-server-side-encryption header is included in the response to declare that the object is encrypted on the server side. For more information, see Server-side encryption.\nClient-side encryption: Objects are encrypted on the local client before they are uploaded to OSS. For more information, see Client-side encryption.\nData durability\nBy default, OSS permanently stores objects uploaded to a bucket except in the following circumstances:\nObjects are manually deleted by using the OSS console, OSS SDKs, API operations, or OSS tools such as ossutil and ossbrowser. For more information, see Delete objects.\nObjects are automatically deleted based on a lifecycle rule. For more information, see Lifecycle rules based on the last modified time.\nOverdue fees are not paid within 15 days after service suspension. For more information, see Service suspension.\nFor more information about OSS features, see Functions and features.\nYou can use the following methods to upload, download, and manage objects in OSS:\nOSS console\nThe OSS console is a web-based console that provides a GUI-based way to manage OSS resources. For more information, see Overview page of the OSS console.\nOSS API operations or OSS SDKs\nOSS provides RESTful API operations and OSS SDKs for multiple programming languages to facilitate custom development. For more information, see List of operations by function and Overview.\nOSS tools\nOSS provides multiple management tools, such as ossbrowser, ossutil, and ossftp. For more information, see OSS tools.\nCSG\nOSS uses a flat structure instead of a hierarchical structure to store objects. All elements are stored as objects in buckets. If you want to manage your resources in OSS in the same way you manage local directories and files on disks, use OSS with Cloud Storage Gateway (CSG). For more information, visit the CSG product page.\nOSS supports the following billing methods:\nPay-as-you-go: By default, the pay-as-you-go billing method applies to all billable items. You are charged for the actual usage of each billable item. Fees are paid after you use resources. This billing method is ideal for scenarios in which resource usage is difficult to predict. For more information, see Pay-as-you-go.\nSubscription (resource plans): OSS provides resource plans to offset fees generated for specific billable items. You can purchase resource plans that cover specific billable items at favorable prices. Resources are consumed before fees are offset by resource plans. Resource plans are ideal for scenarios in which resource usage is easy to predict. For more information, see Overview.\nStorage capacity units (SCUs): You can use SCUs to offset storage fees that are generated for using OSS and other Alibaba Cloud storage services. For more information, see SCUs.\nCompared with the pay-as-you-go billing method, resource plans and SCUs are more cost-effective.\nEach resource plan and SCU has a quota for resource usage. If your resource usage exceeds the quota, you are charged for the excess resource usage based on the pay-as-you-go billing method. We recommend that you purchase resource plans and SCUs based on your workloads and business scale.\nYou can use other Alibaba Cloud services to process data uploaded to OSS.\nThe following services are commonly used with OSS:\nImage processing (IMG): allows you to perform a variety of operations on images in OSS, such as format conversion, resizing, cropping, rotation, and watermarking. For more information, see IMG implementation modes.\nElastic Compute Service (ECS): a cloud computing service that offers elastic and efficient computing. For more information, visit the ECS product page.\nAlibaba Cloud CDN: allows you to cache OSS resources to Alibaba Cloud points of presence (POPs) that are geographically closer to your users to improve their download experience. For more information, visit the CDN product page.\nE-MapReduce (EMR): a big data processing solution built on ECS. EMR is developed based on open source Apache Hadoop and Apache Spark to facilitate data analysis and processing. For more information, visit the EMR product page.\nData Online Migration: allows you to migrate data from a third-party storage service such as AWS and Google Cloud to OSS with ease. For more information, see the Data Online Migration documentation.\nData Transport: helps you migrate large amounts of data to OSS under limited network conditions. For example, you can use Data Transport to migrate petabyte-scale data to OSS when upload speed is slow and hardware expansion costs are high. For more information, see What is Data Transport?\nIn addition to OSS, Alibaba Cloud provides other storage services, such as File Storage NAS (NAS) and Elastic Block Storage (EBS), that you can use to meet different business scenarios. For more information, see Overview.\nFor more information about Alibaba Cloud storage solutions and customer success stories, visit the Alibaba Cloud storage page."
    },
    "129": {
        "title": "Object Storage Service:Functions and features",
        "url": "https://www.alibabacloud.com/help/en/oss/product-function-node-oss",
        "content": "This Product\nObject Storage Service:Functions and features\n\n\nCategory\nFeature\nDescription\nReference\nStorage classes\nStandard\nStandard provides highly reliable, highly available, and high-performance storage for frequently accessed data.\nIA\nInfrequent Access (IA) provides highly durable storage at lower prices compared with Standard. IA has a minimum billable size of 64 KB and a minimum billable storage duration of 30 days. IA is suitable for data that is infrequently accessed, such as data accessed once or twice a month. You can access IA objects in real time. You are charged data retrieval fees when you access IA objects.\nArchive\nArchive provides highly durable storage at lower prices compared with Standard and IA. Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 60 days. You can access an Archive object after it is restored or real-time access of Archive objects is enabled. The amount of time that is required to restore an Archive object is approximately 1 minute. Archive is suitable for data that needs to be stored for a long period of time, such as archival data, medical images, scientific materials, and video footage.\nCold Archive\nCold Archive provides highly durable storage at lower prices compared with Archive. Cold Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 180 days. You must restore a Cold Archive object before you can access it. The amount of time that is required to restore a Cold Archive object varies based on the object size and the restoration mode. You are charged data retrieval fees and API operation calling fees when you restore a Cold Archive object. Cold Archive is suitable for cold data that needs to be stored for an extended period of time.\nDeep Cold Archive\nDeep Cold Archive provides highly durable storage at lower prices compared with Cold Archive. Deep Cold Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 180 days. You must restore a Deep Cold Archive object before you can access it. The amount of time that is required to restore a Deep Cold Archive object varies based on the object size and restoration mode. You are charged data retrieval fees and API operation calling fees when you restore Deep Cold Archive objects. The storage cost of Deep Cold Archive is the lowest, but it takes a long period of time to restore Deep Cold Archive objects.\nBucket management\nMirroring-based back-to-origin\nAfter you configure mirroring-based back-to-origin rules for a bucket, if a requested object does not exist in the bucket, Object Storage Service (OSS) retrieves the object from the origin specified by the back-to-origin rules. OSS returns the object retrieved from the origin to the requester and stores the object in the bucket.\nStatic website hosting\nYou can host a static website on your bucket and access the static website by using the domain name of the bucket.\nTransfer acceleration\nOSS supports the transfer acceleration feature. The feature selects the optimal route and uses tuned protocol stacks to deliver content across geographical regions. This improves the access speed and reliability.\nCreate a bucket\nA bucket is a container for objects in OSS. Before you upload an object to OSS, you must first create a bucket to store the object. You can configure various attributes for a bucket, including the region, access control list (ACL), and storage class. You can create buckets of different storage classes and store data in them based on your business requirements.\nBucket inventory\nYou can configure inventories for buckets to export the metadata of specific objects, including the object sizes and encryption status.\nResource group\nA resource group is a resource-based access control method. You can group your buckets based on your business requirements and configure different permissions for each resource group. This way, you can manage access to your buckets by group.\nPay-by-requester\nYou can enable pay-by-requester for buckets. If pay-by-requester is enabled for a bucket, the requester is charged the request and traffic fees when the requester accesses objects in the bucket. The bucket owner is charged only the storage fees of the objects. You can enable pay-by-requester to share your data in OSS without additional fees.\nDelete a bucket\nYou can delete a bucket that you no longer use to reduce costs.\nBucket tagging\nYou can classify and manage your buckets by using tags. You can use the bucket tagging feature to configure tags for buckets that are used for different purposes and configure ACLs for buckets that have specific tags.\nObject management\nObject tagging\nYou can configure object tags to classify objects. Tags allow you to configure lifecycle rules and ACLs for objects that have the same tag.\nUpload objects\nAlibaba Cloud provides various methods to upload objects to OSS buckets.\nDownload objects\nAlibaba Cloud provides various methods to download objects stored in OSS buckets. You can download objects to the default download path of your browser, or specify a directory to store the downloaded objects.\nList objects\nBy default, when you list objects in a bucket, the objects are returned in alphabetical order. You can list all objects, objects whose names contain a specific prefix, or a specific number of objects in a bucket.\nDelete objects\nYou can delete one or more objects and parts at a time. You can also configure lifecycle rules to periodically delete expired objects to reduce storage costs.\nCopy objects\nYou can copy an object from a source bucket to a destination bucket within the same region without modifying the content of the object.\nRestore objects\nYou must restore an Archive, Cold Archive, or Deep Cold Archive object before you can access it.\nRename objects\nYou cannot rename objects by simply changing their keys. To rename an object in the bucket, you can call the CopyObject operation to copy the source object to the destination object and call the DeleteObject operation to delete the source object.\nShare objects\nYou can share the URL of an object with third parties. This way, the third parties can download or preview the object.\nSearch for objects\nYou can search for objects and directories that you want to access in a bucket.\nSymbolic links\nYou can use symbolic links to access objects that are frequently accessed. A symbolic link points to an object and allows you to quickly access the object. Symbolic links are similar to shortcuts in Windows.\nManage object metadata\nInformation about objects stored in OSS includes keys, data, and object metadata. Object metadata describes object attributes. Object metadata includes standard HTTP headers and user metadata. You can use standard HTTP headers to specify HTTP request policies for an object, such as caching and forced download. You can also configure user metadata to identify the purposes or attributes of objects.\nManage directories\nCompared with traditional file systems that use a hierarchical structure, data in OSS is stored as objects in a flat structure. All objects in OSS are stored in buckets. You can create simulated directories in OSS to help you categorize objects and manage access to your objects in a simplified manner. You can delete directories that you no longer need.\nData indexing\nOSS provides the data indexing feature to allow you to query objects that match specific metadata conditions, such as the name, Etag, storage class, size, and last modified time of objects. The data indexing feature sorts and aggregates the query results based on your business requirements. This improves the efficiency of querying specific objects from a large number of objects.\nUse CSG to attach OSS buckets to ECS instances\nTo allow multiple users to access data in an OSS bucket in different locations by using different devices as they access local files, you can use Cloud Storage Gateway (CSG) to attach the OSS bucket to an Elastic Compute Service (ECS) instance and then map the bucket to a local directory. This way, you can manage OSS objects in the same manner as you manage local files and share objects.\n\nCategory\nFeature\nDescription\nReference\nAccess control\nBucket ACL\nTo implement coarse-grained access control on a bucket, such as the same read/write permissions on all objects in the bucket, configure the ACL of the bucket. The ACL of a bucket can be public-read, public-read-write, or private. You can configure the ACL of a bucket when you create the bucket or modify the ACL of an existing bucket based on your business requirements.\nObject ACL\nYou can grant the read and write permissions on a specific object in a bucket by configuring the ACL of the object. An object ACL allows you to control permissions on a specific object without affecting access permissions on other objects in the bucket. The ACL of an object can be public-read, public-read-write, or private. You can configure the ACL of an object when you create the object or modify the ACL of an existing object based on your business requirements.\nBucket policy\nYou can configure bucket policies to authorize access to resources in a bucket. You can use bucket policies to authorize one or more RAM users or RAM roles that belong to the current Alibaba Cloud account or other Alibaba Cloud accounts to access specific resources in a bucket. You can use the GUI or specify policy statements in the code editor to configure bucket policies for the bucket to accelerate authorization based on your business scenarios.\nHotlink protection\nOSS allows you to configure a Referer-based filtering policy to block requests that contain specific Referers from accessing data in your bucket. This way, you can prevent unauthorized access and unexpected traffic fees.\nCORS\nBrowsers enforce the same-origin policy, which allows JavaScript code executed on a web page to access resources only from the same origin and denies cross-origin requests. Cross-origin resource sharing (CORS) allows web browsers to initiate requests from a domain or an origin to a different domain or origin. CORS allows JavaScript code loaded on your websites to successfully request objects that have a different origin.\nData protection\nZRS\nZone-redundant storage (ZRS) stores multiple copies of your data across multiple zones in the same region. If one zone becomes unavailable, you can access the data that is stored in other zones. ZRS provides 99.9999999999% (12 nines) data durability.\nCRR\nCross-region replication (CRR) allows you to automatically and asynchronously (in near real-time) replicate objects from a bucket in one region to a bucket in a different region within the same account or a different account. CRR synchronizes operations such as object creation, overwriting, and deletion to help meet compliance, latency, security, and availability requirements.\nSRR\nSRR replicates objects across buckets within the same region in an automatic and asynchronous (near real-time) manner. Operations, such as the creation, overwriting, and deletion of objects, can be replicated from a source bucket to a destination bucket.\nVersioning\nOSS allows you to enable versioning for a bucket to protect objects that are stored in the bucket. After you enable versioning for a bucket, existing objects in the bucket are stored as previous versions when they are overwritten or deleted. If you accidentally delete or overwrite an object, you can recover the object to a previous version.\nRTC\nThe Replication Time Control (RTC) feature provided by OSS can meet your compliance requirements or business requirements for CRR. After the RTC feature is enabled, OSS replicates most of the objects that you uploaded to OSS within a few seconds and replicates 99.99% of the objects within 10 minutes. In addition, the RTC feature provides near real-time monitoring of data replication. After you enable the RTC feature, you can view various metrics of replication tasks.\nScheduled backup\nTo prevent data loss and data damage caused by accidental deletion, modification, and overwriting, you can use the scheduled backup feature to periodically back up objects in a bucket to Cloud Backup. In cases of accidental object loss, you can restore lost objects from Cloud Backup. Cloud Backup allows you to configure flexible backup policies to back up data to the cloud. You can view your backups and use them to restore data at any time.\nSecurity and compliance\nServer-side encryption\nOSS encrypts objects uploaded to a bucket for which server-side encryption is configured and stores the encrypted objects. When you call the GetObject operation to download an object, OSS decrypts and returns the object. The x-oss-server-side-encryption header is contained in the response to indicate that the object is encrypted on the server side.\nClient-side encryption\nIf client-side encryption is enabled, objects are locally encrypted before they are uploaded to OSS. Only the owner of the customer master key (CMK) can decrypt the objects. This improves data security during data transmission and storage.\nRetention policies\nThe Write Once Read Many (WORM) feature of retention policies in OSS allows you to prevent users from modifying or deleting data. If you do not want anyone, including resource owners, to modify or delete objects in a bucket within a specific period of time, you can configure a retention policy for the bucket. After you configure a retention policy, users can only read the objects in or upload objects to the bucket until the retention period ends. You can modify or delete objects after the retention period ends.\nOSS DDoS protection\nOSS DDoS protection is a proxy-based attack mitigation service that integrates OSS with Anti-DDoS Proxy. When a bucket for which OSS DDoS protection is enabled suffers a DDoS attack, OSS DDoS protection diverts incoming traffic to an Anti-DDoS instance for scrubbing and then redirects normal traffic to the bucket. This ensures the continuity of your business in the event of DDoS attacks.\nLogging\nOSS generates access logs to record access to resources stored in OSS buckets. After you enable and configure logging for a bucket, OSS generates logs on an hourly basis based on predefined naming conventions and then stores the logs in a specific bucket. You can use Simple Log Service or build a Spark cluster to analyze the logs.\nReal-time log query\nOSS generates access logs to record access to resources stored in OSS buckets. OSS uses Simple Log Service to help you query and collect statistics for OSS access logs and audit access to OSS in the OSS console, track exception events, and troubleshoot problems. This helps you improve work efficiency and make informed decisions.\n\nCategory\nFeature\nDescription\nReference\nData lake\nOSS Select\nYou can call the SelectObject operation to execute SQL statements on an object and obtain the execution results.\nOSS-HDFS\nOSS-HDFS (JindoFS) is a cloud-native data lake storage feature. OSS-HDFS provides centralized metadata management capabilities and is fully compatible with Hadoop Distributed File System (HDFS) API. You can use OSS-HDFS to manage data in data lake-based computing scenarios in the big data and AI fields.\nData processing\nIMG\nYou can add Image Processing (IMG) parameters to GetObject requests to process image objects stored in OSS. For example, you can add image watermarks to images or convert image formats.\nZIP package decompression\nIf you want to upload multiple objects at a time, upload objects with the original directory structure retained, upload a complete list of objects, or assign resources to objects, you can configure a ZIP package decompression rule and upload ZIP objects to the specified directory in an OSS bucket. Function Compute automatically decompresses ZIP objects based on the decompression rule and returns the decompressed data to the specified directory in OSS.\nEvent notifications\nYou may want to monitor changes to objects in OSS for various reasons, such as real-time processing, synchronization, listening, business logic triggers, and logging. You can configure event notification rules to monitor objects and receive notifications so that you can act accordingly at the earliest opportunity.\n\nCategory\nFeature\nDescription\nReference\nClient management\nossutil\nossutil allows you to manage OSS data by using command lines on Windows, Linux, and macOS operating systems.\nossbrowser\nossbrowser is a graphical management tool that is provided by Alibaba Cloud to help you easily manage buckets and objects in OSS. For example, you can use ossbrowser to create buckets, delete buckets, upload objects, download objects, preview objects, copy objects, move objects, and share objects.\nAccess by mounting and mapping\nossfs\nossfs allows you to mount an Object Storage Service (OSS) bucket to a local directory on a Linux system so that your application can access resources in the bucket as if they were local resources. The mount feature facilitates resource sharing.\nossftp\nossftp is an FTP server tool based on Alibaba Cloud OSS. ossftp maps operations related to files and directories to those on OSS objects and directories. This way, you can manage objects stored in OSS over FTP."
    },
    "130": {
        "title": "Object Storage Service:Benefits",
        "url": "https://www.alibabacloud.com/help/en/oss/benefits",
        "content": "This Product\nObject Storage Service:Benefits\nAlibaba Cloud Object Storage Service (OSS) provides unlimited, secure, cost-effective, and durable object storage in the cloud. This topic provides a side-by-side comparison of OSS with self-managed storage solutions to help you better understand the benefits of OSS.\nThe following table compares OSS with self-managed storage solutions in terms of ease of use, durability, security, cost, and support for intelligent storage and access acceleration.\nItem\nOSS\nSelf-managed storage solution\nEase of use\nProvides a variety of data management options. These options include standard RESTful APIs, SDKs for various programming languages, client tools, and a web-based console. You can upload, download, retrieve, and manage large amounts of data used for websites and mobile apps in the same way you use regular file systems.\nProvides unlimited bucket capacity. You can expand bucket capacity based on your business requirements. You no longer have to plan for storage capacity in order to store more files.\nSupports streaming read and write operations. This feature is suitable for scenarios where you want to store large files such as videos and require synchronous reads and writes.\nSupports the lifecycle management of data. You can configure lifecycle rules to delete expired objects or convert the storage classes of objects to more cost-effective storage classes, such as Infrequent Access (IA), Archive, Cold Archive, and Deep Cold Archive.\nRequires you to manually expand your storage capacity when the amount of data grows.\nDoes not support streaming writes and reads.\nDoes not support automatic data deletion based on lifecycle rules.\nDurability\nOSS is part of the core infrastructure used within Alibaba Group. The high availability and reliability of OSS have been tested and proved by its excellent support for performance-demanding Double 11 events. OSS is built with high redundancy in mind, and coupled with a highly available architecture. These features eliminate single points of failure (SPOFs) and provide reliable data storage, ensuring the continuity of your business even under harsh circumstances.\nProvides up to 99.995% data availability.\nProvides up to 99.9999999999% (12 nines) data durability.\nAutomatically expands bucket capacity to store your ever-growing data without causing business interruptions.\nCalculates the checksum of transferred packets to ensure data integrity during data transfer.\nProvides strong consistency for operations on objects. For example, an object can be accessed immediately and have redundant replicas on different facilities after it is uploaded or copied to a bucket.\nStores multiple replicas of each object on multiple physical devices located in different facilities within the same region for better data reliability and availability.\nOSS regularly performs checks on replicas and recovers damaged data to ensure data durability and availability.\nOSS periodically verifies the integrity of data to detect data corruption caused by factors such as hardware failures. If data is partially corrupted or lost, OSS reconstructs and recovers the data based on the replicas.\nRemains prone to data losses from hardware failures. If a disk has a bad sector, data stored on the disk may be permanently lost.\nRequires manual data restoration, which is complex, time-consuming, and labor-intensive.\nData security\nProvides enterprise-grade, multi-level security. OSS provides a suite of data security features, including server-side encryption, client-side encryption, hotlink protection, bucket policies that specify IP address blacklists and whitelists, fine-grained access control, authentication and authorization based on temporary access credentials and signed URLs, log auditing, and the Write Once Read Many (WORM) strategy.\nIsolates resources by user and supports cross-cluster data synchronization and geo-disaster recovery.\nAllows you to configure SSL/TLS encryption to protect data in the cloud.\nProvides the versioning feature to protect objects against unintended operations.\nComplies with the data security and compliance regulations of multiple organizations, including the U.S. Securities and Exchange Commission (SEC) and Financial Industry Regulatory Authority, Inc. (FINRA).\nRequires additional scrubbing devices and black hole filtering services.\nRequires a separate security mechanism.\nCost\nProvides abundant bandwidth and free inbound traffic. OSS supports connections to backbone networks through multi-homed Border Gateway Protocol (BGP).\nRequires no O&M and hosting costs on the user side.\nRequires you to manually expand your storage capacity when the amount of data grows.\nOffers limited bandwidth due to slow single-line or double-line access to backbone networks. You need to manually expand bandwidth capacity during peak hours.\nRequires dedicated O&M personnel, which adds to costs.\nIntelligent storage\nProvides a variety of data processing capabilities, such as Image Processing (IMG), video snapshot, document preview, image scenario recognition, and SQL query. OSS can be seamlessly integrated with the Hadoop ecosystem and Alibaba Cloud services such as Function Compute, E-MapReduce (EMR), Data Lake Analytics (DLA), Batch Compute, MaxCompute, and Data Disaster Recovery to manage and analyze your data.\nRequires data processing capabilities that must be separately purchased and deployed.\nAccess acceleration\nProvides the transfer acceleration feature, which uses optimal route selection and protocol stack tuning to reduce timeouts in long-distance data transfers and improve user experience. For more information, see Transfer acceleration.\nSupports accelerated content delivery. OSS can be used as an origin server and used with Alibaba Cloud CDN to accelerate access to data.\nDoes not support access acceleration."
    },
    "131": {
        "title": "Object Storage Service:Common scenarios",
        "url": "https://www.alibabacloud.com/help/en/oss/common-scenarios",
        "content": "This Product\nObject Storage Service:Common scenarios\nThis topic describes the use scenarios of Object Storage Service (OSS).\nOSS can be used to store large amounts of data, such as images, audio and video data, and logs. Various devices, websites, and mobile applications can directly write data to and read data from OSS. You can write data to OSS by uploading files or using streams.\nYou can concurrently download large amounts of data from OSS over the Internet by using a huge amount of bandwidth. OSS provides the transfer acceleration feature to accelerate uploads and downloads across countries and continents and improve user experience. For more information, see Enable transfer acceleration. You can use OSS together with Alibaba Cloud CDN to cache static data stored in OSS on Alibaba Cloud CDN points of presence (POPs). Users can access the data cached on POPs instead of the same data stored in OSS. This way, concurrent and repeated downloads of an object by users from the same region can be accelerated. For more information, see Access acceleration by using Alibaba Cloud CDN.\n\nAfter you upload objects to OSS, you can use Intelligent Media Management (IMM) and Image Processing (IMG) to process the data in the cloud. For more information, see IMG.\nTo fully monitor your cloud resources, you can use Cloud Config to efficiently collect and store scheduled snapshots and configuration changes of various Alibaba Cloud resources, including Elastic Compute Service (ECS), Virtual Private Cloud (VPC), and ApsaraDB RDS, and deliver the data to a specific OSS bucket. If the size of a single file that you want to deliver to Simple Message Queue (SMQ) exceeds 64 KB or the size of a single file delivered to Simple Log Service exceeds 1 MB, you must deliver the file to a specific OSS bucket. This way, you can prevent data loss and make full use of the massive storage capacity and cost-effectiveness of OSS to store detailed audit information. For more information, see Delivery.\nYou can use ActionTrail to record and audit user operations on cloud resources. You can also create a trail to deliver events to a specific OSS bucket for long-term data storage. This meets the requirements of scenarios, such as security monitoring and assurance, compliance audit, resource change management, and fault diagnosis and O&M. For more information, see Create a single-account trail.\nUse OSS together with Batch Compute\nBatch Compute is a high-performance cloud service designed to process a large number of concurrent jobs. Batch Compute helps you easily manage and run tens of thousands of concurrent jobs. You need to only upload the computing jobs to Batch Compute. The system intelligently runs these jobs on multiple virtual machine (VM) instances of Alibaba Cloud concurrently. After the jobs are complete, the computing results are stored in OSS. OSS securely and reliably stores large amounts of raw data or intermediate computing results. OSS ensures the availability of data at any time due to its unlimited storage capacity and real-time data access.\nUse OSS together with multiple cloud services, such as E-HPC\nAs a cloud-native distributed storage service, OSS provides solid data support for all types of data and applications. OSS plays a key role in meeting the high requirements for data management and storage in Elastic High Performance Computing (E-HPC) scenarios. E-HPC provides on-demand scaling of high-performance computing clusters, including compute nodes and GPU nodes, to run compute-intensive jobs. E-HPC is used in various scenarios, such as physical simulation, climate modeling, genomics analysis, and large-scale machine learning and training. These jobs generate and consume a large amount of data. As a cloud-native distributed storage service, OSS can be used to store a large amount of unstructured data, such as raw data and computing results. OSS allows you to import job data and executable files.\nAs the core carrier of computing resources, ECS instances are used to run various applications and services and support compute nodes in an E-HPC cluster. ECS instances use elastic IP addresses (EIPs) to provide static public IP addresses for ECS instances, which ensures service stability and availability. In order to build a secure and efficient running environment, a VPC is used to build a private network in the cloud to provide a secure and isolated network space for ECS, E-HPC, and other instances, which enhances the resource isolation and protection.\nIn addition, File Storage NAS (NAS) is used to further enhance the data sharing capabilities of clusters. As a centralized file storage service, NAS enables all compute nodes to seamlessly access shared files, which facilitates data sharing and collaboration among team members.\nIn conclusion, OSS combines multiple cloud services, such as E-HPC, to build a highly flexible, efficient, and secure cloud computing ecosystem, which meets the requirements of different scenarios, such as data storage, computing resource scheduling, network construction, and data sharing.\nElastic Desktop Service (EDS) is a cloud-based virtual computer service that allows you to remotely access and use a configured virtual desktop environment over the Internet. As a highly available and durable storage service, OSS can securely and reliably store your images. You can upload images to OSS as backups to prevent image loss due to unexpected circumstances and ensure business continuity. In addition, other users or team members can easily share the images and quickly deploy new EDS instances based on images, which improves work efficiency and maintains environment consistency.\nEDS supports the screen recording audit feature, which allows you to record and monitor the usage of applications or users in EDS and ensure data security and compliance. After you configure a management policy for the screen recording audit feature, the generated screen recording files are automatically delivered to a specific OSS bucket. This way, you can back up and securely store these files in real time. You can also view, analyze, and audit these files, which improves management efficiency and data security.\n"
    },
    "132": {
        "title": "Object Storage Service:FAQ about OSS",
        "url": "https://www.alibabacloud.com/help/en/oss/faq-15",
        "content": "This Product\nObject Storage Service:FAQ about OSS\nThis topic provides answers to some commonly asked questions about Object Storage Service (OSS).\nWhat is Alibaba Cloud OSS?\nAlibaba Cloud OSS is a secure, cost-effective, highly durable, and scalable storage service that allows you to store a large volume of data. OSS is designed to provide data durability of at least 99.9999999999% (twelve 9's) and service availability of at least 99.995%.\nWhat are the features of OSS?\nOSS supports RESTful API operations that do not need to be performed in the OSS console. You can store and access data from all applications anytime and anywhere. OSS is highly scalable. You are charged only for the resources that you use. You can scale OSS resources based on your business requirements without compromising performance or durability.\nAside from the API operations, OSS provides OSS SDKs and migration tools that you can use to easily transfer large amounts of data to and from OSS. OSS provides storage classes that are intended for different storage scenarios. For example, you can store images, audio files, and video files used in your apps and websites as Standard objects for frequent access and store infrequently accessed data as Infrequent Access (IA), Archive, Cold Archive, or Deep Cold Archive objects to reduce the total costs of storage over time.\nFor more information, see Functions and features.\nWho are the intended users of OSS?\nOSS is suitable for users who need to store large volumes of data. These users include app and software developers, game development enterprises, and webmasters of online communities, media sharing sites, and e-commerce websites.\nAudio, video, and image applications: You can use the OSS API to implement a large number of distributed data storage solutions, such as short video storage, live video recording, video on demand, photo-sharing social networking, and video albums.\nEducation: Online education platforms, such as K12, can store their large volumes of data in OSS and use Alibaba Cloud CDN for content delivery.\nAI and IoT: In the autonomous driving field, you can migrate collected training data to OSS by using Data Transport. For IoT-powered video surveillance systems, such as systems used for residential or community security, the video data captured by cameras is directly uploaded to OSS to allow real-time viewing by using mobile apps and tiered data storage based on lifecycle rules. This reduces storage costs while maintaining compliance.\nCinematic rendering: OSS offers large and scalable storage for filmmaking and media assets. OSS can be used together with Intelligent Media Management (IMM) to enable storage and intelligent data processing.\nGenomics: OSS can house data related to DNA sequencing, delivery, and diagnosis. You can combine OSS with cloud computing capabilities to create comprehensive solutions for big data storage, computing, and analysis.\nWhat data does OSS store?\nOSS is suitable for storing attachments, high-definition images, audio and video objects, and backup objects for forums, websites, and software applications, as well as objects for various applications, file synchronization software, and online storage systems.\nWhat are the advantages of OSS compared with local storage solutions?\nOSS allows developers to fully use the economy of scale provided by Alibaba Cloud at minimal cost without additional investments or performance degradation. Developers can focus on their own innovations without performance bottlenecks and security risks that may occur due to business growth. OSS is cost-effective and easy to use.\nWhat is the upper limit of the data volume that OSS can support?\nOSS does not impose limits on the total storage capacity and the storage capacity of a bucket. You can upload an object whose size is up to 5 GB by using the OSS console. To upload an object whose size is larger than 5 GB, you can use multipart upload, ossbrowser 1.0, or ossutil 2.0 (preview).\nWhat are the storage classes of OSS?\nOSS provides the following storage classes to cover various data storage scenarios from hot data storage to cold data storage: Standard, Infrequent Access (IA), Archive, Cold Archive, and Deep Cold Archive. For more information, see Overview.\nHow do I select an appropriate storage class for my data in OSS?\nThe billable size, storage duration, restoration time, and data retrieval vary with the storage class. You can store data in different storage classes based on the data access frequency and application scenarios to reduce storage costs.\nFor example, if 70% of your data is not accessed for more than 30 days, this portion of data is considered cold data. We recommend that you store cold data in the IA or Archive storage class. You can also configure lifecycle rules. This allows OSS to automatically change the storage class of cold data to IA or Archive based on the rules. In most cases, data that is accessed less frequently incurs lower storage costs.\nIf you want to access Archive or Cold Archive data, the data must be restored first, which requires minutes or even hours to complete. Data retrieval fees are generated when you restore data.\nDoes Alibaba Cloud use data that is stored in OSS?\nAlibaba Cloud does not use or disclose your data without your authorization. Alibaba Cloud processes user data only based on your service requirements or requirements of laws and regulations. For more information, see Alibaba Cloud International Website Product Terms of Service.\nDoes Alibaba Cloud use OSS to store their own data?\nYes, Alibaba Cloud developers use OSS to store authorized data for various projects. These projects rely on OSS to perform key business operations.\nHow does OSS ensure service availability when traffic spikes occur?\nOSS is designed to handle traffic spikes that may occur due to traffic that is sent from Internet applications. Pay-as-you-go pricing and unlimited capacity ensure that your service is not interrupted due to traffic spikes. OSS balances loads to prevent applications from being affected by traffic spikes.\nHow is data organized in OSS?\nOSS is a distributed object storage service that stores data in the key-value pair format. When you store an object, you must specify an object name (key). The key can then be used to obtain the content of the object.\nKeys can also be used to simulate features of directories. OSS uses a flat structure for objects instead of a hierarchical structure. All elements are stored as objects in buckets. However, OSS supports directories as a concept to group objects and simplify management. When you use API operations or OSS SDKs to configure an object, you can specify the key value, which is a full name that includes a prefix for the object to manage other objects. For example, if you set the key of an object to dir/example.jpg, a directory named dir is created in the current bucket and an object named example.jpg is created in the dir directory. If you delete the dir/example.jpg object, the dir directory is also deleted.\nWhat are the intelligent features of OSS?\nOSS seamlessly integrates with various computing frameworks, including Hadoop, Spark, MaxCompute, Batch Compute, High Performance Computing (HPC), and E-MapReduce (EMR). To simplify and facilitate user operations, OSS provides easy-to-use SaaS services, including image processing and content detection. In addition, OSS can work with IMM to improve the efficiency of media management and distribution by using various media processing algorithms.\nHow do I get started with OSS?\nBefore you use OSS, make sure that you have created an Alibaba Cloud account. For more information, see Create an Alibaba Cloud account.\nAfter you register an Alibaba Cloud account, click Activate OSS to go to the activation page.\nOptional. After you activate OSS, the default billing method is pay-as-you-go. If you want to reduce OSS fees, we recommend that you purchase resource plans. For more information, see Purchase resource plans.\nYou can get started with OSS by using the OSS console, ossbrowser, ossutil, or OSS SDKs for various programming languages. For more information, see Get started with OSS.\nWhat are the qualifications and certifications of OSS?\nAlibaba Cloud has a variety of major compliance certifications in Asia, Europe, and other countries or regions, and passed major assessments and security reviews in China. Alibaba Cloud is the first company in the world that obtains the ISO 22301 and CSA STAR gold certifications and meets the C5 additional requirements, the first in Asia Pacific to be C5 and ISO27001 certified, and the first in China to be MTCS Level 3 and ISO20000 certified. Alibaba Cloud is also the first cloud security service provider in China to receive the ISO 27001 certification from British Standards Institution (BSI) in 2012. Alibaba Cloud OSS has met the compliance requirements of the Securities and Exchange Commission (SEC) and the Financial Industry Regulatory Authority (FINRA). In addition, Alibaba Cloud is the first cloud service provider in China that has passed the audit and examination of Cohasset Associates, following AWS, Azure, Google Cloud, and IBM. For more information, see Compliance certifications.\nWhy is data restoration required?\nData restoration is required when you need to access data that is stored in OSS for long-term preservation at a low cost. You can access cold data only after you restore the data. Cold data storage significantly reduces storage costs but sacrifices the convenience of real-time access.\nWhere is my data stored?\nWhen you create an OSS bucket, you can specify an Alibaba Cloud region in which the bucket is located. By default, OSS backs up your data to one zone in the specified region. If you enable zone-redundant storage (ZRS), ZRS stores multiple copies of your data across multiple zones in the same region. Your data remains accessible even if a zone becomes unavailable.\nWhat is an Alibaba Cloud region?\nAn Alibaba Cloud region is a geographical region that contains multiple geographically isolated zones. These zones are connected to each other over networks that feature low latency, high throughput, and high redundancy.\nWhat is a zone?\nAn Alibaba Cloud region is a geographical region that contains multiple geographically isolated zones. These zones are connected to each other over networks that feature low latency, high throughput, and high redundancy. The network latency between instances that are deployed in the same zone is lower than the network latency between instances that are deployed in different zones. Zones in the same region are connected over the internal network. When a zone becomes unavailable, other zones are not affected.\nHow do I determine in which region to store my data?\nWhen you select a region, we recommend that you consider factors such as physical locations, relationships between cloud services, and resource prices. For more information, see Choose an OSS region.\nHow are users charged fees?\nOSS supports the pay-as-you-go billing method to allow you to pay for the resources that you use. You are not charged a minimum usage fee when you use OSS. You can also purchase resource plans. Resource plans are used to offset fees incurred due to resource usage. In most cases, resource plans are more cost-effective. For more information about the pricing of OSS, visit the OSS pricing page.\nHow am I charged fees when other accounts are used to access my OSS resources?\nWhen other accounts access your OSS resources, you are charged fees based on the standard pricing. You can enable the pay-by-requester mode for your bucket so that requesters are charged fees that are generated when the requesters send requests and download OSS data. For more information, see Enable pay-by-requester.\nHow do I deactivate OSS?\nIf you deactivate OSS, your business may be affected. Therefore, OSS does not provide the deactivation feature. However, you can use other methods to delete your OSS resources and stop being charged for these resources. For more information, see How do I deactivate OSS or stop OSS charging my resources?\nIs data stored in OSS in a secure manner?\nOSS ensures the security of the data that is stored. By default, only the resource owner can access resources within a bucket. OSS provides user identity verification to manage access to data. You can use various access control policies at the bucket level or object level, such as access control lists (ACLs), to grant specific permissions to specific users and user groups. The OSS console displays the buckets that are available for public access. You can set the bucket ACL to private if you do not want other users to access your bucket or object. If you set the ACL of a private bucket or object to public-read or public-read write, OSS sends you a warning. For more information, see Security and compliance.\nHow do I perform access control on my OSS data?\nOSS provides multiple access control methods, including ACLs, RAM policies, and bucket policies, to allow users to access objects stored in buckets. For more information, see Access control.\nWhat data encryption methods does OSS provide?\nServer-side encryption: OSS encrypts objects uploaded to a bucket for which server-side encryption is configured and stores the encrypted objects. When you download an object, OSS decrypts and returns the object. The x-oss-server-side-encryption header is included in the response to declare that the object is encrypted on the server side. For more information, see Server-side encryption.\nClient-side encryption: Objects are encrypted on the local client before they are uploaded to OSS. For more information, see Client-side encryption.\nHow do I prevent data stored in buckets from being accidentally deleted or overwritten?\nVersioning is a bucket-level data protection feature that you can use to protect objects in a bucket against unintended operations. After versioning is enabled for a bucket, existing objects in the bucket are stored as previous versions when they are overwritten or deleted. Versioning allows you to recover accidentally overwritten or deleted objects to any previous versions. For more information, see Versioning.\nWhat is a retention policy?\nOSS supports the Write Once Read Many (WORM) strategy that prevents an object from being deleted or overwritten for a specified period of time. You can configure time-based retention policies for buckets. After a retention policy is configured and locked for a bucket, you can read objects from or upload objects to the bucket. However, objects in the bucket or the retention policy cannot be deleted within the retention period specified in the retention policy. You can delete the objects only after the retention period ends.\nYou can configure retention policies for infrequently accessed important data that you do not want to be modified or deleted. Such data includes medical records, technical documents, and contracts. You can store the data in a specified bucket and configure a retention policy for the bucket.\nDoes OSS support online object modification?\nOSS does not allow you to modify objects online. If you want to modify objects, you can download the object to your local computer, modify the file, and then upload the file.\nDoes OSS use the triplicate mechanism?\nNo, OSS uses erasure coding (EC), which also ensures storage performance and reliability.\nHow is the 99.995% uptime calculated?\nThe uptime defined in the OSS SLA is calculated by using the following formulas:\nError rate per 5 minutes = Failed requests per 5 minutes/Total valid requests per 5 minutes x 100%\nUptime = (1 - Error rate per 5 minutes during the service period/Total number of errors in 5 minutes during the service period) \u00d7 100%\nFor more information, see the Alibaba Cloud International Website Object Storage Service Service Level Agreement\nHow do I replicate data from a bucket to another bucket in a different region?\nMultiple cross-region replication (CRR) rules can be configured for a bucket to store multiple copies of data in different regions. CRR provides automatic and asynchronous (near real-time) replication of objects across buckets in different OSS regions. Operations such as creating, overwriting, and deleting objects can be replicated from a source bucket to a destination bucket.\nWhat are the advantages of CRR?\nHow am I charged fees when I use CRR?\nAfter CRR is enabled, cross-region traffic is generated when you replicate objects across buckets in the source and destination regions. You are charged for the traffic that is generated when you use CRR. Each time an object is synchronized, OSS calculates the number of requests and the requests are charged on a pay-as-you-go basis. The traffic that is generated when you use CRR can be charged only on a pay-as-you-go basis. Resource plans are unavailable for CRR.\nHow do I query data in OSS?\nOSS supports the SelectObject operation that allows you to use SQL statements to query specific data in a CSV or JSON object instead of querying the entire object. The SelectObject operation simplifies the process used to query data and filter the data into smaller and more specific data sets. This operation is suitable for the multipart query of large objects, query of JSON objects, and analysis of log objects. For more information, see Query objects.\nWhat is OSS lifecycle management? How do I use lifecycle management to minimize OSS storage costs?\nYou can configure a lifecycle rule to regularly delete objects that are no longer accessed or convert the storage class of cold data to IA, Archive, Cold Archive, or Deep Cold Archive. This makes data management easier and reduces storage costs. For example, you can configure lifecycle rules in the following scenarios:\nA medical institution stores medical records in OSS. The objects are occasionally accessed within six months after they are uploaded, and almost never after that. In this case, you can configure a lifecycle rule to convert the storage class of the objects to Archive 180 days after they are uploaded.\nA company stores the call records of its customer service hotline in OSS. These objects are frequently accessed within the first two months, occasionally after two months, and almost never after six months. After two years, the objects no longer need to be stored. In this case, you can configure a lifecycle rule to convert the storage class of the objects to IA 60 days after they are uploaded and to Archive 180 days after they are uploaded, and delete the objects 730 days after they are uploaded.\nA bucket contains a large number of objects, and you want to delete all objects from the bucket. You may need to perform several manual deletion operations because OSS allows you to manually delete up to 1,000 objects at a time. In this case, you can configure a lifecycle rule to delete all objects in the bucket one day later. This way, all objects in the bucket can be deleted the next day.\nFor more information, see Lifecycle rules based on the last modified time.\nHow do I periodically obtain information about objects stored in a bucket?\nYou can use the bucket inventory feature to export information about specific objects in a bucket on a daily or weekly basis. Exported object information includes the number, sizes, storage classes, and encryption status of the objects. For more information, see Bucket inventory.\n"
    },
    "133": {
        "title": "Object Storage Service:Comparison between OSS and file systems",
        "url": "https://www.alibabacloud.com/help/en/oss/comparison-between-oss-and-traditional-file-systems",
        "content": "This Product\nObject Storage Service:Comparison between OSS and file systems\nThis topic provides a side-by-side comparison of Object Storage Service (OSS) with file systems to help you better understand the concepts and differences.\nThe following table compares OSS with file systems in terms of data models, data retrieval methods, advantages, and disadvantages.\nItem\nOSS\nFile system\nData model\nOSS is a distributed object storage service that stores data as key-value pairs.\nA file system uses a tree structure for directory indexing.\nData retrieval method\nObjects in OSS are retrieved based on object names, which are also referred to as keys.\nOSS uses a flat structure to store objects. For example, an object named test1/test.jpg does not mean that the object is stored in the test1 directory. In OSS, test1/test.jpg is a string that is not essentially different from example.jpg. Requests for objects that have different names consume similar resources.\nTo access a file named test1/test.jpg, you must first access the test1 directory and then obtain the test.jpg file from the directory.\nAdvantages\nOSS supports a high number of concurrent operations.\nFiles can be modified. For example, a file can be modified at a specified offset or truncated from the end. Folder operations are supported. For example, a folder can be renamed, moved, or deleted.\nDisadvantages\nObjects in OSS cannot be modified. Object content changes involve calling of a specific API operation and the generated objects have a different type from objects that are normally uploaded. You need to re-upload the entire object even if one byte of the object is modified.\nOSS supports operations on simulated directories at considerable costs. For example, when you rename a directory from test1 to test2, OSS creates a copy of all the objects whose names have the test1/ prefix and renames the copies so that their names are prefixed with test2/. This operation takes time and consumes a large number of bandwidth, storage, and computing resources. We recommend that you do not perform such operations.\nThe performance of a file system is limited by the performance of the device where the file system resides. Accessing files in deeper directories consumes more resources and requires longer time.\nWe recommend that you do not use OSS as a file system. If you must use OSS as a file system, we recommend that you only perform read, write, and delete operations for efficiency. You can make full use of OSS advantages, such as the capability to process and store large amounts of unstructured data such as images, videos, and documents.\nThe following table describes the terminologies and operations in OSS and their equivalents in file systems.\nOSS\nFile system\nobject\nfile\nbucket\nhome directory\nregion\nN/A\nendpoint\nN/A\nAccessKey\nN/A\nN/A\nmultilevel directory\nGetService\nobtain the list of home directories\nGetBucket\nObtain the list of files\nPutObject\ncreate a file\nAppendObject\nappend data to an existing file\nGetObject\nread a file\nDeleteObject\ndelete a file\nN/A\nmodify file content\nCopyObject (same source and destination objects)\nmodify file attributes\nCopyObject (different source and destination objects)\nCopy a file\nRename\nrename a file"
    },
    "134": {
        "title": "Object Storage Service:Instructions on storage solution selection",
        "url": "https://www.alibabacloud.com/help/en/oss/selection-guidance-selection-guidance",
        "content": "This Product\nObject Storage Service:Instructions on storage solution selection\n\nAlibaba Cloud Object Storage Service (OSS) allows you to store all types of data, such as images, audio files, video files, documents, software packages, files in CSV, JSON, and Parquet formats, and backup files. Each object stored in a bucket is of a specific storage class. By default, the storage class of objects stored in OSS is Standard. OSS also provides other storage classes, such as Infrequent Access (IA), Archive, Cold Archive, and Deep Cold Archive.\nWhen you select a storage class for an object, take note of the following factors:\nAccess frequency: the frequency of reading data from and writing data to OSS. Different business may access data at different frequencies, ranging from frequent to rare.\nRetrieval time: the amount of time required to read data from OSS. Different business may have different requirements for data retrieval time, ranging from real-time access to data retrieval in hours or days.\nAvailability: the probability that OSS can be used within a specific period of time. Different business may have different requirements for availability, ranging from 99.00% to 99.995%.\nDurability: the security and integrity of data stored in OSS within a specific period of time. Different business may have different requirements for durability, ranging from 99.999999999% (eleven 9's) to 99.9999999999% (twelve 9's).\nSelect an appropriate storage class for your objects based on the data access frequency, retrieval time, availability, and durability.\nStorage class\nAccess frequency\nRetrieval time\nAvailability\nDurability\nStandard zone-redundant storage (ZRS)\nFrequently accessed\nReal-time access\n99.995%\n99.9999999999% (twelve 9's)\nStandard locally redundant storage (LRS)\nFrequently accessed\nReal-time access\n99.99%\n99.999999999% (eleven 9's)\nIA ZRS\nInfrequently accessed\nReal-time access\n99.50%\n99.9999999999% (twelve 9's)\nIA LRS\nInfrequently accessed\nReal-time access\n99.00%\n99.999999999% (eleven 9's)\nArchive ZRS\nSeldom accessed\nReal-time access or 1 minute\n99.50%\n99.9999999999% (twelve 9's)\nArchive LRS\nSeldom accessed\nReal-time access or 1 minute\n99.00%\n99.999999999% (eleven 9's)\nCold Archive LRS\nRarely accessed\n1 to 12 hours\n99.00%\n99.999999999% (eleven 9's)\nDeep Cold Archive LRS\nRarely accessed\n12 or 48 hours\n99.00%\n99.999999999% (eleven 9's)\nFor more information about the pricing for each storage class, visit the OSS pricing page.\n"
    },
    "135": {
        "title": "Object Storage Service:Terms in OSS",
        "url": "https://www.alibabacloud.com/help/en/oss/terms-2",
        "content": "This Product\nObject Storage Service:Terms in OSS\nThis topic describes the basic terms used in Object Storage Service (OSS).\nA bucket is a container for objects that are stored in OSS. Every object in OSS is contained in a bucket. You can configure various properties for a bucket, including the region, access control list (ACL), and storage class. Storage classes are useful when you need to store data that have different access patterns.\nOSS uses a flat structure rather than a hierarchical structure for objects. Each object belongs to a bucket.\nYou can create multiple buckets.\nA bucket name must be unique in OSS within an Alibaba Cloud account. Bucket names cannot be changed after the buckets are created.\nThe names of buckets created by all Alibaba Cloud accounts cannot be the same. For example, if User A creates a bucket named example, other users cannot create another bucket named example.\nA bucket can contain an unlimited number of objects.\nThe name of a bucket must comply with the following naming conventions:\nThe name can contain only lowercase letters, digits, and hyphens (-).\nThe name must start and end with a lowercase letter or a digit.\nThe name must be 3 to 63 characters in length.\nObjects are the smallest data unit in OSS. Files uploaded to OSS are called objects. Unlike typical file systems, objects in OSS are stored in a flat structure instead of a hierarchical structure. An object is composed of a key, metadata, and the data stored in the object. Each object in a bucket is uniquely identified by the key. Object metadata is a group of key-value pairs that define the properties of an object, such as the file type and encoding format. You can also specify custom user metadata for objects in OSS.\nThe lifecycle of an object starts when the object is uploaded, and ends when the object is deleted. Aside from appendable objects, you cannot modify the content of an object in all stages of the lifecycle of an object. To modify the content of an object, you must upload a new object to replace the existing object. The new object must have the same name as the object whose content you want to modify.\nThe name of an object must comply with the following conventions:\nThe name must be encoded in UTF-8.\nThe name must be 1 to 1,023 characters in length.\nThe name cannot start with a forward slash (/) or a backslash (\\).\nObject names are case-sensitive. Unless otherwise stated, the OSS documentation refers to all objects or files as objects.\nIn OSS SDKs for different programming languages, object key, key, and object name indicate the full path of the object. You must specify the full path of an object when you perform operations on the object. For example, when you upload an object to a bucket, ObjectKey indicates the full path that includes the extension of the object, such as abc/efg/123.jpg.\nObjects can be classified into the following types based on how the objects are created:\nNormal\nObjects of this type are created by using simple upload. The objects can only be read and cannot be modified after the objects are uploaded. To modify the content of an existing object, you must upload an object that has the same name as the existing object to overwrite the existing object. Simple upload allows you to upload an object that is smaller than 5 GB in size. Simple upload is suitable for scenarios in which you can upload an object by sending a single HTTP request. For more information, see Simple upload.\nMultipart\nObjects of this type are created by using multipart upload. The objects can only be read and cannot be modified after the objects are uploaded. To modify the content of an existing object, you must upload an object that has the same name as the existing object to overwrite the existing object. Multipart upload is suitable for scenarios in which you can accelerate the upload of large objects, the network condition is unstable, and the object size is unknown. For more information, see Multipart upload.\nAppendable\nObjects of this type are created by using append upload. You can use append upload to upload video data to the same object immediately after the video data is generated. Append upload is suitable for real-time video streams generated in fields such as video surveillance and live streaming. For more information, see Append upload.\nAn object cannot be converted to a different object type. For example, a normal object cannot be converted to a multipart object or an appendable object.\nA region is a physical location from which OSS provides services. When you create a bucket, you can select a region based on the cost or location from which the bucket is most frequently accessed. In most cases, when you access OSS from a geographically closer location, the access speed is faster. For more information, see Regions and endpoints.\nThe region of a bucket must be specified when the bucket is created. After the bucket is created, its region cannot be changed. All objects in the bucket are stored in the region in which the bucket is located. Regions are configured for buckets instead of objects.\nAn endpoint is a domain name used to access OSS. OSS provides region-specific endpoints that you can use to access your data. You can manage your data in different regions by using OSS API operations. A region has different endpoints for access over the internal network and for access over the Internet. For example, the public endpoint used to access OSS data in the China (Hangzhou) region is oss-cn-hangzhou.aliyuncs.com, and the internal endpoint is oss-cn-hangzhou-internal.aliyuncs.com. For more information, see Regions and endpoints.\nAn AccessKey pair is used to authenticate a requester. An AccessKey pair consists of an AccessKey ID and an AccessKey secret. OSS uses an AccessKey pair to implement symmetric encryption and verify the identity of a requester. The AccessKey ID is used to identify a user. The AccessKey secret is used to encrypt and verify the signature string. The AccessKey secret must be kept confidential. OSS supports AccessKey pairs obtained by using the following methods:\nAccessKey pairs applied for by the bucket owner.\nAccessKey pairs granted by the bucket owner by using Resource Access Management (RAM).\nAccessKey pairs granted by the bucket owner by using Security Token Service (STS).\nFor more information, see Obtain an AccessKey pair.\nAtomicity\nObject operations in OSS are atomic. Operations are either successful or failed without intermediate states. When an object is uploaded, you can get either the data before or after the upload. You cannot obtain partial or corrupted data.\nStrong consistency\nObject operations in OSS are highly consistent. For example, when you receive an upload (PUT) success response, you can immediately read the uploaded object, and replicas of the object are created for redundancy. Therefore, there are no scenarios in which data is not obtained when you perform the read-after-write operation. Similarly, after you delete an object, the object and its replicas no longer exist.\nThe data redundancy mechanism is implemented based on erasure coding to ensure data durability and availability when hardware failures occur.\nOperations on objects in OSS are highly consistent. For example, when you receive an upload or replication success response, you can immediately read the uploaded object, and replicas of the object are created for redundancy.\nTo ensure that data is completely transmitted, OSS calculates the checksum of network traffic packets to check for errors when the packets are transmitted between the client and the server.\nThe data redundancy mechanism of OSS can prevent data loss even when two storage facilities are damaged at the same time.\nOSS periodically performs checks on replicas and recovers damaged data to ensure data durability and availability.\nOSS periodically verifies the integrity of data to detect data corruption caused by errors and hardware failures. If data is partially corrupted or lost, OSS recovers the data by using the replicas of the data."
    },
    "136": {
        "title": "Object Storage Service:Limits and performance metrics of OSS",
        "url": "https://www.alibabacloud.com/help/en/oss/limits",
        "content": "This Product\nObject Storage Service:Limits and performance metrics of OSS\nThis topic describes the limits and performance metrics of Object Storage Service (OSS).\nThe following table describes the maximum bandwidth of a single Alibaba Cloud account in different regions.\nRegion\nTotal download bandwidth for internal networks and the Internet\nInternet download bandwidth\nTotal upload bandwidth for internal networks and the Internet\nInternet upload bandwidth\nChina (Shanghai)\n100 Gbit/s\n10 Gbit/s\n20 Gbit/s\n10 Gbit/s\nChina (Shenzhen)\n100 Gbit/s\n10 Gbit/s\n20 Gbit/s\n10 Gbit/s\nChina (Beijing)\n100 Gbit/s\n10 Gbit/s\n20 Gbit/s\n10 Gbit/s\nChina (Hangzhou)\n100 Gbit/s\n20 Gbit/s\n20 Gbit/s\n20 Gbit/s\nChina (Zhangjiakou)\n20 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n20 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nChina (Nanjing - Local Region)\n2 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n2 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nChina (Fuzhou - Local Region)\n2 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n2 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nChina (Wuhan - Local Region)\n2 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n2 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nSouth Korea (Seoul)\n2 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n2 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nThailand (Bangkok)\n2 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n2 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nOther regions in the Chinese mainland\n10 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n10 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nOther regions outside the Chinese mainland\n5 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n5 Gbit/s\nNo additional limits apply, but the Internet upload bandwidth is limited to the total upload bandwidth for internal networks and the Internet.\nAnywhere\n10 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\n10 Gbit/s\nNo additional limits apply, but the Internet download bandwidth is limited to the total download bandwidth for internal networks and the Internet.\nIf the maximum bandwidth is reached, new requests are throttled. When a request is throttled, the response to the request contains the x-oss-qos-delay-time: number header, in which number indicates the duration in milliseconds for which the request is throttled. For a throttled upload request, this header indicates the exact duration of throttling. For a throttled download request, this header indicates a throttling duration estimated based on the extent of throttling and the object size.\nIf your business, such as offline big data processing, requires a higher bandwidth, contact\ntechnical support.\n\nThe total queries per second (QPS) for an Alibaba Cloud account is 10,000. The actual maximum QPS performance varies based on the read and write modes:\nRead/write mode\nQPS\nSequential read and write\n2,000\nNon-sequential read and write\n10,000\nIf you upload a large number of objects and the names of the objects contain sequential prefixes such as timestamps and letters, multiple object indexes may be stored in a single partition. In this case, if you send a large number of requests to query these objects, latency is increased. We recommend that you do not use object names that contain sequential prefixes if you want to upload a large number of objects. For more information about how to change sequential prefixes to random prefixes, see OSS performance best practices.\nIf your business has higher QPS requirements, contact\ntechnical support.\n\nYou can use an Alibaba Cloud account to create up to 100 buckets in the same region. If you want to create more than 100 buckets in a region based on your business requirements, go to Quota Center to submit a request.\nA bucket name must be globally unique in OSS. For more information, see Bucket naming conventions.\nAfter a bucket is created, you cannot change its name, region, or storage class.\nOSS does not impose limits on the capacity of a bucket.\nThe size of an object that you can upload\nWhen you use simple upload, form upload, or append upload to upload an object, the size of the object cannot exceed 5 GB. For more information, see Simple upload, Form upload, and Append upload.\nWhen you use multipart upload to upload an object, the size of the object cannot exceed 48.8 TB. For more information, see Multipart upload.\nThe size of an object that you can rename\nYou can rename only objects whose sizes are less than or equal to 1 GB in the OSS console. If you want to rename objects whose sizes exceed 1 GB, we recommend that you use OSS SDKs or ossutil. For more information, see Rename objects.\nThe number of objects that you can delete\nYou can delete up to 100 objects at a time in the OSS console or up to 1,000 objects at a time by using OSS SDKs. You can delete an unlimited number of objects at a time by using ossutil or ossbrowser.\nDeleted objects cannot be recovered. Proceed with caution.\nOverwrites of objects that have the same names\nBy default, if you upload an object that has the same name as an existing object, the existing object is overwritten.\nOverwritten objects cannot be recovered. Proceed with caution. To prevent objects from being accidentally overwritten, you can enable versioning for the bucket in which the objects are stored. You can also include the x-oss-forbid-overwrite header in upload requests and set the header to true.\nIf real-time access of Archive objects is not enabled and you want to access Archive, Cold Archive, or Deep Cold Archive objects, you must first restore the objects. A higher restoration priority indicates a shorter restoration period and higher data retrieval fees. For more information, see the OSS Billing Details section on the\nOSS product page.\n\nStorage class\nRestoration period\nReference value for the amounts of retrieved objects\nArchive\n1 minute\nN/A\nCold Archive\nExpedited: within 1 hour\nStandard: 2 to 5 hours\nBulk: 5 to 12 hours\nAn average of 500 Cold Archive objects can be restored per second in a region within an Alibaba Cloud account. The total amount of data retrieved based on the preceding priorities ranges from 100 TB to 120 TB per day.\nDeep Cold Archive\nExpedited: within 12 hours\nStandard: within 48 hours\nAn average of 100 Deep Cold Archive objects can be restored per second in a region within an Alibaba Cloud account. The total amount of data retrieved based on the preceding priorities ranges from 10 TB to 15 TB per day.\nAfter the reference value for the amounts of retrieved Cold Archive and Deep Cold Archive objects is exceeded, you can still submit a restore request. The restore request is queued, and the time that the restore task takes to complete may be longer than the expected time that corresponds to the selected priority.\nIf you have higher business requirements for the amount of retrieved Cold Archive and Deep Cold Archive objects, contact\ntechnical support.\n\nIf you want to map a domain name to a bucket located in a region in the Chinese mainland, you must apply for an ICP filing from the Ministry of Industry and Information Technology (MIIT).\nUp to 100 domain names can be mapped to a bucket. However, a domain name can be mapped to only one bucket.\nOSS does not impose limits on the number of domain names that can be mapped to the buckets of an Alibaba Cloud account.\nYou can configure up to 1,000 lifecycle rules for a bucket.\nCompletion time\nLifecycle rule that does not contain tags\nFor a lifecycle rule that is not based on tags, up to 1 billion lifecycle management actions, including object deletion, storage class conversion, and part expiration, can be completed within 24 hours in the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), and Singapore. If the number of lifecycle management actions based on the lifecycle rule exceeds 1 billion, the time required to complete the actions may exceed 24 hours.\nFor a lifecycle rule that is not based on tags, up to 100 million lifecycle management actions can be completed within 24 hours in other regions. If the number of lifecycle management actions based on the lifecycle rule exceeds 100 million, the time required to complete the actions may exceed 24 hours.\nLifecycle rule that contains tags\nFor a lifecycle rule that is based on tags, up to 500 million lifecycle management actions, including object deletion, storage class conversion, and part expiration, can be completed within 24 hours in the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), and Singapore. If the number of lifecycle management actions based on the lifecycle rule exceeds 500 million, the time required to complete the actions may exceed 24 hours.\nFor a lifecycle rule that is based on tags, up to 50 million lifecycle management actions can be completed within 24 hours in other regions. If the number of lifecycle management actions based on the lifecycle rule exceeds 50 million, the time required to complete the actions may exceed 24 hours.\nIf versioning is enabled for a bucket, a lifecycle management action on each object version in the bucket is counted towards the applicable limit.\nYou can configure up to 20 back-to-origin rules for a bucket.\nIn regions in the Chinese mainland and the China (Hong Kong) region, the default QPS and the default bandwidth for mirroring-based back-to-origin requests are 2,000 and 2 Gbit/s, respectively. In other regions, the default QPS and the default bandwidth for mirroring-based back-to-origin requests are 1,000 and 1 Gbit/s, respectively.\nLimits on images\nSource images\nOnly JPG, PNG, BMP, GIF, WebP, TIFF, HEIC, and AVIF images are supported.\nA source image cannot be greater than 20 MB in size.\nFor the rotate operation, the height or width of a source image cannot exceed 4,096 pixels. For other operations, the width or height of a source image cannot exceed 30,000 pixels, and the total number of pixels of the source image cannot exceed 250 million.\nThe total number of pixels of a dynamic image, such as a GIF image, is calculated by using the following formula: Width \u00d7 Height \u00d7 Number of image frames. The total number of pixels of a static image, such as a PNG image, is calculated by using the following formula: Width \u00d7 Height.\nResized images\nThe width or height of a resized image cannot exceed 16,384 pixels. The total number of pixels of the resized image cannot exceed 16,777,216.\nLimits on image styles\nYou can create up to 50 image styles for a bucket.\nIf you want to create more styles based on your business requirements, contact\ntechnical support.\n\nLimits on processing capabilities\nPer-second processing throughput (by source image)\nThe maximum throughput of image processing is 20 MB/s for the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), and China (Shenzhen).\nThe maximum throughput of image processing for other regions is 2 MB/s.\nQPS\nThe QPS is 50 for the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), and China (Shenzhen).\nThe QPS for other regions is 5.\nYou may want processing capabilities that exceed the preceding limits in compute intensive business applications, such as encoding WebP, AVIF, or HEIF images at a resolution higher than 1080p. To increase the processing capabilities, contact\ntechnical support.\n\nResource plans that you purchase for a specific region can be used to offset the fees for resource usage only in the region.\n\n\nYou cannot change the region of a purchased resource plan.\nYou can purchase only one storage plan for a given period of time. However, you can upgrade the storage plan that you purchased. For more information about how to upgrade a storage plan, see Overview.\nYou can purchase multiple transfer acceleration plans and back-to-origin traffic plans that have the same validity period to offset your fees. However, these plans cannot be upgraded or renewed.\nYou can purchase multiple outbound traffic plans that have the same validity period to offset your fees. These plans can be renewed but cannot be upgraded.\nNo resource plans can be used to offset API operation calling fees, data processing fees, and cross-region replication (CRR) traffic fees. You are charged these fees based on the pay-as-you-go billing method. For more information, see API operation calling fees, Data processing fees, and Traffic fees.\n"
    },
    "137": {
        "title": "Object Storage Service:Release notes for OSS features",
        "url": "https://www.alibabacloud.com/help/en/oss/release-notes",
        "content": "This Product\nObject Storage Service:Release notes for OSS features\nThis topic describes the release notes for Object Storage Service (OSS) and provides links to the relevant references.\nFeature\nDescription\nRelease date\nRegion\nReferences\nQuality of service (QoS) policy of resource pools\nAfter you add multiple buckets in your Alibaba Cloud account to the same resource pool, you are allowed to dynamically change the bandwidth of each bucket based on their usage. This ensures that resources are preferentially allocated to key services and compute-intensive tasks during peak hours and prevents bottlenecks caused by uneven resource allocation.\n2024-11-29\nAll regions\nResource pool QoS\nOSS SDK for Go V2.0\nOSS SDK for Go V2 is a major rewrite of the OSS SDK for Go V1 code repository.\nOSS SDK for Go V2 is a new version that simplifies underlying operations such as identity authentication, automatic request retry, and error handling. You can access OSS by calling API operations without complex programming.\nOSS SDK for Go V2 provides flexible parameter configuration methods and rich advanced operations, such as paginator, transmission managers, and File-like operations. This comprehensively improves development efficiency and experience.\n2024-11-26\nAll regions\nOSS SDK for Go 2.0 (preview version)\nGet Started\nFeature\nDescription\nRelease date\nRegion\nReferences\nData indexing-AISearch\nAISearch is available. AISearch allows you to quickly search for specific objects among a large number of objects based on object information conditions of documents, images, videos, and audio files, such as semantic content, multimedia metadata, and custom metadata. AISearch improves search efficiency based on object content and multimedia attributes.\n2024-09-25\nChina (Qingdao), China (Beijing), China (Zhangjiakou), China (Hangzhou), China (Shanghai), China (Shenzhen), China (Guangzhou), and China (Chengdu)\nOverview\nAISearch\nOSS Connector for AI/ML\nOSS Connector for AI/ML is a Python library that is used to efficiently access and store OSS data in PyTorch training jobs. You can build map-style and iterable-style datasets that are suitable for random data access and sequential streaming data access by using data in OSS. OSS Connector for AI/ML allows you to create an OssCheckpoint object. This object allows you to directly load checkpoints from OSS during model training and save checkpoints to OSS after periodic model training. This way, workflow is simplified.\n2024-09-02\nAll regions\nOSS Connector for AI/ML\nFeature\nDescription\nRelease date\nRegion\nReferences\nossutil v2\nCompared with ossutil 1.0, ossutil 2.0 is comprehensively and significantly optimized and improved in the following aspects: the structure and supported types of configuration files, the uniformity of commands in different operating systems, the functions and rules of various types of commands, the matching mode and supported values of options, the default parameter configurations, and the default status of resumable upload.\n2024-07-31\nAll regions\nossutil 2.0 (preview)\nFeature\nDescription\nRelease date\nRegion\nReferences\nAccess OSS by using PrivateLink\nPrivateLink can be used to establish private, stable, and secure connections between virtual private clouds (VPCs) and other Alibaba Cloud services. PrivateLink simplifies network architectures and prevents risks that may arise from accessing services over the Internet.\n2024-06-13\nChina (Hangzhou), China (Shanghai), China (Beijing), China (Ulanqab), China (Shenzhen), China (Hong Kong), Singapore, and Indonesia (Jakarta)\nAccess OSS by using PrivateLink\n\nFeature\nDescription\nRelease date\nRegion\nReferences\nBandwidth increase in the China (Hangzhou) region\nThe total download bandwidth for internal networks and the Internet is increased to 100 Gbit/s in the China (Hangzhou) region.\n2024-05-10\nChina (Hangzhou)\nLimits and performance metrics\n\nFeature\nDescription\nRelease date\nRegion\nReferences\nBlock Public Access\nYou can allow public access to OSS resources by configuring bucket policies and access control lists (ACLs). Public access specifies access to OSS resources without specific permissions or authentication. Public access can cause data breaches and generate a large amount of outbound traffic over the Internet due to malicious access. To prevent risks caused by public access, OSS allows you to enable Block Public Access with a few steps for OSS, a bucket, an access point, and an Object FC Access Point. If you enable Block Public Access, existing public access permissions are ignored and you cannot configure public access permissions. This disables public data access channels and ensures data security.\n2024-04-11\nAll regions\nBlock Public Access\n\nFeature\nDescription\nRelease date\nRegion\nReferences\nPermissions to activate OSS\nThe oss:ActivateProduct permission is required for a RAM user or RAM role to activate OSS.\n2023-12-25\nAll regions\nExample 14: Authorize a RAM user to activate OSS\nPermissions to purchase OSS resource plans\nThe oss:CreateOrder permission is required for a RAM user or RAM role to purchase OSS resource plans.\n2023-12-20\nAll regions\nExample 13: Authorize a RAM user to place an order for an OSS resource plan\nFeature\nDescription\nRelease date\nRegion\nReferences\nBandwidth increase in the China (Shanghai) and China (Shenzhen) regions\nThe total download bandwidth over the internal network and the Internet is increased from 10 Gbit/s to 100 Gbit/s in the China (Shanghai) and China (Shenzhen) regions.\n2023-10-31\nChina (Shanghai) and China (Shenzhen)\nLimits and performance metrics\nObject FC Access Point\nIf you want OSS to automatically trigger Function Compute when you initiate a GetObject request and return the transformed result of the retrieved data to the application, you must initiate the request by using an Object FC Access Point. You can initiate requests by using Object FC Access Points to seamlessly modify or filter the content of objects without the need to change object storage semantics or modify the client.\n2023-10-31\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Shenzhen), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Japan (Tokyo), South Korea (Seoul), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Germany (Frankfurt), and UK (London)\nCreate Object FC Access Points\nCompile a function that is used to process GetObject requests\nUse Object FC Access Points\nCRR\nCross-region replication (CRR) across accounts and same-region replication (SRR) across accounts allow the automatic and asynchronous (near real-time) replication of OSS objects from a bucket within an Alibaba Cloud account to another bucket within another Alibaba Cloud account. CRR across accounts requires that the source and destination buckets be located in different regions, and SRR across accounts requires that the source and destination buckets be located in the same region. CRR across accounts and SRR across accounts replicate operations, such as the creation, overwriting, and deletion of objects, from a source bucket to a destination bucket.\n2023-10-17\nAll regions\nCRR across accounts\nSRR across accounts\nData replication permissions\nFeature\nDescription\nRelease date\nRegion\nReferences\nTLS version management\nCommunication between client applications and OSS is encrypted by using the transport layer security (TLS) protocol. TLS is a standard cryptographic protocol that ensures privacy and data integrity between clients and servers that communicate over the Internet. You can use an OSS server to configure the TLS version. After you configure the TLS version, clients can use only the configured TLS version to send requests to and receive requests from OSS to meet the security requirements of the communication link.\n2023-09-19\nAll regions\nConfigure the TLS version\nFeature\nDescription\nRelease date\nRegion\nReferences\nReal-time access of Archive objects\nReal-time access of Archive objects is supported. This feature allows you to access Archive objects in real time without the need to restore them. Compared with accessing restored objects, real-time access of Archive objects requires less time to retrieve data but generates higher data retrieval fees. This feature is suitable for occasional access to rarely accessed data.\n2023-06-30\nAll regions\nReal-time access of Archive objects\nData processing fees\nChange of the storage redundancy type\nThe storage redundancy type of a bucket can be changed from locally redundant storage (LRS) to zone-redundant storage (ZRS) to withstand zone-level failures.\n2023-06-28\nChina (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), China (Hong Kong), Japan (Tokyo), Singapore, Indonesia (Jakarta), and Germany (Frankfurt).\nOverview\nChange the storage redundancy type of a bucket\nFeature\nDescription\nRelease date\nRegion\nReferences\nDeep Cold Archive\nDeep Cold Archive provides highly durable storage at lower prices compared with Cold Archive. Deep Cold Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 180 days. You must restore a Deep Cold Archive object before you can access it. The amount of time that is required to restore a Deep Cold Archive object varies based on the object size and restoration priority. You are charged data retrieval fees and API operation calling fees when you restore Deep Cold Archive objects. Deep Cold Archive is suitable for extremely cold data that must be stored for an extremely long period of time, including raw data that is accumulated over an extended period of time in the big data and AI fields, retained media resources, regulatory and compliance documents, and data that needs to be migrated from tapes to the cloud for long-term storage.\n2023-05-07\nChina (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), and Singapore\nDeep Cold Archive\nFeature\nDescription\nRelease date\nRegion\nReferences\nBandwidth increase in the China (Beijing) region\nThe total download bandwidth over internal and external networks is increased from 10 Gbit/s to 100 Gbit/s in the China (Beijing) region.\n2023-03-12\nChina (Beijing)\nLimits and performance metrics\nFeature\nDescription\nRelease date\nRegion\nReferences\nSignature tools\nThe OSS console provides the following signature tools:\nSignature in Authorization Header\nAfter you use the signature tool to specify parameters, the system automatically generates a request signature and verifies the request signature.\nPostObject Policy Signature\nAfter you use the signature tool to specify parameters, the system automatically generates a request signature for the upload task by using an HTML form and verifies the request signature.\nURL Signature\nYou can use the signature tool to generate a signed object URL for temporary access. When you generate a signed object URL, you can specify the validity period of the URL to limit the period in which visitors can use the URL to access resources.\n2023-02-03\nAll regions\nSignature in Authorization Header\nPostObject Policy Signature\nURL Signature\nFeature\nDescription\nRelease date\nRegion\nReferences\nResource group\nA resource group is a resource-based access control method. You can group your buckets based on your business requirements and configure different permissions for each resource group. This way, you can manage access to your buckets by group.\n2022-12-16\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Japan (Tokyo), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Germany (Frankfurt), UK (London), and UAE (Dubai)\nUse resource groups\nRTC\nThe Replication Time Control (RTC) feature provided by OSS can meet your compliance requirements or business requirements for CRR. After the RTC feature is enabled, OSS replicates most of the objects that you uploaded to OSS within a few seconds and replicates 99.99% of the objects within 10 minutes. In addition, the RTC feature provides near real-time monitoring of data replication. After you enable the RTC feature, you can view various metrics of replication tasks.\n2022-12-01\nRegions in the Chinese mainland\nRTC is available in the following regions: China (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), and China (Shenzhen).\nRegions outside the Chinese mainland\nRTC is available in the following regions: US (Silicon Valley) and US (Virginia).\nRTC\nFeature\nDescription\nRelease date\nRegion\nReferences\nResponse header adjustment for object access\nThe Content-Disposition: attachment header is automatically added to the response that is returned when you access an OSS object from a browser by using the default domain name of a bucket created after October 9, 2022. The browser detects the value of the response header and downloads the object as an attachment instead of providing a preview of the object. This response header is not added if you access objects by using a custom domain name.\n2022-10-09\nAll regions\nWhat do I do if an object cannot be previewed when I access the object?\nFeature\nDescription\nRelease date\nRegion\nReferences\nAutomatic storage tiering of OSS-HDFS\nThe automatic storage tiering feature of OSS-HDFS is available. Some data stored in OSS-HDFS does not need to be frequently accessed. However, due to data compliance or archiving requirements, the data still needs to be retained. To meet your business requirements, OSS-HDFS provides the automatic storage tiering feature. Data that is frequently accessed is stored as Standard objects, whereas data that is infrequently accessed is stored as Archive objects. This helps reduce the total storage costs.\n2022-08-16\nChina (Hangzhou), China (Shanghai), China (Shenzhen), China (Beijing), China (Zhangjiakou), and Singapore\nAutomatic storage tiering of OSS-HDFS\nFeature\nDescription\nRelease date\nRegion\nReferences\nData indexing-MetaSearch\nObject Storage Service (OSS) provides MetaSearch to allow you to quickly search for specific objects among a large number of objects based on object metadata conditions. The metadata of objects can be specified as index conditions to query objects. This way, you can efficiently manage and learn about data structures, perform queries, collect statistics, and manage objects.\n2022-03-21\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Shenzhen), China (Guangzhou), China (Chengdu), China (Hong Kong), Singapore, Indonesia (Jakarta), Germany (Frankfurt), US (Silicon Valley), US (Virginia), and UK (London)\nOverview\nMetaSearch\nFeature\nDescription\nRelease date\nRegion\nReferences\nOSS-HDFS\nOSS-HDFS is compatible with Hadoop Distributed File System (HDFS) API operations and supports directory-level operations. This facilitates the use of OSS resources in open source ecosystems.\n2022-01-27\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Ulanqab), China (Shenzhen), China (Guangzhou), China (Zhangjiakou), China (Hong Kong), Japan (Tokyo), Singapore, Germany (Frankfurt), US (Silicon Valley), US (Virginia), Indonesia (Jakarta), and Thailand (Bangkok)\nWhat is OSS-HDFS?\nFeature\nDescription\nRelease date\nRegion\nReferences\nLifecycle rules based on last access time\nYou can configure lifecycle rules based on the last access time of objects in a bucket. After you configure a lifecycle rule based on the last access time of objects, OSS monitors the access patterns of objects in the bucket, identifies cold data, and then converts the storage class of cold data. This way, cold data is stored by using storage classes that are different from the storage classes of hot data, which helps you reduce storage costs.\n2021-10-19\nAll regions\nLifecycle rules based on last access time\nFeature\nDescription\nRelease date\nRegion\nReferences\nSRR\nSRR replicates objects across buckets within the same region in an automatic and asynchronous (near real-time) manner. Operations, such as the creation, overwriting, and deletion of objects, can be replicated from a source bucket to a destination bucket.\n2021-09-06\nAll regions\nSRR\nFeature\nDescription\nRelease date\nRegion\nReferences\nOSS DDoS protection for custom domain names\nDDoS protection is supported for custom domain names of buckets. If you want to access a bucket by using the custom domain names that are mapped to the bucket when the bucket is under attack, add the custom domain names to the protection lists of Anti-DDoS instances in the OSS console. Up to five custom domain names can be added for each bucket.\n2021-08-13\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Shenzhen), and China (Hong Kong)\nOSS DDoS protection\nCold Archive storage\nCold Archive is suitable for cold data that needs to be stored for a long period of time. Cold Archive objects have a minimum billable size of 64 KB and a minimum billable storage period of 180 days. The unit price of Cold Archive is lower than that of Archive.\n2021-08-01\nCold Archive is supported in the following regions: China (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Japan (Tokyo), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Germany (Frankfurt), UK (London), and UAE (Dubai).\nCold Archive\nFeature\nDescription\nRelease date\nRegion\nReferences\nObject tagging for different versions of an object\nAfter versioning is enabled for a bucket, object tagging can be configured for different versions of objects stored in the bucket.\n2021-07-15\nAll regions\nConfigure object tagging\nFeature\nDescription\nRelease date\nRegion\nReferences\nBucket Policy\nBucket policies can be configured by using graphical user interfaces (GUIs) and policy syntax.\n2021-04-16\nAll regions\nConfigure bucket policies to authorize other users to access OSS resources\nCRR improvement\nCRR automatically and asynchronously (in near real time) replicates objects across buckets in different OSS regions. CRR can help you meet compliance requirements for cross-region disaster recovery and minimize the latency that occurs when customers from different regions access the data in the bucket.\n2021-04-23\nAll regions\nCRR\nFeature\nDescription\nRelease date\nRegion\nReferences\nExport of multiple object URLs at a time\nThe URLs of multiple objects can be exported at a time. This makes it easier to export object URLs and share the URLs with third parties for object downloads or previews.\n2021-01-18\nAll regions\nUse object URLs\nOSS DDoS protection\nOSS DDoS protection can be used to protect buckets from DDoS attacks and maintain normal access to the buckets in the face of DDoS attacks.\n2021-01-07\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Shenzhen), and China (Hong Kong)\nOSS DDoS protection\nFeature\nDescription\nRelease date\nRegion\nReferences\nMirroring-based back-to-origin rules for objects in private buckets\nMirroring-based back-to-origin rules can be configured to obtain private objects in other buckets owned by the same Alibaba Cloud account.\n2020-12-17\nAll regions\nOverview\nDecompression of a ZIP package to a subdirectory with the same name as the package\nA ZIP package can be decompressed to a subdirectory that has the same name as the package. This way, files decompressed from different ZIP packages can be easily classified.\n2020-12-01\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Shenzhen), China (Chengdu), China (Hong Kong), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Japan (Tokyo), Germany (Frankfurt), UK (London), US (Virginia), and US (Silicon Valley)\nZIP package decompression\nFeature\nDescription\nRelease date\nRegion\nReferences\nService availability improvement of the Standard storage class\nThe service availability of the Standard storage class is improved:\nStandard ZRS: provides 99.995% service availability.\nStandard LRS: provides 99.99% service availability.\n2020-11-12\nAll regions\nOverview\nCRR for encrypted objects\nCRR supports replicating objects that are encrypted by using server-side encryption based on KMS-managed CMKs (SSE-KMS) or server-side encryption based on OSS-managed keys (SSE-OSS).\n2020-11-01\nAll regions\nConfigure CRR\nFeature\nDescription\nRelease date\nRegion\nReferences\nDisplay of the list of directory deletion tasks in the OSS console\nThe progress of directory deletion tasks is displayed, and ongoing deletion tasks in the task list can be paused at any time.\n2020-09-28\nAll regions\nDelete directories\nFeature\nDescription\nRelease date\nRegion\nReferences\nCRR for objects with specific tags\nWhen versioning is enabled for both the source and destination buckets and the Replication Policy parameter is set to Add/Change, a CRR rule can be configured to replicate objects that have specific tags to the destination bucket.\n2020-08-28\nIf the source region is China (Hangzhou), the destination region can be a region other than China (Hangzhou)\nConfigure CRR\nTransfer acceleration for CRR\nTransfer acceleration is supported for CRR tasks.\n2020-08-28\nBetween regions inside and outside the Chinese mainland\nConfigure CRR\nFeature\nDescription\nRelease date\nRegion\nReferences\nAcceleration endpoint of regions outside the Chinese mainland for transfer acceleration\nThe following acceleration endpoint of regions outside the Chinese mainland is supported for transfer acceleration: oss-accelerate-overseas.aliyuncs.com. If you want to use a custom domain name that is not filed at the Ministry of Industry and Information Technology (MIIT) to enable transfer acceleration for a bucket outside the Chinese mainland, map the custom domain name to this endpoint. In other scenarios, we recommend that you use the global acceleration endpoint.\n2020-07-28\nAll regions outside the Chinese mainland\nMap a custom domain to an OSS-accelerated domain\nRecovery and batch deletion of previous versions of objects in the OSS console\nSpecified previous versions of an object in a versioning-enabled bucket can be recovered, and multiple previous versions of objects can be deleted at a time by using the OSS console.\n2020-07-24\nAll regions\nConfigure versioning\nMirroring-based back-to-origin with a forward slash (/) retained in the name of the origin file\nIf the name of the requested file in the origin starts with a forward slash (/), the forward slash is retained in the origin URL of the file.\n2020-07-20\nUS (Silicon Valley), US (Virginia), and China (Hangzhou)\nOverview\nFeature\nDescription\nRelease date\nRegion\nReferences\nAuto CDN cache update supported for specified operations\nOperations, such as PutObject and DeleteObject, can be specified to trigger auto CDN cache updates. When the specified operations are performed on objects, the CDN cache is automatically updated.\n2020-06-05\nAll regions\nMap accelerated domain names\nFeature\nDescription\nRelease date\nRegion\nReferences\nMD5 verification and object name prefix replacement for mirroring-based back-to-origin\nMD5 verification is supported for mirroring-based back-to-origin. When the response contains the Content-MD5 header, OSS checks whether the MD5 hash of the returned object matches the value of Content-MD5. If the MD5 hash matches the value of Content-MD5, the object is stored in OSS. Otherwise, the object is discarded.\nReplacement of object name prefixes is supported for mirroring-based back-to-origin. When OSS sends a request to the origin, the prefix in the object name is replaced with the specified prefix.\n2020-05-22\nAll regions\nOverview\nRetention of directories uploaded by using drag upload\nWhen a directory is uploaded to OSS by using drag upload in the OSS console, all subdirectories in the directory are retained.\n2020-05-22\nAll regions\nUpload objects\nFeature\nDescription\nRelease date\nRegion\nReferences\nBucket inventory\nYou can use the bucket inventory feature to export information about specific objects in a bucket, such as the number, size, storage class, and encryption status. To list a large number of objects, we recommend that you use the bucket inventory feature instead of the GetBucket (ListObjects) operation.\n2020-04-30\nAll regions\nBucket inventory\nImprovement in OSS SLA-guaranteed availability\nThe SLA-guaranteed availability of Standard LRS objects is improved from 99.9% to 99.99%. The SLA-guaranteed availability of Standard ZRS objects is improved from 99.95% to 99.995%.\n2020-04-30\nAll regions\nOverview\nCold Archive storage\nThe Cold Archive storage class is available. Cold Archive is suitable for cold data that must be stored for a long period of time. Cold Archive objects have a minimum storage size of 64 KB and a minimum storage period of 180 days. The unit price of Cold Archive is lower than that of Archive.\n2020-04-22 (invitational preview)\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Japan (Tokyo), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Germany (Frankfurt), UK (London), and UAE (Dubai)\nCold Archive\nFeature\nDescription\nRelease date\nRegion\nReferences\nTemporary access authorization by using bucket policies\nBucket policies can be used to grant users temporary access permissions.\n2020-03-13\nAll regions\nConfigure bucket policies to authorize other users to access OSS resources\nFeature\nDescription\nRelease date\nRegion\nReferences\nIncrease in the maximum number of buckets that can be created\nThe maximum number of buckets that can be created by using an Alibaba Cloud account in a region is increased to 100.\n2019-12-13\nAll regions\nLimits and performance metrics\nFeature\nDescription\nRelease date\nRegion\nReferences\nVersioning\nVersioning protects data at the bucket level. When versioning is enabled for a bucket, data that is overwritten or deleted in the bucket is saved as a previous version. After you enable versioning for a bucket, you can recover objects in the bucket to a previous version to protect your data from being accidentally overwritten or deleted.\n2019-11-15\nAll regions\nOverview\nFeature\nDescription\nRelease date\nRegion\nReferences\nChanges to the image preview feature\nIf OSS domain names are used in a browser to access image objects in buckets that are created on or after September 23, 2019, the objects are downloaded as attachments. To preview an image when you access the image from a browser, you must use a custom domain name. Buckets that are created before 00:00:00 September 23, 2019 are not affected.\n2019-09-23\nAll regions\nMap custom domain names\nTransfer acceleration\nTransfer acceleration is available. Transfer acceleration is implemented by using data centers that are distributed around the globe. When a data transfer request is sent, the request is resolved and routed over the optimal network path and protocol to the data center in which your bucket is located. Transfer acceleration improves user experience and reduces the amount of time needed for your business to deliver services to users.\n2019-09-10\nAll regions\nTransfer acceleration\nZRS\nZRS stores multiple copies of your data across multiple zones in the same region. If a zone becomes unavailable, you can continue to access the data that is stored in other zones. ZRS provides 99.9999999999% (twelve 9's) data durability and 99.995% service availability.\n2019-09-09 (available for commercial use)\nChina (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), China (Hong Kong), Japan (Tokyo), Singapore, Indonesia (Jakarta), and Germany (Frankfurt)\nCreate a ZRS bucket\nFeature\nDescription\nRelease date\nRegion\nReferences\nBucket tagging\nBucket tags can be configured to classify and manage buckets. For example, you can list buckets that have specific tags and configure ACLs for buckets that have specific tags.\n2019-08-29\nAll regions\nManage bucket tagging\nObject tagging\nObject tags can be configured to classify objects. You can configure lifecycle rules and ACLs for objects that have specific object tags.\n2019-08-29\nAll regions\nAdd tags to an object\nSingle-connection bandwidth throttling\nBandwidth throttling for upload, download, and copy operations is supported to ensure sufficient bandwidth for other applications.\n2019-08-17\nAll regions\nSingle-connection bandwidth throttling\nFeature\nDescription\nRelease date\nRegion\nReferences\nServer-side encryption\nServer-side encryption of uploaded data is supported. When you upload data, OSS encrypts the received data and stores the encrypted data. When you download the data, OSS automatically decrypts the encrypted data. OSS returns the original data and declares that the data has been encrypted on the server in the returned HTTP header.\n2019-06-18\nAll regions\nConfigure server-side encryption\nFeature\nDescription\nRelease date\nRegion\nReferences\nBucket Policy\nA bucket policy is a resource-based authorization policy. Bucket policies can be configured by using GUIs in the OSS console. The bucket owner can grant other users the permissions to access the OSS resources that are stored in the bucket.\n2019-01-21\nAll regions\nConfigure bucket policies to authorize other users to access OSS resources\nFeature\nDescription\nRelease date\nRegion\nReferences\nReal-time log query\nThe real-time log query feature is supported. Real-time log query is based on the integration of Simple Log Service and OSS. This feature allows you to query and collect statistics about OSS access logs and audit access to OSS by using the OSS console, track exceptions, and troubleshoot problems.\n2018-12-26\nAll regions\nReal-time log query\nFeature\nDescription\nRelease date\nRegion\nReferences\nObject storage class configuration and conversion\nThe storage class of an object can be set to Standard, IA, or Archive when you upload the object. The configuration of the storage class takes effect in real time.\nThe CopyObject operation can be called to convert the storage class of an object. The amount of time required for the conversion is reduced from days to seconds.\n2018-11-10\nAll regions\nOverview\nConvert storage classes\nCopyObject\nTerraform\nThe Terraform module is supported. The versions of OSS resources can be managed by using the Terraform module. For example, you can use Terraform to create buckets and manage objects.\n2018-11-07\nAll regions\nTerraform\nCreate a bucket by using Terraform\nFeature\nDescription\nRelease date\nRegion\nReferences\nKMS-based server-side encryption\nKMS-based server-side encryption is supported for objects.\n2018-10-20\nAll regions\nConfigure server-side encryption\nFeature\nDescription\nRelease date\nRegion\nReferences\nOSS Select\nOSS Select is supported. The content of an object can be selected and obtained by using simple SQL statements. The amount of data that is transmitted from OSS can be reduced by using OSS Select to improve data retrieval efficiency.\n2018-09-28\nAll regions\nSelectObject\nRetention policies\nRetention policies for buckets are supported. A retention policy helps prevent objects in a bucket from being deleted or overwritten within a specific period of time.\n2018-09-28\nAll regions\nRetention policies\nConfigure retention policies\nZRS\nZRS stores multiple copies of your data across multiple zones in the same region. If a zone becomes unavailable, you can continue to access the data that is stored in other zones. ZRS provides 99.9999999999% (twelve 9's) data durability and 99.995% service availability.\n2018-09-28 (public preview)\nChina (Shenzhen), China (Beijing), China (Hangzhou), China (Shanghai), and Singapore\nCreate a ZRS bucket\nPay-by-requester\nPay-by-requester is supported. When pay-by-requester is enabled for a bucket, the requester pays the request and traffic fees, and the bucket owner pays the storage costs.\n2018-09-27\nAll regions\nEnable pay-by-requester\nFeature\nDescription\nRelease date\nRegion\nReferences\nSSE-KMS\nServer-side encryption based on SSE-KMS is supported. A CMK ID is required to use KMS for server-side encryption. This allows you to implement bring your own key (BYOK) for server-side encryption in OSS.\n2018-08-14\nAll regions\nConfigure server-side encryption\nFeature\nDescription\nRelease date\nRegion\nReferences\nClient-side encryption by using OSS SDK for Python\nClient-side encryption by using OSS SDK for Python is supported. Data on the client can be encrypted locally by using OSS SDK for Python before the data is uploaded to OSS. However, in this scenario, you must manage the encryption process and the encryption key.\n2018-06-05\nAll regions\nClient-side encryption\nFeature\nDescription\nRelease date\nRegion\nReferences\nCombination of OSS and DLA\nInteractive queries and analysis of data in OSS can be performed by using the serverless architecture in the Data Lake Analytics (DLA) console.\n2018-05-31\nAll regions\n\nBackground information and preparations\nFeature\nDescription\nRelease date\nRegion\nReferences\nResumable upload by using OSS SDKs for Browser.js and Node.js\nResumable upload is supported by using OSS SDK for Browser.js and OSS SDK for Node.js. An object can be split into several parts that can be simultaneously uploaded. After all parts are uploaded, the parts are combined into a complete object.\n2018-03-07\nAll regions\nResumable upload\nResumable upload\nSSL certificate hosting\nTo use a custom domain name to access OSS resources over HTTPS, you can host an SSL certificate in OSS.\n2018-03-05\nAll regions\nMap custom domain names\nHost SSL certificates\nFeature\nDescription\nRelease date\nRegion\nReferences\nSwift-based mobile apps by using OSS SDK for iOS\nOSS SDK for iOS can be used by users who use Swift-based mobile apps.\n2018-01-18\nAll regions\nOSSSwiftDemo\nFeature\nDescription\nRelease date\nRegion\nReferences\nCRC-64 data verification by using OSS SDKs for iOS 2.8 and Android 2.5\nCRC-64 data verification is supported by using OSS SDKs for iOS 2.8 and Android 2.5. After CRC-64 is enabled and an object is uploaded or downloaded, the system checks whether the calculated CRC-64 value is the same as the CRC-64 value of the source data to ensure the integrity of the transmitted data.\n2017-12-21\nAll regions\nOSS SDK for Android: Data verification\nOSS SDK for iOS: Data security\nFeature\nDescription\nRelease date\nRegion\nReferences\nossimport\nYou can use ossimport to migrate data to OSS buckets.\n2017-10-23\nAll regions\nStandalone deployment\nDistributed deployment\nFeature\nDescription\nRelease date\nRegion\nReferences\nCRR\nCRR automatically and asynchronously (in near real time) replicates objects across buckets in different regions. CRR can also synchronize operations, such as the creation, overwriting, and deletion of objects, from a source bucket to a destination bucket.\n2017-09-15\nRegions in the Chinese mainland, US (Virginia), and US (Silicon Valley)\nConfigure CRR\nFeature\nDescription\nRelease date\nRegion\nReferences\nDecrease in the unit price of the Archive storage class\nThe unit price of the Archive storage class is reduced by 45%. The minimum billable storage duration for Archive objects is changed to 60 days.\n2017-07-21\nAll regions\nBilling overview\nRestoreObject\nOfficial release of the new version of the OSS console\nThe new OSS console is available. The web page layouts and navigation system are optimized.\nInformation aggregation on the Overview page is improved.\nThe configuration and management of buckets and objects are improved.\n2017-07-01\nAll regions\nUse Alibaba Cloud accounts to log on to the OSS console\nFeature\nDescription\nRelease date\nRegion\nReferences\nossutil\nThe command line tool ossutil is available on Windows, Linux, and macOS. ossutil allows you to manage buckets and objects by using a rich set of commands.\n2017-04-26\nAll regions\nOverview\nIncrease in the maximum number of buckets that can be created\nThe maximum number of buckets that can be created by using an Alibaba Cloud account in a region is increased to 30.\n2017-04-24\nAll regions\nLimits and performance metrics\nPutBucket\nFeature\nDescription\nRelease date\nRegion\nReferences\niOS SDK 2.6.0\nThe HTTPS request access specifications of App Store are supported by OSS SDK for iOS 2.6.0.\n2016-12-16\nAll regions\nInstallation\nFeature\nDescription\nRelease date\nRegion\nReferences\nPart management\nLifecycle rules can be configured to periodically delete the parts that you no longer need.\n2016-03-10\nAll regions\nDelete parts\nFeature\nDescription\nRelease date\nRegion\nReferences\nBack-to-origin\nData that is requested from the origin can be retrieved in multiple ways by configuring back-to-origin rules based on your requirements for specific operations, such as hot data migration and specific request redirection.\n2016-01-14\nAll regions\nBack-to-Origin\nFeature\nDescription\nRelease date\nRegion\nReferences\nRuby SDK\nOSS SDK for Ruby is officially released.\n2015-11-26\nAll regions\nInstallation\nIMG\nBy default, image processing (IMG) is enabled for buckets.\n2015-11-10\nAll regions\nIMG implementation modes\nFeature\nDescription\nRelease date\nRegion\nReferences\nAppend upload\nContent can be appended to appendable objects by calling the AppendObject operation.\n2015-07-18\nAll regions\nAppend upload\nUpload callbacks for application servers\nAn OSS-based direct data transfer service for mobile apps can be built, and upload callbacks can be configured.\n2015-07-08\nAll regions\nSet up upload callbacks for mobile apps\nFeature\nDescription\nRelease date\nRegion\nReferences\nRAM-based access\nYou can use Security Token Service (STS) to generate temporary access credentials to authorize a RAM user to access your OSS resources within a specific period of time.\n2015-04-26\nAll regions\nRAM Policy\nUse temporary access credentials provided by STS to access OSS\nFeature\nDescription\nRelease date\nRegion\nReferences\nLifecycle rules\nThe lifecycle rule feature is supported. The PutBucketLifecycle operation can be called to create a lifecycle rule that automatically deletes expired objects and parts to reduce storage costs.\n2014-10-20\nAll regions\nLifecycle rules based on the last modified time\nFeature\nDescription\nRelease date\nRegion\nReferences\nCORS\nCross-origin access is supported by using cross-origin resource sharing (CORS), which is a standard cross-origin solution that is provided by HTML5.\n2014-03-15\nAll regions\nCORS\nFeature\nDescription\nRelease date\nRegion\nReferences\nForm upload\nForm upload is supported by calling the PostObject operation to upload an object of up to 5 GB in size.\n2014-02-12\nAll regions\nForm upload\nFeature\nDescription\nRelease date\nRegion\nReferences\nServer-side encryption\nServer-side encryption for uploaded data is supported. When you upload data, OSS encrypts the received data and stores the encrypted data. When you download the data, OSS automatically decrypts the encrypted data. Then, OSS returns the data and declares that the data has been encrypted on the server in the returned HTTP header.\n2012-11-4\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Japan (Tokyo), South Korea (Seoul), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Thailand (Bangkok), Germany (Frankfurt), UK (London), and UAE (Dubai)\nserver-side encryption\nFeature\nDescription\nRelease date\nRegion\nReferences\nCNAME\nA custom domain name can be mapped to a bucket. To map a custom domain name to a bucket, add a CNAME record that maps the custom domain name to the public domain name of the bucket. This way, you can use the custom domain name to access objects in the bucket.\n2012-09-04\nAll regions\nMap a custom domain name to the default domain name of a bucket\nFeature\nDescription\nRelease date\nRegion\nReferences\nLogging\nLogging can be configured for a bucket. A large number of logs are generated over time when OSS resources are accessed. Access logs that are generated by OSS on an hourly basis are written to a specified bucket as objects based on a predefined naming rule.\n2012-08-09\nAll regions\nLogging\nFeature\nDescription\nRelease date\nRegion\nReferences\nStatic website hosting\nStatic website hosting can be configured for a bucket by calling the PutBucketWebsite operation. This way, the static website can be accessed by using the domain name of the bucket.\n2012-06-20\nAll regions\nOverview\nFeature\nDescription\nRelease date\nRegion\nReferences\nMultipart upload\nAn object can be split into several parts that can be simultaneously uploaded. After all parts are uploaded, you can combine the parts into a complete object.\n2012-03-29\nAll regions\nMultipart upload\nFeature\nDescription\nRelease date\nRegion\nReferences\nObject copy\nObjects can be copied from a bucket to another bucket without modifying the object content.\n2011-12-16\nAll regions\nCopy objects\nHotlink protection\nHotlink protection can be configured for a bucket by calling the PutBucketReferer operation to configure the Referer whitelist and prevent unauthorized users from accessing data in OSS.\n2011-12-16\nAll regions\nHotlink protection\nHTTP header\nHTTP headers can be configured to specify HTTP request policies, such as the cache policy and the forced object download policy.\n2011-12-16\nAll regions\nConfigure object metadata\nFeature\nDescription\nRelease date\nRegion\nReferences\nOfficial release of OSS\nAlibaba Cloud OSS is available for commercial use.\n2011-10-22\nAll regions\nWhat is OSS?\n"
    },
    "138": {
        "title": "Object Storage Service:Billing overview",
        "url": "https://www.alibabacloud.com/help/en/oss/billing-overview",
        "content": "This Product\nObject Storage Service:Billing overview\nThis topic describes the billable items, billing methods, unit prices, billing cycle, and bill generation time of Object Storage Service (OSS).\nThe billable items of OSS are classified into the following types:\nBasic billable items: Fees that most users incur when using OSS, including storage fees for data storage, traffic fees for downloading objects from OSS buckets or delivering objects by using Alibaba Cloud CDN, and API operation calling fees for read and write requests.\nBillable items for value-added features: Fees incurred by a minority of users who enable and use value-added features. To improve data processing efficiency or enhance user experience, the value-added features, such as image processing (IMG), transfer acceleration, and DDoS protection, are provided. For more information, see Billable items for value-added features.\nThe following figure shows the billable items of OSS.\n\nOSS supports the following billing methods:\nPay-as-you-go: By default, the pay-as-you-go billing method applies to all billable items. You are charged based on the actual usage of each billable item after you use resources. This billing method is ideal for scenarios in which resource usage fluctuates.\nSubscription (resource plans): OSS provides resource plans to offset fees of specific billable items, such as storage and traffic fees. You can purchase resource plans that cover specific billable items at favorable prices. Resources are consumed before fees are offset by resource plans. If the resource plans are exhausted, you are charged for excess resource usage on a pay-as-you-go basis. This billing method is suitable for scenarios in which resource usage is stable.\nSCUs to offset storage fees\nYou can use storage capacity units (SCUs) to offset storage fees that are generated for using OSS and other Alibaba Cloud storage services.\nFor more information about OSS pricing, see OSS pricing.\nOSS calculates all resource usage by hour and charges you based on your actual usage.\nStorage fees are calculated in USD per GB-month, as indicated on the OSS pricing page. When you use the pay-as-you-go billing method, storage fees are calculated based on the following formula: Storage fees = Actual storage usage (GB) \u00d7 Unit price per hour. Therefore, when you calculate storage fees charged based on actual storage usage, you must convert GB-month to GB-hour based on the following formula: Unit price in USD per GB-hour = Unit price in USD per GB-month/30/24. For example, the unit price for the storage usage of Standard locally redundant storage (LRS) objects is USD 0.0173 per GB-month, and the unit price in GB-hour is USD 0.000024 per GB-hour (0.0173/30/24).\nBills are generally generated within 1 hour after a billing cycle ends. The time when bills are generated is determined by the system. For example, you are billed at 09:30:00 for the fees that are generated from 08:00:00 to 09:00:00 of the same day.\nThe bill that you receive at 09:30:00 may include only the fees that are generated from 07:00:00 to 08:00:00 because of system latency.\nBillable items\nBilling methods\nQuery OSS billing data generated on an hourly basis\nQuery resource usage of an Alibaba Cloud account\nQuery bills\nFAQ about billing\nOverdue payments"
    },
    "139": {
        "title": "Object Storage Service:Billable items",
        "url": "https://www.alibabacloud.com/help/en/oss/billable-items/",
        "content": "This Product\nObject Storage Service:Billable items\nThe billable items of Object Storage Service (OSS) are classified into the following types:\nBasic billable items: Fees that most users incur when using OSS, including\u00a0Storage fees for data storage,\u00a0Traffic fees for downloading files from OSS buckets or delivering files by using Alibaba Cloud CDN, and\u00a0API operation calling fees for read and write requests.\nBillable items for value-added features: Fees incurred by a minority of users who enable and use value-added features. Intended to improve data processing efficiency or user experience, the value-added features include, but are not limited to image processing, transfer acceleration, and DDoS protection. For more information, see Billable items for value-added features\nBillable items\nThe following figure shows the billable items of OSS.\n"
    },
    "140": {
        "title": "Object Storage Service:Billing methods",
        "url": "https://www.alibabacloud.com/help/en/oss/billing-method/",
        "content": "This Product\nObject Storage Service:Billing methods"
    },
    "141": {
        "title": "Object Storage Service:Free quota for new users",
        "url": "https://www.alibabacloud.com/help/en/oss/free-quota-for-new-users",
        "content": "This Product\nObject Storage Service:Free quota for new users\nAn individual or enterprise user that has created an Alibaba Cloud account and completed real-name registration but has not activated Object Storage Service (OSS) is eligible for a free trial of OSS. During the free trial period, you can store a certain amount of Standard locally redundant storage (LRS) objects free of charge.\nThe free trial of OSS applies only to specific billable items.\nCurrently, the free quota of OSS can be used only to offset the storage fees of Standard LRS objects in buckets. Storage fees of other billable items, such as the storage fees of Infrequent Access (IA) LRS objects, and image processing (IMG) fees cannot be offset by this free quota. After the free trial period ends, you are charged different fees for using OSS. For more information about the billing rules, see Billing overview.\nThe following table lists the billable items for which OSS provides free quotas.\nBillable item\nFree quota\nIntended user\nSupported region\nStorage usage of Standard LRS objects\nStandard (LRS) storage plan: 500 GB/month\nIndividual users\nAll regions\nStandard (LRS) storage plan: 1 TB/month\nEnterprise users\nUser type: individual or enterprise users\nConditions:\nReal-name registration is completed but OSS is not activated.\nYou must configure a payment method in your account during the free trial period to maintain your eligibility for a free trial. The payment methods include credit cards, debit cards, or a Paytm wallet.\nUsers who completed Alibaba Cloud real-name registration for enterprises are eligible for the free trial of OSS Enterprise Edition. Users who have enjoyed the free trial of OSS Personal Edition are no longer eligible for the free trial of OSS Enterprise Edition.\nAlibaba Cloud international site terms also apply to the free trial.\nMethod to obtain the free quota: All Free Tier Products Available.\nYou can use the preceding quotas at the same time only in the following regions: China (Hangzhou), China (Shanghai), China (Nanjing - Local Region), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Thailand (Bangkok), Japan (Tokyo), South Korea (Seoul), Germany (Frankfurt), UK (London), UAE (Dubai), and SAU (Riyadh - Partner Region).\nNew users who meet the preceding prerequisites can obtain a free quota of 500 GB/month (individual users) or 1 TB/month (enterprise users) for the storage usage of Standard LRS objects and a free additional fixed quota of 5 GB/month for the storage usage of Standard LRS objects. New users have fixed free capacity per month. Take note of the following items when you use the free quotas:\nIntended user\nEffective at\nFree quota\nActual usage\nDescription\nIndividual users\nAny hour during the one-month free trial period\n\n505GB\n\nLess than or equal to 505 GB\nNo charges for the storage usage of Standard LRS objects\nGreater than 505 GB\nYou are charged for the storage usage that exceeds the free quota (Actual usage - 505 GB).\nEnterprise users\n1029GB\nLess than or equal to 1029 GB\nNo charges for the storage usage of Standard LRS objects\nGreater than 1029 GB\nYou are charged for the storage usage that exceeds the free quota (Actual usage - 1029 GB).\nDuring the one-month free trial period, the specified quota for the storage usage of Standard LRS objects that is not used within an hour cannot be used in the next hour.\nFor more information about billing rules for the storage usage of Standard LRS objects, see Storage fees.\nThe free quota for the new user is used to offset storage usage first. Then, the fixed quota of 5 GB/month is used. If you purchased resource plans, the resource plans are used to offset the fees for corresponding billable items. If the resource plans are exhausted, you are charged for the excess resource usage based on the pay-as-you-go billing method."
    },
    "142": {
        "title": "Object Storage Service:Query OSS billing data generated on an hourly basis",
        "url": "https://www.alibabacloud.com/help/en/oss/query-oss-billing-data-generated-on-an-hourly-basis",
        "content": "This Product\nObject Storage Service:Query OSS billing data generated on an hourly basis\nThis topic describes how to call the QueryUserOmsData operation to query Object Storage Service (OSS) billing data generated on an hourly basis.\nParameter\nType\nRequired\nExample\nDescription\nAction\nString\nYes\nQueryUserOmsData\nThe operation that you want to perform. Set the value to QueryUserOmsData.\nDataType\nString\nYes\nHour\nThe unit in which billing data is generated. Set the value to Hour.\nTable\nString\nYes\nOSS\nThe type of report that contains billable items. Valid values:\nOSS: the OSS billing report that contains basic OSS billable items.\nOssDataReplication: the OSS billing report that contains billable items related to cross-region replication (CRR).\nOssSddpScan: the OSS billing report that contains billable items related to Sensitive Data Discovery and Protection (SDDP).\nOssCache: the OSS billing report that contains billable items related to the accelerator cache capacity.\nStartTime\nString\nYes\n2022-12-01T09:12:43Z\nThe beginning of the time range to query. The time must be in UTC.\nEndTime\nString\nYes\n2022-12-01T09:13:46Z\nThe end of the time range to query. The time must be in UTC.\nMarker\nString\nNo\ntest\nSpecifies that billing data that is alphabetically after the value of Marker is returned. By default, if this parameter is not specified, all billing data is returned.\nPageSize\nInteger\nNo\n50\nThe number of entries to return on each page.\nValid values: 1 to 200.\nDefault value: 100\nFor more information about common request parameters involved in the operation, see Common Parameters.\nParameter\nType\nExample\nDescription\nHostId\nString\nintl\nThe site to which the user belongs. Valid value: intl.\nMarker\nstring\nNextToken\nSpecifies that the query operation starts from the value of the Marker parameter until all data on all pages is queried. If the value of the Marker parameter is empty, all data is returned.\nProviderId\nString\n26888\nThe ID of the product provider. Valid value: 26888.\nUserId\nString\n148562088256****\nThe ID of the Alibaba Cloud account.\nLessthanMonthDatasize\nInteger\n180\nThe billed storage usage of Infrequent Access (IA) and Archive objects that are stored for less than the minimum storage duration. Unit: bytes.\nStorage usage of IA objects that are stored for less than the minimum storage duration\nIf an IA locally redundant storage (LRS) object is overwritten or deleted when it is stored for less than 30 days (720 hours), you are charged for the remainder (720 hours - Actual storage duration) of the minimum storage duration.\nStorage usage of Archive objects that are stored for less than the minimum storage duration\nIf an Archive LRS object is overwritten or deleted when it is stored for less than 60 days (1,440 hours), you are charged for the remainder (1,440 hours - Actual storage duration) of the minimum storage duration.\nChargedDatasize\nInteger\n200\nThe billed storage usage of IA LRS and Archive LRS objects. Unit: bytes.\nRetrievalData\nInteger\n200\nThe retrieval of IA and Archive objects.\nData retrieval of IA objects\nWhen you access IA objects, you are charged data retrieval fees based on the size of the retrieved IA objects.\nData retrieval of Archive objects\nWhen you access Archive objects, you need to restore them. You are charged data retrieval fees based on the size of the restored Archive objects.\nRetrievalDataArchiveDirect\nInteger\n200\nThe retrieval of Archive objects in real time. When you access Archive objects without restoring the objects, you are charged Archive data retrieval fees based on the size of the retrieved Archive objects.\nChargedDatasizeCA\nInteger\n100\nThe billed storage usage of Cold Archive LRS objects. You are charged storage fees for Cold Archive LRS objects based on the total size and storage duration of the objects.\nCold Archive LRS objects have a minimum billable size of 64 KB. Objects that are smaller than 64 KB are charged for 64 KB of storage usage. Objects that are greater than or equal to 64 KB are charged based on their actual sizes.\nEarlyDeletionCA\nInteger\n100\nThe billed storage usage of Cold Archive objects that are stored for less than the minimum storage duration. If a Cold Archive object is overwritten or deleted when it is stored for less than 180 days (4,320 hours), you are charged for the remainder (4,320 hours - Actual storage duration) of the minimum storage duration.\nBucket\nString\nexamplebucket\nThe name of the bucket.\nNetworkIn\nInteger\n2000\nThe traffic generated by data transmission from the client to OSS over the Internet within the specified time range. Unit: bytes.\nNetworkOut\nInteger\n2000\nThe traffic generated by data transmission from OSS to the client over the Internet within the specified time range. Unit: bytes.\nPutRequest\nInteger\n1000\nThe number of PUT requests initiated by calling OSS API operations. This is a billable item for API operation fees.\nGetRequest\nInteger\n2000\nThe number of GET requests initiated by calling OSS API operations. This is a billable item for API operation fees.\nProcessImgSize\nInteger\n200\nThe size of processed images. You are charged image processing fees based on the size of the source images. Unit: bytes.\nAdvImageProcLow\nInteger\n200\nThe number of times you use the advanced image compression feature to generate compressed images with a resolution smaller than 800 \u00d7 600 pixels.\nAdvImageProcMed\nInteger\n200\nThe number of times you use the advanced image compression feature to generate compressed images with a resolution smaller than 1600 \u00d7 1200 pixels.\nStorage\nInteger\n2000\nThe billed storage usage of objects in a storage class specified by StorageType. Unit: bytes.\nIf you call the GetBucketInfo operation by using an endpoint that does not correspond to the region in which the bucket is located, the value of Storage may be 0.\nThe metered storage usage of IA, Archive, Cold Archive, or Deep Cold Archive objects may not equal the billed storage usage of these objects because each of these objects has a minimum billable size of 64 KB.\nStorageType\nString\nstandard\nThe storage class of objects. Values:\nstandard: Standard LRS\nIA: IA LRS\narchive: Archive LRS\ncoldarchive: Cold Archive\ndeepcoldarchive: Deep Cold Archive\nstandard-zrs: Standard zone-redundant storage (ZRS)\nIA-zrs: IA ZRS\narchive-zrs: Archive ZRS\nFor more information, see Overview.\nCAStdRetrievalData\nInteger\n65536\nThe amount of Cold Archive data that is restored using the standard priority (within 2 to 5 hours). Unit: bytes.\nCABulkRetrievalData\nInteger\n65536\nThe amount of Cold Archive data that is restored using the bulk priority (within 5 to 12 hours). Unit: bytes.\nCAHighPriorRetrievalData\nInteger\n65536\nThe amount of Cold Archive data that is restored using the expedited priority (within 1 hour). Unit: bytes.\nDeepCAStdRetrievalData\nInteger\n65536\nThe amount of Deep Cold Archive data that is restored using the standard priority (within 48 hours). Unit: bytes.\nDeepCAHighPriorRetrievalData\nInteger\n65536\nThe amount of Deep Cold Archive data that is restored using the expedited priority (within 12 hours). Unit: bytes.\nCAStdRetrievalRequest\nInteger\n10000\nThe number of requests initiated to restore Cold Archive data based on the standard priority.\nCABulkRetrievalRequest\nInteger\n10000\nThe number of requests initiated to restore Cold Archive data based on the bulk priority.\nCAHighPriorRetrievalRequest\nInteger\n10000\nThe number of requests initiated to restore Cold Archive data based on the expedited priority.\nDeepCAStdRetrievalRequest\nInteger\n10000\nThe number of requests initiated to restore Deep Cold Archive data based on the standard priority.\nDeepCAHighPriorRetrievalRequest\nInteger\n10000\nThe number of requests initiated to restore Deep Cold Archive data based on the expedited priority.\nCdnIn\nInteger\n500\nThe inbound traffic generated when you access data by using Alibaba Cloud CDN. Unit: bytes.\nCdnOut\nInteger\n500\nThe outbound traffic generated when you access data by using Alibaba Cloud CDN. The outbound traffic is also the origin traffic. Unit: bytes.\nProcessI\nInteger\n50\nThe number of images captured by using video snapshots. You are charged based on the number of images.\nStorageZRS\nInteger\n100\nThe billed storage usage of Standard ZRS objects. You are charged storage fees for Standard ZRS objects based on the total size and storage duration of the objects.\nChargedDatasizeZRS\nInteger\n65536\nThe billed storage usage of IA ZRS objects. You are charged storage fees for IA ZRS objects based on the total size and storage duration of the objects.\nIA ZRS objects have a minimum billable size of 64 KB. Objects that are smaller than 64 KB are charged for 64 KB of storage usage. Objects that are greater than or equal to 64 KB are charged based on their actual sizes.\nLessthanMonthDatasizeZRS\nInteger\n700\nThe billed storage usage of IA ZRS objects that are stored for less than the minimum storage duration. If an IA ZRS object is overwritten or deleted when it is stored for less than 30 days (720 hours), you are charged for the remainder (720 hours - Actual storage duration) of the minimum storage duration.\nAccM2MIn\nInteger\n500\nThe traffic generated when your transfer acceleration endpoint is used to upload data between regions inside the Chinese mainland. Unit: bytes.\nAccM2MOut\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to download data between regions inside the Chinese mainland. Unit: bytes.\nAccM2OIn\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to upload data from regions inside the Chinese mainland to regions outside the Chinese mainland. Unit: bytes.\nAccM2OOut\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to download data from regions outside the Chinese mainland to regions inside the Chinese mainland. Unit: bytes.\nAccO2MIn\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to upload data from regions outside the Chinese mainland to regions inside the Chinese mainland. Unit: bytes.\nAccO2MOut\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to download data from regions inside the Chinese mainland to regions outside the Chinese mainland. Unit: bytes.\nAccO2OIn\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to upload data between regions outside the Chinese mainland. Unit: bytes.\nAccO2OOut\nInteger\n500\nThe traffic generated when your acceleration endpoint is used to download data between regions outside the Chinese mainland. Unit: bytes.\nTempStorageCAStd\nInteger\n500\nThe temporary storage usage of Standard LRS replica objects that are created for temporary access when you restore Cold Archive and Deep Cold Archive objects. You are charged for the temporary storage of the replicas until the restored Cold Archive or Deep Cold Archive objects return to the frozen state. The replicas are automatically deleted after the Cold Archive or Deep Cold Archive objects return to the frozen state.\nSelectScanSize\nInteger\n300\nThe size of objects scanned by calling the SelectObject operation. This is a billable item for data processing fees.\nTagCount\nInteger\n100\nThe number of object tags in a bucket. You are charged for object tagging based on the number of tags.\nStartTime\nString\n2022-12-01T09:12:43Z\nThe start time of the billing data. The time is in UTC.\nEndTime\nString\n2022-12-01T09:13:46Z\nThe end time of the billing data. The time is in UTC.\nParameter\nType\nExample\nDescription\nHostId\nString\ncn\nThe site to which the user belongs. Valid value: intl.\nMarker\nstring\nNextToken\nSpecifies that the query operation starts from the value of the Marker parameter until all data on all pages is queried. If the value of the Marker parameter is empty, all data is returned.\nProviderId\nString\n26842\nThe ID of the product provider. Valid value: 26888.\nUserId\nString\n148562088256****\nThe ID of the Alibaba Cloud account.\nChargedDatasizeDeepCA\nInteger\n100\nThe billed storage usage of Deep Cold Archive LRS objects. You are charged storage fees for Deep Cold Archive LRS objects based on the total size and storage duration of the objects.\nDeep Cold Archive objects have a minimum billable size of 64 KB. Objects that are smaller than 64 KB are charged for 64 KB of storage usage. Objects that are greater than or equal to 64 KB are charged based on their actual sizes.\nEarlyDeletionDeepCA\nInteger\n100\nThe billed storage usage of Deep Cold Archive objects that are stored for less than the minimum storage duration. If a Deep Cold Archive object is overwritten or deleted after it is stored for less than 180 days (4,320 hours), you are charged for the remainder (4,320 hours - Actual storage duration) of the minimum storage duration.\nStartTime\nString\n2022-12-01T09:12:43Z\nThe start time of the billing data. The time is in UTC.\nEndTime\nString\n2022-12-01T09:13:46Z\nThe end time of the billing data. The time is in UTC.\n\nParameter\nType\nExample\nDescription\nHostId\nString\ncn\nThe site to which the user belongs. Valid value: intl.\nMarker\nstring\nNextToken\nSpecifies that the query operation starts from the value of the Marker parameter until all data on all pages is queried. If the value of the Marker parameter is empty, all data is returned.\nProviderId\nString\n26842\nThe ID of the product provider. Valid value: 26888.\nUserId\nString\n148562088256****\nThe ID of the Alibaba Cloud account.\nSourceRegion\nString\noss-cn-hangzhou\nThe region in which the source bucket is located when CRR is used.\nDestRegion\nString\noss-us-west-1\nThe region in which the destination bucket is located when CRR is used.\nSourceBucket\nString\nsrcbucket\nThe name of the source bucket.\nDestBucket\nString\ndestbucket\nThe name of the destination bucket.\nReplicationDatasize\nInteger\n1000\nThe size of the data replicated from the source bucket to the destination bucket. Unit: bytes.\nRtcDatasize\nInteger\n1000\nThe data replication traffic generated by data replication tasks for which Replication Time Control (RTC) is enabled. Unit: bytes.\nStartTime\nString\n2022-12-01T09:12:43Z\nThe start time of the billing data. The time is in UTC.\nEndTime\nString\n2022-12-01T09:13:46Z\nThe end time of the billing data. The time is in UTC.\nParameter\nType\nExample\nDescription\nHostId\nString\ncn\nThe site to which the user belongs. Valid value: intl.\nMarker\nstring\nNextToken\nSpecifies that the query operation starts from the value of the Marker parameter until all data on all pages is queried. If the value of the Marker parameter is empty, all data is returned.\nProviderId\nString\n26842\nThe ID of the product provider. Valid value: 26888.\nUserId\nString\n148562088256****\nThe ID of the Alibaba Cloud account.\nBucket\nString\nexamplebucket\nThe name of the bucket for which Anti-DDoS Proxy is enabled.\nStartTime\nString\n2022-12-01T09:12:43Z\nThe start time of the billing data. The time is in UTC.\nEndTime\nString\n2022-12-01T09:13:46Z\nThe end time of the billing data. The time is in UTC.\nSecReserved\nInteger\n5\nThe number of Anti-DDoS Proxy instances. You are charged based on the number of Anti-DDoS Proxy instances that you purchase and the usage duration of the instances.\nSecEarlyReleased\nInteger\n100\nThe fees for Anti-DDoS Proxy instances that are stored for less than the minimum usage duration. If an Anti-DDoS Proxy instance is released within seven days after the instance is created, you are charged for the remainder (7 days \u00d7 24 hours - Actual usage duration) of the minimum usage duration.\nSecFlow\nInteger\n2000\nThe outbound traffic and inbound traffic that are generated over the Internet when the buckets that are attached to the purchased Anti-DDoS Proxy instance are accessed. You are charged for the generated outbound traffic and inbound traffic. The fees are calculated based on the maximum outbound or inbound traffic.\nSecRequest\nInteger\n10000\nThe number of requests initiated to access buckets that are attached to the purchased Anti-DDoS Proxy instances. You are charged for the API requests. The fees are calculated based on the number of API requests.\nYou are charged for both successful and failed requests.\nParameter\nType\nExample\nDescription\nHostId\nString\ncn\nThe site to which the user belongs. Valid value: intl.\nMarker\nstring\nNextToken\nSpecifies that the query operation starts from the value of the Marker parameter until all data on all pages is queried. If the value of the Marker parameter is empty, all data is returned.\nProviderId\nString\n26842\nThe ID of the product provider. Valid value: 26888.\nUserId\nString\n148562088256****\nThe ID of the Alibaba Cloud account.\nBucket\nString\nexamplebucket\nThe name of the bucket in which sensitive data is stored.\nStartTime\nString\n2022-12-01T09:12:43Z\nThe start time of the billing data. The time is in UTC.\nEndTime\nString\n2022-12-01T09:13:46Z\nThe end time of the billing data. The time is in UTC.\nSddpScanSize\nInteger\n1000\nThe size of data on which Data Security Center (DSC) is authorized to perform full or incremental scanning. Unit: bytes.\nSample request\nSample response\n"
    },
    "143": {
        "title": "Object Storage Service:Overdue payments",
        "url": "https://www.alibabacloud.com/help/en/oss/overdue-payments",
        "content": "This Product\nObject Storage Service:Overdue payments\nThis topic describes the causes of Object Storage Service (OSS) overdue payments, service suspension, and how to view overdue payments.\nYou have not purchased resource plans and the balance of your Alibaba Cloud account is insufficient.\nYou have purchased resource plans, but the resource plans cannot offset all fees. For more information about the causes of overdue payments, see Why am I still in arrears after I purchase a resource plan?\nYou are notified if OSS is about to be suspended due to an overdue payment. To prevent negative impacts on your business, we recommend that you top up the balance of your Alibaba Cloud account at the earliest opportunity.\nAn overdue payment causes the following changes to the status of OSS based on your actions:\nIf you top up the balance of your Alibaba Cloud account within 360 hours, your service is not suspended.\nIf you fail to settle all overdue bills within 360 hours, OSS is suspended and your buckets in the OSS console become unavailable. However, you are still charged for the buckets. Consequently, the overdue amount continues to increase.\nIf you settle all overdue bills within the grace period of seven days after OSS is suspended, OSS is automatically activated.\nIf you fail to settle all overdue bills within the grace period of seven days, Alibaba Cloud determines that you no longer use OSS. Alibaba Cloud terminates the service terms of OSS and no longer provides you with the services that are related to OSS. The data in your buckets is deleted. You cannot recover the data. Take note that you are still charged for the data that is stored in OSS buckets before the data is deleted. Therefore, if you no longer use OSS, make sure that all your data that is stored in OSS buckets is deleted.\nIf you fail to settle all overdue bills within the grace period of seven days (your account balance is less than USD 0), the data in your buckets is deleted regardless of whether you purchased resource plans or whether resource plans are within the validity period. You cannot recover the data.\nLog on to the Expenses and Costs console.\nOn the Account Overview page, view overdue payments."
    },
    "144": {
        "title": "Object Storage Service:Query bills",
        "url": "https://www.alibabacloud.com/help/en/oss/query-bills",
        "content": "This Product\nObject Storage Service:Query bills\nThis topic describes how to query bills of Object Storage Service (OSS).\nLog on to the Expenses and Costs console.\nIn the left-side navigation pane, choose Bills > Bill Details.\nOn the Bill Details page, click the Billing Details tab, specify Billing Cycle, and set Product to Object Storage Service.\nYou can also configure Statistic Item and Statistic Period to specify the content of the bills that you want to display.\nParameter\nDescription\nStatistic Item\nBills are displayed based on the statistic item that you specify. Valid values:\nBilling Item: Bills are displayed by billable item. The bills that are generated based on the same billable item are combined.\nInstance: Bills are displayed by instance. The bills that are generated by the same instance are combined.\nProduct: Bills are displayed by product. The bills that are generated by the same product are combined.\nAccount: Bills are displayed by account. The bills that are generated in the same account are combined.\nCost Center: Bills are displayed by cost center. The bills that are generated by the same cost center are combined.\nStatistic Period\nBills are displayed based on the statistic period that you specify. Valid values:\nBilling Cycle: The bills of the specified billing cycle are displayed.\nBy Day: The bills of the specified billing cycle are displayed by day.\nBilling Period: The bills of the specified billing cycle are displayed by hour.\nOSS is billed on an hourly basis. If you select Billing Cycle or By Day for Statistic Period, data in the Usage column specifies the cumulative usage in the current month or on the current day. For example, you select By Day for Statistic Period and your actual storage usage is 1 TB. The storage usage that is displayed in the bill is 24 TB. You are charged for the 24-hour storage of 1 TB of data.\nYou can click Customize Column Options in the upper-right corner of the bills and select the columns that you want to view.\nYou can click Export Billing Overview (CSV) to export the bills to your computer. This way, you can view and analyze the bills on your computer.\n"
    },
    "145": {
        "title": "Object Storage Service:FAQ about billing",
        "url": "https://www.alibabacloud.com/help/en/oss/faq-6/",
        "content": "This Product\nObject Storage Service:FAQ about billing"
    },
    "146": {
        "title": "Object Storage Service:Before you begin",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/setting-up",
        "content": "This Product\nObject Storage Service:Before you begin\nWhen you register for Alibaba Cloud, you automatically sign up for all Alibaba Cloud products and services, including Object Storage Service (OSS). You will only be charged for the services you use.\nFollow the steps in the subsequent sections to\u00a0get\u00a0prepared\u00a0for\u00a0using\u00a0Alibaba\u00a0Cloud\u00a0OSS.\nIf you do not yet have an Alibaba Cloud account, visit the signup page and complete the registration process as directed.\nThe registration process includes an email or mobile phone verification step, during which you will receive an email or short message and be asked to enter a verification code.\nAfter you perform the preceding steps, an Alibaba Cloud account is created. Before you purchase Alibaba Cloud products and services, you must also enter your\u00a0billing information\u00a0and\u00a0payment information. For more information, see Introduction to Alibaba Cloud Payment. If you need to purchase an Alibaba Cloud service in a region in the Chinese mainland, you must complete\u00a0real-name verification\u00a0for your Alibaba Cloud account.\nThe user signed in with an Alibaba Cloud account has full access to all Alibaba Cloud services and resources in the account. For enhanced security, we recommend that you assign administrative access to a Resource Access Management (RAM) user and do not use the Alibaba Cloud account for regular tasks.\nSecure your Alibaba Cloud account by turning on the account protection. For more information, see Enable the account protection feature.\nCreate an administrative user to handle day-to-day operations instead of using the Alibaba Cloud account for regular tasks. For more information, see Create an account administrator.\nCreate more RAM users, add them to groups and grant them access to OSS resources. When you grant permissions to RAM user groups, we recommend that you grant only the required permissions based on the principle of least privilege. For more information, see Create a RAM user group and grant permissions to the group.\nAfter completing these steps, you can start to use OSS. For more information, see Get started with OSS."
    },
    "147": {
        "title": "Object Storage Service:Get started with OSS",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/get-started-with-oss",
        "content": "This Product\nObject Storage Service:Get started with OSS\nObject Storage Service (OSS) provides multiple methods for you to access and manage buckets and objects. This topic describes how to manage your OSS resources by using the OSS console, ossutil, ossbrowser, OSS SDKs, and OSS API operations.\nGo to the OSS activation page.\nOn the OSS activation page, follow the on-screen instructions to activate OSS.\nAfter OSS is activated, the default billing method is pay-as-you-go. If you want to reduce OSS fees, we recommend that you use OSS resource plans.\nYou can create a bucket and upload objects to the bucket by using the OSS console. After you upload objects to the bucket, you can download the objects to local disks or generate signed URLs to share the objects with third parties for downloads or previews. For more information, see Operations in the OSS console.\nossutil is a command-line tool that allows you to manage OSS data by using commands. ossutil supports the following operating systems: Windows, Linux, and macOS. ossutil provides simple commands for you to efficiently manage buckets and objects. For more information, see ossutil command reference.\nossbrowser is a graphical management tool that you can use to manage buckets and objects. This tool supports Windows, Linux, and macOS. You can use ossbrowser to manage buckets, upload and download objects and directories, and grant permissions to users based on policies. For more information, see Get started with ossbrowser.\nAs a GUI tool, ossbrowser provides slower data transfers and less powerful performance than ossutil.\nWatch the following tutorial video to get started with ossbrowser.\nOSS provides SDKs for various programming languages, such as Java, Python, PHP, and Go, to facilitate custom development. For code examples of using OSS SDKs, see Overview.\nIf your business requires a high level of customization, you can directly call RESTful APIs. To directly call an API, you must include the signature calculation in your code. For more information about the OSS API operations, see Description."
    },
    "148": {
        "title": "Object Storage Service:Get started by using the OSS console",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/console-quick-start",
        "content": "This Product\nObject Storage Service:Get started by using the OSS console\nThe Object Storage Service (OSS) console is a web-based platform that allows you to easily manage your OSS resources. This topic describes how to create or delete buckets, upload, download, and share files or folders by using OSS console.\nAn Alibaba Cloud account is created. For more information, see Sign up to Alibaba Cloud.\nOSS is activated. For more information, see Activate OSS.\nA RAM user is created as an administrator.\nAn OSS bucket is a container that stores objects.\nOn the Buckets page, click Create Bucket.\nDo not include sensitive information in the name of your bucket, for the name is visible in all regions.\nIn the Create Bucket panel, specify the name of the bucket and retain the default settings for other parameters.\nClick OK. Follow the on-screen instructions to complete the creation.\nAfter creating a bucket, you can upload objects in any format to the bucket for persistent storage.\nYou can upload files up to 5GB by using OSS console.\nDownload the sample object named exampleobject.jpg to your local computer.\nOn the Buckets page, click the name of the bucket that you created.\nOn the Objects page, click Upload Object.\nScan exampleobject.jpg that you want to upload, retain the default settings for other parameters and click Upload File.\nYou can view the upload progress of the file in the Upload Tasks panel. After the objects are uploaded, you can view the names, sizes, and storage classes of the uploaded objects in the directory.\nAfter objects are uploaded to a bucket, you can download the objects to a local directory.\nIn the left-side navigation pane, choose Object Management > Objects.\nSelect the uploaded exampleobject.jpg, then click Download below.\nAfter an object is uploaded to a bucket, you can share the URL of the object in the bucket with third-party users.\nIn the left-side navigation pane, choose Object Management > Objects.\nOn the Objects page, click the name of the uploaded example object or click View Details in the Actions column.\nIn the View Details panel, click Copy Object URL.\nCheck whether the object that you want to share contains sensitive data to prevent leakage of sensitive data.\nThe default validity period of a URL is 300 seconds. You must obtain a valid URL again after the validity period is exceeded.\nCopy the signed URL to the address bar of a browser to access the object.\nAlibaba Cloud OSS uses the pay-as-you-go billing method. Fees continue to be incurred during the object retention period. To prevent additional fees from being incurred for the uploaded objects, please empty all files in the storage space first, then delete the bucket itself.\nIn the left-side navigation pane, choose Object Management > Objects.\nSelect the uploaded exampleobject.jpg, click Permanently Delete below.\nClick OK, and the object will be permanently deleted.\nOn the Buckets page, click the name of a bucket to go to the bucket details page.\nIn the navigation pane, click Delete Bucket. On the Delete Bucket page, click Delete Bucket and follow the on-screen instructions.\nThe preceding steps describe the basic usage of the OSS console. For more information, see Advanced features.\n"
    },
    "149": {
        "title": "Object Storage Service:Get started with ossutil",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/command-line-tools-ossutil-quickstart",
        "content": "This Product\nObject Storage Service:Get started with ossutil\nossutil is a command-line tool for managing Alibaba Cloud Object Storage Service (OSS) on Windows, macOS, and Linux systems. It allows you to perform batch operations and automate tasks efficiently. This guide covers operations such as creating buckets, uploading and downloading files, listing files, and deleting files and buckets using the command line.\nThis guide uses ossutil 2.0 as an example. ossutil 2.0 offers a comprehensive upgrade in features compared to ossutil 1.0. We strongly recommend using the latest version of ossutil 2.0. For information on ossutil 1.0, please refer to ossutil 1.0.\nIf you have already installed and configured ossutil 2.0, you can refer directly to ossutil 2.0 commands.\nAn Alibaba Cloud account is created.\nOSS is activated.\nAn AccessKey pair is created for a Resource Access Management (RAM) user that has full OSS access permissions.\nCreate an AccessKey pair by using ROS\nYou can quickly create an AccessKey pair for a RAM user that has full OSS access permissions by using a Resource Orchestration Service (ROS) script. To do so, go to the wizard for template-based stack creation, select I confirm that Alibaba Cloud ROS may create RAM resources in the Security Confirmation section, and click Create.\n\nAfter the AccessKey pair is created, copy the AccessKey pair on the Outputs tab.\n\nInstall the unzip tool.\nDownload the ossutil package.\nThis example downloads ossutil for a 64-bit Linux x86 system. For other systems, see Download ossutil.\nExtract the package in the directory where it was downloaded.\nNavigate to the ossutil-2.0.6-beta.01091200-linux-amd64 directory.\nRun the following command in the current directory.\nEnable global invocation of ossutil with the following command.\nVerify the installation of ossutil by running the ossutil command.\nIf ossutil's help information is displayed, the installation was successful.\nInstall ossutil.\nDownload the installation package for your system:\nx86_32 architecture: Windows x86 32bit.\nx86_64 architecture: Windows x86 64bit.\nFor Windows 7, Windows 8, or Windows Server 2008R2: Windows 7, Windows 8, Windows Server 2008R2.\nExtract the .zip package to the target folder and navigate to the extracted directory as shown in the figure.\n\nCopy the path of the extracted ossutil folder to configure the system environment variable.\nClick the path bar of the current directory and copy the displayed path.\n\nOpen the  Environment Variables dialog box. In the  System Variables section, find and double-click the  Path variable. Click the  New button, and then paste the copied path of the ossutil folder into the new entry box.\n\nVerify the installation of ossutil by running the ossutil command.\nIf ossutil's help information is displayed, the installation was successful.\nInstall ossutil.\nThis example downloads ossutil for a 64-bit macOS ARM system. For other systems, see Download ossutil.\nExtract the package in the directory where it was downloaded.\nNavigate to the ossutil-2.0.6-beta.01091200-mac-arm64 directory.\nRun the following command in the current directory.\nEnable global invocation of ossutil with the following command.\nVerify the installation of ossutil by running the ossutil command.\nIf ossutil's help information is displayed, the installation was successful.\nConfigure ossutil.\nSet the path of the ossutil configuration file as prompted. Press Enter to use the default path.\nThe following prompt is based on a Linux system.\nEnter the AccessKey ID you created earlier when prompted.\nEnter the AccessKey Secret you created earlier when prompted.\nEnter the region ID of the OSS data center when prompted.\nThis guide uses Hangzhou as an example. For other regions' IDs, see OSS regions and endpoints.\nIf you do not need to customize the endpoint, press Enter to skip this step. By default, the public endpoint corresponding to the region ID is used. For instance, if the region-id is set to cn-hangzhou, the default public endpoint is https://oss-cn-hangzhou.aliyuncs.com. To customize the endpoint, enter your specific endpoint information.\nCreate a bucket.\nIf the output is similar to the following, the bucket named examplebucket has been created.\nUpload a file to the bucket.\nCreate a local file named uploadFile.txt.\nUpload the file to the bucket named examplebucket.\nIf the output is similar to the following, the file has been uploaded to examplebucket.\nDownload a file.\nDownload the sample file uploadFile.txt from examplebucket to the local folder named localfolder.\nIf the output is similar to the following, the file has been downloaded to the local folder named localfolder.\nList files in examplebucket.\nIf the output is similar to the following, the files in examplebucket are listed.\nDelete uploadFile.txt from examplebucket.\nIf the output is similar to the following, uploadFile.txt has been deleted from examplebucket.\nDelete examplebucket.\nIf the output is similar to the following, examplebucket has been deleted.\nFor more information about common issues during the use of ossutil, see ossutil 2.0 FAQ."
    },
    "150": {
        "title": "Object Storage Service:Get started with ossbrowser",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/get-started-with-ossbrowser-2-0",
        "content": "This Product\nObject Storage Service:Get started with ossbrowser\nossbrowser is a graphical management tool that is provided by Alibaba Cloud to help you easily manage buckets and objects in Object Storage Service (OSS). For example, you can use ossbrowser to create buckets, delete buckets, upload objects, download objects, preview objects, copy objects, move objects, and share objects.\nWatch the following tutorial video to get started with ossbrowser.\nOSS is activated. For more information, see Activate OSS.\nossbrowser is installed, and you have logged on to ossbrowser. For more information, see Install and log on to ossbrowser.\nYou can use ossbrowser to perform the same object-level operations that you can perform in the OSS console. You can follow the on-screen instructions in ossbrowser to manage objects. Before you can manage objects in a bucket, you must click the name of the bucket to view the object list.\nTo perform a specific operation on objects, you must have the required permissions. For more information, see Manage permissions.\nFor more information about a specific operation, see the topic related to the operation in the OSS console.\nOperation\nDescription\nUpload an object\nBy default, ossbrowser uses multipart upload and resumable upload to upload an object. The object that you want to upload cannot exceed 48.8 TB in size. If an upload task is interrupted before the upload task is complete, the uploaded portion is stored as parts in the bucket. If you no longer need these parts, you can use one of the following methods to delete the parts to avoid additional storage fees.\nManually delete parts. For more information, see Delete parts.\nUse lifecycle rules to automatically delete parts. For more information, see Lifecycle rules based on the last modified time.\nIf the uploaded object has the same name as an existing object in the bucket, the existing object is overwritten.\nUpload a directory\nClick the  icon to upload a directory.\nDownload an object\nSelect the object that you want to download and click Download in the Actions column.\nYou can also select multiple objects and click Download in the upper part of the object list to download them at a time.\nDownload a directory\nSelect the directory that you want to download and click the  icon in the upper part of the object list.\nList objects\nIf you click the name of a bucket, objects in the bucket are automatically listed.\nPreview an object\nClick the name of an object to preview the object.\nCopy an object\nIn the source bucket, select the object that you want to copy and click Copy. In the destination bucket, click Paste.\nMove an object\nChoose More > Move.\nThe object that you want to move or copy by using ossbrowser cannot exceed 5 GB in size. To move or copy an object that is larger than 5 GB, we recommend that you use ossutil.\nRename an object\nSelect the object that you want to rename and choose More > Rename at the top of the object list.\nSearch for objects\nEnter the prefix of the specified object name in the search box at the top of the object list. You can view the objects and folders that match the specified prefix in the bucket root directory.\nRestore an object\nSelect the object that you want to restore and choose More > Restore at the top of the object list.\nDelete an object\nSelect the object and click Remove in the Actions column.\nCreate a symbolic link for an object\nSelect the object for which you want to create a symbolic link and choose More > Set Soft Link at the top of the object list.\nIn the Set Soft Link dialog box, configure the Soft Link File or Folder parameter and click OK.\nManage metadata of an object\nSelect the object whose metadata you want to manage and choose More > Http Headers at the top of the object list.\nIn the Http Headers dialog box, configure the metadata headers and click OK.\nShare an object\nYou can share the URL of an object with third parties. This way, the third parties can download or preview the object. To share an object, find the object and click Address in the Actions column to generate a URL.\nConfigure the ACL of an object\nSelect the object for which you want to configure ACL and choose More > ACL at the top of the object list.\nIn the Update ACL dialog box, specify the desired ACL and click OK."
    },
    "151": {
        "title": "Object Storage Service:Use ossfs to mount an OSS bucket to a local directory on the Linux operating system",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/ossfs-quick-start",
        "content": "This Product\nObject Storage Service:Use ossfs to mount an OSS bucket to a local directory on the Linux operating system\nossfs allows you to mount an Object Storage Service (OSS) bucket to a local directory on the Linux operating system. This way, your application can access resources in the bucket in the same manner your application accesses local resources. The mount feature facilitates resource sharing.\nOSS is activated and an OSS bucket is created. For more information, see Get started with OSS and Create a bucket.\nThe following table provides download links to ossfs installer packages for commonly used Linux distributions. If you want to use ossfs on a different distribution, source code compiling is required.\nLinux distribution\nLinks\nUbuntu 22.04 (x64)\nossfs_1.91.5_ubuntu22.04_amd64.deb\nUbuntu 20.04 (x64)\nossfs_1.91.5_ubuntu20.04_amd64.deb\nUbuntu 18.04 (x64)\nossfs_1.91.5_ubuntu18.04_amd64.deb\nUbuntu 16.04 (x64)\nossfs_1.91.5_ubuntu16.04_amd64.deb\nUbuntu 14.04 (x64)\nossfs_1.91.5_ubuntu14.04_amd64.deb\nCentOS 8.0 (x64)\nossfs_1.91.5_centos8.0_x86_64.rpm\nCentOS 7.0 (x64)\nossfs_1.91.5_centos7.0_x86_64.rpm\nAnolis8/Alibaba Cloud Linux 3\nossfs_1.91.5_alinux3_x86_64.rpm\nAnolis7/Alibaba Cloud Linux 2\nossfs_1.91.5_alinux2_x86_64.rpm\nInstall ossfs.\nWhen you download a software package by using a command, you must enter the URL of the software package in a specific format. The following code provides an example on the format of the URL to enter if you want to download the software package of CentOS 7.0 (x64).\nRun the following commands in sequence to install ossfs in Ubuntu 16.04 (x64):\nRun the following command to install ossfs in CentOS 7.0 (x64):\nIf your client uses Yellowdog Updater, Modified (YUM) to install RPM packages, dependencies may fail to be downloaded by using YUM due to network environment factors on the client node. To resolve this issue, you can use YUM to download the dependencies over a normal network to a node that runs the same operating system version, and then copy the dependencies to the required node. For example, ossfs runs on FUSE 2.8.4 or later. Run the following command to download the latest version of FUSE from the YUM source to your local device:\nTo download other dependencies, replace FUSE with the name of the required package.\nAdd the mime.types file if you want the content type and file name extension of the uploaded object to match. ossfs queries the content in /etc/mime.types to configure the content type of the object.\nIf you do not add the mime.types file, OSS sets the content type of the uploaded object to application/octet-stream by default.\nRun the following command to add the mime.types file:\nRun the following command to add the mime.types file:\nRun the following command to add the mime.types file:\nRun the ossfs --version command to view the version information of ossfs. The following output indicates that ossfs is installed.\n\nSelect the bucket that you want to mount to a local directory.\nWe recommend that you do not mount an Infrequent Access (IA) bucket or a bucket for which real-time access of Archive objects is enabled to the local directory because two upload requests may be initiated when you upload objects to the preceding buckets from the local directory. The first request creates a 0-byte object and the second request uploads actual data to the object in the bucket. You are charged a 30-day storage fee of 64 KB for the 0-byte object based on the IA or Archive storage class. This results in unexpected storage costs.\nConfigure the account information that is used to access your bucket.\nWrite the following information to the /etc/passwd-ossfs file: the bucket name and the AccessKey pair (AccessKey ID and AccessKey secret) of the RAM user that has access permissions on the bucket. Then, set the permissions of the file to 640.\nReplace BucketName, yourAccessKeyId, and yourAccessKeySecret with your actual bucket name, AccessKey ID, and AccessKey secret. Example:\nMount the bucket to the specified directory.\nTo ensure data access security after you mount the bucket to the specified directory by using ossfs, we recommend that you configure the correct account information and access permissions. For more information, see ossfs configuration and mounting. Moreover, solutions in Best practices are intended for proficient users of ossfs to improve user experience.\nRun the following command to mount a bucket named bucket-test in the China (Hangzhou) region to the /tmp/ossfs directory:\nTo reduce traffic costs generated when you read data, we recommend that you deploy ossfs in an Elastic Compute Service (ECS) instance and use -o url to specify that the internal endpoint is used to access the destination bucket. In this example, the internal endpoint is http://oss-cn-hangzhou-internal.aliyuncs.com. To use an internal endpoint, the ECS instance and the destination bucket must be located in the same region. For more information , see Regions and endpoints.\nRead objects in the bucket from the local file system.\nQuery the list of objects in the bucket.\n\nMetadata-related operations, such as list directory, involve remote access to OSS and have a specific level of latency.\nCopy objects from the bucket.\nUpload an object to the bucket.\nThe preceding command is used to upload the forest.jpeg file to the mounted bucket from the local root directory.\n\nIf the upload is interrupted and not resumed, the uploaded data of the object is stored in the bucket as parts. To prevent additional storage fees, we recommend that you use one of the following methods to delete these parts that you no longer need:\nManually delete parts. For more information, see Delete parts.\nAutomatically delete parts by configuring lifecycle rules. For more information, see Lifecycle rules based on the last modified time.\nExecute the following command to unmount the bucket if it is no longer required to be mounted.\nFor more information about how to configure ossfs, see Advanced configurations.\nFor more information about the ossfs options, see Common options .\nFor more information about the commonly asked questions about ossfs, see FAQ."
    },
    "152": {
        "title": "Object Storage Service:Get started with OSS SDKs",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/oss-sdk-quick-start",
        "content": "This Product\nObject Storage Service:Get started with OSS SDKs\nYou can use OSS SDKs to perform operations such as bucket creation, object uploads, and object downloads. This topic uses OSS SDK for Java as an example to show you how to programmatically perform operations in OSS.\nOSS is activated. For more information, see Activate OSS.\nOSS SDK for Java is installed and access credentials are configured. For more information, see the following topics:\nInstallation\nConfigure access credentials\nA bucket is a global namespace in OSS. A bucket is a container that is used to store objects. The following sample code provides an example on how to create a bucket:\nAfter the sample code is run successfully, the examplebucket bucket is created.\nThe following sample code provides an example on how to upload an object to OSS by using streaming upload:\nAfter the sample code is run successfully, the exampleobject.txt object is uploaded to the exampledir directory.\nThe following sample code provides an example on how to download an object from OSS by using streaming download:\nAfter the sample code is run successfully, the content of the downloaded object is displayed in the compiler.\nThe following sample code provides an example on how to list objects in a bucket. By default, up to 100 objects are listed.\nAfter the sample code is run successfully, the details of the exampledir/exampleobject.txt object are displayed in the compiler.\nThe following sample code provides an example on how to delete an object:\nAfter the sample code is run successfully, the exampleobject.txt object is deleted from the exampledir directory.\nFor more information about how to use OSS SDKs for other programming languages to perform operations such as bucket creation, object uploads, and object downloads, see the following topics:\nGet started with OSS SDK for PHP\nGet started with OSS SDK for Node.js\nGet Started\nGet started with OSS SDK for Browser.js\nGet started with OSS SDK for .NET\nGet started with OSS SDK for Android\nGet Started with OSS SDK for Go V2\nGet started with OSS SDK for iOS\nGet started with OSS SDK for C++\nGet started with OSS SDK for C\nGet started with OSS SDK for Ruby"
    },
    "153": {
        "title": "Object Storage Service:Use OSS Connector for AI/ML to efficiently complete data training tasks",
        "url": "https://www.alibabacloud.com/help/en/oss/getting-started/oss-connector-for-ai-ml-quick-start",
        "content": "This Product\nObject Storage Service:Use OSS Connector for AI/ML to efficiently complete data training tasks\nThis topic describes how to use OSS Connector for AI/ML to efficiently create and train data models.\nOperating system: 64-bit x86 Linux\nglibc: 2.17 or later\nPython: 3.8 to 3.12\nPyTorch: 2.0 or later\nTo use the OSS checkpoint feature, the Linux kernel must support userfaultfd.\nIn this example, Ubuntu is used. You can run the sudo grep CONFIG_USERFAULTFD /boot/config-$(uname -r) command to check whether the Linux kernel supports userfaultfd. If CONFIG_USERFAULTFD=y is returned, the Linux kernel supports userfaultfd. If CONFIG_USERFAULTFD=n is returned, the Linux kernel does not support userfaultfd. In this case, you cannot use the OSS checkpoint feature.\nThe following example describes how to install OSS Connector for AI/ML for Python 3.12.\nRun the pip3.12 install osstorchconnector command to install OSS Connector for AI/ML in the container that is generated by using Linux or an image based on Linux.\nRun the pip3.12 show osstorchconnector command to check whether the OSS Connector for AI/ML is installed.\nIf the version information of osstorchconnector is returned, OSS Connector for AI/ML is installed.\n\nCreate a configuration file for access credentials.\nAdd the access credentials to the configuration file and save the configuration file.\nReplace <Access-key-id> and <Access-key-secret> in the example with the AccessKey ID and AccessKey secret of a RAM user. For more information about how to create an AccessKey ID and AccessKey secret, see Create an AccessKey pair. For more information about the configuration items and configuration by using temporary access credentials, see Configure access credentials.\nCreate an configuration file for OSS Connector.\nAdd the configurations of the OSS connector to the configuration file and save the configuration file. For more information about the configuration items, see Configure OSS Connector.\nIn most cases, you can use the following default configurations.\nThe following example shows how to create a handwritten digit recognition model by using PyTorch. The MNIST dataset used for the model is created by using OssMapDataset. Checkpoints are stored and accessed by using OssCheckpoint."
    },
    "154": {
        "title": "Object Storage Service:Endpoint",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/endpoint/",
        "content": "This Product\nObject Storage Service:Endpoint\nObject Storage Service (OSS) uses RESTful API operations to provide services and assigns a default endpoint to each bucket.\nAll requests to OSS over OSS domain names, except GetService (ListBuckets) and DescribeRegions requests, contain bucket information in the domain names.\nThe domain name used to access a bucket is in the BucketName.Endpoint format, in which BucketName is the name of the bucket and Endpoint is the endpoint of the region in which the bucket is located.\nOSS endpoints include internal endpoints, public endpoints, and acceleration endpoints. For example, the following endpoints are used to access buckets located in the China (Hangzhou) region:\nYou can use public endpoints without additional configurations.\nYou can use internal endpoints without additional configurations.\nAcceleration endpoints include the global acceleration endpoint and the acceleration endpoint of regions outside the Chinese mainland.\nGlobal acceleration endpoint\nAcceleration endpoint of regions outside the Chinese mainland\nThe public network is the Internet. OSS allows you to upload or write data to OSS over the Internet free of charge. You are charged when you download or read data from OSS.\nFor more information about the pricing and billing rules of OSS, see OSS pricing and Billing overview.\nYou can use one of the following methods to access OSS over the Internet:\nIf you use a URL to access an OSS object, the access control list (ACL) that is configured for the object determines whether you can read and write the object.\nObject ACL\nPublic-read or public-read-write\nPrivate\nURL format\n<Schema>://<Bucket>.<Public endpoint>/<Object>\n<Schema>://<Bucket>.<Public endpoint>/<Object>?Signature information\nParameter description\nSchema: HTTP or HTTPS.\nBucket: the name of the OSS bucket.\nPublic endpoint: the endpoint used to access the region in which the bucket is located over the Internet. For more information about the endpoints used to access different regions, see Regions and endpoints.\nObject: the path of the object.\nThe URLs used to access private objects have all parameters of the URLs of public-read and public-read-write objects plus the signature information. The signature information of a URL includes the Expires, AccessKey ID, and Signature parameters. The Expires parameter specifies the expiration time of the URL.\nFor more information about how to add a signature to an object URL, see Add signatures to URLs.\nExample\nYou create a bucket named examplebucket in the China (Hangzhou) region. The bucket contains the example.txt object. The object is in the exampledir directory and allows anonymous access. In this case, the object URL is https://examplebucket.oss-cn-hangzhou.aliyuncs.com/exampledir/example.txt.\nYou create a bucket named examplebucket in the China (Hangzhou) region. The bucket contains the example.txt object. The object is in the exampledir directory. The ACL of the object is set to private. In this case, the object URL is https://examplebucket.oss-cn-hangzhou.aliyuncs.com/exampledir/example.txt?OSSAccessKeyId=nz2p***********&Expires=1141889120&Signature=vjbyPxybdZaNmGa%2ByT272Y********.\nAn OSS SDK concatenates the endpoint that you specify for each operation. You must specify the endpoint based on the region in which the bucket on which you want to perform the operation is located.\nThe following sample code provides an example on how to use OSS SDK for Java to specify an endpoint. In this example, the endpoint is specified when OSSClient is created to manage a bucket located in the China (Hangzhou) region.\nYou can use an internal endpoint to communicate between Alibaba Cloud services located within the same region over the internal network. For example, you can access an OSS bucket from an Elastic Compute Service (ECS) instance over the internal network if the OSS bucket and the ECS instance are located within the same region. You are not charged for the traffic generated over the internal network. However, you are charged for requests that you send.\nFor more information about OSS fees, see OSS pricing and Billing overview.\nYou can use one of the following methods to access OSS over the internal network:\nIf you use a URL to access an OSS object, the ACL that is configured for the object determines whether you can read and write the object.\nObject ACL\nPublic-read or public-read-write\nPrivate\nURL format\n<Schema>://<Bucket>.<Internal endpoint>/<Object>\n<Schema>://<Bucket>.<Internal endpoint>/<Object>?Signature information\nParameter description\nSchema: HTTP or HTTPS.\nBucket: the name of the OSS bucket.\nInternal endpoint: the endpoint used by ECS instances to access buckets that are located in the same region as the ECS instances over the internal network. For more information about the endpoint of each region, see Regions and endpoints.\nObject: the path of the object.\nThe URLs used to access private objects have all parameters of the URLs of public-read and public-read-write objects plus the signature information. The signature information of a URL includes the Expires, AccessKey ID, and Signature parameters. The Expires parameter specifies the expiration time of the URL.\nFor more information about how to add a signature to an object URL, see Add signatures to URLs.\nExample\nYou create a bucket named examplebucket in the China (Hangzhou) region. The bucket contains the example.txt object. The object is in the exampledir directory and allows anonymous access. The object URL is https://examplebucket.oss-cn-hangzhou-internal.aliyuncs.com/exampledir/example.txt.\nYou create a bucket named examplebucket in the China (Hangzhou) region. The bucket contains the example.txt object. The object is in the exampledir directory. The ACL of the object is set to private. In this case, the object URL is https://examplebucket.oss-cn-hangzhou-internal.aliyuncs.com/exampledir/example.txt?OSSAccessKeyId=nz2p***********&Expires=1141889120&Signature=vjbyPxybdZaNmGa%2ByT272Y********.\nThe following sample code provides an example on how to use OSS SDK for Java to specify an internal endpoint. In this example, the endpoint is set to the internal endpoint of the China (Hangzhou) region to manage a bucket located in the China (Hangzhou) region.\nIf the OSS bucket and the ECS instance are located in the same region, you can use the internal endpoint to access the OSS bucket from the ECS instance over the internal network. If the OSS bucket and the ECS instance are located in different regions, you cannot use the internal endpoint to access the OSS bucket from the ECS instance over the internal network. For example, you have two OSS buckets and you purchased an ECS instance located in the China (Beijing) region.\nOne bucket is named srcbucket and located in the China (Beijing) region. You can use https://srcbucket.oss-cn-beijing-internal.aliyuncs.com to access resources in srcbucket from the ECS instance located in the China (Beijing) region.\nThe other bucket is named destbucket and located in the China (Qingdao) region. You cannot use https://destbucket.oss-cn-qingdao-internal.aliyuncs.com to access resources in destbucket from the ECS instance located in the China (Beijing) region. To access resources in destbucket from the ECS instance located in the China (Beijing) region, you must use https://destbucket.oss-cn-qingdao.aliyuncs.com to access resources in destbucket over the Internet.\nOSS provides the transfer acceleration feature to accelerate date transfers of data uploads and downloads across countries and regions. To use an acceleration endpoint to access a bucket in OSS, you must enable transfer acceleration for the bucket. After you enable transfer acceleration for a bucket, you can use the acceleration endpoint instead of the public endpoint to access the bucket and accelerate data transfers.\nFor example, you want to access the myphoto.jpg object in the root directory of the examplebucket bucket from a browser and use the global acceleration endpoint to accelerate your access. The ACL of the object is public-read or public-read-write. In this case, the URL of the object is https://examplebucket.oss-accelerate.aliyuncs.com/myphoto.jpg.\nIf the ACL of the myphoto.jpg object is private, you must add signature information to the object URL. Example: https://examplebucket.oss-accelerate.aliyuncs.com/myphoto.jpg?OSSAccessKeyId=nz2p***********&Expires=1141889120&Signature=vjbyPxybdZaNmGa%2ByT272Y********. For more information about how to add a signature to an object URL, see Add signatures to URLs.\nDifferent regions are accessed by using different endpoints. For more information, see Regions and endpoints.\nThe endpoints listed in this topic are IPv4 domain names. If you want to access OSS buckets over IPv6, you must use endpoints that support IPv6. For more information, see Use an endpoint that supports IPv6 to access OSS.\nTo access an OSS bucket over the internal network from an ECS instance in a different region or a device in an on-premises data center, you can use Cloud Enterprise Network (CEN), Express Connect, leased lines, or virtual private networks (VPNs) to connect to the internal network of the region in which the OSS bucket is located. Then, you can configure a route that directs to the virtual IP address (VIP) ranges of the internal network. For more information, see Internal OSS endpoints and VIP ranges.\nYou can map a custom domain name to a bucket and use the domain name to access the resources in the bucket. For example, you can map the static.example.com custom domain name to a bucket and then use the domain name to access the resources in the bucket.\nTo access an object, you must include the path of the object in an OSS domain name. For example, if you use examplebucket.oss-cn-hangzhou.aliyuncs.com to access an object without including the path of the object in the OSS domain name, an error is reported. To use an OSS endpoint to access an object without including the path of the object, configure static website hosting.Static website hosting"
    },
    "155": {
        "title": "Object Storage Service:Storage classes",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/overview-53/",
        "content": "This Product\nObject Storage Service:Storage classes\nObject Storage Service (OSS) provides the following storage classes for various data storage scenarios from hot data storage to cold data storage: Standard, Infrequent Access (IA), Archive, Cold Archive, and Deep Cold Archive.\nFor more information about the pricing for each storage class, visit the OSS pricing page. For more information about the billing method for each storage class, see Storage fees.\nStandard provides highly reliable, highly available, and high-performance object storage for data that is frequently accessed. Standard is suitable for various business applications, such as social networking applications, image, audio, and video resource sharing applications, large websites, and big data analytics. ZRS (Zone-redundant storage) and LRS (Locally redundant storage) are supported for Standard objects.\nStandard ZRS (Recommended)\nZRS stores multiple copies of your data across multiple zones in the same region. Your data is still accessible even if a zone becomes unavailable.\nStandard zone-redundant storage (ZRS) is supported in the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), China (Hong Kong), Japan (Tokyo), Singapore, Indonesia (Jakarta), and Germany (Frankfurt).\nStandard LRS\nLRS stores multiple copies of your data on multiple devices of different facilities in the same zone. LRS provides data durability and availability even if hardware failures occur.\nLRS stores multiple data copies in a single zone. If the zone becomes unavailable, data in the zone is inaccessible. If your business application requires higher availability, we recommend that you use ZRS.\nIA provides highly durable storage at lower prices compared with Standard. IA has a minimum billable size of 64 KB and a minimum billable storage duration of 30 days. IA is suitable for data that is infrequently accessed, such as data accessed once or twice a month. You can access IA objects in real time. You are charged data retrieval fees when you access IA objects. ZRS and LRS are supported for IA objects.\nIf the size of an IA object is smaller than 64 KB, you are charged for the minimum billable size. If an IA object is stored for less than the minimum billable storage duration of 30 days, you are charged for the storage usage of the IA objects that are stored for less than the minimum storage duration. For more information, see Storage fees.\nIA ZRS (Recommended)\nZRS stores multiple copies of your data across multiple zones in the same region. Your data is still accessible even if a zone becomes unavailable.\nIA ZRS is supported in the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), China (Hong Kong), Japan (Tokyo), Singapore, Indonesia (Jakarta), and Germany (Frankfurt).\nIA LRS\nLRS stores multiple copies of your data on multiple devices of different facilities in the same zone. LRS provides data durability and availability even if hardware failures occur.\nLRS stores multiple data copies in a single zone. If the zone becomes unavailable, data in the zone is inaccessible. If your business application requires higher availability, we recommend that you use ZRS.\nArchive provides high-durability storage at lower prices compared with Standard and IA. Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 60 days. You can access an Archive object after it is restored or real-time access of Archive objects is enabled. The amount of time that is required to restore an Archive object is approximately 1 minute. You are charged data retrieval fees if you restore an Archive object. If you access an Archive object after real-time access of Archive objects is enabled, you are charged Archive data retrieval fees based on the size of the Archive object. Archive is suitable for data that needs to be stored for a long period of time and is rarely accessed, such as archival data, medical images, scientific materials, and video footage. ZRS and LRS are supported for Archive objects\nIf the size of an Archive object is smaller than 64 KB, you are charged for the minimum billable size. If an Archive object is stored for less than the minimum billable storage duration of 60 days, you are charged for the storage usage of the Archive object that is stored for less than the minimum storage duration. For more information, see Storage fees.\nArchive ZRS (Recommended)\nZRS stores multiple copies of your data across multiple zones in the same region. Your data is still accessible even if a zone becomes unavailable.\nArchive ZRS is supported in the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), China (Hong Kong), Japan (Tokyo), Singapore, Indonesia (Jakarta), and Germany (Frankfurt).\nArchive LRS\nLRS stores multiple copies of your data on multiple devices of different facilities in the same zone. LRS provides data durability and availability even if hardware failures occur.\nLRS stores multiple data copies in a single zone. If the zone becomes unavailable, data in the zone is inaccessible. If your business application requires higher availability, we recommend that you use ZRS.\nCold Archive provides highly durable storage at lower prices compared with Archive. Cold Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 180 days. You must restore a Cold Archive object before you can access it. The amount of time required to restore a Cold Archive object varies based on the object size and restoration priority. You are charged data retrieval fees and API operation calling fees when you restore Cold Archive objects. Cold Archive is suitable for cold data that needs to be stored for an extended period of time, including data that must be retained for an extended period of time to meet compliance requirements, raw data that is accumulated over an extended period of time in the big data and AI fields, retained media resources in the film and television industries, and archived videos in the online education industry. Only LRS is supported for Cold Archive objects.\nLRS data is stored in a specific zone. If the zone fails, the data stored within becomes inaccessible. If your business application requires higher availability, we recommend that you use ZRS (supported for Standard, IA and Archive objects).\nCold Archive is supported in the following regions: China (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), US (Silicon Valley), US (Virginia), Japan (Tokyo), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Germany (Frankfurt), UK (London), and UAE (Dubai).\nIf the size of a Cold Archive object is smaller than 64 KB, you are charged for the minimum billable size. If a Cold Archive object is stored for less than the minimum billable storage duration of 180 days, you are charged for the storage usage of the Deep Cold Archive object that is stored for less than the minimum storage duration. For more information, see Storage fees.\nDeep Cold Archive provides highly durable storage at lower prices compared with Cold Archive. Deep Cold Archive has a minimum billable size of 64 KB and a minimum billable storage duration of 180 days. You must restore a Deep Cold Archive object before you can access it. The amount of time that is required to restore a Deep Cold Archive object varies based on the object size and restoration priority. You are charged data retrieval fees and API operation calling fees when you restore Deep Cold Archive objects. Deep Cold Archive is suitable for extremely cold data that needs to be stored for an extremely long period of time, including raw data that is accumulated over an extended period of time in the big data and AI fields, retained media resources, regulatory and compliance documents, and data that is archived by using tapes. Only LRS is supported for Deep Cold Archive objects.\nLRS data is stored in a specific zone. If the zone fails, the data stored within becomes inaccessible. If your business application requires higher availability, we recommend that you use ZRS (supported for Standard, IA and Archive objects).\nDeep Cold Archive is supported in the following regions: China (Hangzhou), China (Shanghai), China (Beijing), China (Zhangjiakou), China (Ulanqab), China (Shenzhen), and Singapore.\nIf the size of a Deep Cold Archive object is smaller than 64 KB, you are charged for the minimum billable size. If a Deep Cold Archive object is stored for less than the minimum billable storage duration of 180 days, you are charged for the storage usage of the Deep Cold Archive object that is stored for less than the minimum storage duration. For more information, see Storage fees.\nStorage class\nRedundancy type\nData durability\nService availability\nMinimum billable size\nMinimum storage duration\nData access frequency\nAccess latency\nStandard\nZRS (Recommended)\n99.9999999999%\n99.995%\nActual size of objects\nNone\nMore than once a month\nReal-time access\nIA\n99.50%\n64 KB\n30 days\nLess than once a month\nReal-time access\nArchive\n99.50%\n64 KB\n60 days\nLess than once in 90 days\nReal-time access after real-time access of Archive objects is enabled or access after an Archive object is restored.\nThe amount of time required to restore an Archive object is approximately 1 minute.\nStandard\nLRS\n99.999999999%\n\n99.99%\nActual size of objects\nNone\nMore than once a month\nReal-time access\nIA\n99.00%\n64 KB\n30 days\nLess than once a month\nReal-time access\nArchive\n99.00%\n64 KB\n60 days\nLess than once in 90 days\nReal-time access after real-time access of Archive objects is enabled or access after an Archive object is restored.\nThe amount of time required to restore an Archive object is approximately 1 minute.\nCold Archive\n99.00%\n64 KB\n180 days\nLess than once a year\nObjects must be restored before you can access them.\nThe amount of time required to restore an Archive object ranges from 1 to 12 hours.\nDeep Cold Archive\n99.00%\n64 KB\n180 days\nLess than once a year\nObjects must be restored before you can access them.\nThe amount of time required to restore an Archive object is 12 or 48 hours.\nStandard\n99.00%\nActual size of objects\nNone\nMore than once a month\nReal-time access\nBy default, the storage class of objects uploaded to buckets is Standard. Standard is suitable for scenarios in which data needs to be frequently accessed and can be accessed with low latency. If you no longer need to frequently access specific objects or you want to reduce storage costs, you can convert the storage class of Standard objects to a more economical storage class, such as IA or Archive. For more information, see Convert storage classes.\nDeep Cold Archive provides highly durable and low-cost storage for extremely cold data that needs to be stored for an ultra-long period of time. For more information, see Best practices for using Deep Cold Archive.\nIf the storage usage of objects in the storage class of the destination objects increases, but the storage usage of the objects in the storage class of the source objects remains the same after the storage class of the source objects is converted, see Why does the storage usage of the objects in the storage class of the source objects remain the same after the storage class of the source objects is converted?"
    },
    "156": {
        "title": "Object Storage Service:Buckets",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/overview-19/",
        "content": "This Product\nObject Storage Service:Buckets\nA bucket is a container used to store objects in Object Storage Service (OSS). Buckets help you efficiently organize and manage objects. This topic describes basic information about buckets and provides follow-up guidelines.\nLimits on bucket capacity and number: You can create up to 100 buckets in a region by using an Alibaba Cloud account. No limit is imposed on the capacity of a bucket.\nFlat structure: Buckets use a flat structure instead of a hierarchical structure to store objects and do not have directories, as shown in the following figure. To facilitate object management, graphical tools, such as the OSS console and ossbrowser, display objects whose names end with a forward slash (/) as directories. For more information, see Manage directories.\nBefore you use buckets, take note of the following items:\nBucket name: When you create a bucket, you must specify the name of the bucket. The name of a bucket must be unique in OSS in an Alibaba Cloud account. We recommend that you use a business-related name to facilitate identification. For example, myapp-logs-Hangzhou specifies a bucket in which the logs of myapp in the Hangzhou region are stored. For more information, see Naming conventions.\nRegion: When you create a bucket, you must specify the physical location of the bucket. You cannot change the region of a bucket after you create the bucket. To improve access speed, we recommend that you select a region that is geographically closest to your business. For more information, see Choose an OSS region.\nEndpoint: You can use an endpoint to access objects in OSS. Each region has its own endpoints. To access objects in a bucket by calling API operations or by using OSS SDKs, ossutil, and ossfs, you must use the endpoint of the region in which the bucket is located. For more information, see Regions and endpoints.\nStorage class :OSS provides the following storage classes to meet different storage requirements: Standard (default), Infrequent Access (IA), Archive, Cold Archive, and Deep Cold Archive. You can store objects in different storage classes based on the application scenarios to reduce storage costs. For example, Standard is suitable for frequently accessed objects, while Cold Archive is suitable for cold data that must be retained for a long period of time. For more information, see Overview.\nRedundancy type: The redundancy mechanism improves data reliability by backing up data in multiple devices or zones. If you require higher reliability, we recommend that you select zone-redundant storage (ZRS). If you want to reduce costs, we recommend that you select locally redundant storage (LRS). ZRS is used by default. For more information, see Storage redundancy.\nLRS supports the following storage classes: Standard, IA, Archive, Cold Archive, and Deep Cold Archive. ZRS supports the following storage classes: Standard, IA, and Archive.\nACL: You can specify the bucket access control list (ACL) to manage the read and write permissions on the bucket and objects in the bucket. Bucket ACLs include private (default), public-read, and public-read-write. We recommend that you set the bucket ACL to private to ensure data security. For more information, see Access and control.\nBlock Public Access: If you enable Block Public Access for a bucket, existing public access permissions are ignored and you cannot configure public access permissions. This disables public data access channels and ensures data security. By default, this feature is enabled. For more information, see Block Public Access.\nResource group: You can select resource groups to which buckets belong to manage the buckets by department or project. A default resource group is provided for use. For more information, see Use resource groups.\nAfter you are familiar with the basic information about buckets, you can use and manage buckets based on your business requirements.\nOperation\nDescription\nCreate a bucket\nBefore you upload an object to OSS, you must create a bucket to store the object.\nList buckets\nYou can specify different conditions to list all buckets or specific buckets in a region.\nDelete a bucket\nYou can delete a bucket that is no longer required to release storage capacity.\nView the resource usage of a bucket\nYou can view basic statistics, ranking statistics, region and operator statistics, API statistics, and object access statistics in the OSS console.\nQuery the region in which a bucket is located\nIf you created a large number of buckets across regions, you can specify the bucket name to query the region of the bucket.\nResolve common issues\nIf you encounter issues when you use buckets, see FAQ about buckets.\nOperation\nDescription\nManage bucket tags\nOSS allows you to configure bucket tags to classify and manage buckets. For example, you can list buckets that have specific tags and configure the ACL for buckets that have specific tags.\nMap a custom domain name to the default domain name of a bucket\nAfter you upload objects to a bucket, OSS automatically generates URLs that include the public endpoint of the bucket for the uploaded objects. You can use these URLs to access the objects. If you want to access the objects by using a custom domain name, you must map the custom domain name to the bucket in which the objects are stored.\nEnable transfer acceleration\nOSS uses regions that are distributed around the world to perform transfer acceleration. When a request to access your bucket is sent, the request is parsed and routed to the region in which the bucket is located over the optimal network path and protocol. The transfer acceleration feature provides an optimized end-to-end acceleration solution to access OSS over the Internet.\nEnable pay-by-requester\nIf you want requesters to pay the fees that are generated when they access objects in a bucket, enable pay-by-requester for the bucket.\nUse resource groups\nA resource group is a resource-based access control method. You can group your buckets based on your business requirements and configure different access permissions for different resource groups. This way, you can manage access to your buckets by group.\nBy default, Alibaba Cloud uses an Alibaba Cloud account to perform OSS operations. However, the Alibaba Cloud account has full access permissions, which poses high security risks. We recommend that you use an Alibaba Cloud account to create RAM users as account administrators and attach RAM policies to the RAM users to grant permissions to the RAM users. If you want to authorize bucket access across accounts, you can configure bucket policies to grant other accounts the permissions to access the bucket. If you want to implement coarse-grained access control on a bucket, you can specify the bucket ACL to manage access to the bucket. We recommend that you turn on Block Public Access to prevent accidental data disclosure and enhance data security.\nFeature\nDescription\nBlock Public Access\nIf you enable Block Public Access, existing public access permissions are ignored and you cannot configure public access permissions. This disables public data access channels and ensures data security. By default, Block Public Access is enabled when you create a bucket.\nBucket ACL\nYou can configure the ACL for a bucket when you create the bucket or change the ACL of an existing bucket based on your business requirements. Only the owner of a bucket can configure or change the ACL of the bucket.\nBucket Policy\nYou can configure bucket policies for a bucket to grant permissions to other users to access specific OSS resources.\nRAM Policy\nResource Access Management (RAM) is a service provided by Alibaba Cloud to manage access permissions on resources. RAM policies are user-based authorization policies. You can configure RAM policies to manage users, such as employees, systems, or applications. You can specify which resources are accessible to the users. For example, you can create a RAM policy to grant users only read permissions on a bucket.\nOperation\nDescription\nEnable versioning\nAfter you enable versioning for a bucket, each time you upload an object that has the same name as an existing object in the bucket, a new version is created. In this case, the existing object is not overwritten. This way, you can find and restore previous versions of the object at any time. This feature is suitable for scenarios in which you frequently update objects or historical objects need to be retained.\nConfigure hotlink protection\nYou can configure hotlink protection for a bucket to prevent unauthorized access to resources in the bucket.\nConfigure CORS rules\nCross-origin resource sharing (CORS) is a standard cross-origin solution provided by HTML5 to allow web application servers to control cross-origin access. This ensures the security of data transmission across origins.\nConfigure retention policies\nOSS supports the Write Once Read Many (WORM) feature. The feature helps prevent objects from being deleted or overwritten within a specific period of time. Enterprises use this feature to comply with the regulations of the U.S. Securities and Exchange Commission (SEC) and Financial Industry Regulatory Authority (FINRA).\nConfigure server-side encryption\nOSS encrypts objects uploaded to a bucket for which server-side encryption is configured and stores the encrypted objects. When you call the GetObject operation to download an object, OSS decrypts and returns the object. The x-oss-server-side-encryption header is included in the response to indicate that the object is encrypted on the server side.\nConfigure the TLS version\nCommunication between the client applications and OSS is encrypted by using Transport Layer Security (TLS) to ensure the security of the communication link. You can specify the allowed TLS versions to improve the security of connections between the client applications and OSS.\nOperation\nDescription\nConfigure SRR rules\nSame-region replication (SRR) allows you to automatically and asynchronously (in near real-time) replicate objects across buckets within the same region. SRR replicates operations, such as object creation, update, and deletion, from a source bucket to a destination bucket.\nConfigure CRR rules\nCross-region replication (CRR) allows you to automatically and asynchronously (in near real-time) replicate objects from a bucket in one region to a bucket in a different region. CRR replicates operations, such as object creation, update, and deletion, from a source bucket to a destination bucket.\nConfigure lifecycle rules\nYou can configure lifecycle rules for a bucket based on the last modified time and last access time of objects in the bucket. This way, Object Storage Service (OSS) can regularly convert the storage class of the objects or delete expired objects and parts to reduce your storage costs.\nConfigure bucket inventory\nYou can use the bucket inventory feature to export information about specific objects in a bucket, such as the number, size, storage class, and encryption status of the objects. To list a large number of objects, we recommend that you use the bucket inventory feature instead of calling the GetBucket (ListObjects) operation.\nConfigure static website hosting\nStatic websites are websites in which all web pages consist of only static content, including scripts such as JavaScript code that can be run on a client. You can use the static website hosting feature to host your static website on an OSS bucket and use the domain name of the bucket to access the website. For more information, see Map custom domain names.\nConfigure mirroring-based back-to-origin rules\nAfter you configure mirroring-based back-to-origin rules for a bucket, if a requested object does not exist in the bucket, OSS obtains the object from the origin specified by the back-to-origin rules. OSS returns the object retrieved from the origin to the requester and stores the object in the bucket.\nEnable real-time access of Archive objects\nAfter you enable real-time access of Archive objects for a bucket, you can access Archive objects in the bucket in real time without the need to restore them. Compared with accessing restored objects, real-time access of Archive objects requires less time to retrieve data but generates higher data retrieval fees.\nOperation\nDescription\nUse IMG\nYou can use image processing (IMG) to resize images, crop images, and configure image styles.\nConfigure event notification rules\nYou can configure event notification rules for objects that you want to monitor in the OSS console. If the events that are specified in the rules occur on these objects, you can be immediately notified.\nFeature\nDescription\nLogging\nA large number of logs are generated when OSS resources are accessed. After you enable and configure logging for a bucket, OSS generates logs on an hourly basis based on predefined naming conventions and then stores the logs in a specific bucket. You can use Simple Log Service or build a Spark cluster to analyze the logs.\nReal-time log query\nReal-time log query allows you to query, filter, and analyze OSS access logs in the OSS console to track exceptions and troubleshoot errors. You can enable real-time log query based on your business requirements.\nFeature\nDescription\nOSS-HDFS\nOSS-HDFS integrates OSS and Hadoop Distributed File System (HDFS). OSS-HDFS allows you to store data in OSS and use Hadoop tools to process and analyze the data. OSS-HDFS is suitable for scenarios in which a large amount of data needs to be processed, such as big data analysis, data mining, and machine learning scenarios.\n\n"
    },
    "157": {
        "title": "Object Storage Service:Object",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/overview-18/",
        "content": "This Product\nObject Storage Service:Object\nIn Object Storage Service (OSS), an object serves as the fundamental unit for data storage, functioning similarly to a file. Files, including documents, images, and videos, uploaded to OSS are stored as objects within OSS buckets for further management.\nKey: the name of the object. An object key acts like a file path and is globally unique. It is used to query the object. We recommend that you specify proper names for objects for efficient management. For information about the naming conventions, see Object naming conventions.\nData: the content stored within an object. Similar to file content, object data can be any sequence of bytes and may vary in length.\nObject metadata: the metadata of the object. It consists of key-value pairs that define attributes, such as the last modification time and size of the object. Object metadata also supports the storage of custom information.\nVersion ID: the unique identifier assigned to an object version. To store multiple versions of an object, you must enable versioning. When an object with the same name is uploaded, OSS generates a distinct version ID for the new version. This ID allows you to access and manage a specific version of the object.\nIn OSS SDKs for different programming languages, object keys may be referred to by different aliases, such as ObjectKey, ObjectName, or object name. When specifying an object key, you must include the full path, such as exampledir/example.jpg. To simplify understanding, the term \"object name\" is used to describe the last segment of the key path. In the given example, the object name is \"example.jpg\".\nIn OSS, traditional file system concepts like files and folders do not exist. To enhance user experience, forward slashes (/) are used in object keys to mimic a folder structure, such as exampledir/example.jpg. The given example simulates exampledir as a folder and example.jpg as a file within exampledir. This folder-like structure is visible in the OSS console and graphical tools like ossbrowser. However, the object key remains exampledir/example.jpg. For more information, see Manage directories.\nObjects can be categorized into four types based on their creation methods. The following table describes these four types.\nYou cannot change the type of an object. For example, you cannot convert a normal object into a multipart object or an appendable object.\nType\nCreation method\nDescription\nNormal\nObjects of this type are created by using simple upload.\n\nIf multiple users upload objects with identical name to a bucket that has versioning disabled or suspended, the most recently uploaded object overwrites the previous one. Only the last uploaded object is stored. For example, if User A uploads an object after User B, the object from User A is retained and replaces the object from User B.\nIf multiple users upload objects with identical names to a versioning-enabled bucket, OSS creates a new version of the object for each upload operation and assigns a unique version ID to the new version. OSS identifies the latest version of an object based on the upload start time. For example, if User A and User B upload objects with identical name to a versioning-enabled bucket, and User B begins the upload after User A, the object uploaded by User B will be designated as the latest version.\nMultipart\nObjects of this type are created by using multipart upload.\nIf you combine uploaded parts into a complete object with identical name to an existing object in a bucket that has versioning disabled or suspended, the new object replaces the existing one. Only the most recently combined object is retained.\nIf you combine uploaded parts into a complete object with identical name to an existing object in a versioning-enabled bucket, OSS creates a new version of the object and assigns it a unique version ID. The most recently combined object is designated as the latest version.\nAppendable\nObjects of this type are created by using append upload.\nWhen data is appended to an appendable object, OSS does not create a new version of the object, regardless of the versioning status. The data is directly appended to the original object.\nSymlink\nObjects of this type are created by using symbolic links created by calling the PutSymlink operation.\nYou can use symbolic links to access objects that are frequently accessed.\nDelete markers\nOSS uses a special type of object marker called delete marker. When you call the DeleteObject operation to delete an object in a versioning-enabled or versioning-suspended bucket, OSS generates a delete marker for the object. If no version ID is specified during deletion, OSS assigns the delete marker as the latest version of the object. This ensures the data in the object is preserved and can be restored even after deletion. However, if a version ID is specified, OSS deletes the specific version and does not generate a delete marker.\nFeature\nDescription\nSimple upload\nSimple upload enables you to call the PutObject operation to upload a single object of up to 5 GB in size. This feature is ideal for scenarios where the object can be uploaded in a single HTTP request.\nMultipart upload\nMultipart upload allows you to split an object into multiple parts and upload them separately. Once all parts are uploaded, call the CompleteMultipartUpload operation to merge them into a complete object.\nResumable upload\nWhen using resumable upload to transfer objects to OSS, you can designate a checkpoint file. This file tracks the progress of the upload task. If the upload is interrupted by a network issue or program error, the task can resume from the last recorded progress in the checkpoint file, allowing the remaining data to be uploaded.\nUpload callback\nAfter you upload an object, OSS can send a callback request to your application server. To enable upload callback, simply include the necessary callback parameters in the upload request sent to OSS.\nDirect client upload\nA direct client upload enables data to be uploaded directly from clients to OSS. This feature enhances upload speed and decreases server resource consumption by eliminating the need to route objects through the application server.\nForm upload\nYou can use the PostObject operation to upload objects of up to 5 GB in size by using an HTML form.\nAppend upload\nYou can use append upload to add content to an appendable object.\nRTMP-based stream ingest\nYou can use the Real-Time Messaging Protocol (RTMP) to ingest H.264-encoded video streams and AAC-encoded audio streams into OSS. The uploaded audio and video data can be played on demand or utilized for livestreaming in scenarios where latency is not a critical factor.\nFeature\nDescription\nSimple download\nSimple download enables you to use the GetObject operation to retrieve an object. This feature is ideal for scenarios where the object can be downloaded in a single HTTP request.\nResumable download\nResumable download allows you to download data from a specific position within an object. For large objects, you can divide the object into multiple parts and download them at different times. If a download task is interrupted, you can resume it from the point where it was paused.\nAuthorize third-party users to download objects\nYou can grant third-party users the permissions to download an object by issuing temporary access credentials or a signed URL, ensuring the AccessKey pair of the object owner account remains secure and is not exposed.\nUse a signed URL to download an object\nAfter uploading objects to a bucket, you can share their URLs with third parties to allow downloads or previews.\nConditional download\nObjects are downloaded only if their content has changed, determined by the last modified time or ETag. This feature ensures downloads are triggered solely when updates occur, avoiding unnecessary repeated downloads.\nFeature\nDescription\nList objects\nBy default, listing objects in a bucket returns them in alphabetical order. You can list all objects in a bucket, objects with a specific name prefix, or a limited number of objects.\nCopy objects\nYou can copy an object from a source bucket to a destination bucket within the same region without modifying the object content.\nRename objects\nYou can rename an object in a bucket.\nSearch for objects\nIf a bucket contains a large number of objects, you can search for objects by using a prefix.\nRestore objects\nBefore accessing an object in Cold Archive or Deep Cold Archive, you must initiate a restoration process for the object.\nDelete objects\nYou can delete unwanted objects from your OSS buckets by using various methods.\nAdd tags to an object\nYou can use object tags to classify objects. These tags enable you to set up lifecycle rules and access control lists (ACLs) for objects sharing the same tag.\nCreate symbolic links\nYou can use symbolic links to access objects that are frequently used in buckets. You can use symbolic links to access frequently used objects in buckets. After setting up a symbolic link for an object, you can use the link to access the object quickly. A symbolic link operates like a Windows shortcut.\nManage object metadata\nObject metadata defines the attributes of an object and consists of standard HTTP headers and user metadata. Standard HTTP headers can be configured to establish custom HTTP request policies, such as cache control or forced download policies. User metadata can be configured to specify the purpose or attributes of objects.\nSingle-connection bandwidth throttling\nAccessing objects in OSS by using a client, particularly when traffic throttling is challenging to implement, can consume substantial bandwidth. This may negatively impact other applications accessing OSS. To prevent this, use the single-connection bandwidth throttling feature to limit bandwidth for operations like object uploads and downloads. This ensures sufficient bandwidth for other OSS applications.\nQuery objects\nYou can use the SelectObject operation to execute SQL statements on an object and retrieve the results.\nDelete parts\nIf you no longer require specific parts that are not uploaded during multipart upload, you can call the AbortMultipartUpload operation to delete the parts.\nUse CSG to attach OSS buckets to ECS instances\nTo enable multiple users to access resources in an OSS bucket from different locations and devices, you can use Cloud Storage Gateway (CSG) to map the OSS bucket to a shared file storage system. This allows users to perform operations on OSS resources as they would with local files and disks.\nFAQ about uploading objects\nFAQ about sharing objects\nFAQ about managing object metadata\nFAQ about browsers\nOther FAQ"
    },
    "158": {
        "title": "Object Storage Service:Access control",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/overview-75/",
        "content": "This Product\nObject Storage Service:Access control\nBy default, the access control list (ACL) of Object Storage Service (OSS) resources, including buckets and objects, is set to private to ensure data security. Only the owners of the resources and authorized users can access these resources. OSS allows you to configure a variety of policies to grant third-party users specific permissions to access or use your OSS resources.\nThe following table describes the access control policies that you can configure for objects stored in buckets.\nParameter\nDescription\nScenario\nRAM Policy\nResource Access Management (RAM) is a service provided by Alibaba Cloud to manage access permissions on resources. RAM policies are authorization policies configured based on users. You can configure RAM policies to manage your users, such as employees, systems, or applications, and control user permissions on your resources. For example, you can configure a RAM policy to allow your users to only read one bucket.\nGrant permissions to RAM users, RAM user groups, or RAM roles within the current Alibaba Cloud account.\nBucket Policy\nA bucket policy is a resource-based authorization policy. Unlike RAM policies, bucket policies can be easily configured on the GUI of the console. In addition, the owner of a bucket can configure bucket policies for the bucket without RAM permissions. You can configure bucket policies to grant permissions to the RAM users of other Alibaba Cloud accounts or anonymous users who access OSS by using the specified IP addresses.\nGrant permissions to RAM users or RAM roles within the current Alibaba Cloud account.\nGrant permissions to RAM users or RAM roles within other Alibaba Cloud accounts.\nGrant permissions to anonymous users.\nBucket ACLs\nYou can configure the ACL of a bucket when you create the bucket or modify the ACL of a created bucket. Only the owner of a bucket can configure or modify the ACL of the bucket. You can set the ACL of a bucket to one of the following values: public-read-write, public-read, and private.\nSet the same ACL permissions for all objects in a bucket.\nObject ACLs\nYou can also configure the ACL of each object stored in OSS. You can configure the ACL of an object when you upload the object or modify the ACL of an uploaded object. You can set the ACL of an object to one of the following values: default, public-read-write, public-read, and private.\nSet the ACL permissions of a single or multiple objects respectively.\nFor example, you configure RAM policies or bucket policies for a bucket to set the ACL of all objects in the bucket or objects whose names contain the specified prefix to private. In this case, if you want an object in the bucket to be accessed by all anonymous users from the Internet, you can set the ACL of the object to public-read.\nBlock Public Access\nYou can allow public access to OSS resources by configuring bucket policies and ACLs. Public access specifies access to OSS resources without specific permissions or authentication. Public access can cause data breaches and generate a large amount of outbound traffic over the Internet due to malicious access. OSS allows you to enable Block Public Access to prevent risks that may be caused. After you enable this feature, existing public access permissions will be ignored and you cannot grant public access permissions. This disables public access channels and ensures data security.\nEnable Block Public Access for OSS resources.\nEnable Block Public Access for a bucket.\nEnable Block Public Access for an access point.\nEnable Block Public Access for an Object FC Access Point.\nFor more information about the authentication process of OSS when multiple access control policies, such as RAM policies, ACLs, and bucket policies, are configured for a bucket, see Authorization."
    },
    "159": {
        "title": "Object Storage Service:Security of OSS data",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/data-security-11/",
        "content": "This Product\nObject Storage Service:Security of OSS data\nObject Storage Service (OSS) provides multiple security capabilities to ensure the confidentiality, integrity, and availability of data.\nTo prevent business interruption or damage caused by accidental object deletion or overwriting, you can enable versioning for OSS buckets. After you enable versioning for a bucket, objects in the bucket are stored as previous versions when they are overwritten or deleted. If you accidentally delete or overwrite an object, you can recover the object to a previous version. For more information, see Versioning.\nTo prevent additional traffic costs generated due to the access of data in OSS by external websites, you can enable hotlink protection for OSS buckets. After you enable hotlink protection for a bucket, only your website can request to access objects in the bucket. For more information, see Hotlink protection.\nWhen you access OSS in browsers by using JavaScript, cross-origin request errors can occur due to the same-origin policy enforced by the browsers. To resolve the issue, you can configure cross-origin resource sharing (CORS) for OSS buckets. After you configure CORS for a bucket, you are allowed to access objects in the bucket across regions in browsers by using JavaScript. For more information, see CORS.\nHigh requirements are imposed on data security and compliance in fields and scenarios such as finance, insurance, healthcare, securities, and log data. If you do not want anyone, including resource owners, to modify or delete objects in a bucket within a specific period of time, you can configure a retention policy for the bucket. After you configure a retention policy, users can only read the objects in or upload objects to the bucket until the retention period ends. You can modify or delete objects only after the retention period ends. For more information, see Retention policies.\nThe server-side encryption feature of OSS helps enhance the security of data storage and can be used in most data protection scenarios. After you configure server-side encryption for an OSS bucket, OSS automatically encrypts and persistently stores objects that are uploaded to the bucket. When you download an object, OSS automatically decrypts and returns the object. For more information, see Server-side encryption.\nThe client-side encryption feature of OSS helps enhance the security of data transmission and storage and is suitable for scenarios in which highly sensitive data exists. If you enable client-side encryption for a bucket, objects are locally encrypted before they are uploaded to OSS. Only the owner of the customer master key (CMK) can decrypt the objects. For more information, see Client-side encryption.\nTransport Layer Security (TLS) is a standard cryptographic protocol that can be used to ensure the privacy and integrity of data transmitted between clients and OSS. You can specify the TLS version used to access an OSS bucket. After you specify the TLS version for a bucket, clients can use only the specified TLS version to communicate with the bucket. This ensures the security of data transmission. For more information, see Configure the TLS version.\nWhen your OSS bucket is under attack or is used to distribute illegal content, OSS automatically moves the bucket to the sandbox. The buckets that are in the sandbox can still respond to requests, but service degradation may occur. In this case, network availability may be affected, and a request timeout error is returned. After OSS automatically moves a bucket to the sandbox, your application may be aware of the operation. For more information, see OSS sandbox.\nTo prevent business interruption caused by DDoS attacks, you can enable OSS DDoS protection for OSS buckets. After you enable OSS DDoS protection for a bucket, the system diverts incoming traffic to an Anti-DDoS Proxy instance for scrubbing and then redirects normal traffic to the bucket when the bucket suffers a DDoS attack. This ensures business continuity in the event of DDoS attacks. For more information, see OSS DDoS protection.\nHow do I access a private image object within a specific period of time?\nHow do I configure an HTTPS request and an SSL certificate?\nHow do I set the ACL of an object in a directory of a public-read bucket to private?\nWhy are anonymous users unable to access public-read objects?\nCan I recover an OSS object after the object is deleted or overwritten?\nWhat do I do if my data is lost?\nHow do I prevent unauthorized access to OSS?\nHow do I encrypt OSS resources across Alibaba Cloud accounts by using KMS?"
    },
    "160": {
        "title": "Object Storage Service:Acceleration management",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/accelerated-management-overview/",
        "content": "This Product\nObject Storage Service:Acceleration management\nYou can use the transfer acceleration feature, Alibaba Cloud CDN, or the OSS accelerator feature to accelerate access to Object Storage Service (OSS) resources. This topic describes the features, scenarios, and advantages and disadvantages of different acceleration solutions.\nAcceleration solution\nFeature\nScenario\nAdvantage\nDisadvantage\nTransfer acceleration\nOSS uses data centers that are distributed around the world to perform transfer acceleration. When a request to access your bucket is sent, the request is parsed and routed to the data center where the bucket is located over the optimal network path and protocol. The transfer acceleration feature provides an optimized end-to-end acceleration solution for access to OSS over the Internet.\nAccelerate remote data transfer\nAccelerate uploads and downloads of gigabyte-size and terabyte-size objects\nAccelerate the download of dynamic and non-hot data\nOSS buckets are distributed across the world.\nTransfer accelerationaccelerates the upload and download of long-distance and large objects.\nAll access requests are redirected to OSS, which consumes the bandwidth of OSS.\nWhen a large number of users in the same region access resources at the same time, the transfer accelerationperformance is not as good as that of Alibaba Cloud CDN acceleration.\nAlibaba Cloud CDN acceleration\nAlibaba Cloud CDN caches static data stored in OSS on points of presence (POPs) that are distributed around the world. When customers access OSS data, data is served from the POPs to accelerate access.\nAccelerate the download of static and hot data\nAccelerate on-demand audio and video streaming\nAccelerate the delivery of small files on websites and applications\n\nAlibaba Cloud CDN POPs are distributed across the world.\nAlibaba Cloud CDN POPs provide high bandwidth.\nThe cache hit ratio is high for resources that are frequently accessed and low for resources that are infrequently accessed. If resources are not cached on POPs, access to the resources is redirected to OSS by using back-to-origin links over the Internet.\nThe accelerationperformance is not as expected for dynamic requests, such as object upload and deletion.\nOSS accelerator\nThe OSS accelerator feature provides high-performance and high-throughput data access services by storing data on high-performance media.\nLow-latency data sharing\nBig data analysis\nSimulated training\nMulti-level acceleration\nThe OSS accelerator feature can effectively reduce data access latency.\nThe OSS accelerator feature ensures strong consistency between data and OSS. You do not need to worry about cache eviction.\nData writes cannot be accelerated. If the size of data to be written is too large, the acceleration performance of access to OSS resources is reduced.\nThe minimum cache capacity that an accelerator can provide is very large. You can use the OSS accelerator feature only in specific regions by submitting a ticket.\n"
    },
    "161": {
        "title": "Object Storage Service:Domain name management",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/manage-a-domain/",
        "content": "This Product\nObject Storage Service:Domain name management\nAccessing objects by using default domain names may lead to issues such as the failure to preview the content in a browser, or restrictions for downloading .apk files. To resolve these issues, you can map a custom domain name to your bucket for accessing objects stored within. To access resources over HTTPS, you need to purchase an SSL certificate and host the SSL certificate in Object Storage Service (OSS).\nDue to security restrictions, accessing objects by using default domain names may result in issues such as the failure to preview the content in a browser, or restrictions on downloading .apk and .ipa files. To resolve these issues, you can map a custom domain name (Example: example.com) to your bucket for accessing objects stored within. Accessing resources using registered domain names can prevent preview failures and bypass restrictions for downloading. Refer to the following guidelines for information about how to map OSS domain names of different types.\nMap a custom domain name to the default domain name of a bucket\nMap a custom domain to an OSS-accelerated domain\nIn contrast to OSS domain names that can be accessed over HTTP and HTTPS, custom domain names can only be accessed over HTTP by default. To use a custom domain name to access resources over HTTPS, you need to purchase an SSL certificate and host the SSL certificate in OSS. For more information, see Certificate hosting.\nFor information about frequently asked questions regarding how to map domain names, see FAQ."
    },
    "162": {
        "title": "Object Storage Service:Change the throttling thresholds of buckets, RAM users, or RAM roles by using resource pool QoS",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/oss-resource-pool-qos/",
        "content": "This Product\nObject Storage Service:Change the throttling thresholds of buckets, RAM users, or RAM roles by using resource pool QoS\nTo meet the demand for processing increasing volumes of data stored in Object Storage Service (OSS), Alibaba Cloud provides comprehensive data lake solutions that can handle throughput rates exceeding 10 terabits per second (Tbps). In daily operations, parallel execution of tasks, such as data collection, preprocessing, AI model training, and debugging, on the same platform can lead to uneven resource distribution and access bottlenecks. To resolve these issues, OSS introduced the resource pool Quality of Service (QoS) feature. You can use the feature to dynamically change the throttling thresholds of buckets and requesters, including the bandwidth and queries per second (QPS). This way, resources can be preferentially allocated to key services and compute-intensive resources during peak hours, and the stability of the business is ensured.\nWatch the following video for a quick introduction to resource pool QoS.\nChange the bandwidth threshold of buckets\nYou can change the bandwidth threshold of one or more buckets that are added to a resource pool.\nChange the bandwidth threshold of a requester\nThe resource pool QoS feature allows you to change the bandwidth threshold of a requester based on a bucket or resource pool.\nChange the thresholds of multiple configuration items\nYou can change the thresholds of total read throughput, total write throughput, internal network read throughput, internal network write throughput, external network read throughput, and external network write throughput.\nConfigure alerts for throttling events\nThe resource pool QoS feature allows you to configure alerts for throttling events. When the specified throttling threshold is reached, the system immediately sends a notification to the administrator. For more information, see Use CloudMonitor to monitor OSS throttling information in real time.\nMonitor throttling and performance\nYou can use CloudMonitor to obtain real-time information about the bandwidth setting and usage of a resource pool. For more information, see Use CloudMonitor.\nYou can create up to 100 resource pools for an Alibaba Cloud account.\nYou can add up to 100 buckets to a resource pool.\nYou can configure bandwidth thresholds for up to 300 RAM users in a resource pool.\nResource pool QoS is in invitational preview. If the throughput of your OSS buckets in a region has reached or exceeded 500 Gbps, you can contact technical support to apply for this feature.\nAfter you pass the application to use the resource pool QoS feature, you can use ossutil or call API operations to configure bandwidth thresholds in different dimensions. The configuration takes effect within 2 minutes.\nDimension\nossutil\nConfigure the bandwidth threshold of a bucket\nput-bucket-qos-info\nConfigure throttling thresholds for requesters for buckets\nput-bucket-requester-qos-info\nConfigure throttling thresholds for requesters for resource pools\nput-resource-pool-requester-qos-info\nResource pool QoS configuration examples\n"
    },
    "163": {
        "title": "Object Storage Service:Data management",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/data-management/",
        "content": "This Product\nObject Storage Service:Data management\nObject Storage Service (OSS) provides various data management features to help you efficiently manage data stored in OSS and ensure data availability and cost-effectiveness.\nCRRCross-region replication (CRR) allows the automatic and asynchronous (near real-time) replication of OSS objects from a bucket in a region to another bucket in another region. CRR is suitable for scenarios in which data consistency needs to be maintained across regions, such as multi-data center deployment or disaster recovery. By configuring CRR rules, you can implement near-real-time data synchronization to ensure the high availability and consistency of data.\nScheduled backupScheduled backup can back up objects in a specific bucket every day and retain the backup records of the previous week. Scheduled backup is suitable for scenarios in which you want to back up important data periodically and restore objects that are corrupted or lost. This ensures business continuity. You can modify the backup plan based on your business requirements to meet different backup policies.\nStorage redundancy\nOSS provides locally redundant storage (LRS) and zone-redundant storage (ZRS) to ensure data durability and availability. LRS provides data redundancy within one zone, and ZRS provides data redundancy across zones. LRS and ZRS are suitable for regions in which you have high requirements on data reliability. This prevents data loss due to single points of failure (SPOF). LRS stores multiple copies of your data on multiple devices of different facilities in the same zone. ZRS stores multiple copies of your data across multiple zones in the same region.\nYou can create lifecycle rules for a bucket based on the last modified time or last access time of the objects in the bucket. The lifecycle rules based on the last modified time or last access time of the objects can periodically move objects to a specific storage class or periodically delete expired objects and parts for cost optimization.\nReal-time access of Archive objectsOSS provides real-time access of Archive objects that allows you to access rarely accessed data in real time. Unlike the Archive storage class which requires you to restore objects before you can access the objects, real-time access of Archive objects allows you to directly read Archive objects in real-time and reduce storage costs.\nBucket inventoryYou can use the bucket inventory feature to export information about specific objects in a bucket, such as the number, size, storage class, and encryption status of the objects. To list a large number of objects, we recommend that you use the bucket inventory feature instead of calling the GetBucket (ListObjects) operation.\nStatic website hostingStatic websites are websites in which all web pages consist of only static content, including scripts such as JavaScript code that can be run on a client. You can use the static website hosting feature to host your static website on an OSS bucket and use the domain name of the bucket to access the website.\nBack-to-origin configurations\nIf a requester accesses data in your bucket but the data does not exist in your bucket, 404 Not Found is returned. If you configure back-to-origin rules that contain a valid origin for the bucket, the requester can obtain the data based on the rules. You can configure mirroring-based or redirection-based back-to-origin rules for hot migration and specific request redirection.\nData replication\nScheduled Backup\nLifecycle\nBucket inventory\nStatic website hosting\nBack-to-origin\nStorage redundancy\nReal-time access of Archive objects"
    },
    "164": {
        "title": "Object Storage Service:Search for objects based on metadata and semantic content",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/data-indexing-overview/",
        "content": "This Product\nObject Storage Service:Search for objects based on metadata and semantic content\nYou can create a data index and use the metadata and semantic content of objects as index conditions to quickly search for images, videos, documents, and audio files in Object Storage Service (OSS).\nEase of use: You can use the data indexes created by using OSS without the need to migrate data or build a search system.\nMultimodal search: Multiple types of data indexes, including object metadata, media metadata, custom metadata, and semantic content, are supported. Approximately 100 index conditions are provided.\nHigh-performance search: You can index and aggregate data within seconds and build an index library that supports up to tens of billions of objects to meet large-scale data processing requirements.\nOSS supports MetaSearch and AISearch. The following table describes the preceding data indexing methods.\nItem\nMetaSearch\nAISearch\nDescription\nSearch for specific objects based on metadata attributes, such as object metadata, ETags, and tags.\nSearch for specific objects based on the information about documents, images, videos, and audio files. You can specify semantic content as index conditions, and OSS compares the semantic content with objects in OSS.\nScenario\nObject query and statistics\nMultimodal search and complex object search\nSample index condition\nSearch for Standard objects whose access control list (ACL) is private and which are uploaded on September 14, 2024\n\nSearch for images related to the semantic content \"apple\"\n\nSample result\nReturn Standard objects whose ACL is private and which are uploaded on September 14, 2024\n\nReturn images related to the semantic content \"apple\"\n\nYou can select a suitable data indexing method based on search conditions. The following table describes the search conditions supported by MetaSearch and AISearch.\nSearch condition\nMetaSearch\nAISearch\nOSS metadata\n\u2705\n\u2705\nObject tags and ETags\n\u2705\n\u2705\nUser metadata\n\u274c\n\u2705\nMultimedia metadata\n\u274c\n\u2705\nSemantic content\n\u274c\n\u2705\nFor more information about the fields and operators supported by MetaSearch, see Appendix: Fields and operators supported in scalar search.\nFor more information about the fields and operators supported by AISearch, see Appendix: Fields and operators supported by AISearch.\nThe following figures show how MetaSearch and AISearch work.\nThe following figure shows how to use MetaSearch to search for objects based on metadata attributes.\nYou upload files, such as images, videos, documents, and audio files, from an application to an OSS bucket.\nYou use a RAM user that has the permissions to manage OSS to enable data indexing for the bucket and select MetaSearch.\nOSS uses the default index table structure to automatically create data indexes that contain OSS metadata, object ETags, and object tags.\nThe application calls the DoMetaQuery operation to search for objects based on metadata attributes.\nOSS returns the objects that meet the search conditions.\nThe following figure shows to use AISearch to search for objects based on metadata attributes and semantic content.\nYou upload files, such as images, videos, documents, and audio files, from an application to an OSS bucket.\nYou use a RAM user that has the permissions to manage OSS to enable data indexing for the bucket and select AISearch.\nOSS uses the default index table structure and Embedding model to automatically create data indexes that contain OSS metadata, object ETags, object tags, user metadata, multimedia metadata, and semantic content.\nThe application calls the DoMetaQuery operation to search for objects based on metadata attributes and semantic content.\nOSS returns the objects that meet the search conditions.\nFor more information about how to use MetaSearch and AISearch to search for objects, see the following topics:\nUse MetaSearch to search for OSS objects based on metadata attributes\nUse AISearch to quickly search for objects based on semantic content and multimedia metadata"
    },
    "165": {
        "title": "Object Storage Service:Overview of data processing",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/overview-50/",
        "content": "This Product\nObject Storage Service:Overview of data processing\nObject Storage Service (OSS) provides professional data processing capabilities by developing and integrating other services.\nData processing supports the following features.\nFeature\nDescription\nReferences\nIMG\nYou can use image processing (IMG) to resize images, crop images, and configure image styles.\nIMG\nVideo snapshots\nOSS captures images from video objects in the H.264 and H.265 formats.\nVideo snapshots\nZIP package decompression\nYou can configure rules for a bucket to automatically decompress ZIP packages uploaded to the bucket. After you configure decompression rules for a bucket, all ZIP packages uploaded to the path specified in the rules are automatically decompressed.\nZIP package decompression\nEvent notifications\nYou can configure event notification rules for objects that you want to monitor in the OSS console. If the events that are specified in the rules occur on these objects, you can be immediately notified.\nUse event notifications to monitor object changes in real time\nConcepts\nIMG\nVideo snapshots\nZIP package decompression\nEvent notifications\n"
    },
    "166": {
        "title": "Object Storage Service:Data lake management",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/dla/",
        "content": "This Product\nObject Storage Service:Data lake management\nData lake management provided by Object Storage Service (OSS) is designed to help you efficiently build and manage data lakes to meet the requirements of massive data storage, analysis, and migration. Data lake management, with OSS-HDFS as its core and combined with the OSS accelerator feature, allows you to seamlessly integrate the big data ecosystem. Data lake management is compatible with Hadoop Distributed File System (HDFS) API, supports hierarchical namespace, and optimizes data management in real-time computing scenarios, which significantly improves data analysis performance, reduces storage costs, and simplifies the complexity of migrating data from HDFS to the cloud.\nOSS-HDFS (JindoFS) is a cloud-native data lake storage feature. OSS-HDFS provides centralized metadata management capabilities and is fully compatible with HDFS API. You can use OSS-HDFS to manage data in data lake-based computing scenarios in the big data and AI fields.\nBy integrating with various ecosystem tools, such as Hadoop, Hive, Presto, and Spark provided by open source ecosystem, and MaxCompute and Simple Log Service (SLS) provided by Alibaba Cloud ecosystem, OSS-HDFS supports full lifecycle management that covers data storage and analysis without the need for additional development.\nOffline data warehousing: OSS-HDFS supports operations on files and directories.\nOnline analytical processing (OLAP): OSS-HDFS supports basic file-related operations, such as append, truncate, and flush, which meets the requirements of decoupling storage from computing.\nDecoupling of storage from computing for HBase: OSS-HDFS supports operations on files and directories and flush operations. You can use OSS-HDFS instead of HDFS to decouple storage from computing for HBase.\nReal-time computing: OSS-HDFS supports flush operations and truncate operations. You can use OSS-HDFS instead of HDFS to store sinks and checkpoints in real-time computing scenarios of Apache Flink.\nData migration: As a novel cloud-native data lake storage service, OSS-HDFS allows HDFS to migrate data to Alibaba Cloud and improves the experience of HDFS users. This way, OSS-HDFS provides storage services that are scalable and cost-effective.\nCompatibility: You can configure OSS-HDFS with ease to access and manage data in the same manner in which you access and manage data in HDFS without the need to change existing Hadoop applications.\nAutomatic scaling: You can take advantage of OSS characteristics, such as unlimited storage capacity, elastic scalability, high security, reliability, and availability.\nHierarchical namespace: You can use the hierarchical namespace feature to manage objects in the hierarchical directory structure. OSS-HDFS automatically converts the storage structure between the flat namespace and the hierarchical namespace to help you manage object metadata in a centralized manner.\nHigh performance. You can use OSS-HDFS to analyze exabytes of data, manage hundreds of millions of objects, and obtain terabytes of throughput.\nFor business scenarios that require low latency and high throughput, such as AI, data warehousing, and big data analytics, accelerators cache hotspot files on high-performance Non-Volatile Memory Express (NVMe) SSDs to reduce data write latency and improve throughput. This significantly optimizes the performance of Realtime Compute jobs and helps you quickly deploy stable stream processing pipelines in the cloud.\nLow-latency data sharing: The OSS accelerator feature is suitable for scenarios in which you want to quickly access uploaded data, such as uploading and analyzing the images of mobile applications.\nModel inference: The OSS accelerator feature is suitable for scenarios in which you want to quickly load and switch the model objects to improve inference efficiency.\nBig data analysis: The OSS accelerator feature is suitable for scenarios in which you want to query data from a large amount of data and the query range is uncertain. This reduces query latency.\nMulti-level acceleration: The OSS accelerator feature can work with client-side caching to achieve multi-level acceleration and improve data access efficiency.\nLow latency: The NVMe SSD media of an accelerator can provide millisecond-level download latency for business. The accelerator provides better performance for hot data query in data warehouses and inference model download.\nHigh throughput: The bandwidth of an accelerator increases linearly together with the cache capacity of the accelerator and provides burst throughput of up to hundreds of Gbit/s, which meets the requirements for fast reading of large amounts of data.\nAutomatic scaling: The accelerator supports at least 50 GB of cache capacity and up to 100 TB of cache capacity. You can scale up or scale down the cache capacity of an accelerator online based on your business requirements. This helps reduce costs.\nData consistency: The OSS accelerator feature ensures that you can read the latest versions of the objects.\nMultiple warmup policies: The accelerator provides the warmup during read, synchronous warmup, and asynchronous warmup policies to ensure that the engine can read the latest data.\nConnect OSS to data lake ecosystems\nOSS-HDFS\nOSS accelerator\n"
    },
    "167": {
        "title": "Object Storage Service:What is OSS on CloudBox?",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/introduction-of-oss-deployed-in-cloudbox/",
        "content": "This Product\nObject Storage Service:What is OSS on CloudBox?\nObject Storage Service (OSS) on CloudBox provides local storage, local access, and local data processing of unstructured data for CloudBox. You can create a bucket in OSS on CloudBox and use the same OSS API operations and OSS SDKs as Alibaba Cloud public cloud to access data in OSS on CloudBox.\nCloudBox is a fully managed cloud service provided by Alibaba Cloud. The hardware and software of Alibaba Cloud public cloud are integrated into your data center to meet specific requirements, such as data security, local data processing, and low latency. You can have the same user experience that you have on the public cloud in your data center. You can use CloudBox out of the box. This helps you better focus on business logic and reduce the O&M workloads on hardware and the cloud platform. For more information about CloudBox, see What is CloudBox?\nCompared with Alibaba Cloud public cloud, CloudBox provides advantages, such as data security, local data processing, and low latency.\nData security: Data is stored in data centers under your control, which meets the regulatory requirements for locally storing data.\nLocal data processing: You do not need to upload data to Alibaba Cloud public cloud, which reduces the cost of uploading large amounts of data to Alibaba Cloud public cloud.\nLow latency: Your cloud box is geographically close to your local devices and can interact with local devices and applications in near real time.\nExclusive resources: You do not need to share storage with other customers in the Alibaba Cloud public cloud. In this case, you can store sensitive data with ease.\nFor more information about the billing methods, scale up rules, and billing cases of OSS on CloudBox, see OSS resources.\nEach Alibaba Cloud account can create up to 100 region-specific buckets in OSS on CloudBox.\nYou can set the storage class of OSS on CloudBox buckets and objects in OSS on CloudBox buckets only to Standard.\nThe server-side encryption method of OSS on CloudBox can only be SSE-OSS. SSE-KMS is not supported.\nOSS on CloudBox can only be accessed by using internal endpoints. Public endpoints are not supported. If you want to transfer OSS data between CloudBox and Alibaba Cloud public cloud, establish a network connection between CloudBox and Alibaba Cloud public cloud, and use ossimport to transfer data.\nYou can use a CloudBox VPC to access an OSS on CloudBox bucket. Access endpoints are divided into control endpoints and data endpoints.\nControl endpoints\nControl endpoints are used only for operations on OSS on CloudBox buckets. For more information about the API operations supported by control endpoints, see API operations supported by control endpoints.\nControl endpoints are in the following format: <Cloudbox-Id>.<Region>.oss-cloudbox-control.aliyuncs.com. Example: cb-f8z7yvzgwfkl9q0h****.cn-shenzhen.oss-cloudbox-control.aliyuncs.com.\nData endpoints\nData endpoints can be used to perform operations on OSS on CloudBox buckets and data in OSS on CloudBox buckets. For more information about the API operations supported by data endpoints, see API operations supported by data endpoints.\nData endpoints are in the following format: <Cloudbox-Id>.<Region>.oss-cloudbox.aliyuncs.com. Example: cb-f8z7yvzgwfkl9q0h****.cn-shenzhen.oss-cloudbox.aliyuncs.com.\nIf you create a VPC in CloudBox and need to use OSS in the VPC environment, contact technical support to enable the endpoints.\nThe following table describes the bucket-level API operations supported by OSS on CloudBox control endpoints.\nCategory\nAPI\nDescription\nBasic operations\nPutBucket\nCreates an OSS on CloudBox bucket.\nDeleteBucket\nDeletes an OSS on CloudBox bucket.\nGetBucketInfo\nQueries information about an OSS on CloudBox bucket.\nGetBucketLocation\nQueries the region in which an OSS on CloudBox bucket is located.\nACL\nPutBucketAcl\nSpecifies the access control list (ACL) of an OSS on CloudBox bucket.\nGetBucketAcl\nQueries the ACL of an OSS on CloudBox bucket.\nLifecycle\nPutBucketLifecycle\nConfigures lifecycle rules for an OSS on CloudBox bucket.\nGetBucketLifecycle\nQueries the lifecycle rules of an OSS on CloudBox bucket.\nDeleteBucketLifecycle\nDeletes the lifecycle rules of an OSS on CloudBox bucket.\nVersioning\nPutBucketVersioning\nSpecifies the versioning status of an OSS on CloudBox bucket.\nGetBucketVersioning\nQueries the versioning status of an OSS on CloudBox bucket.\nBucket policy\nPutBucketPolicy\nConfigures a bucket policy for an OSS on CloudBox bucket.\nGetBucketPolicy\nQueries the bucket policies of an OSS on CloudBox bucket.\nDeleteBucketPolicy\nDeletes a bucket policy of an OSS on CloudBox bucket.\nLogging\nPutBucketLogging\nEnables logging for an OSS on CloudBox bucket.\nGetBucketLogging\nQueries the logging configurations of an OSS on CloudBox bucket.\nDeleteBucketLogging\nDisables logging for an OSS on CloudBox bucket.\nStatic website hosting\nPutBucketWebsite\nEnables static website hosting for an OSS on CloudBox bucket.\nGetBucketWebsite\nQueries the static website hosting configurations of an OSS on CloudBox bucket.\nDeleteBucketWebsite\nDisables static website hosting for an OSS on CloudBox bucket.\nHotlink protection\nPutBucketReferer\nConfigures hotlink protection for an OSS on CloudBox bucket.\nGetBucketReferer\nQueries the hotlink protection configurations of an OSS on CloudBox bucket.\nEncryption\nPutBucketEncryption\nConfigures encryption rules for an OSS on CloudBox bucket.\nGetBucketEncryption\nQueries the encryption rules of an OSS on CloudBox bucket.\nDeleteBucketEncryption\nDeletes the encryption rules of an OSS on CloudBox bucket.\nThe following tables describe the API operations supported by the data endpoints of OSS on CloudBox.\nAPI\nDescription\nListBuckets (GetService)\nLists all buckets that are owned by the requester.\nCategory\nAPI\nDescription\nBasic operations\nPutBucket\nCreates an OSS on CloudBox bucket.\nDeleteBucket\nDeletes an OSS on CloudBox bucket.\nGetBucket (ListObjects)\nQueries information about all objects in an OSS on CloudBox bucket.\nListObjectsV2 (GetBucketV2)\nQueries information about all objects in an OSS on CloudBox bucket.\nGetBucketInfo\nQueries information about an OSS on CloudBox bucket.\nGetBucketLocation\nQueries the region in which an OSS on CloudBox bucket is located.\nACL\nPutBucketAcl\nSpecifies the ACL of an OSS on CloudBox bucket.\nGetBucketAcl\nQueries the ACL of an OSS on CloudBox bucket.\nLifecycle\nPutBucketLifecycle\nConfigures lifecycle rules for an OSS on CloudBox bucket.\nGetBucketLifecycle\nQueries the lifecycle rules of an OSS on CloudBox bucket.\nDeleteBucketLifecycle\nDeletes the lifecycle rules of an OSS on CloudBox bucket.\nVersioning\nPutBucketVersioning\nSpecifies the versioning status of an OSS on CloudBox bucket.\nGetBucketVersioning\nQueries the versioning status of an OSS on CloudBox bucket.\nListObjectVersions (GetBucketVersions)\nLists the versions of all objects in an OSS on CloudBox bucket.\nBucket policy\nPutBucketPolicy\nConfigures a bucket policy for an OSS on CloudBox bucket.\nGetBucketPolicy\nQueries the bucket policies of an OSS on CloudBox bucket.\nDeleteBucketPolicy\nDeletes a bucket policy of an OSS on CloudBox bucket.\nLogging\nPutBucketLogging\nEnables logging for an OSS on CloudBox bucket.\nGetBucketLogging\nQueries the logging configurations of an OSS on CloudBox bucket.\nDeleteBucketLogging\nDisables logging for an OSS on CloudBox bucket.\nStatic website hosting\nPutBucketWebsite\nEnables static website hosting for an OSS on CloudBox bucket.\nGetBucketWebsite\nQueries the static website hosting configurations of an OSS on CloudBox bucket.\nDeleteBucketWebsite\nDisables static website hosting for an OSS on CloudBox bucket.\nHotlink protection\nPutBucketReferer\nConfigures hotlink protection for an OSS on CloudBox bucket.\nGetBucketReferer\nQueries the hotlink protection configurations of an OSS on CloudBox bucket.\nEncryption\nPutBucketEncryption\nConfigures encryption rules for an OSS on CloudBox bucket.\nGetBucketEncryption\nQueries the encryption rules of an OSS on CloudBox bucket.\nDeleteBucketEncryption\nDeletes the encryption rules of an OSS on CloudBox bucket.\nCategory\nAPi\nDescription\nBasic operations\nPutObject\nUploads an object.\nGetObject\nQueries an object.\nCopyObject\nCopies an object.\nAppendObject\nUploads an object by using append upload.\nDeleteObject\nDeletes an object.\nDeleteMultipleObjects\nDeletes multiple objects at a time.\nHeadObject\nQueries only the metadata of an object.\nGetObjectMeta\nQueries only the basic metadata of an object, including the ETag, size, and last modified time.\nMultipart upload\nInitiateMultipartUpload\nInitiates a multipart upload task.\nUploadPart\nUploads an object by part based on a specific object name and upload ID.\nUploadPartCopy\nCopies data from an existing object to upload a part by adding the x-oss-copy-source request header to an UploadPart request.\nCompleteMultipartUpload\nCompletes the multipart upload task of an object.\nAbortMultipartUpload\nCancels a multipart upload task and deletes the uploaded parts.\nListMultipartUploads\nLists all ongoing multipart upload tasks, which include tasks that are initiated but are not completed or canceled.\nListParts\nLists all parts uploaded by a multipart upload task that has a specific upload ID.\nACL\nPutObjectACL\nModifies the ACL of an object.\nGetObjectACL\nQueries the ACL of an object.\nSymbolic link\nPutSymlink\nCreates a symbolic link.\nGetSymlink\nQueries a symbolic link.\nTagging\nPutObjectTagging\nAdds tags to or modifies the tags of an object.\nGetObjectTagging\nQueries the tags of an object.\nDeleteObjectTagging\nDeletes the tags of an object.\nGet started with OSS on CloudBox\nBucket operations supported by OSS on CloudBox\nObject operations supported by OSS on CloudBox"
    },
    "168": {
        "title": "Object Storage Service:Overview page of the OSS console",
        "url": "https://www.alibabacloud.com/help/en/oss/user-guide/overview-of-the-oss-console/",
        "content": "This Product\nObject Storage Service:Overview page of the OSS console\nThe Object Storage Service (OSS) console is a web-based platform that allows you to easily manage your OSS resources. You can view the general information about all your buckets on the Overview page of the console, such as the quantity, storage usage, and amount of consumed traffic of your buckets, and number of API requests sent to the buckets.\nIf you use OSS for the first time, we recommend that you click Quick Start in the upper-right corner of the Overview page in the OSS console to gain the basic knowledge of OSS.\nYou can use one of the following methods to query the resource usage of all buckets owned by the current Alibaba Cloud account, including the storage and amount of traffic used by the buckets and the number of API requests sent to the buckets.\nQuery the current storage usage of all buckets\nYou can query the storage usage of all buckets in the Basic Data section, including the storage usage of Standard, Infrequent Access (IA), Archive, Cold Archive, and Deep Cold Archive data and Elastic Compute Service (ECS) snapshots.\nIA, Archive, Cold Archive, and Deep Cold Archive storage classes have a minimum billable size of 64 KB for each object. You are charged for the minimum billable size for an object that is smaller than 64 KB. If the size of an object is greater than or equal to 64 KB, you are charged for the actual object size. When a bucket contains multiple IA, Archive, Cold Archive, or Deep Cold Archive objects that are smaller than 64 KB in size, the billed storage usage is greater than the actual storage usage in the bucket. For more information about storage classes, see Overview.\nQuery the amount of traffic consumed by all buckets in the current month\nYou can query the amount of traffic for all buckets in the current month in the Basic Data section, including inbound and outbound traffic over the Internet and origin traffic. For more information about traffic types and billing methods, see Traffic fees.\nQuery the number of API requests sent to all buckets in the current month\nIn the Basic Data section, you can query the number of API requests sent to all buckets in the account in the current month, including read and write requests. For more information about the API operations used to send read and write requests, see Put requests and Get requests described in View the resource usage of a bucket.\nQuery the storage usage of all buckets within a specific period\nIn the Storage Class section, you can query storage usage statistics for each storage class from the line chart. You can query statistics within a time range of up to 65 days. For example, if you set the end of the time range to December 31, 2023, the earliest start time that you can specify in the query is October 27, 2023.\nQuery the amount of traffic consumed by all buckets within a specific period\nIn the Traffic Usage section, you can query traffic statistics within a given period from the line chart. You can query statistics within a time range of up to 65 days. For example, if you set the end of the time range to December 31, 2023, the earliest start time that you can specify in the query is October 27, 2023.\nYou can query the number of buckets owned by your Alibaba Cloud account by region or storage class in the Bucket Management section in the upper-right corner of the Overview page.\nTo query the number and percentage of buckets in different regions, click Sort by Region.\nTo query the number and percentage of buckets of different storage classes, click Sort by Storage Class.\nTo export the information about buckets such as names, regions, storage classes, and creation times to a local CSV file, click Export CSV.\nIn the Common Tools section, you can learn about and download common OSS tools, such as ossbrowser, which is a graphical tool that supports Windows, Linux, and macOS, and ossutil, which is a command-line tool for managing objects and buckets. For more information, see OSS tools.\nYou can configure alert rules in the Alert Rules section on the right side of the Overview page to monitor the specified metrics. When an alert rule is triggered, OSS immediately notifies you. For more information, see Use the alert service.\nYou can check resource plans that are in effect, about to expire, or about to be exhausted in the Resource Plan section on the right side of the Overview page. You can also click Purchase to buy a resource plan or click Manage to manage existing resource plans. For more information, see Resource plans.\nUse Alibaba Cloud accounts to log on to the OSS console\nUse the credentials of a RAM user to log on to the OSS console\nBucket overview\nOSS access paths\n"
    },
    "169": {
        "title": "Object Storage Service:Integration overview",
        "url": "https://www.alibabacloud.com/help/en/oss/developer-reference/integration-overview",
        "content": "This Product\nObject Storage Service:Integration overview\nYou can programmatically integrate capabilities of Object Storage Service (OSS) into your applications and automate bucket management for streamlined operations and lower management costs. This topic describes methods that you can use to integrate OSS.\nYou can choose an integration method that best fits your practical requirements to integrate OSS.\nWe recommend that you use OSS SDKs to integrate OSS. OSS SDKs are available for many programming languages, such as Java, C#, Go, Python, TypeScript, PHP, and C++. OSS SDKs encapsulate the signing logic, timeout mechanisms, and retry mechanisms. A call to an OSS SDK returns a structured Response object. Integrating OSS SDKs facilitates your application development. For more information about OSS SDKs, see OSS SDKs.\nOSS is also compatible with Alibaba Cloud SDKs. For more information, see Alibaba Cloud SDKs.\nIf you want to manage data in OSS by using a CLI tool, we recommend that you use ossutil. ossutil supports Windows, Linux, and macOS. For more information, see Overview.\nYou can also use Alibaba Cloud CLI to manage data in OSS by specifying the aliyun command in the terminal. For more information, see What is Alibaba Cloud CLI?\nOSS provides various management tools that can be used to streamline OSS operations, such as uploads of large objects, signature generation, data migration, and bucket mounting. In addition, third-party tools and plug-ins available in the communities can help provide more enhancements and ease of use. For more information about common OSS tools, see OSS tools.\nResource Orchestration Service (ROS) is an Alibaba Cloud service that simplifies the management of cloud computing resources. You can create templates to define the required Alibaba Cloud resources such as Elastic Compute Service (ECS) and ApsaraDB RDS instances, as well as the dependencies between the resources. ROS automatically creates and configures all resources based on the template to implement automated deployment and O&M. For more information, see What is ROS?.\nYou can use OSS together with ROS to create applications. For more information, see Create an NGINX application by using OSS and ROS and Create a SharePoint 2013 application by using OSS and ROS.\nTerraform is an open-source automated resource orchestration tool that you can use to programmatically manage IT resources. Terraform CLI allows you to easily deploy configuration files to Alibaba Cloud and other supported clouds and implement version control of configuration files.\nFor more information, see Overview and Use Terraform to manage OSS.\nIf none of the preceding methods suits your business requirements, you can encapsulate the API in your code and initiate RESTful API requests to manage data in OSS. However, this is not the recommended method. For more information, see Overview.\nIf your access experiences an error, OSS returns information such as the error code, error message, and request ID to help you troubleshoot the error. For more information, see Overview."
    },
    "170": {
        "title": "Object Storage Service:Developer Guide",
        "url": "https://www.alibabacloud.com/help/en/oss/developer-reference/developer-guide/",
        "content": "This Product\nObject Storage Service:Developer Guide"
    },
    "171": {
        "title": "Object Storage Service:SDK Reference",
        "url": "https://www.alibabacloud.com/help/en/oss/developer-reference/sdk-code-samples/",
        "content": "This Product\nObject Storage Service:SDK Reference"
    },
    "172": {
        "title": "Object Storage Service:Common Tools",
        "url": "https://www.alibabacloud.com/help/en/oss/developer-reference/common-tools/",
        "content": "This Product\nObject Storage Service:Common Tools"
    },
    "173": {
        "title": "Object Storage Service:Terraform",
        "url": "https://www.alibabacloud.com/help/en/oss/developer-reference/terraform-overview/",
        "content": "This Product\nObject Storage Service:Terraform\nTerraform is an open source automatic resource orchestration tool that supports multiple cloud service providers. Alibaba Cloud is the third largest cloud service provider. The Alibaba Cloud provider supports at least 90 resources and data sources across more than 20 services and products. An increasing number of developers contribute to the Alibaba Cloud Terraform ecosystem. For more information, visit terraform-alicloud-provider.\nHashiCorp Terraform is an automatic IT infrastructure orchestration tool that can use code to manage and maintain IT resources. The easy-to-use command line interface (CLI) of Terraform allows you to deploy configuration files on Alibaba Cloud or any other supported cloud and control the versions of the configuration files. The CLI provides code for infrastructure resources such as VMs, storage accounts, and network interfaces defined in the configuration files that describe the cloud resource topology. Terraform is a highly scalable tool that supports new infrastructures from providers. You can use Terraform to create, modify, or delete cloud resources, such as OSS objects, ECS instances, VPCs, ApsaraDB RDS instances, and SLB instances.\nOSS Terraform module provides bucket and object management features. Example:\nBucket management features:\nCreate a bucket.\nConfigure an ACL for a bucket.\nConfigure Cross-Origin Resource Sharing (CORS) for a bucket.\nConfigure logging for a bucket.\nConfigure static website hosting for a bucket.\nConfigure hotlink protection for a bucket.\nConfigure the lifecycle rules of a bucket.\nObject management features:\nUpload an object.\nConfigure server-end encryption for an object.\nConfigure an ACL for an object.\nConfigure object metadata.\nFor more information about how to install and use Terraform, see Create a bucket by using Terraform.\nFor more information about the download address of the OSS Terraform module, visit terraform-alicloud-modules.\nFor more information about the OSS Terraform module, visit alicloud_oss_bucket."
    },
    "174": {
        "title": "Object Storage Service:ROS",
        "url": "https://www.alibabacloud.com/help/en/oss/developer-reference/ros/",
        "content": "This Product\nObject Storage Service:ROS\nAlibaba Cloud Resource Orchestration Service (ROS) and Object Storage Service (OSS) provide powerful automated deployment and O&M capabilities to help you quickly create and configure complex cloud resources.\nYou can create an NGINX application by using OSS and ROS. The ROS engine automatically creates and configures all resources in a stack based on a template to implement automated deployment and O&M. The NGINX application is suitable for scenarios in which you need to quickly build a high-performance web server environment, such as website hosting, reverse proxy, and Server Load Balancer (SLB).\nYou can create a SharePoint 2013 application by using Object Storage Service (OSS) and ROS. ROS automatically creates and configures the required resources based on the template, which enables rapid deployment of the SharePoint 2013 application. The SharePoint 2013 application integrates with the features of Office suites and is suitable for content management, collaboration, and document sharing within the enterprise.\nFor more information about how to create an NGINX application by using OSS and ROS, see Create an NGINX application by using OSS and ROS.\nFor more information about how to create Sharepoint 2013 by using OSS and ROS, see Create a SharePoint 2013 application by using OSS and ROS."
    },
    "175": {
        "title": "Object Storage Service:Overview of OSS best practices",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/practice-tutorial-overview",
        "content": "This Product\nObject Storage Service:Overview of OSS best practices\nAlibaba Cloud Object Storage Service (OSS) provides best practices on direct data transfer from clients to OSS, using ECS instances to configure a reverse proxy for access to OSS, data verification, data lakes, content delivery and data processing, data analysis, data backup and recovery, data migration, data monitoring, using OSS in third-party applications, and OSS security, performance, and cost optimization. This way, you can use OSS in a more efficient manner to meet your business requirements.\nCategory\nReference\nDirect data transfer from clients to OSS\nDirect client uploads\nUpload objects to OSS from web applications\nSet up direct data transfer for mobile applications\nUse ECS instances to configure a reverse proxy for access to OSS\nUse an ECS instance that runs Ubuntu to configure a reverse proxy for access to OSS\nUse an ECS instance that runs CentOS to configure a reverse proxy for access to OSS\nUse an ECS instance that runs Windows to configure a reverse proxy for access to OSS\nData verification\nCan I use ETag values as OSS MD5 hashes to check data consistency?\nCheck data integrity by using CRC-64\nData lakes\nOpen source ecosystem\nAlibaba Cloud ecosystem\nContent delivery and data processing\nCreate HLS streams based on OSS\nUse Function Compute to download multiple objects as a package\nData analysis\nAnalyze intermediaries based on custom log fields\nData backup and recovery\nBack up buckets\nData migration\nMigrate data to OSS\nData monitoring\nUse CloudMonitor to monitor OSS throttling information in real time\nUse OSS in third-party applications\nUse OSS in third-party applications\nOSS security optimization\nReduce the risks of unauthorized access caused by AccessKey pair leaks\nReduce the risks of unexpectedly high fees caused by malicious access traffic\nReduce the risks of data loss caused by accidental operations\nSensitive data protection\nOSS performance optimization\nOSS performance best practices\nOSS cost optimization\nHow do I reduce my OSS costs?"
    },
    "176": {
        "title": "Object Storage Service:Upload objects directly to OSS from clients",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/uploading-objects-to-oss-directly-from-clients/",
        "content": "This Product\nObject Storage Service:Upload objects directly to OSS from clients\nA direct client upload allows you to upload data directly to Object Storage Service (OSS) from clients. The direct client upload solution accelerates uploads and reduces the resource usage of the application server by eliminating the need to transfer objects to and from the application server. This topic describes the benefits, implementation methods, and best practices of this solution.\nIn the traditional server and client architecture, uploading data to OSS from the application server is the common upload method. The client uploads objects to the application server, and then the application server uploads the objects to OSS. During the upload process, data must be transferred twice over the network. This results in a waste of network resources and an increase in the resource usage of the application server. To resolve this issue, you can upload objects directly to OSS without the need to upload the objects to the application server.\nTo upload data directly to OSS from clients, you must resolve the following issues:\nIf your client is a web client or mini program, you must allow cross-origin resource sharing (CORS). In most cases, browsers and mini programs prohibit CORS to ensure data security. This prevents your client code from being used to connect to OSS. You can configure CORS rules to allow web applications or mini programs on a specific domain name to access OSS. For more information, see CORS.\nTo upload an object to OSS, you need to use the AccessKey pair of a RAM user to complete signing for authentication. However, if the client uses a permanent AccessKey pair, AccessKey pair leaks may occur, which causes data security risks. To resolve this issue, you can use one of the following solutions to implement secure upload:\nObtain temporary access credentials from STS on the application server\nIn most object upload scenarios, we recommend that you use Security Token Service (STS) SDKs to obtain temporary access credentials on the application server, and then use the temporary access credentials and OSS SDKs to upload objects from the client directly to OSS. The client can reuse the temporary access credentials on the application server to generate a signature. This is suitable for scenarios in which multipart upload and resumable upload are used to upload large objects. However, frequent calls to STS may cause throttling. In this case, we recommend that you cache the temporary access credentials and renew them before they expire. To further prevent abuses of temporary access credentials on the client, we recommend that you configure additional policies to restrict the use of the temporary access credentials. For more information, see What is STS?\nObtain a signature and POST policy for PostObject from the application server\nIn scenarios in which you want to limit the attributes of an object to upload, you need to obtain information required to call the PostObject operation from the application server. The required information includes a signature and a POST policy. Then, the client can use the obtained information to upload the object directly to OSS without using OSS SDKs. You can use the policy generated by the application server to limit the attributes of the object, such as the object size and type. This solution is suitable for scenarios in which you want to upload objects by using HTML forms. This solution does not support multipart upload and resumable upload. For more information, see PostObject.\nObtain a signed URL for PutObject from the application server\nFor simple object upload scenarios, you can use OSS SDKs on the application server to obtain a signed URL that is required to call the PutObject operation. Then, the client can use the signed URL to upload an object without using OSS SDKs. This solution is not suitable for multipart upload and resumable upload. The application server generates a signed URL for each part and returns the signed URL to the client. This increases the number of interactions with the application server and the complexity of network requests. In addition, the client may modify the content or order of the parts, which results in an invalid combined object. For more information, see Include a V1 signature in a URL.\nThe following figure shows how to upload an object to OSS from a client by using STS temporary access credentials returned from the application server.\nThe client requests temporary access credentials from the application server.\nThe application server uses STS SDKs to call the AssumeRole operation to obtain temporary access credentials.\nSTS generates and returns the temporary access credentials to the application server.\nThe application server returns the temporary access credentials to the client.\nThe client uses OSS SDKs to upload an object to OSS by using the temporary access credentials.\nOSS returns a success response to the client.\nThe following examples provide only core code blocks. For complete code samples, download the sts.zip package.\nServer-side sample code\nThe following sample code provides examples on how the application server obtains temporary access credentials from STS:\nThe sample code can be deployed in Function Compute. oss-upload-sts-app\nClient-side sample code\nThe following sample code provides an example on how to use the temporary access credentials to upload an object to OSS from a web client:\nThe following figure shows how to upload an object from a client to OSS by using the signature and POST policy that are obtained from the application server.\nThe client requests information, such as a signature and POST policy, from the application server.\nThe application server generates and returns information, such as the signature and POST policy, to the client.\nThe client uses information, such as the signature and POST policy, to call the PostObject operation to upload the object to OSS by using an HTML form.\nOSS returns a success response to the client.\nThe following examples provide only core code blocks. For complete code samples, download the postsignature.zip package.\nServer-side sample code\nThe following sample code provides examples on how the application server generates a signature and POST policy for PostObject:\nThe sample code can be deployed in Function Compute. oss-upload-post-signature-app\nClient-side sample code\nThe following sample code provides an example on how to use a signature and a POST policy to upload an object to OSS from a web client:\nThe following figure shows how to upload an object to OSS from a client by using a signed URL obtained from the application server.\nThe client requests a signed URL from the application server.\nThe application server uses OSS SDKs to generate a signed URL for PUT requests and returns the signed URL to the client.\nThe client uses the signed URL to call the PutObject operation to upload an object to OSS.\nOSS returns a success response to the client.\nThe following examples provide only core code blocks. For complete code samples, download the presignedurl.zip package.\nServer-side sample code\nThe following sample code provides examples on how to obtain a signed URL from the application server:\nThe sample code can be deployed in Function Compute. oss-upload-presigned-url-app\nClient-side sample code\nThe following sample code provides an example on how to use a signed URL to upload an object to OSS from a web client:\nFor information about the best practices for uploading data to OSS from clients, see the following topics:\nOverview of uploading objects to OSS from web clients\nSet up direct data transfer for mobile applications\n"
    },
    "177": {
        "title": "Object Storage Service:Use ECS instances to configure a reverse proxy to access OSS",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/use-an-ecs-instance-that-runs-centos-to-configure-a-reverse-proxy-for-access-to-oss",
        "content": "This Product\nObject Storage Service:Use ECS instances to configure a reverse proxy to access OSS\nThe IP address used to access an Object Storage Service (OSS) bucket by using DNS resolution dynamically changes. However, you may need to use a static IP address to access objects in the bucket in specific scenarios. In this case, you can configure an NGINX reverse proxy on an Elastic Compute Service (ECS) instance to access the bucket by using a static IP address. You can access the objects in the bucket by using port 80 of the public IP address of the reverse proxy. This way, you can access objects through a static IP address.\n\nAfter you configure an NGINX reverse proxy on an ECS instance, you can use the static IP address of the reverse proxy to forward the access requests to the internal endpoint of the region in which the bucket is located. The following items describe the benefits:\nStatic IP address access: Access by using the static IP address resolves the issue that the IP address of the default domain name of the bucket dynamically changes and is suitable for scenarios in which a static IP address must be used to meet the requirements of enterprise firewall whitelists and third-party system calls.\nEnhanced security: The name of the bucket and the region in which the bucket is located are hidden and only the domain name or IP address of the ECS instance is exposed, which reduces the risk of directly exposing OSS.\nCost optimization: The ECS instance is located in the same region in which the bucket is located and can communicate with the bucket over the same internal network to reduce data transfer costs.\nIn this example, an ECS instance that runs Ubuntu 18.04 (64-bit) is created. Make sure that the instance and the bucket that you want to access are located in the same region.\nCreate and connect to an ECS instance. For more information, see Create an instance on the Custom Launch tab in the ECS console and manage the instance.\nEnable TCP port 80 of the ECS instance. By default, NGINX uses TCP port 80. Therefore, you must enable TCP port 80 when you configure a security group rule for the ECS instance. For more information, see Add a security group rule.\nRun the following command to update the APT repository:\nRun the following commands to install NGINX:\nRun the following command to open the nginx.conf file:\nRefer to the following parameters to modify the HTTP module in the nginx.conf file:\nIn this example, a demo environment is used. To ensure data security, we recommend that you configure the HTTPS module based on your actual scenario. For more information, see Install SSL certificates on NGINX or Tengine servers.\nYou can configure a reverse proxy for only one bucket if you use this configuration method.\nParameter\nDescription\nserver_name\nThe IP address used to provide the reverse proxy service. Set this parameter to the public IP address of the ECS instance.\nproxy_pass\nThe IP address of the proxy server, which specifies the endpoint of the bucket.\nIf the ECS instance and the bucket that you want to access are located in the same region, specify the internal endpoint of the bucket. Example: http://bucketname.oss-cn-beijing-internal.aliyuncs.com.\nIf the ECS instance and the bucket that you want to access are located in different regions, specify the public endpoint of the bucket. Example: http://bucketname.oss-cn-beijing.aliyuncs.com.\nFor more information about endpoints, see Endpoints.\nPress the Esc key and enter :wq to save the changes and close the nginx.conf file.\nRun the following command to test the status of the nginx.conf file:\nRun the following command to restart NGINX and allow the configurations to take effect:\nYou can skip the following steps and use template-based quick deployment to deploy a reverse proxy on a CentOS ECS instance.\nIn this example, an ECS instance that runs CentOS 7.6 (64-bit) is created. Make sure that the ECS instance and the bucket that you want to access are located in the same region.\nCreate and connect to an ECS instance. For more information, see Create an instance on the Custom Launch tab in the ECS console and manage the instance.\nEnable TCP port 80 of the ECS instance. By default, NGINX uses TCP port 80. Therefore, you must enable TCP port 80 when you configure a security group rule for the ECS instance. For more information, see Add a security group rule.\nRun the following commands to install NGINX:\nRun the following command to open the nginx.conf file:\nRefer to the following parameters to modify the HTTP module in the nginx.conf file:\nIn this example, a demo environment is used. To ensure data security, we recommend that you configure the HTTPS module based on your actual scenario. For more information, see Install SSL certificates on NGINX or Tengine servers.\nYou can configure a reverse proxy for only one bucket if you use this configuration method.\nParameter\nDescription\nserver_name\nThe IP address used to provide the reverse proxy service. Set this parameter to the public IP address of the ECS instance.\nproxy_pass\nThe IP address of the proxy server, which specifies the endpoint of the bucket.\nIf the ECS instance and the bucket that you want to access are located in the same region, specify the internal endpoint of the bucket. Example: http://bucketname.oss-cn-beijing-internal.aliyuncs.com.\nIf the ECS instance and the bucket that you want to access are located in different regions, specify the public endpoint of the bucket. Example: http://bucketname.oss-cn-beijing.aliyuncs.com.\nFor more information about endpoints, see Endpoints.\nPress the Esc key and enter :wq to save the changes and close the nginx.conf file.\nRun the following command to test the status of the nginx.conf file:\nRun the following command to restart NGINX and allow the configurations to take effect:\nIn this example, an ECS instance that runs Windows Server 2019 Datacenter 64-bit is used. Make sure that the instance and the bucket that you want to access are located in the same region.\nCreate and connect to an ECS instance. For more information, see Create an instance on the Custom Launch tab in the ECS console and manage the instance.\nEnable TCP port 80 of the ECS instance. By default, NGINX uses TCP port 80. Therefore, you must enable TCP port 80 when you configure a security group rule for the ECS instance. For more information, see Add a security group rule.\nDownload the NGINX package and decompress the package. In this example, NGINX 1.19.2 is used.\nIn this topic, a demo environment is used as an example. To ensure data security, we recommend that you configure the HTTPS module based on your actual scenario. For more information, see Install SSL certificates on NGINX or Tengine servers.\nYou can configure a reverse proxy for only one bucket if you use this configuration method.\nGo to the conf directory and open the nginx.conf file by using a Notepad.\nModify the content of the nginx.conf file.\nParameter\nDescription\nserver_name\nThe IP address used to provide the reverse proxy service. Set this parameter to the public IP address of the ECS instance.\nproxy_pass\nThe IP address of the proxy server, which specifies the endpoint of the bucket.\nIf the ECS instance and the bucket that you want to access are located in the same region, specify the internal endpoint of the bucket. Example: http://bucketname.oss-cn-beijing-internal.aliyuncs.com.\nIf the ECS instance and the bucket that you want to access are located in different regions, specify the public endpoint of the bucket. Example: http://bucketname.oss-cn-beijing.aliyuncs.com.\nFor more information about endpoints, see Endpoints.\nGo to the directory in which the NGINX executable file is located. Double-click nginx.exe to start NGINX.\nYou can add a public-read or public-read-write object path to the public IP address of the ECS instance to access the object.  If the object can be accessed, the configurations are successful. For example, the following result is returned if you use http://ECS public IP address/demo.png to access the demo.png object.\nIf the object access control list (ACL) is private, you must include a signature in the object URL. For more information, see (Recommended) Include a V4 signature in a URL.\n\nYou can refer to the following code to modify the HTTP module in the nginx.conf file based on your business scenario.\nParameter\nRequired\nDescription\nserver_name\nYes\nThe IP address used to provide the reverse proxy service. Set this parameter to the public IP address of the ECS instance.\nproxy_pass\nYes\nThe IP address of the proxy server, which specifies the endpoint of the bucket.\nIf the ECS instance and the bucket that you want to access are located in the same region, specify the internal endpoint of the bucket. Example: http://bucketname.oss-cn-beijing-internal.aliyuncs.com.\nIf the ECS instance and the bucket that you want to access are located in different regions, specify the public endpoint of the bucket. Example: http://bucketname.oss-cn-beijing.aliyuncs.com.\nFor more information about endpoints, see Endpoints.\nproxy_set_header Host\nNo\nIf you specify this parameter, the $host value is replaced with the IP address of the ECS instance when NGINX sends a request to OSS.\nYou must specify this parameter in the following scenarios:\nSignature errors occur.\nThe custom domain name that is mapped to the bucket is resolved to the public IP address of the ECS instance, and you need to preview image objects or web page objects in the bucket by using a browser. You can map the custom domain name to the bucket for which a reverse proxy is configured without adding a CNAME record for the custom domain name.\nproxy_connect_timeout\nNo\nThe timeout period for the connection between NGINX and the backend server. This parameter determines the maximum timeout period for NGINX to establish a connection with the backend server. If the connection times out, NGINX returns an error message.\nproxy_read_timeout\nNo\nThe timeout period for NGINX to read the response from the backend server. If the response cannot be read from the backend server before the timeout period ends, NGINX returns an error message. This is important for processing requests that may require a long response time.\nproxy_send_timeout\nNo\nThe timeout period for NGINX to send request data to the backend server. This parameter is used to ensure that NGINX connects to the backend server when the request data is sent to the backend server before the connection times out or is explicitly closed.\nproxy_set_header Connection\nNo\nSpecifies whether to add the Connection field to the request. If you set the Connection field in the request header to an empty string, NGINX does not add the Connection field to the request. This prevents the HTTP/1.1 persistent connection issues and ensures that NGINX connects to the backend server as expected.\nproxy_buffering\nNo\nSpecifies whether NGINX caches data received from the backend server.\nIf you set the parameter to on, NGINX immediately caches data and sends the data to the client from the cache\nIf you set the parameter to off, NGINX immediately sends data to the client without caching data, which can reduce the latency, but may also increase bandwidth consumption.\nproxy_request_buffering\nNo\nSpecifies whether NGINX waits for the entire request body to be fully received before forwarding it to the backend server. If you set the parameter to off, NGINX immediately forwards the received data without waiting for the entire request body to be received. This is suitable for scenarios that require high real-time performance.\nFor security reasons, when you access an image or web page object in a bucket by using the default domain name of the bucket in a browser, the object is downloaded. To preview an image object or web page object by using a browser, map a custom domain name to the bucket in which the object is stored and add the custom domain name to the value of the proxy_pass parameter. For more information about how to map a custom domain name to a bucket, see Map a custom domain name to the default domain name of a bucket.\n\n"
    },
    "178": {
        "title": "Object Storage Service:How to verify the integrity of data uploaded to OSS from clients",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/data-verification/",
        "content": "This Product\nObject Storage Service:How to verify the integrity of data uploaded to OSS from clients\nAlibaba Cloud Object Storage Service (OSS) provides the MD5 and CRC-64 data verification mechanisms to ensure the consistency and integrity of uploaded and downloaded data. You can use the preceding verification mechanisms in your projects to ensure the reliability of data transmission and storage and the stability of the business system.\nMD5: When you upload an object, you can include the MD5 value of the object. After OSS receives the object, the system automatically compares the received MD5 value with the MD5 value calculated based on the actual object content to ensure data consistency.\nCRC64: OSS can return a CRC-64 value of an object uploaded by using any of the methods provided. The client compares the CRC-64 value with the CRC-64 value calculated on the local machine to verify data integrity.\nFor information about how to ensure that an uploaded object in OSS is consistent with the local file, see Can I use ETag values as OSS MD5 hashes to check data consistency? For information about how to verify data integrity during data upload and download, see Check data integrity by using CRC-64.\n"
    },
    "179": {
        "title": "Object Storage Service:Data lake",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/data-lake/",
        "content": "This Product\nObject Storage Service:Data lake\nBy integrating with the AI ecosystem, open source ecosystem, and Alibaba Cloud ecosystem, data lake can process various data processing requirements and provide enterprises with a powerful and flexible data analysis platform.\nIntegrate with open source ecosystem\nData lake extensively uses open source technologies and frameworks, such as Apache Hadoop, Spark, and Apache Flink, which ensures the openness and flexibility of the system and supports complex data processing tasks, such as gene sequencing. For more information about the engines and platforms supported by the open source ecosystem, see Open source ecosystem.\nIntegrate with the Alibaba Cloud ecosystem\nOSS is deeply integrated with other Alibaba Cloud services, such as MaxCompute, DataWorks, and Realtime Compute for Apache Flink, to form an integrated data lake architecture that supports full lifecycle management covering data collection, storage, processing, and analysis. For more information about the engines and platforms supported by Alibaba Cloud, see Alibaba Cloud ecosystem.\n"
    },
    "180": {
        "title": "Object Storage Service:Content distribution and data processing",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/content-distributing-and-data-processing/",
        "content": "This Product\nObject Storage Service:Content distribution and data processing\nObject Storage Service (OSS) provides a set of content distribution and data processing capabilities that meet the requirements of data storage, management, and access in different scenarios. This guarantees the efficiency and security of data transmission and processing.\nOSS allows you to use Real-Time Messaging Protocol (RTMP) to ingest video and audio streams to OSS buckets and store the streams in the HTTP Live Streaming (HLS) format. OSS also provides various authentication and authorization methods that you can use to achieve fine-grained access control on audio and video data stored in buckets. For more information, see Build HLS Streams Based on OSS.\nYou can use Function Compute to build applications and functions of any type. This topic describes how to use Function Compute to compress multiple objects into a package and download the package from OSS to your local computer. For more information, see Use Function Compute to Package and Download OSS Files."
    },
    "181": {
        "title": "Object Storage Service:Data backup and recovery",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/data-backup-and-recovery/",
        "content": "This Product\nObject Storage Service:Data backup and recovery"
    },
    "182": {
        "title": "Object Storage Service:How to migrate data to OSS",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/data-migration-overview",
        "content": "This Product\nObject Storage Service:How to migrate data to OSS\nThis topic describes how to migrate data to Object Storage Service (OSS) or OSS-HDFS.\nYou can migrate data from local devices, third-party storage devices, or a source bucket to a destination bucket. The following table describes the methods that you can use to migrate data to OSS.\nMigration method\nDescription\nReferences\nData Online Migration\nYou can use Data Online Migration to migrate data from third-party data storage devices to OSS. You do not need to set up an environment for migration tasks. You can submit a migration job online and monitor the migration process.\nWhat is Data Online Migration?\nossimport (obsolete)\nMigrate historical data from various sources to OSS in batches, including historical data from local storage devices, Qiniu Cloud Object Storage (KODO), Baidu Object Storage (BOS), Amazon Simple Storage Service (Amazon S3), Azure Blob, UPYUN Storage Service (USS), Tencent Cloud Object Service (COS), Kingsoft Standard Storage Service (KS3), HTTP, and OSS. You can specify additional sources based on your business requirements.\nossimport (discontinued)\nossutil\nMigrate large amounts of historical data from various sources to OSS in batches.\nossutil\nMirroring-based back-to-origin\nSeamlessly migrate data from origins to OSS. You can migrate your business from origins or other cloud services to OSS without service interruption. After ossimport migrates historical data to OSS and the business runs in OSS, if requested data does not exist in OSS, mirroring-based back-to-origin is triggered to retrieve the requested data from the origins and download the data to OSS.\nFor example, you can use mirroring-based back-to-origin rules to migrate business from a self-managed origin or from another cloud service to OSS without service interruption. You can use mirroring-based back-to-origin rules during migration to obtain data that is not migrated to OSS. This ensures business continuity.\nBack-to-Origin\nData replication\nUse OSS data replication features to replicate objects across buckets within the same region or across regions within the same account or across accounts.\n\nCRR overview\nSRR overview\nData Transport\nMigrate terabytes to petabytes of data from a local data center to OSS.\nWhat is Data Transport?\nOSS API operations or OSS SDKs\nCall OSS API operations or use OSS SDKs to programmatically migrate data to OSS. This migration method is especially suitable for developers.\nOSS API\nOSS SDK\nOSS external tables (gpossext)\nUse the OSS external table (gpossext) feature of AnalyticDB for PostgreSQL to import data from or export data to OSS tables.\nUse an external table to import data from OSS\nUse OSS external tables to export data to OSS\nJindo DistCp\nCopy files within or between large-scale clusters. Jindo DistCp uses MapReduce to distribute files, handle errors, and restore data. The lists of files and directories are used as the input of the MapReduce tasks. Each task copies specific files and directories from the input list.\nMigrate data from HDFS to OSS\nOSS-HDFS (JindoFS) is a cloud-native data lake storage service. OSS-HDFS provides unified metadata management capabilities and is fully compatible with the Hadoop Distributed File System (HDFS) API. OSS-HDFS also supports Portable Operating System Interface (POSIX). OSS-HDFS allows you to manage data in data lake-based computing scenarios in the big data and AI fields. You can migrate data to OSS-HDFS or between buckets for which OSS-HDFS is enabled. The following table describes the methods that you can use to migrate data to OSS-HDFS.\nMigration method\nDescription\nReferences\nJindo DistCp\nCopy files within or between large-scale clusters. Jindo DistCp uses MapReduce to distribute files, handle errors, and restore data. The lists of files and directories are used as the input of the MapReduce tasks. Each task copies specific files and directories from the input list.\nMigrate data from HDFS to OSS-HDFS\nMigrate data across multiple buckets in OSS-HDFS\nJindoDistJob\nMigrate full or incremental metadata of files from a semi-hosted JindoFS cluster to OSS-HDFS without the need to copy data blocks.\nMigrate data from a semi-hosted JindoFS cluster to OSS-HDFS\nMoveTo command of JindoTable\nAutomatically update metadata after the command copies the underlying data. This way, data in a table or partitions can be fully migrated to the destination path. If you want to migrate data in a large number of partitions at the same time, you can specify filter conditions in the MoveTo command. JindoTable also provides protective measures to ensure data integrity and security when the MoveTo command is used to migrate data.\nUse the JindoTable MoveTo command to migrate Hive tables and partitions to OSS-HDFS"
    },
    "183": {
        "title": "Object Storage Service:OSS monitoring, O&M, and alerts",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/data-monitoring/",
        "content": "This Product\nObject Storage Service:OSS monitoring, O&M, and alerts"
    },
    "184": {
        "title": "Object Storage Service:Use OSS in third-party applications",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/use-oss-in-third-party-applications/",
        "content": "This Product\nObject Storage Service:Use OSS in third-party applications"
    },
    "185": {
        "title": "Object Storage Service:OSS security best practices",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/security/",
        "content": "This Product\nObject Storage Service:OSS security best practices"
    },
    "186": {
        "title": "Object Storage Service:OSS performance best practices",
        "url": "https://www.alibabacloud.com/help/en/oss/use-cases/oss-performance-best-practices/",
        "content": "This Product\nObject Storage Service:OSS performance best practices\nThis topic describes how to use the distributed architecture of Alibaba Cloud Object Storage Service (OSS) to accelerate data processing, reduce data latency, and shorten application response time. This topic aims to help you optimize OSS performance.\nTo optimize data distribution and improve processing efficiency, we recommend that you use random prefixes instead of traditional sequential prefixes to name your objects. OSS automatically partitions data based on the UTF-8 encoding order of the key of the object to support large-scale object management and high-concurrency requests. However, if you use sequential prefixes, such as timestamps and alphabetical strings, a large number of objects are stored in a few partitions.\nFor example, if you perform operations more than 2,000 times per second, the following issues may occur. An operation performed on a single object, such as downloading, uploading, deleting, and copying of an object, or querying the metadata of an object, is counted as a request, whereas an operation performed on multiple objects, such as downloading and listing multiple objects, is counted as multiple requests.\nGeneration of hotspot partitions: Requests are frequently initiated for objects in specific partitions, which turns these partitions into hotspot partitions. As a result, the I/O capacity of the partitions is exhausted or the system automatically limits the request rate.\nLimited request rate: OSS continuously partitions data in hotspot partitions to balance the distribution of the data among partitions. This process may increase the request processing time.\nThe even distribution of data is performed based on the analysis result of system status and processing capability. Objects that use sequential prefixes in their keys may be stored in hotspot partitions after the preceding operation is performed.\nTo resolve these issues, you can change the sequential prefixes in the keys of the object to random prefixes to achieve the even distribution of object indexes and I/O loads among different partitions.\nSpecify a hexadecimal hash as the prefix in the key of an object\nIf you use dates and customer IDs to generate keys, sequential prefixes that use timestamps are included in the keys as shown in the following examples:\nIn this case, you can use an MD5 hash of multiple characters of the customer ID as the object name prefix. If you use an MD5 hash of four characters of the customer ID as the object name prefix, the names of the objects are changed as shown in the following examples:\nIf you use a hexadecimal hash of four characters of the customer ID as the object name prefix, each character can be one of the 16 values (0-9 and a-f). This way, the total number of combinations of the four characters is 65,536 (16 4). In OSS, data can be continuously distributed to up to 65,536 partitions. You can perform up to 2,000 operations per second on each partition based on the performance bottleneck. You can use the request rate to determine whether the number of the hash of four characters that you use as the object name prefix meets your business requirements.\nIf you want to list the objects whose names contain a specific date, such as the objects whose names contain the 2024-07-19 string in a bucket named sample-bucket-01, you need to only call the ListObject operation multiple times to list the objects in the sample-bucket-01 bucket in batches, and then group the objects whose names contain the specified date.\nReverse the order of digits that indicate milliseconds in object names\nIf you use the UNIX timestamps which are accurate to milliseconds to generate object names, sequential prefixes are included in object names as shown in the following examples:\nIn this case, you can reverse the order of the digits in the UNIX timestamp. This way, the object names do not contain sequential prefixes. After you reverse the order of the digits, the object names are displayed as shown in the following examples:\nThe first three digits indicate milliseconds and 1,000 values are available. The fourth digit changes at an interval of 1 second. The fifth digit changes at an interval of 10 seconds. The reverse operation increases the randomness of prefixes. This way, requests are evenly distributed among each partition to prevent performance bottleneck issues.\nWhen you download a large object whose size is greater than 100 MB from OSS, the download operation may fail due to an unstable network environment. If you want to download only part of the object, you can initiate an HTTP Range request. Example:\nAccording to the HTTP protocol specification, you can configure the Range request header to specify the range of the object that you want to download. The range must be within [0, content-length - 1]. For more information, see How to Obtain OSS Resources by Segmenting HTTP Range Requests.\nYou can enable transfer acceleration to speed up the upload and download of objects in a bucket over long distances. For example, if you are located in the Chinese mainland, you can enable transfer acceleration when you upload objects to or download objects from a bucket that is located outside the Chinese mainland. This way, the upload and download of gigabyte-size and terabyte-size objects are accelerated. The transfer acceleration feature provides an optimized end-to-end solution with data centers distributed across the world to accelerate access to OSS over the Internet. When the feature is enabled, requests destined for your bucket are routed to the data center nearest to users over the optimal network path and protocol. For more information, see Transfer acceleration.\nTo accelerate access to frequently accessed objects in OSS, we recommend that you use Alibaba Cloud CDN. Alibaba Cloud CDN caches static content on points of presence (POPs) around the world. You can retrieve static content from the nearest POPs. This improves website access speed and stability.\nWhen you request an object in OSS, Alibaba Cloud CDN first checks whether the object is cached on a POP. If the object is not cached or is expired, the object is requested from OSS and cached on a nearby POP. When the object in OSS changes, Alibaba Cloud CDN automatically updates the cache on the POP to ensure data consistency between OSS and the POP.\nIf you use the preceding solution, Alibaba Cloud CDN can effectively reduce the load on OSS and improve the website access speed and stability. This solution is especially suitable for enterprises whose users are located around the world. For more information, see Access acceleration by using Alibaba Cloud CDN.\nOSS SDKs provide built-in support for optimizing OSS performance. The following items describe how the latest OSS SDKs improve OSS performance:\nSupport for new features: In most cases, the latest OSS SDKs support the latest features and improvements. It can take advantage of the new features of OSS, such as the latest API operations, optimized algorithms, and more efficient coding methods to improve performance.\nError handling and retry mechanism: The latest OSS SDKs include a more complete error handling and retry mechanism that can automatically handle common errors, such as errors with HTTP status code 503 returned, to reduce the number of failed operations caused by network issues and improve the success rate.\nTransmission management: The latest OSS SDKs provide a higher level of transmission management, which supports automatic scaling and properly uses range requests for efficient throughput.\nSupport for parallel threads: The latest OSS SDKs support a multi-thread programming model, which can process parallel requests and improve data processing speed.\nMemory management optimization: To effectively use memory resources, the latest OSS SDKs have deeply optimized memory management to reduce unnecessary memory overheads and improve memory usage efficiency.\nCompatibility improvement: The latest OSS SDKs are dedicated to resolving the historical issues and continuously improving compatibility with various third-party software libraries and operating systems.\nFor more information about how to obtain the latest OSS SDKs, see Overview.\nTo take full advantage of OSS and Elastic Compute Service (ECS), we recommend that you deploy your ECS instances and OSS buckets within the same region. This deployment strategy can significantly reduce the latency of the data transmission and improve the data reading speed, thereby enhancing the overall performance of the application. \nIf your ECS instances and OSS buckets are located in the same region and communicate with each other by using internal endpoints, you are not charged internal network traffic fees. In this case, when you transfer large amounts of data between ECS instances and OSS buckets, you are not charged high network bandwidth fees, which reduces the overall costs. \nFor more information, see Access to OSS resources from an ECS instance by using an internal endpoint of OSS.\nOSS throttles the queries per second (QPS) of management-related API operations, such as GetService (ListBuckets), PutBucket, and GetBucketLifecycle. If your application initiates a large number of requests at the same time, HTTP status code 503 may be returned to indicate that request throttling is triggered. In this case, we recommend that you retry the requests after a few seconds.\nThe total QPS of a single Alibaba Cloud account is 10,000. If you require a higher QPS, contact technical support. Take note that if the overall QPS does not exceed 10,000 and the requests are sent to a specific partition, the server may automatically limit the request rate and return HTTP status code 503 because the I/O capacity of the partition is exhausted. If random prefixes in object names are used for even distribution of object indexes and I/O loads among different partitions, OSS automatically increases the number of partitions to support higher QPS. You need to only wait until the process is complete. For more information, see OSS performance and scalability best practices.\nWhen you initiate a large number of requests for objects of different sizes, such as objects that are more than 128 MB in size, we recommend that you measure throughput and retry the slowest 5% of requests. In most cases, the responses to requests for objects that are smaller than 512 KB in size are returned within tens of milliseconds. If you need to retry GET or PUT requests, we recommend that you retry the requests 2 seconds after the requests are sent. If a request fails multiple times, we recommend that you close the program and retry the request. For example, you can retry a request 2 seconds after the request is sent and then retry the request after 4 seconds.\nIf the requests are sent by your application for objects of the same size and you want the response time of all requests to be consistent, we recommend that you identify and retry the slowest 1% requests. In this case, the response time of the requests can be reduced when the requests are retried.\nOSS is a large-scale distributed storage system. To fully utilize the throughput of OSS, we recommend that you send concurrent requests to OSS and distribute the requests across multiple OSS service nodes. This way, workloads can be distributed by using multiple network paths.\nTo increase throughput during data transmission, we recommend that you create multiple threads or instances and initiate multiple requests in the threads or instances to concurrently upload and download data. For specific applications, you can initiate multiple requests in different threads or instances to concurrently access OSS. You can determine how to distribute requests based on the architecture of your application and the structure of objects that you want to access.\nBefore you change the number of concurrent requests, you need to check the performance metrics. We recommend that you first check the bandwidth usage and other resources that are consumed by a single request. This helps you identify resources with the highest usage and determine the maximum number of concurrent requests that can be processed based on the resource upper limit. For example, if 10% CPU resources are required to process a request, you can send up to 10 concurrent requests.\nIt is common to distribute requests to multiple connections for high performance in the design of applications. When you develop a high-performance application, you can use OSS as a large-scale distributed storage system instead of a single storage node such as a traditional storage server. You can send multiple concurrent requests to OSS to improve application performance. You can distribute requests to multiple connections to fully use the bandwidth provided by OSS. OSS does not impose limits on the number of connections to a bucket.\nThe first time a request is sent, OSS may require an extended period of time to respond to the request due to its large scale. In this case, you can resend the request. You can use OSS SDKs to configure a timeout period and the allowed number of retries for requests based on your business requirements.\n\n"
    },
    "187": {
        "title": "Object Storage Service:Security and compliance",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/overview-11",
        "content": "This Product\nObject Storage Service:Security and compliance\nAlibaba Cloud Object Storage Service (OSS) has multiple compliance certifications and provides a variety of security features, including server-side encryption, client-side encryption, hotlink protection based on Referer whitelists, fine-grained access control, log audit, and retention policies based on Write Once Read Many (WORM). OSS provides complete security protection for your data stored in Alibaba Cloud to meet your security and compliance requirements for your enterprise data.\nFeature\nDescription\nAccess control\nOSS provides access control lists (ACLs), Resource Access Management (RAM) and bucket policies, and hotlink protection based on Referer whitelists to control and manage access to your OSS resources.\nData encryption\nOSS provides server-side encryption, client-side encryption, and SSL or TLS encrypted transmission over HTTPS to protect data from potential security risks in the cloud.\nMonitoring and auditing\nOSS allows you to store and query access logs to meet your requirements for monitoring and auditing enterprise data.\nDisaster recovery\nOSS has disaster recovery capabilities that support zone-redundant storage (ZRS) and cross-region replication (CRR) for data centers in a region or across regions.\nData retention compliance\nOSS supports WORM storage that prevents users from accidentally deleting or tampering with your data. OSS conforms to the requirements under the regulations of the U.S. Securities and Exchange Commission (SEC) and Financial Industry Regulatory Authority, Inc. (FINRA).\nCompliance certifications\nOSS helps you meet different compliance requirements based on the compliance with assurance programs such as Cohasset Associates compliance assessment, Financial Industry Regulatory Authority (FINRA) Rule 4511, Commodity Futures Trading Commission (CFTC) Regulation 1.31, ISO, BS10012, and the Cloud Security Alliance Security, Trust, Assurance, and Risk (CSA STAR).\nSDK compliance guide\nOSS helps developers protect personal information and prevent infringement upon the personal information rights of end users when using third-party SDKs. Developers who use OSS SDKs can refer to this topic to check whether their configurations meet regulatory compliance requirements.\nOther features\nOSS provides the versioning feature to prevent data from being accidentally deleted or overwritten. If one of your buckets is attacked or used to distribute illegal content, OSS automatically moves the bucket to the sandbox to prevent your other buckets from being affected."
    },
    "188": {
        "title": "Object Storage Service:Access control",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/access-control-6/",
        "content": "This Product\nObject Storage Service:Access control\nObject Storage Service (OSS) provides access control lists (ACLs), RAM and bucket policies, and hotlink protection based on Referer whitelists to control and manage access to your OSS resources.\nOSS provides ACLs for access control. You can configure ACL for buckets and objects to control access.  You can set the bucket or object ACL when you create a bucket or upload an object. You can also modify the ACL of a created bucket or an uploaded object at any time.\nBucket ACLs\nBucket ACLs are used to control access to buckets. The following table describes the ACLs that you can configure for a bucket.\nACL\nDescription\nAccess control\nPublic Read/Write\nPublic-read-write\nAll users, including anonymous users, can read data from, write data to, and delete objects in the bucket. The bucket owner is charged for these operations. Exercise caution when you set the bucket ACL to Public Read/Write.\nIf you set the ACL of a bucket to public read/write, all users can access the objects in the bucket and write data to the bucket over the Internet. This may result in unauthorized access to the data in your bucket and high costs. If a user uploads prohibited data or information, your legitimate interests and rights may be infringed. Therefore, we recommend that you do not set the ACL of a bucket to public-read-write unless necessary.\nPublic Read\nPublic-read\nOnly the bucket owner and authorized users can write data to and delete objects in the bucket. Other users, including anonymous users, can only read the objects in the bucket.\nThis may result in unexpected access to the data in your bucket and unexpectedly high costs. Exercise caution when you set your bucket ACL to this value.\nPrivate\nPrivate\nOnly the bucket owner and authorized users can read data from, write data to, and delete objects in the bucket. Other users cannot access the objects in the bucket.\nObject ACLs\nObject ACLs are used to control access to objects. The following table describes the ACLs that you can configure for an object.\nACL\nDescription\nAccess control\nPublic Read/Write\nPublic-read-write\nAll users can read data from and write data to the object.\nIf you set the object ACL to this value, all users can access the object and write data to the object over the Internet. This may result in unauthorized access to data in your bucket and high costs. If a user uploads prohibited data or information to the bucket, your legitimate interests and rights may be infringed. Therefore, we recommend that you do not set the ACL of a bucket to public-read-write unless necessary.\nPublic Read\nPublic-read\nOnly the object owner can read data from and write data to the object. Other users can only read the object.\nThis may result in unauthorized access to data in your bucket and high costs. Exercise caution when you set the object ACL to public-read.\nPrivate\nPrivate\nOnly the object owner can read data from and write data to the object. Other users cannot access the object.\nInherited from Bucket\nDefault\nThe ACL of the object is the same as that of the bucket in which the object is stored.\nBy default, the ACL of an object is inherited from the bucket. The ACL of an object takes precedence over that of the bucket in which the object is stored. For example, if the ACL of an object is set to public-read, all authenticated and anonymous users can read the object regardless of the bucket ACL.\nFor more information, see Object ACLs.\nRAM is a resource access control service provided by Alibaba Cloud. You can configure RAM policies based on users. You can configure RAM policies to manage your users, such as employees, systems, or applications, by specifying the resources that are accessible to the users in the RAM policies. For example, you can create a RAM policy to grant users the read permissions on only specific objects in a bucket.\nA RAM policy is in the JSON format. You can configure a RAM policy by specifying the Action, Effect, Resource, and Condition elements in the statements. You can specify multiple statements in a RAM policy to help you manage authorization in a more efficient manner. For more information, see System policies for OSS and Custom policies for OSS.\nRAM policies allow you to manage long-term access permissions. If you want to allow users to access resources only for a short period of time, you can use Security Token Service (STS) to create temporary access credentials. You can obtain temporary access credentials which consist of an AccessKey pair and a security token from environment variables by using STS SDKS, and send them to temporary users to access the corresponding resources. The permissions that are obtained by using STS are restricted and have time limits. The leak of temporary access credentials causes lower-level risks than the leak of other credentials.\nYou can use STS to authorize temporary access to OSS. You can use STS to grant temporary access credentials that have a custom validity period and custom permissions to a third-party application or a RAM user that is managed by you. For more information, see Use OSS with RAM.\nA bucket policy is a resource-based authorization policy. Compared with RAM policies, bucket policies can be configured in the OSS console. The bucket owner can grant other users permissions to access OSS resources.\nBy configuring bucket policies, you can authorize RAM users of another Alibaba Cloud account to access your OSS resources or authorize anonymous users from specific IP addresses to access your OSS resources. For more information, see Configure bucket policies to authorize other users to access OSS resources.\nYou are charged for OSS based on resource usage. To prevent additional fees caused by unauthorized access to the data in your bucket, you can configure hotlink protection for your buckets based on the Referer field in HTTP and HTTPS requests.\nYou can configure a Referer whitelist to allow only requests from specific domain names or HTTP and HTTPS requests that contain the Referer header to access your OSS resources. Hotlink protection can prevent the data in public-read or public-read-write buckets from being hotlinked to protect your legal rights. For more information, see Hotlink protection.\n"
    },
    "189": {
        "title": "Object Storage Service:Fine-grained resource management by using resource groups",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/fine-grained-resource-control-using-resource-groups",
        "content": "This Product\nObject Storage Service:Fine-grained resource management by using resource groups\nTo manage Object Storage Service (OSS) resources in a more efficient manner, you can use resource groups to sort the resources into groups and manage the resource groups. Resource groups allow you to sort the resources into groups by department, project, and environment, and use Resource Access Management (RAM) to isolate resources and manage resource permissions in a fine-grained manner within a single Alibaba Cloud account. This topic describes the support of OSS for resource groups and how to sort OSS resources into groups and authorize resource groups.\nResource groups allow you to sort the resources owned by your Alibaba Cloud account into groups. This simplifies resource grouping, permission management, and cost allocation within your Alibaba Cloud account. For example, you can create resource groups for different projects and transfer the resources that are used by the projects to the groups corresponding to the projects. This way, you can manage the resources of the projects in a centralized manner. For more information, see What is Resource Group? and Best practices for designing resource groups.\nAfter you sort resources into groups, you can use RAM to grant permissions on a specific resource group to a RAM user, RAM user group, or RAM role. This way, the resources that the authorized RAM user, RAM user group, or RAM role can manage are limited to the resources in the specified resource group. This authorization method has good extensibility. When you add a resource later, you need only to add the resource to the corresponding resource group without modifying the policy that you specify. For more information, see Classify resources into resource groups and grant permissions on the resource groups.\nThe following example describes how to grant a RAM user the permissions to manage OSS resources in a specific resource group.\nLog on to the RAM console and create a RAM user.\nFor more information, see Create a RAM user.\nLog on to the Resource Management console and go to the Resource Group page to create a resource group.\nFor more information, see Create a resource group.\nSort resources into the resource groups.\nIf you want to create a resource, specify the resource group to which the resource belongs.\nIf you want to use an existing resource, transfer the resource to the corresponding resource group. For more information, see Perform manual resource transfer across resource groups.\nLog on to the RAM console and create a custom policy.\nThe created custom policy must contain operation permissions that are required by the RAM user For more information, see Create custom policies. If you want to attach a system policy to the RAM user, skip this step.\nIn actual business environments, we recommend that you grant only the required permissions to RAM users based on the principle of least privilege. This prevents security risks caused by excessive user permissions.\nExamples of a custom policy:\nAttach the custom policy whose effective scope is the resource group to the RAM user.\nYou can grant permissions to the RAM user by using one of the following methods:\nLog on to the Resource Management console and then select the resource group on the Resource Group page. For more information, see Add RAM authorization.\n\nLog on to the RAM console, and then set the Resource Scope parameter to ResourceGroup in the Grant Permission panel. For more information, see Grant permissions to a RAM user.\n\nResource group authorization takes effect only for resource types that support resource groups. For resource types that do not support resource groups, the permissions that are granted to the resource groups do not take effect. When you select a resource scope, select the account-level for account-level authorization. For more information, see Actions that do not support resource group-level authorization.\nThe following table describes the resource type that supports resource groups in OSS.\nService name\nService code\nResource type\nOSS\noss\nbucket\nIf you have requirements for resource types that do not support resource groups, you can submit a ticket.\nThe following table describes the actions that do not support resource group-level authorization in OSS and APIs corresponding to the actions.\nAction\nAPI\nAPI Description\noss:DescribeRegions\nDescribeRegions\nQueries the endpoints of all supported regions or a specific region.\noss:ListUserDataRedundancyTransition\nListUserDataRedundancyTransition\nLists all redundancy type change tasks of the requester.\noss:PutPublicAccessBlock\nPutPublicAccessBlock\nEnables Block Public Access for OSS resources.\noss:GetPublicAccessBlock\nGetPublicAccessBlock\nQueries the Block Public Access configurations of OSS resources.\noss:DeletePutblicAccessBlock\nDeletePublicAccessBlock\nDeletes the Block Public Access configurations of OSS resources.\noss:InitUserAntiDDosInfo\nInitUserAntiDDosInfo\nCreate an Anti-DDoS instance.\noss:UpdateUserAntiDDosInfo\nUpdateUserAntiDDosInfo\nChanges the status of an Anti-DDoS instance.\noss:GetUserAntiDDosInfo\nGetUserAntiDDosInfo\nQueries information about Anti-DDoS instances that belong to a specific Alibaba Cloud account.\noss:InitBucketAntiDosInfo\nInitBucketAntiDosInfo\nInitializes Anti-DDoS instances for a bucket.\noss:UpdateBucketAntiDDosInfo\nUpdateBucketAntiDDosInfo\nUpdates the status of the Anti-DDoS instances of a bucket.\noss:ListBucketAntiDDosInfo\nListBucketAntiDDosInfo\nQueries the protection list of an Anti-DDoS instance of a bucket.\noss:ListResourcePools\nListResourcePools\nLists the resource pools of the current Alibaba Cloud account.\noss:GetResourcePoolInfo\nGetResourcePoolInfo\nQueries information about a resource pool.\noss:ListResourcePoolBuckets\nListResourcePoolBuckets\nLists the buckets in a resource pool.\noss:PutResourcePoolRequesterQoSInfo\nPutResourcePoolRequesterQoSInfo\nConfigures throttling for a requester in a resource pool.\noss:GetResourcePoolRequesterQoSInfo\nGetResourcePoolRequesterQoSInfo\nQueries the throttling configurations of a requester in a resource pool.\noss:ListResourcePoolRequesterQoSInfos\nListResourcePoolRequesterQoSInfos\nLists the throttling configurations of all requesters in a resource pool.\noss:DeleteResourcePoolRequesterQoSInfo\nDeleteResourcePoolRequesterQoSInfo\nDeletes the throttling configurations of a requester in a resource pool.\nFor more information, see RAM policies.\nFor resource types that do not support resource groups, the permissions that are granted to the resource groups do not take effect. You must create a custom policy and set the Resource Scope parameter to Account in the RAM console.\nThe following sample code shows two custom policies. You can modify the policy content based on your requirements.\nThe following custom policy allows read-only operations that do not support resource group-level authorization. In the custom policy, the Action field contains all read-only operations that do not support resource group-level authorization.\nThe following custom policy allows all operations that do not support resource group-level authorization. In the custom policy, the Action field contains all operations that do not support resource group-level authorization.\nA RAM user or RAM role that has account-level permissions can manage all resources owned by the Alibaba Cloud account. Make sure that the permissions you grant to the RAM user or RAM role meet your expectations and follow the principle of least privilege.\n\n"
    },
    "190": {
        "title": "Object Storage Service:Data encryption",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/data-encryption-2",
        "content": "This Product\nObject Storage Service:Data encryption\nObject Storage Service (OSS) provides server-side encryption and client-side encryption, and supports encryption in transit using HTTPS over SSL or Transport Layer Security (TLS) to protect data in the cloud from potential security risks.\nOSS supports server-side encryption for uploaded data. When you upload data, OSS encrypts the data and stores the encrypted data. When you download data, OSS decrypts the data and returns the decrypted data. In addition, a header is added to the response to declare that the data is encrypted on the server.\nOSS uses server-side encryption to protect data at rest. You can enable this feature in scenarios in which additional security or compliance is required, such as the storage of deep learning samples and online collaborative documents. You can choose one of the following methods to implement server-side encryption:\nServer-side encryption using KMS-managed keys (SSE-KMS)\nWhen you upload an object, you need to select the default customer master key (CMK) managed by Key Management Service (KMS) or specify a CMK to encrypt and decrypt data. This method is especially helpful in scenarios where lots of data encryption and decryption operations are involved. Server-side encryption by using SSE-KMS is cost-effective because you do not need to send data to the KMS server for encryption and decryption.\nKMS is a secure and easy-to-use key management service provided by Alibaba Cloud. KMS ensures the privacy, integrity, and availability of your keys at minimal cost. Therefore, you can focus on the development of encryption and decryption functions that best suit your needs. You can view and manage keys in the KMS console.\nKMS encrypts data based on AES-256 and stores and manages CMKs that are used to encrypt data keys. KMS also generates data keys that can be used to encrypt and decrypt data. In addition, envelope encryption provided by KMS can protect your data and corresponding data keys from unauthorized access. You can use the default CMK stored in KMS or generate a CMK by using your BYOK materials or BYOK materials provided by Alibaba Cloud.\nServer-side encryption using OSS-managed keys (SSE-OSS)\nThis encryption method is an attribute of objects. OSS server-side encryption uses AES-256 to encrypt objects with different data keys. To improve security, OSS uses master keys to encrypt cryptographic keys. This method is suitable for encryption and decryption of multiple objects at a time.\nIn this method, data keys are generated and managed by OSS. To use server-side encryption to encrypt an object, you can specify AES-256 as the default server-side encryption algorithm for the bucket to which the object is uploaded or specify the x-oss-server-side-encryption header in the request to upload the object and set the header to AES256.\nFor more information, see Server-side encryption.\nClient-side encryption is performed to encrypt objects on the local client before the objects are uploaded to OSS. When you use client-side encryption, you are responsible for the integrity and validity of the CMKs. When you copy or migrate encrypted data, you must ensure the integrity and validity of the object metadata related to client-side encryption.\nIn client-side encryption, a random data key is generated for each object to perform symmetric encryption on the object. The client uses a CMK to generate a random data key. The encrypted data key is saved as a part of the object metadata and stored on the OSS server. When an encrypted object is downloaded, the client uses the CMK to decrypt the random data key and then uses the data key to decrypt the object. The CMK is used only on the client and is not transmitted over the network or stored on the server, which ensures data security.\nYou can use two types of CMKs for client-side encryption:\nKMS-managed CMKs\nIf you use a KMS-managed CMK for client-side encryption, you specify a CMK ID when you upload an object, without the need to provide the OSS encryption client with a data key. The following figure shows the encryption process.\nUse customer-managed CMKs\nIf you use customer-managed CMKs for client-side encryption, you need to generate and manage CMKs. When you implement client-side encryption on an object that you want to upload, you must upload a symmetric or an asymmetric CMK to the client. The following figure shows the encryption process.\nFor more information, see Client-side encryption.\nOSS supports access over HTTP and HTTPS. You can configure a bucket policy to allow only access over HTTPS (TLS) for better security in data transmission. TLS is a cryptographic protocol that provides data security and data integrity for communications over networks. For more information, see Configure bucket policies to authorize other users to access OSS resources.\n"
    },
    "191": {
        "title": "Object Storage Service:Monitoring and auditing",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/monitoring-and-audit",
        "content": "This Product\nObject Storage Service:Monitoring and auditing\nObject Storage Service (OSS) provides logging and real-time log query and supports bucket-level log analysis and audits to address your monitoring and auditing needs for enterprise data.\nCloudMonitor allows you to monitor OSS metrics, such as the resource status, performance, and usage, and configure custom alerts rules. These metrics and alert rules help you track requests, analyze resource usage, obtain business insights, and identify and troubleshoot problems at the earliest opportunity. For more information, see Overview.\nCloud Config is a resource auditing service that allows you to track configuration changes of your resources and evaluate configuration compliance. For example, Cloud Config can monitor noncompliant OSS configurations and notify you of noncompliant configurations. You can manually correct noncompliant configurations or have them automatically corrected by using Function Compute. Cloud Config can help you evaluate a large number of resources and maintain the continuous compliance of your cloud infrastructure. For more information, see What is Cloud Config?\nData stored in OSS may include sensitive information such as personal data, passwords, keys, and sensitive images. You can combine OSS with Sensitive Data Discovery and Protection (SDDP) to better identify, classify, and protect sensitive data. After you authorize SDDP to scan your OSS buckets, SDDP identifies sensitive data in your OSS buckets, classifies and displays sensitive data by risk level, and tracks the use of sensitive data. In addition, SDDP protects and audits sensitive data based on built-in security rules, so that you can query the security status of your data assets in OSS buckets at any time. For more information, see Sensitive data protection.\nOSS supports real-time log query based on Simple Log Service. In the OSS console, you can query and analyze access logs to audit operations, collect access statistics, track exceptions, and troubleshoot problems. Real-time log query helps you improve efficiency and make informed decisions. For more information, see Real-time log query.\nOSS generates a large number of access logs to record access requests. After you enable and configure logging for a bucket, OSS generates log objects every hour in accordance with a predefined naming rule and then stores the access logs as objects in the specified bucket. You can use Simple Log Service or build a Spark cluster to analyze logs. For more information, see Logging.\nAlibaba Cloud ActionTrail provides the Inner-ActionTrail feature. This feature allows you to transfer the operation logs of Alibaba Cloud services from ActionTrail to Simple Log Service in near real time for analysis and auditing. You can configure ActionTrail to record and store the operations logs of OSS and transfer these logs to Simple Log Service for analysis and auditing. This way, you can efficiently implement log query and analysis, reporting, alerting, and downstream computing, and delivery capabilities. For more information, see Inner-ActionTrail overview."
    },
    "192": {
        "title": "Object Storage Service:Disaster recovery",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/disaster-recovery",
        "content": "This Product\nObject Storage Service:Disaster recovery\nObject Storage Service (OSS) has disaster recovery capabilities that support zone-redundant storage (ZRS) and cross-region replication (CRR) for data centers in a region or across regions.\nZRS uses the multi-zone mechanism to distribute user data across multiple zones in the same region. If one zone becomes unavailable, you can continue to access the data that is stored in other zones.\nZRS provides disaster recovery at the data center level. If a data center becomes unavailable due to network disconnections, power outages, or other disasters, OSS continues to provide highly consistent services. This way, the services are not interrupted, and data is not lost during failovers. This helps meet the strict requirements of key business systems for which the recovery time objective (RTO) and the recovery point objective (RPO) must be zero.\nFor more information, see ZRS in OSS Developer Guide.\nCRR enables the automatic and asynchronous (near real-time) replication of objects across buckets in different OSS regions. Operations, such as the creation, overwriting, and deletion of objects, can be synchronized from a source bucket to a destination bucket.\nCRR can meet your requirements for cross-region disaster recovery and data replication. Objects in the destination bucket are exact replicas of those in the source bucket. They have the same object names, versioning information, object content, and object metadata, such as the creation time, owner, user metadata, and object access control lists (ACLs). CRR can replicate objects that are not encrypted and objects that are encrypted by using SSE-KMS or SSE-OSS at the server side.\nFor more information, see CRR in OSS Developer Guide."
    },
    "193": {
        "title": "Object Storage Service:Data retention compliance",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/data-retention-compliance",
        "content": "This Product\nObject Storage Service:Data retention compliance\nOSS supports the Write Once Read Many (WORM) strategy that prevents an object from\n                  being deleted or overwritten for a specified period of time. This strategy is applicable\n                  to business under the regulations of the U.S. Securities and Exchange Commission (SEC)\n                  and Financial Industry Regulatory Authority, Inc. (FINRA).\nOSS is the only cloud service in China that has passed the audit and certification\n                  of Cohasset Associates and can meet specific requirements for electronic data storage.\n                  OSS buckets configured with retention policies can be used for business that is subject\n                  to regulations such as SEC Rule 17a-4(f), CFTC Rule 1.31(c)-(d), and FINRA Rule 4511(c).\n                  For more information, see OSS Cohasset Assessment.\nOSS provides strong compliant policies. You can configure time-based retention policies\n                  for buckets. After a retention policy is locked, you can read objects from or upload\n                  objects to buckets. However, the objects or retention policies within the retention\n                  period cannot be deleted. You can delete objects only after their retention period\n                  ends. The WORM strategy is suitable for industries such as finance, insurance, health\n                  care, and securities. OSS provides the WORM strategy to allow you to build a compliant\n                  bucket in the cloud.\nFor more information, see Retention policy."
    },
    "194": {
        "title": "Object Storage Service:Compliance certifications",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/compliance-certifications",
        "content": "This Product\nObject Storage Service:Compliance certifications\nObject Storage Service (OSS) has obtained certifications for compliance with local and international certification programs and standards, helping customers meet various compliance requirements. The following table describes the compliance certification programs with which OSS complies:\nCompliance certifications\nDescription\nCohasset Associates compliance assessment\nCohasset Associates has certified OSS as a service that meets electronic record keeping requirements and is compliant with Securities and Exchange Commission (SEC) 17a-4(f), FINRA 4511(c), and CFTC 1.31(c)-(d).\nFor more information, see OSS Cohasset Assessment Report.\nISO9001\nISO9001 is a series of quality management requirements that apply to the following scenarios:\nOrganizations that want to provide products and services that meet customer expectations and comply with applicable laws and relevant regulations.\nOrganizations that want to strengthen customer recognition by using a quality management system, including management system optimization and consistency with applicable laws and relevant norms.\nISO20000\nISO20000 is a service management system (SMS) standard that specifies requirements for service providers to plan, establish, implement, operate, monitor, review, maintain, and improve a service management system.\nISO22301\nISO 22301 is a business continuity standard that helps enterprises establish an integrated management procedure.\nThis standard helps enterprises identify and protect against potential business disruptions and establish an effective management mechanism to prevent or offset consequences when disruptions occur.\nISO/IEC 27001\nISO/IEC 27701 is a privacy protection extension to ISO 27001 and provides guidance for establishing, implementing, maintaining, and continually improving an information security management system (ISMS) to strengthen privacy information management and mitigate privacy information threats.\nISO27017\nISO27017 provides guidelines for information security controls that are applicable to the use of cloud services by providing:\nAdditional implementation guidance for controls that are specified in ISO/IEC 27002\nAdditional controls with implementation guidance that is specifically related to cloud services.\nISO27018\nISO27018 is a Personally Identifiable Information (PII) standard that establishes commonly accepted control objectives, controls, and guidelines for implementing measures to protect PII. ISO27018 specifies applicable PII requirements based on the information security risks that are described in ISOIEC 27002.\nISO29151\nISO29151 provides many practical guidelines for enterprises to secure personal privacy and mitigate compliance risks to meet the requirements for PII protection and security assessment.\nBS10012\nThe BS 10012 standard demonstrates compliance with the General Data Protection Regulation (GDPR). BS 10012 specifies the requirements for a personal information management system that is aligned to recognized best practices and helps organizations appropriately use personal information while respecting personal privacy and securing personal records related to individuals.\nFor more information, visit the BS 10012 Personal Information Management website.\nCSA STAR\nThe Cloud Security Alliance Security, Trust, Assurance, and Risk (CSA STAR) is based on ISO/IEC 27001 certification and uses the maturity model and evaluation method provided by BSI to comprehensively evaluate cloud security management and technical capabilities. The CSA STAR certification program is a third-party attestation.\nFor more information, visit the CSA STAR official website.\nPCI DSS\nThe Payment Card Industry Data Security Standard (PCI DSS) specifies security requirements for assessing payment card data, including credit card numbers and Card Verification Value 2 (CVV2) codes. This standard also specifies requirements for securing accounts and storing and transmitting passwords.\nThe PCI DSS helps secure payment card and account data. The PCI DSS sets business and technical guidelines for organizations to accept or process payment card information. The standard is intended for software developers as well as applications and device manufacturers involved in payment transactions.\nFor more information, see PCI DDS.\nC5\nAlibaba Cloud follows the Cloud Computing Compliance Controls Catalog (C5) standard to achieve strict compliance in terms of cloud computing control and security.\nC5 is primarily intended for professional cloud service providers, their auditors, and customers of the cloud service providers. This standard specifies control requirements across 17 fields and requires cloud service providers to adhere to or meet the defined minimum baseline. C5 compliance is necessary for cooperation with German public service sectors and is increasingly adopted by private service sectors. C5 aims to unify the currently fragmented cloud computing certification.\nFor more information, see the C5 document.\nMTCS\nAlibaba Cloud achieved the Multi-Tier Cloud Security (MTCS) T3 certification issued by SOCOTEC Certification International. MTCS is a cloud security standard that is initiated by Infocomm Development Authority of Singapore (IDA) and launched by Standards, Productivity and Innovation Board (SPRING Singapore). The MTCS standard specifies three tiers of security certification, of which T3 is the highest tier with the most stringent security requirements.\nGxP\nGxP is a collection of guidelines and regulations for the life sciences industry, including Good Manufacturing Practices (GMP), Good Safety Practices (GSP), and Good Laboratory Practices (GLP). OSS has achieved third-party validation for compliance with standards such as ISO9001, ISO27017, ISO27001, and ISO27018 to meet GxP compliance requirements.\nTPN\nThe Trusted Partner Network (TPN) is a joint venture between the Motion Picture Association of America (MPAA) and the Content Delivery & Security Association (CDSA). TPN aims to build a single, global network of trusted partners to help ensure content security and prevent leaks, breaches and hacks of films and television shows prior to their intended release.\nTPN certifies that service providers adopt the industry best practices and meet the security requirements by assessing the facilities, staff, and workflows based on the industry best practices and by experienced auditors.\nFor more information, visit the TPN official website.\nTrusted Cloud Service Assessment\nTrusted Cloud Service Assessment is cloud computing evaluation program launched by the China Academy of Information and Communications Technology (CAICT) in the supervision of the Department of Telecommunication Development of the Ministry of Industry and Information Technology. Trusted Cloud Service Evaluation helps establish an evaluation system for cloud services, provide support for users to choose trusted and secure cloud services, and facilitate the healthy and orderly development of the cloud computing market. Alibaba Cloud became one of the first cloud service providers to pass the trusted cloud service evaluation.\nSOC 1, SOC 2, and SOC 3\nAlibaba Cloud has been issued a Cloud Service Organization Controls (SOC) report by an independent third-party auditor after the inspection and assessment of cloud services provided by Alibaba Cloud. The report explains the key controls and control objectives of Alibaba Cloud to Alibaba Cloud customers and their auditors to help customers better assess the internal control mechanisms of Alibaba Cloud and effectively manage outsourcing risks."
    },
    "195": {
        "title": "Object Storage Service:SDK compliance guide",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/sdk-compliance-guide",
        "content": "This Product\nObject Storage Service:SDK compliance guide\nThis guide is provided to help developers protect the personal information of users and prevent infringement upon the personal information rights of end users when using third-party SDKs. Developers who use Object Storage Service (OSS) SDKs can refer to this topic to check whether their configurations meet regulatory compliance requirements.\nApp operators must clearly inform end users of the following information about OSS SDKs: the SDK name, business features, purpose of processing personal information, types of personal information collected, and link for privacy policies. App operators must formulate a separate privacy policy to inform users that they are using an OSS SDK. For example, app operators can include the following information in the Third-party Sharing List:\nSDK name: OSS SDK\nBusiness features: upload or download objects by using corresponding OSS services.\nTypes of personal information collected: system name, system version number, network connection method, mobile phone model, and build ID.\nThe first time users initialize an app, they must agree to the privacy policy before they can use the SDK. Users can call the corresponding API operations only when they use the features provided by the SDK. To prevent excessive or premature data collection, do not collect device information immediately after users agree to the privacy policy.\nThe following table describes the system permissions for Android apps.\nPermission\nRequired\nPurpose\nApplication timing\nINTERNET\nYes\nThe permissions to access networks.\nIf an SDK does not have the permissions, specific features are unavailable.\nBefore calling the API operation for collecting information.\nWRITE_EXTERNAL_STORAGE\nNo (We recommend that you grant the permissions to an OSS SDK.)\nThe permissions to write data into logs and record files for multipart upload and download tasks.\nBefore calling the API operation for collecting information.\nREAD_EXTERNAL_STORAGE\nYes\nThe permissions to read data from files during data upload.\nBefore calling the API operation for collecting information.\nOSS SDK for Android: Android\nOSS SDK for iOS: iOS\nSecurity and compliance: Compliance certifications"
    },
    "196": {
        "title": "Object Storage Service:Other features",
        "url": "https://www.alibabacloud.com/help/en/oss/security-and-compliance/other-features",
        "content": "This Product\nObject Storage Service:Other features\nObject Storage Service (OSS) provides the versioning feature to prevent data from\n                  being accidentally deleted or overwritten. If your bucket is attacked or used to share\n                  illegal content, OSS moves the bucket to a sandbox to prevent your other buckets from\n                  being affected. If your business is prone to distributed denial of service (DDoS)\n                  attacks, you can enable the OSS DDoS protection feature for your buckets.\nOSS provides the versioning feature to prevent your data from being accidentally deleted\n                     or overwritten. After versioning is enabled for a bucket, data that is deleted or\n                     overwritten in the bucket is stored as a previous version. You can use versioning\n                     to recover a previous version of an object that was overwritten or deleted.\nVersioning is applied to all objects within a versioned bucket. After you enable versioning\n                     for a bucket, versioning applies to all objects in the bucket. OSS generates a unique\n                     ID for each version of objects in the bucket. You can upload objects to a versioning-enabled\n                     bucket and list, download, delete, and recover the objects. You can also suspend versioning\n                     for a bucket to stop OSS from generating new object versions. After versioning is\n                     suspended for a bucket, you can still specify a version ID in a request to download,\n                     copy, or delete the specified previous version of an object in the bucket. You are\n                     charged for each version of objects in your bucket. You can configure lifecycle rules\n                     to delete expired versions on a regular basis.\nFor more information, see Overview.\nIf your bucket is attacked or used by other users to share illegal content, OSS moves\n                     the bucket to the sandbox. A bucket in the sandbox can respond to requests. However,\n                     the service quality is degraded. The users of your application may be aware of the\n                     degradation. In this case, you are charged the fees caused by the attack.\nTo prevent your bucket from being moved to the sandbox due to attacks, we recommend\n                     that you use Anti-DDoS Pro to prevent DDoS attacks and HTTP floods. To prevent your bucket from being moved\n                     to the sandbox due to the distribution of illegal content, we recommend that you activate\n                     Content Moderation to periodically scan your bucket to monitor the distribution of illegal content.\nFor more information, see OSS sandbox.\nOSS DDoS protection is a proxy-based mitigation service that integrates OSS with DDoS\n                     protection. When a bucket for which OSS DDoS protection is enabled suffers DDoS attacks,\n                     OSS DDoS protection diverts malicious traffic to an Anti-DDoS Pro or Anti-DDoS Premium\n                     instance for scrubbing and then redirects normal traffic to the bucket. This way,\n                     your business can power through DDoS attacks and continue to function normally.\nOSS DDoS protection can be used to protect your buckets from DDoS attacks that involve\n                     up to terabytes of traffic per second and millions of queries per second (QPS), and\n                     can switch over between Anti-DDoS Pro and Anti-DDoS Origin within a few seconds. These\n                     capabilities can prevent attacks such as SYN flood, ACK flood, Internet Control Message\n                     Protocol (ICMP) flood, UDP flood, NTP flood, Simple Service Discovery Protocol (SSDP)\n                     flood, DNS flood, and HTTP flood attacks. OSS DDoS protection is suitable for scenarios\n                     where your business is prone to attacks, ransom-driven attacks, click farming, and\n                     fraudulent traffic.\nFor more information, see OSS DDoS protection in OSS Developer Guide."
    },
    "197": {
        "title": "Object Storage Service:Error code",
        "url": "https://www.alibabacloud.com/help/en/oss/support/overview-14/",
        "content": "This Product\nObject Storage Service:Error code\nIf an error occurs when you access Object Storage Service (OSS), OSS returns error information, such as the HTTP status code, error message, request ID, and error code. You can identify and resolve the issue based on the returned information.\nThe following table describes the error response headers.\nResponse header\nDescription\nx-oss-ec\nA fine-grained error code in OSS. Each error cause corresponds to a unique error code. Compared with Code in the XML error response body, the error code can more accurately reflect the cause of the request error and facilitate retrieval of the corresponding solution. If a request error occurs, an error code is included in the response header x-oss-ec and the XML response body (in the EC child element of the Error element). You can use the x-oss-ec header to find the cause and solution of the error.\nYou can use an error code only to identify issues. An error code does not ensure forward compatibility because the error code may change. Therefore, do not develop business logic that relies on error codes.\nFor more information about common error response headers such as Content-Length, Connection, and x-oss-request-id, see Common response headers.\nThe following table describes the response elements that are included in the preceding error response body.\nResponse element\nDescription\nCode\nThe error code that is returned in the error response body.\nMessage\nThe error message that is returned in the error response body.\nRequestId\nThe UUID that is used to identify the request. If an issue occurs, provide the request ID when you contact technical support to identify and resolve the issue.\nHostId\nThe ID of a host in the accessed OSS cluster. The ID is the same as the host ID specified in the request.\nEC\nA fine-grained error code in OSS. Each error cause corresponds to a unique error code. Compared with Code in the XML error response body, the error code can more accurately reflect the cause of the request error and facilitate retrieval of the corresponding solution. If a request error occurs, an error code is included in the response header x-oss-ec and the XML response body (in the EC child element of the Error element). You can use the x-oss-ec header to find the cause and solution of the error.\nYou can use an error code only to identify issues. An error code does not ensure forward compatibility because the error code may change. Therefore, do not develop business logic that relies on error codes.\nRecommendDoc\nThe link to the troubleshooting topic specific to the error code in OpenAPI Explorer. You can click the link to troubleshoot the error on the page.\nObtain request IDs\nSelf-help troubleshooting by using error codes\nError codes\nHTTP status code"
    },
    "198": {
        "title": "Object Storage Service:Whitepapers",
        "url": "https://www.alibabacloud.com/help/en/oss/support/whitepapers/",
        "content": "This Product\nObject Storage Service:Whitepapers"
    },
    "199": {
        "title": "Object Storage Service:What is OSS?",
        "url": "https://www.alibabacloud.com/help/en/oss/product-overview/what-is-oss",
        "content": "This Product\nObject Storage Service:What is OSS?\nAlibaba Cloud Object Storage Service (OSS) is a secure, cost-effective, and highly reliable cloud storage service that allows you to store large amounts of data. OSS is designed to provide 99.9999999999% (twelve 9's) data durability and 99.995% data availability. OSS provides multiple storage classes to help you manage and reduce storage costs.\nOSS provides platform-independent API operations, which allows you to upload and access your data from any application, anytime, and anywhere.\nAside from the API operations, OSS provides OSS SDKs and migration tools that you can use to easily transfer large amounts of data to and from OSS. OSS provides storage classes that are intended for different storage scenarios. For example, you can store images, audio files, and video files used in your apps and websites as Standard objects for frequent access and store infrequently accessed data as Infrequent Access (IA), Archive, Cold Archive, or Deep Cold Archive objects to reduce the total costs of storage over time.\nOSS as a cloud data lake can provide high bandwidth to download objects. In specific regions, a single Alibaba Cloud account can provide up to 100 Gbit/s of total download bandwidth over the internal network and Internet to meet the requirements of AI and large-scale data analysis. For more information about the bandwidth of each region, see Bandwidth.\nVideo introduction\nWatch the following video for a quick introduction to OSS.\n\nFAQ\nBrowse the FAQ to obtain answers to frequently asked questions about OSS.\nOSS stores data as objects within buckets. To store data in OSS, you must first create a bucket within a region and specify the access control list (ACL) and storage class for the bucket. When you upload an object to OSS, you must specify the name of the object (also referred to as an object key or a key). This name is the unique identifier of the object within a bucket.\nOSS provides region-specific endpoints through which you can access your data. Endpoints allow you to use OSS operations to manage your data. OSS authenticates a request by verifying the symmetric AccessKey pair (AccessKey ID and AccessKey secret) included in the request.\nOSS ensures atomic updates to all objects and provides strong consistency for operations on all objects.\nBucket\nA bucket is a container for objects that are stored in OSS. Every object in OSS is contained in a bucket. You can configure various properties for a bucket, including the region, access control list (ACL), and storage class. Storage classes are useful when you need to store data that have different access patterns.\nObject\nObjects are the smallest data unit in OSS. Files uploaded to OSS are called objects. Unlike typical file systems, objects in OSS are stored in a flat structure instead of a hierarchical structure. An object is composed of a key, metadata, and the data stored in the object. Each object in a bucket is uniquely identified by the key. Object metadata is a group of key-value pairs that define the properties of an object, such as the file type and encoding format. You can also specify custom user metadata for objects in OSS.\nObject key\nIn OSS SDKs for different programming languages, object key, key, and object name indicate the full path of the object. You must specify the full path of an object when you perform operations on the object. For example, when you upload an object to a bucket, ObjectKey indicates the full path that includes the extension of the object, such as abc/efg/123.jpg.\nRegion\nA region is a physical location from which OSS provides services. When you create a bucket, you can select a region based on the cost or location from which the bucket is most frequently accessed. In most cases, when you access OSS from a geographically closer location, the access speed is faster. For more information, see Regions, endpoints and open ports.\nEndpoint\nAn endpoint is a domain name used to access OSS. OSS provides region-specific endpoints that you can use to access your data. You can manage your data in different regions by using OSS API operations. A region has different endpoints for access over the internal network and for access over the Internet. For example, the public endpoint used to access OSS data in the China (Hangzhou) region is oss-cn-hangzhou.aliyuncs.com, and the internal endpoint is oss-cn-hangzhou-internal.aliyuncs.com. For more information, see Regions, endpoints and open ports.\nAccessKey pair\nAn AccessKey pair is used to authenticate a requester. An AccessKey pair consists of an AccessKey ID and an AccessKey secret. OSS uses an AccessKey pair to implement symmetric encryption and verify the identity of a requester. The AccessKey ID is used to identify a user. The AccessKey secret is used to encrypt and verify the signature string. The AccessKey secret must be kept confidential. OSS supports AccessKey pairs obtained by using the following methods:\nAccessKey pairs applied for by the bucket owner.\nAccessKey pairs granted by the bucket owner by using Resource Access Management (RAM).\nAccessKey pairs granted by the bucket owner by using Security Token Service (STS).\nFor more information, see Obtain an AccessKey pair.\nAtomicity and strong consistency\nObject operations in OSS are atomic. Operations are either successful or failed without intermediate states. When an object is uploaded, you can get either the data before or after the upload. You cannot obtain partial or corrupted data.\nObject operations in OSS are highly consistent. For example, when you receive an upload (PUT) success response, you can immediately read the uploaded object, and replicas of the object are created for redundancy. Therefore, there are no scenarios in which data is not obtained when you perform the read-after-write operation. Similarly, after you delete an object, the object and its replicas no longer exist.\nFor more information about the terms in OSS, see Terms.\nVersioning\nVersioning is a bucket-level data protection feature that you can use to protect objects in a bucket against unintended operations. After versioning is enabled for a bucket, existing objects in the bucket are stored as previous versions when they are overwritten or deleted. Versioning allows you to recover accidentally overwritten or deleted objects to any previous versions. For more information, see Overview.\nBucket policy\nA bucket policy is an access policy that provides flexible and fine-grained permission management. The owner of a bucket can configure bucket policies to grant users access permissions on the bucket and the objects in the bucket. For example, you can configure bucket policies to authorize other Alibaba Cloud accounts or anonymous users to access or manage all or specific resources in your bucket. You can also configure bucket policies to grant read-only, read/write, or full permissions to different RAM users of the same Alibaba Cloud account. For more information about how to configure bucket policies, see Configure bucket policies to authorize other users to access OSS resources.\nCRR\nCross-region replication (CRR) allows you to automatically and asynchronously (in near real-time) replicate objects in a bucket from one region to a bucket in a different region within the same account or a different account. CRR replicates operations, such as the creation, overwriting, and deletion of objects, from a source bucket to a destination bucket. CRR can help you meet compliance requirements for cross-region disaster recovery and data replication. For more information, see CRR overview.\nData encryption\nServer-side encryption: OSS encrypts objects uploaded to a bucket for which server-side encryption is configured and stores the encrypted objects. When you download an object, OSS decrypts and returns the object. The x-oss-server-side-encryption header is included in the response to declare that the object is encrypted on the server side. For more information, see Server-side encryption.\nClient-side encryption: Objects are encrypted on the local client before they are uploaded to OSS. For more information, see Client-side encryption.\nData durability\nBy default, OSS permanently stores objects uploaded to a bucket except in the following circumstances:\nObjects are manually deleted by using the OSS console, OSS SDKs, API operations, or OSS tools such as ossutil and ossbrowser. For more information, see Delete objects.\nObjects are automatically deleted based on a lifecycle rule. For more information, see Lifecycle rules based on the last modified time.\nOverdue fees are not paid within 15 days after service suspension. For more information, see Service suspension.\nFor more information about OSS features, see Functions and features.\nYou can use the following methods to upload, download, and manage objects in OSS:\nOSS console\nThe OSS console is a web-based console that provides a GUI-based way to manage OSS resources. For more information, see Overview page of the OSS console.\nOSS API operations or OSS SDKs\nOSS provides RESTful API operations and OSS SDKs for multiple programming languages to facilitate custom development. For more information, see List of operations by function and Overview.\nOSS tools\nOSS provides multiple management tools, such as ossbrowser, ossutil, and ossftp. For more information, see OSS tools.\nCSG\nOSS uses a flat structure instead of a hierarchical structure to store objects. All elements are stored as objects in buckets. If you want to manage your resources in OSS in the same way you manage local directories and files on disks, use OSS with Cloud Storage Gateway (CSG). For more information, visit the CSG product page.\nOSS supports the following billing methods:\nPay-as-you-go: By default, the pay-as-you-go billing method applies to all billable items. You are charged for the actual usage of each billable item. Fees are paid after you use resources. This billing method is ideal for scenarios in which resource usage is difficult to predict. For more information, see Pay-as-you-go.\nSubscription (resource plans): OSS provides resource plans to offset fees generated for specific billable items. You can purchase resource plans that cover specific billable items at favorable prices. Resources are consumed before fees are offset by resource plans. Resource plans are ideal for scenarios in which resource usage is easy to predict. For more information, see Overview.\nStorage capacity units (SCUs): You can use SCUs to offset storage fees that are generated for using OSS and other Alibaba Cloud storage services. For more information, see SCUs.\nCompared with the pay-as-you-go billing method, resource plans and SCUs are more cost-effective.\nEach resource plan and SCU has a quota for resource usage. If your resource usage exceeds the quota, you are charged for the excess resource usage based on the pay-as-you-go billing method. We recommend that you purchase resource plans and SCUs based on your workloads and business scale.\nYou can use other Alibaba Cloud services to process data uploaded to OSS.\nThe following services are commonly used with OSS:\nImage processing (IMG): allows you to perform a variety of operations on images in OSS, such as format conversion, resizing, cropping, rotation, and watermarking. For more information, see IMG implementation modes.\nElastic Compute Service (ECS): a cloud computing service that offers elastic and efficient computing. For more information, visit the ECS product page.\nAlibaba Cloud CDN: allows you to cache OSS resources to Alibaba Cloud points of presence (POPs) that are geographically closer to your users to improve their download experience. For more information, visit the CDN product page.\nE-MapReduce (EMR): a big data processing solution built on ECS. EMR is developed based on open source Apache Hadoop and Apache Spark to facilitate data analysis and processing. For more information, visit the EMR product page.\nData Online Migration: allows you to migrate data from a third-party storage service such as AWS and Google Cloud to OSS with ease. For more information, see the Data Online Migration documentation.\nData Transport: helps you migrate large amounts of data to OSS under limited network conditions. For example, you can use Data Transport to migrate petabyte-scale data to OSS when upload speed is slow and hardware expansion costs are high. For more information, see What is Data Transport?\nIn addition to OSS, Alibaba Cloud provides other storage services, such as File Storage NAS (NAS) and Elastic Block Storage (EBS), that you can use to meet different business scenarios. For more information, see Overview.\nFor more information about Alibaba Cloud storage solutions and customer success stories, visit the Alibaba Cloud storage page."
    },
    "200": {
        "title": "Object Storage Service:Basic billable items",
        "url": "https://www.alibabacloud.com/help/en/oss/product-overview/basic-billing-item",
        "content": "This Product\nObject Storage Service:Basic billable items"
    },
    "201": {
        "title": "Object Storage Service:Billable items for value-added features",
        "url": "https://www.alibabacloud.com/help/en/oss/product-overview/value-added-billing-item",
        "content": "This Product\nObject Storage Service:Billable items for value-added features"
    },
    "202": {
        "title": "Object Storage Service:Pay-as-you-go",
        "url": "https://www.alibabacloud.com/help/en/oss/product-overview/pay-as-you-go",
        "content": "This Product\nObject Storage Service:Pay-as-you-go\nBy default, OSS uses the pay-as-you-go billing method. This billing method allows you to pay after you use resources.\nItem\nDescription\nBilling rule\nYou are charged based on the resource usage. Bills are generated and fees are deducted from the balance of your Alibaba Cloud account after a billing cycle ends.\nScenario\nThe pay-as-you-go billing method is suitable for the following scenarios:\nResource usage frequently fluctuates.\nYour business has short-term requirements on resource usage.\nBillable item\nThe following items support the pay-as-you-go billing method:\nStorage fees\nTraffic fees\nAPI operation calling fees\nData processing fees\nObject tagging fees\nTransfer acceleration fees\nTemporary storage fees\nOSS DDoS protection fees\nData indexing fees\nRTC traffic fees\nBilling cycle\nYou are billed on an hourly basis. The fees are automatically deducted from the balance of your Alibaba Cloud account. Bills are generally generated after a billing cycle ends. The time when bills are generated is determined by the system.\nIf the total value of your account balance and the vouchers in your Alibaba Cloud account is less than the amount that you need to pay, you are notified by text messages or emails.\nPricing\nFor more information about the pricing of the pay-as-you-go billing method, visit the OSS Pricing page."
    },
    "203": {
        "title": "Object Storage Service:Overview of resource plans",
        "url": "https://www.alibabacloud.com/help/en/oss/product-overview/resource-plan",
        "content": "This Product\nObject Storage Service:Overview of resource plans\nThe default billing method for Object Storage Service (OSS) resources is pay-as-you-go. Compared with the pay-as-you-go billing method, resource plans can be more cost-effective. To reduce costs, we recommend that you purchase resource plans. Resource plans can be used to offset resource fees, such as storage and traffic fees. If a resource plan expires or the actual resource usage exceeds the quota of the resource plan, the pay-as-you-go billing method is automatically used.\nOSS provides free resource quotes for you to try the specified features free of charge. For more information, see Free OSS resource plans.\nResource plan\nDescription\nStorage plan\nOffsets the storage fees of OSS objects.\nStandard (LRS) storage plan\nOffsets the storage fees of Standard locally redundant storage (LRS) objects.\nIA (LRS) storage plan\nOffsets the storage fees of Infrequent Access (IA) LRS objects.\nData transfer plan\nOffsets OSS traffic fees.\nOutbound traffic plan\nOffsets the traffic fees generated when data is transferred from OSS to the client over the Internet.\nTransfer acceleration plan\nOffsets the transfer acceleration fees generated when OSS is accessed by using acceleration endpoints.\nDDoS protection basic plan\nOffsets the fees that are generated when Anti-DDoS Proxy instance resources are reserved.\nA common resource plan combination is the storage and outbound traffic plans. Storage plans are used to offset the storage fees of OSS objects. Outbound traffic plans are used to offset the fees that are generated when OSS objects are accessed over the Internet.\nScenario\nResource plan\nText, images, audio files, and videos are stored as Standard (LRS) objects in OSS.\nStandard (LRS) storage plan\nOSS objects are browsed or downloaded over the Internet.\nOutbound traffic plan\nFor more information about the application scenarios of different resource plans, see Resource plan types.\nYou can select resource plans based on specific billable items on the Details tab of the Bills page.\nFor example, if the billable item is the storage usage of Standard (LRS) objects, you can purchase a Standard (LRS) storage plan to offset the storage fees.\n\nYou can select resource plans based on the usage of specific billable items on the Details tab of the Bills page.\nFor example, if the storage usage of Standard (LRS) objects is 40 GB per hour, you can purchase a Standard (LRS) storage plan that has a capacity of 40 GB to offset the storage fees.\nYou can view the types of billable items and the usage and consumption time of resources on the Details tab of the Bills page.\nYou can view the types, number, and effective time of resource plans that are in effect on the Resource Packages tab of the Manage Reserved Instances page.\nCompare the billable items and resource plans.\nSample issue\nSolution\nThe bill contains fees for outbound traffic over the Internet (NetworkOut), but the resource plan list does not contain outbound traffic plans.\nPurchase outbound traffic plans.\nThe bill contains fees for storage usage of Standard (LRS) objects, but the resource plan list does not contain Standard (LRS) storage plans.\nPurchase Standard (LRS) storage plans.\nThe storage usage of Standard (LRS) objects on the bill is 100 GB per hour, but the Standard (LRS) storage plan in the resource plan list has a capacity of 40 GB.\nIncrease the capacity of the Standard (LRS) storage plan to 100 GB.\nThe bill is generated before you purchase resource plans.\nNone.\nResource plans can be used to offset the fees only for the current Alibaba Cloud account and cannot be used across accounts.\nOSS resource plans are specific to OSS. You cannot use an OSS resource plan to offset fees that another service incurs.\nResource plans can be used to offset only the fees generated after the resource plans are purchased.\nResource plans of a specific type can be used to offset only the fees for billable items that are specific to the resource plans. For more information, see Resource plan types.\nA region-specific OSS resource plan can be used to offset the fees for the specified billable item in the region. A resource plan for the Chinese mainland can be used to offset fees for the applicable billable items in regions in the Chinese mainland. For more information, see Regions.\nOffset method\nResource plan\nExample\nFixed total amount\nStorage plan\nA fixed per-hour quota applies. If the per-hour quota is not exhausted within one hour, the unused quota cannot be transferred to the next hour.\nFor example, a resource plan that has a capacity of 10 TB can be used to offset fees for storage usage of up to 10 TB per hour.\nIf the storage usage is 9 TB in the first hour, the resource plan can be used to fully offset the storage fees.\nIf the storage usage is 10 TB in the second hour, the resource plan can still be used to fully offset the storage fees.\nIf the storage usage is 11 TB in the third hour, the resource plan can be used to offset the storage fees for the first 10 TB. You are charged for the excess 1 TB on a pay-as-you-go basis.\nMonthly subscription\nOutbound traffic plan\nA fixed quota is available every month. The quota is reset on the first day of each month. The unused quota cannot be transferred to the next month.\nFor example, if you purchase an outbound traffic plan that has a capacity of 100 GB and a validity period of 6 months, you can use the traffic plan to offset fees for 100 GB of outbound traffic over the Internet per month within the 6 months. The excess part is billed on a pay-as-you-go basis.\nDecreasing total capacity\nTransfer acceleration plan\nTransfer acceleration plans are used to offset the fees of actual resource usage until the quota is used up or until the plans expire.\nFor example, if you purchase a transfer acceleration plan that has a capacity of 5 TB and a validity period of 3 months, you can use the plan to offset fees for 5 TB of transfer acceleration traffic within the 3 months. The excess part is billed on a pay-as-you-go basis.\nWhen you purchase resource plans, you must select the region in which you want to use the resource plans. You do not need to select a region when you purchase a DDoS protection basic plan because this plan takes effect in all regions. Region-specific resource plans are available only in specific regions.\nYou can use the DDoS protection basic plan to offset the fees generated for Anti-DDoS Proxy instances in different regions. One DDoS protection basic plan can be used to offset the fees generated only for a single instance in a single region within the same hour. If fees are generated in multiple regions within the same hour, you can purchase multiple DDoS protection basic plans to offset the fees.\nRegion type\nDescription\nAll regions\nOffset resource usage fees in all regions.\nSpecific regions \u2460\nOffset resource usage fees only in selected regions. \u2461\nChinese mainland \u2460\nOffset resource usage fees in regions in the Chinese mainland. \u2462\nTransfer acceleration regions\nOffset transfer acceleration fees generated when you use an acceleration endpoint to accelerate uploads or downloads. The acceleration endpoint can be used to access OSS buckets across different regions.\nTransfer acceleration M2M\nOffset transfer acceleration fees generated when you use an acceleration endpoint to accelerate uploads (AccM2MIn) or downloads (AccM2MOut) across regions in the Chinese mainland.\nTransfer acceleration M2O_O2M\nOffset transfer acceleration fees generated when you use an acceleration endpoint to accelerate uploads (AccM2OIn or AccO2MIn) or downloads (AccM2OOut or AccO2MOut) from regions outside the Chinese mainland to regions in the Chinese mainland or from regions in the Chinese mainland to regions outside the Chinese mainland.\nTransfer acceleration O2O\nOffset transfer acceleration fees generated when you use an acceleration endpoint to accelerate uploads (AccO2OIn) or downloads (AccO2OOut) across regions outside the Chinese mainland.\n\u2460 You can purchase resource plans for the Chinese mainland and region-specific resource plans at the same time. Region-specific resource plans are preferentially used to offset fees. After the quota is exceeded, fees are offset based on resource plans for the Chinese mainland. If the actual usage still exceeds the quota of resource plans for the Chinese mainland, you are billed for the excess usage on a pay-as-you-go basis.\n\u2461 For example, resource plans for the China (Qingdao) region can be used to offset only the resource usage fees that are generated in the China (Qingdao) region.\n\u2462 For more information about the regions that are supported by resource plans for the Chinese mainland, see Regions supported by resource plans for the Chinese mainland.\nResource plan\nRegion\nOutbound traffic plan\nChina (Hangzhou), China (Shanghai), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Nanjing-Local Region), and China (Fuzhou-Local Region)\nIn the following table, a check mark (\u221a) indicates that the operation is supported by the corresponding resource plan, and a cross (\u00d7) indicates that the operation is not supported by the corresponding resource plan.\nResource plan\nPurchase\nUpgrade\nRenew\nRepeated purchases \u2460\nDetails\nStandard (LRS) storage plan\n\u2713\n\u2713\n\u2713\n\u00d7\n\u2713\nIA (LRS) storage plan\n\u2713\n\u2713\n\u2713\n\u00d7\n\u2713\nOutbound traffic plan\n\u2713\n\u00d7\n\u2713\n\u2713\n\u2713\nTransfer acceleration plan\n\u2713\n\u00d7\n\u00d7\n\u2713\n\u2713\nDDoS protection basic plan\n\u2713\n\u00d7\n\u2713\n\u2713\n\u2713\n\u2460: Purchase of multiple resource plans of the same type. If you purchase multiple resource plans of the same type, the resource plan that has the earliest expiration time is used to offset fees first. For example, you purchased an outbound traffic plan for the Chinese mainland that has a capacity of 1 TB and a 1-year validity period on February 1, 2022. On March 1, 2022, you purchased an outbound traffic plan for the Chinese mainland that has a capacity of 1 TB and a 3-month validity period. In this case, the outbound traffic plan for the Chinese mainland purchased on March 1, 2022 is used to offset fees first.\nPurchase resource plans\nUpgrade resource plans\nRenew resource plans\nView the usage details of a resource plan\nRefund resource plans\nFAQ about resource plans\n"
    },
    "204": {
        "title": "Object Storage Service:Query bills",
        "url": "https://www.alibabacloud.com/help/en/oss/product-overview/query-bills",
        "content": "This Product\nObject Storage Service:Query bills\nThis topic describes how to query bills of Object Storage Service (OSS).\nLog on to the Expenses and Costs console.\nIn the left-side navigation pane, choose Bills > Bill Details.\nOn the Bill Details page, click the Billing Details tab, specify Billing Cycle, and set Product to Object Storage Service.\nYou can also configure Statistic Item and Statistic Period to specify the content of the bills that you want to display.\nParameter\nDescription\nStatistic Item\nBills are displayed based on the statistic item that you specify. Valid values:\nBilling Item: Bills are displayed by billable item. The bills that are generated based on the same billable item are combined.\nInstance: Bills are displayed by instance. The bills that are generated by the same instance are combined.\nProduct: Bills are displayed by product. The bills that are generated by the same product are combined.\nAccount: Bills are displayed by account. The bills that are generated in the same account are combined.\nCost Center: Bills are displayed by cost center. The bills that are generated by the same cost center are combined.\nStatistic Period\nBills are displayed based on the statistic period that you specify. Valid values:\nBilling Cycle: The bills of the specified billing cycle are displayed.\nBy Day: The bills of the specified billing cycle are displayed by day.\nBilling Period: The bills of the specified billing cycle are displayed by hour.\nOSS is billed on an hourly basis. If you select Billing Cycle or By Day for Statistic Period, data in the Usage column specifies the cumulative usage in the current month or on the current day. For example, you select By Day for Statistic Period and your actual storage usage is 1 TB. The storage usage that is displayed in the bill is 24 TB. You are charged for the 24-hour storage of 1 TB of data.\nYou can click Customize Column Options in the upper-right corner of the bills and select the columns that you want to view.\nYou can click Export Billing Overview (CSV) to export the bills to your computer. This way, you can view and analyze the bills on your computer.\n"
    },
    "205": {
        "title": "ApsaraDB RDS:Product Introduction",
        "url": "https://www.alibabacloud.com/help/en/rds/product-introduction/",
        "content": "This Product\nApsaraDB RDS:Product Introduction"
    },
    "206": {
        "title": "ApsaraDB RDS:Billing",
        "url": "https://www.alibabacloud.com/help/en/rds/product-overview/billing-1/",
        "content": "This Product\nApsaraDB RDS:Billing"
    },
    "207": {
        "title": "ApsaraDB RDS:Announcements and Updates",
        "url": "https://www.alibabacloud.com/help/en/rds/product-overview/announcements-and-updates-of-apsaradb-rds",
        "content": "This Product\nApsaraDB RDS:Announcements and Updates\n\nAnnouncements and Updates of Apsaradb RDS for MySQL\nAnnouncements and Updates of Apsaradb RDS for PostgreSQL\nAnnouncements and Updates of Apsaradb RDS for SQL Server\nAnnouncements and Updates of Apsaradb RDS for MariaDB\n[EOS/Discontinuation] ApsaraDB RDS for PPAS are no longer available for purchase from May 16, 2022"
    },
    "208": {
        "title": "ApsaraDB RDS:Integration overview",
        "url": "https://www.alibabacloud.com/help/en/rds/developer-reference/using-openapi",
        "content": "This Product\nApsaraDB RDS:Integration overview\nApsaraDB RDS provides a console for visual operations and multiple methods for calling API operations, including OpenAPI Explorer, Alibaba Cloud SDKs, and Resource Orchestration Service (ROS). OpenAPI Explorer supports online debugging of API operations. To improve development efficiency by using ApsaraDB RDS, we recommend that you use appropriate API operations and integration methods based on your business requirements.\nAlibaba Cloud provides OpenAPI Explorer for developers to understand and use the API operations of various Alibaba Cloud services in a quick and efficient manner. OpenAPI Explorer integrates multiple features related to API operations, including intelligent search, documentation, online debugging, SDK download, sample code, error diagnosis, and call statistics. In OpenAPI Explorer, you can call API operations of Alibaba Cloud services and view API requests and responses. In addition, OpenAPI Explorer automatically generates the corresponding SDK sample code to facilitate the use of Alibaba Cloud services. For more information, see What is an API?\nAlibaba Cloud APIs use version numbers to manage the versions of cloud service APIs. For example, ApsaraDB RDS supports the API of the 2014-08-15 version. 2014-08-15 is an API version number instead of a date. You are provided with the latest public information about the API. 2014-08-15 is the up-to-date version of the ApsaraDB RDS API.\nVersion\nDescription\n2014-08-15\nRecommended\nApsaraDB RDS provides features such as API debugging in OpenAPI Explorer. Before you call API operations, take note of the following information provided by ApsaraDB RDS: versions, endpoints, and integration methods.\n\nAccess OpenAPI Explorer.\nYou must use the endpoint based on the region of your instance to reduce latency. For example, if your instance resides in the China (Zhangjiakou) region, the public endpoint is rds.cn-zhangjiakou.aliyuncs.com and the virtual private cloud (VPC) endpoint is rds-vpc.cn-zhangjiakou.aliyuncs.com.\nThe public endpoint can be accessed globally.\nVPCs are isolated from each other. Each VPC corresponds to a virtual network. The following list describes the benefits of VPC endpoints:\nHigh security: VPC endpoints can be accessed only within a VPC. This provides higher security and privacy.\nFast response: VPC endpoints deliver faster responses than public endpoints because VPC endpoints enable data transmission over VPCs. In addition, problems such as network latency and bandwidth limitations can be avoided.\nLow cost: VPC endpoints are accessed over an internal network.\nFor more information, see Endpoints.\nBy default, after you log on to OpenAPI Explorer by using your Alibaba Cloud account, the Alibaba Cloud account is used to perform online debugging. An Alibaba Cloud account has permissions on all API operations. If you use an Alibaba Cloud account to call API operations, security risks may arise. We strongly recommend that you call API operations or perform routine O&M by using a RAM user. Before you call API operations by using a RAM user, grant the required permissions to the RAM user based on your business requirements. The RAM user must have the permissions to manage ApsaraDB RDS resources. For more information, see Authorize a RAM user to manage ApsaraDB RDS instances.\nIdentity\nSupported\nAlibaba Cloud account\nYes\nRAM user (recommended)\nYes\nRAM role (recommended)\nYes\nIdentity, credential, and authorization\nThrottling and quota management\nApsaraDB RDS provides various integration methods such as Alibaba Cloud SDKs, Terraform, ROS, and custom encapsulation. You can select an integration method based on your business requirements.\nCalling method\nSupported\nAlibaba Cloud SDK\nYes\nAlibaba Cloud CLI\nYes\nROS\nYes\nTerraform\nYes\nCustom encapsulation\nYes\nSDKs are the most recommended method to call API operations because SDKs can be easily integrated.\nAlibaba Cloud provides SDKs in multiple programming languages, including Java, C#, Go, Python, TypeScript, Node.js, PHP, and C++. You can integrate SDKs into your applications to directly call API operations. SDKs encapsulate various information, including the data signing logic, timeout mechanism, and retry mechanism. SDKs return structured response objects based on specifications to facilitate development. For more information, see Alibaba Cloud SDKs.\nYou can use Alibaba Cloud SDKs to call the API operations of ApsaraDB RDS. For more information about supported languages and dependencies, go to OpenAPI Explorer.\nAlibaba Cloud CLI allows you to run aliyun commands to interact with Alibaba Cloud services and manage cloud service resources. For more information, see What is Alibaba Cloud CLI?\nYou can use Alibaba Cloud CLI to call the API operations of ApsaraDB RDS. For more information, see Generate a command.\nROS is an Alibaba Cloud service that simplifies the management of cloud computing resources. You can create a template to describe the cloud computing resources that you require, such as Elastic Compute Service (ECS) and ApsaraDB RDS instances, and the relationship between the resources. ROS automatically creates and configures all resources based on the template to implement automated deployment and O&M. For more information, see What is ROS?\nYou can use ROS to call the API operations of ApsaraDB RDS. For more information about the supported resources and data, see ApsaraDB RDS resources supported by ROS.\nTo make native HTTP calls, you must construct custom requests and sign the requests. For more information about the signature mechanism, see List of operations by function and Request syntax and signature method V3.\nIf an error is returned after you call an API operation of ApsaraDB RDS, check whether the input parameters and values are valid based on the returned error code. For more information, see Public error codes.\nYou can also use Alibaba Cloud OpenAPI Diagnostics to perform self-service diagnostics based on the returned request ID or SDK error information.\n"
    },
    "209": {
        "title": "ApsaraDB RDS:API Reference",
        "url": "https://www.alibabacloud.com/help/en/rds/developer-reference/api-reference/",
        "content": "This Product\nApsaraDB RDS:API Reference"
    },
    "210": {
        "title": "ApsaraDB RDS:SDK references",
        "url": "https://www.alibabacloud.com/help/en/rds/developer-reference/sdk-reference/",
        "content": "This Product\nApsaraDB RDS:SDK references\nApsaraDB RDS provides Software Development Kits (SDKs) that support multiple programming languages. You can integrate the SDKs based on your business requirements.\nSupported programming language\nSDK download\nJava (Asynchronous)\nJava (asynchronous)\nJava\nJava\nTypeScript\nTypeScript\nGo\nGo\nPHP\nPHP\nPython\nPython\nC#\nC#\nC++\nC++\nSwift\nSwift\nThis topic describes how to call an SDK in Python to query instances and instance information. For more information, see Example on how to call an SDK in Python.\nFor more information about Alibaba Cloud SDKs, see Alibaba Cloud SDKs."
    },
    "211": {
        "title": "ApsaraDB RDS:Alibaba Cloud CLI integration example",
        "url": "https://www.alibabacloud.com/help/en/rds/developer-reference/alibaba-cloud-cli-integration-example",
        "content": "This Product\nApsaraDB RDS:Alibaba Cloud CLI integration example\nAlibaba Cloud CLI is a general-purpose command-line tool that is developed based on APIs. You can use Alibaba Cloud CLI to interact with ApsaraDB RDS and manage ApsaraDB RDS instances in shell. This topic describes how to use Alibaba Cloud CLI to call ApsaraDB RDS API operations.\nFor more information about Alibaba Cloud CLI, see What is Alibaba Cloud CLI?\nYou must install Alibaba Cloud CLI before you can use Alibaba Cloud CLI. You can install Alibaba Cloud CLI in the Windows, Linux, and macOS operating systems. You must select an installation package of Alibaba Cloud CLI based on the operating system of your device. For more information, see the following topics:\nWindows operating system: Windows.\nLinux operating system: Linux.\nmacOS operating system: macOS.\nYou can also use Cloud Shell provided by Alibaba Cloud to debug the commands that you want to run in Alibaba Cloud CLI. For more information about Cloud Shell, see What is Cloud Shell?\nAn Alibaba Cloud account has the permissions to manage and access the APIs of all Alibaba Cloud services. If you use an Alibaba Cloud account to call API operations, security risks may arise. We recommend that you create and use a RAM user to call API operations or perform routine O&M operations. If you want to use a RAM user to manage RDS instances, you must attach the AliyunRDSReadOnlyAccess policy to the RAM user. The policy grants the permissions to query RDS instances. You can also attach the AliyunRDSFullAccess policy to the RAM user based on your business requirements. The policy grants full permissions on RDS instances.\nBefore you use Alibaba Cloud CLI, you must configure information, such as identity credentials and region IDs, in Alibaba Cloud CLI. Alibaba Cloud CLI supports various types of identity credentials. For more information, see Identity credential types. In this example, AccessKey credentials are used.\nCreate a RAM user and grant the RAM user the permissions to manage Alibaba Cloud services based on your business requirements. For more information, see Create a RAM user and Grant permissions to a RAM user.\nCreate an AccessKey pair for the RAM user and record the AccessKey ID and AccessKey secret for the configuration of identity credentials. For more information, see Create an AccessKey pair for a RAM user.\nObtain and record the ID of an available region for the configuration of identity credentials. Alibaba Cloud CLI uses the specified region ID to initiate API calls. For more information about the available regions, see Endpoints.\nWhen you use Alibaba Cloud CLI, you can use the --region option to run a command in a specific region. If you use the option, Alibaba Cloud CLI ignores the region information in the default credential configurations and environment variable settings. For more information, see Command line options for API calls.\nUse the AccessKey pair of the RAM user to configure identity credentials in the configuration file named AkProfile. For more information, see Configuration examples.\nGo to the Debugging page of the ApsaraDB RDS API.\nIn the left-side search box of the page that appears, search for the operation that you want to call. On the Parameters tab, configure the parameters based on API documentation. You can click the CLI Example tab on the right to view the generated sample CLI command that contains the specified parameters.\n\nClick the  icon to view information about Cloud Shell. For more information, see What is Cloud Shell? Then, complete the command debugging.\nClick the  icon to copy the sample command to the clipboard. You can also paste the sample command into your shell to run.\nWhen you paste the sample command into your shell for debugging, take note of the formats of parameters. For more information about the parameter formats of Alibaba Cloud CLI, see Parameter formats.\nBy default, OpenAPI Explorer adds the --region option to the generated CLI command. When you copy the command to your shell, Alibaba Cloud CLI ignores the region information in the default identity credential configurations and environment variable settings, and preferentially runs the command in the specified region. You can delete or retain the option based on your business requirements.\nIn Alibaba Cloud CLI, you can use the following syntax to run commands. For more information, see Command structure.\nWhen you use Alibaba Cloud CLI, you can specify command options to change the behaviors of commands or implement the extended features of commands. In most cases, the following command options are used:\n--profile<profileName>: You can use the --profile option and the profileName parameter to specify a configuration profile. After you specify a valid configuration profile, Alibaba Cloud CLI ignores the information in default credential configurations and environment variable settings and preferentially uses the configurations that you specify to run commands.\n--help: You can use the --help option to obtain the help information about a command. For more information, see Use the help command.\nFor more information, see Command line options for API calls.\nSample 1: The following sample code describes how to use the --help option to obtain the list of ApsaraDB RDS API operations supported by Alibaba Cloud CLI. You can also view the API operations that can be called in List of operations by function.\nRun the following command:\nView the result.\nCommand output\nSample 2: The following sample code describes how to use Alibaba Cloud CLI to call the DescribeDBInstanceAttribute operation of ApsaraDB RDS.\nRun the following command:\nView the result.\nCommand output\nIf an error is returned after you call an API operation of ApsaraDB RDS, check whether the input parameters and values are valid based on the error code.\nYou can also use Alibaba Cloud OpenAPI Diagnostics to perform self-service diagnostics based on the returned request ID or SDK error information."
    },
    "212": {
        "title": "ApsaraDB RDS:Integration with ROS",
        "url": "https://www.alibabacloud.com/help/en/rds/developer-reference/use-ros",
        "content": "This Product\nApsaraDB RDS:Integration with ROS\nResource Orchestration Service (ROS) templates can be used to define cloud resources and dependencies of the resources. The ROS engine automatically creates and configures all resources based on a template to implement automated deployment and O&M. This topic describes how to use ROS to query information about an ApsaraDB RDS instance.\nROS is a service provided by Alibaba Cloud to simplify the management of cloud computing resources. You can create a template to describe the required cloud computing resources such as Elastic Compute Service (ECS) and ApsaraDB RDS instances, as well as the dependencies between the resources. The ROS engine automatically creates and configures all resources based on a template to implement automated deployment and O&M. For more information, see What is ROS?\nYou can use ROS to call ApsaraDB RDS resources. Resources that can be orchestrated by using ROS include regular resources and data resources.\nRegular resources:\nALIYUN::RDS::Account: creates an account that is used to manage a database.\nALIYUN::RDS::AccountPrivilege: authorizes an account to access a database.\nALIYUN::RDS::ADInfo: configures an Active Directory (AD) domain.\nALIYUN::RDS::Connection: applies for a public endpoint for an RDS instance.\nALIYUN::RDS::Database: creates a database on an RDS instance.\nALIYUN::RDS::DBInstance: creates an RDS instance.\nALIYUN::RDS::DBInstanceParameterGroup: modifies the parameters of an RDS instance.\nALIYUN::RDS::DBInstanceSecurityIps: modifies the IP address whitelist of an RDS instance.\nALIYUN::RDS::DBInstanceClone: restores historical data of an RDS instance to a new RDS instance. The new RDS instance is called the cloned instance.\nALIYUN::RDS::MigrateTask: restores the data of a backup file from an Object Storage Service (OSS) bucket to an ApsaraDB RDS for SQL Server instance.\nALIYUN::RDS::PrepayDBInstance: creates a subscription RDS instance.\nALIYUN::RDS::ReadOnlyDBInstance: creates a read-only RDS instance.\nData resources:\nDATASOURCE::RDS::Accounts: queries account information about an RDS instance.\nDATASOURCE::RDS::DBInstance: queries information about an RDS instance.\nDATASOURCE::RDS::Databases: queries database information about an RDS instance.\nDATASOURCE::RDS::DBInstances: queries RDS instances.\nDATASOURCE::RDS::Zones: queries zones.\nTo use ROS, you must create an Alibaba Cloud account and obtain the AccessKey pair of the account. To ensure the security of your Alibaba Cloud account and cloud resources, do not use your Alibaba Cloud account to access ApsaraDB RDS instances. We recommend that you create a Resource Access Management (RAM) user, obtain the AccessKey of the user, and grant RDS permissions to the user.\nCreate a RAM user.\nLog on to the RAM console, go to the Users page, and then click Create User.\nSet the Logon Name parameter to rds-test-operator and the Access Method parameter to Using permanent AccessKey to access.\nClick OK.\nGrant permissions to the RAM user.\nGo to the Users page, find the RAM user that you created, and then click Add Permissions in the Actions column.\nAttach the following policies to the RAM user:\nAliyunRDSFullAccess: grants full permissions to query and modify RDS instances.\nYou can also attach the AliyunRDSReadOnlyAccess policy that grants the permissions to query RDS instances or create a custom policy. For more information, see Create custom policies.\nAliyunROSFullAccess: grants full permissions to manage ROS resources.\nClick Grant permissions.\nLog on to the ROS console.\nIn the top navigation bar, select the region in which your RDS instance resides.\nIn the left-side navigation pane, click Stacks. On the page that appears, choose Create Stack > Use ROS.\nSelect a template and click Next.\nIn this example, a custom template is used to query information about an RDS instance. For more information about how to use a template, see Create a stack.\nIn the Specify Template section, select Select an Existing Template.\nIn the Template Import Method section, select Enter Template Content.\nIn the Template Content section, click the ROS tab and enter the template code.\nThe following sections show the template code in different formats. You can select a format based on your business requirements. For more information, see DATASOURCE::RDS::DBInstance.\nJSON format\nYAML format\nConfigure the parameters.\nParameter\nRequired\nDescription\nExample\nStack Name\nYes\nThe name of the stack.\nRds_Test\nDBInstanceId\nYes\nThe ID of the RDS instance.\nrm-bp1tuz16pa5x8****\nConfigure Stack Settings\nNo\nThe stack parameters.\nFor more information, see Create a stack.\nClick Create.\nClick the Outputs tab to view the instance details.\n\n"
    },
    "213": {
        "title": "ApsaraDB RDS:Security White Paper",
        "url": "https://www.alibabacloud.com/help/en/rds/support/security-white-paper/",
        "content": "This Product\nApsaraDB RDS:Security White Paper"
    },
    "214": {
        "title": "ApsaraDB RDS:Performance White Paper",
        "url": "https://www.alibabacloud.com/help/en/rds/support/performance-white-paper-for-apsaradb-rds",
        "content": "This Product\nApsaraDB RDS:Performance White Paper\n\nApsaraDB RDS for MySQL performance white paper\nApsaraDB RDS for PostgreSQL performance white paper\nApsaraDB RDS for SQL Server performance white paper\n"
    },
    "215": {
        "title": "ApsaraDB RDS:FAQ",
        "url": "https://www.alibabacloud.com/help/en/rds/support/faqs/",
        "content": "This Product\nApsaraDB RDS:FAQ"
    },
    "216": {
        "title": "ApsaraDB RDS:Glossary",
        "url": "https://www.alibabacloud.com/help/en/rds/support/glossary/",
        "content": "This Product\nApsaraDB RDS:Glossary"
    },
    "217": {
        "title": "ApsaraDB RDS:Related Protocols",
        "url": "https://www.alibabacloud.com/help/en/rds/support/related-protocols/",
        "content": "This Product\nApsaraDB RDS:Related Protocols"
    },
    "218": {
        "title": "ApsaraDB RDS:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/product-overview/",
        "content": "This Product\nApsaraDB RDS:Product Overview"
    },
    "219": {
        "title": "ApsaraDB RDS:Quick start",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/getting-started/",
        "content": "This Product\nApsaraDB RDS:Quick start"
    },
    "220": {
        "title": "ApsaraDB RDS:Proprietary AliSQL",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/proprietary-alisql/",
        "content": "This Product\nApsaraDB RDS:Proprietary AliSQL"
    },
    "221": {
        "title": "ApsaraDB RDS:User Guide",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/user-guide/",
        "content": "This Product\nApsaraDB RDS:User Guide"
    },
    "222": {
        "title": "ApsaraDB RDS:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/use-cases/",
        "content": "This Product\nApsaraDB RDS:Use Cases"
    },
    "223": {
        "title": "ApsaraDB RDS:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/developer-reference/",
        "content": "This Product\nApsaraDB RDS:Developer Reference"
    },
    "224": {
        "title": "ApsaraDB RDS:Support",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mysql/support/",
        "content": "This Product\nApsaraDB RDS:Support"
    },
    "225": {
        "title": "ApsaraDB RDS:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/product-overview/",
        "content": "This Product\nApsaraDB RDS:Product Overview"
    },
    "226": {
        "title": "ApsaraDB RDS:Quick Start",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/getting-started/",
        "content": "This Product\nApsaraDB RDS:Quick Start"
    },
    "227": {
        "title": "ApsaraDB RDS:Proprietary AliPG",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/proprietary-alipg/",
        "content": "This Product\nApsaraDB RDS:Proprietary AliPG"
    },
    "228": {
        "title": "ApsaraDB RDS:Extensions",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/plug-ins-1/",
        "content": "This Product\nApsaraDB RDS:Extensions"
    },
    "229": {
        "title": "ApsaraDB RDS:User Guide",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/user-guide/",
        "content": "This Product\nApsaraDB RDS:User Guide"
    },
    "230": {
        "title": "ApsaraDB RDS:Best Practices",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/use-cases/",
        "content": "This Product\nApsaraDB RDS:Best Practices"
    },
    "231": {
        "title": "ApsaraDB RDS:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/developer-reference/",
        "content": "This Product\nApsaraDB RDS:Developer Reference"
    },
    "232": {
        "title": "ApsaraDB RDS:Support",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-postgresql/support/",
        "content": "This Product\nApsaraDB RDS:Support"
    },
    "233": {
        "title": "ApsaraDB RDS:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-sql-server/product-overview/",
        "content": "This Product\nApsaraDB RDS:Product Overview"
    },
    "234": {
        "title": "ApsaraDB RDS:Quick start",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-sql-server/getting-started/",
        "content": "This Product\nApsaraDB RDS:Quick start"
    },
    "235": {
        "title": "ApsaraDB RDS:User Guide",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-sql-server/user-guide/",
        "content": "This Product\nApsaraDB RDS:User Guide"
    },
    "236": {
        "title": "ApsaraDB RDS:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-sql-server/use-cases/",
        "content": "This Product\nApsaraDB RDS:Use Cases"
    },
    "237": {
        "title": "ApsaraDB RDS:Integration overview",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-sql-server/developer-reference/",
        "content": "This Product\nApsaraDB RDS:Integration overview\nApsaraDB RDS provides a console for visual operations and multiple methods for calling API operations, including OpenAPI Explorer, Alibaba Cloud SDKs, and Resource Orchestration Service (ROS). OpenAPI Explorer supports online debugging of API operations. To improve development efficiency by using ApsaraDB RDS, we recommend that you use appropriate API operations and integration methods based on your business requirements.\nAlibaba Cloud provides OpenAPI Explorer for developers to understand and use the API operations of various Alibaba Cloud services in a quick and efficient manner. OpenAPI Explorer integrates multiple features related to API operations, including intelligent search, documentation, online debugging, SDK download, sample code, error diagnosis, and call statistics. In OpenAPI Explorer, you can call API operations of Alibaba Cloud services and view API requests and responses. In addition, OpenAPI Explorer automatically generates the corresponding SDK sample code to facilitate the use of Alibaba Cloud services. For more information, see What is an API?\nAlibaba Cloud APIs use version numbers to manage the versions of cloud service APIs. For example, ApsaraDB RDS supports the API of the 2014-08-15 version. 2014-08-15 is an API version number instead of a date. You are provided with the latest public information about the API. 2014-08-15 is the up-to-date version of the ApsaraDB RDS API.\nVersion\nDescription\n2014-08-15\nRecommended\nApsaraDB RDS provides features such as API debugging in OpenAPI Explorer. Before you call API operations, take note of the following information provided by ApsaraDB RDS: versions, endpoints, and integration methods.\n\nAccess OpenAPI Explorer.\nYou must use the endpoint based on the region of your instance to reduce latency. For example, if your instance resides in the China (Zhangjiakou) region, the public endpoint is rds.cn-zhangjiakou.aliyuncs.com and the virtual private cloud (VPC) endpoint is rds-vpc.cn-zhangjiakou.aliyuncs.com.\nThe public endpoint can be accessed globally.\nVPCs are isolated from each other. Each VPC corresponds to a virtual network. The following list describes the benefits of VPC endpoints:\nHigh security: VPC endpoints can be accessed only within a VPC. This provides higher security and privacy.\nFast response: VPC endpoints deliver faster responses than public endpoints because VPC endpoints enable data transmission over VPCs. In addition, problems such as network latency and bandwidth limitations can be avoided.\nLow cost: VPC endpoints are accessed over an internal network.\nFor more information, see Endpoints.\nBy default, after you log on to OpenAPI Explorer by using your Alibaba Cloud account, the Alibaba Cloud account is used to perform online debugging. An Alibaba Cloud account has permissions on all API operations. If you use an Alibaba Cloud account to call API operations, security risks may arise. We strongly recommend that you call API operations or perform routine O&M by using a RAM user. Before you call API operations by using a RAM user, grant the required permissions to the RAM user based on your business requirements. The RAM user must have the permissions to manage ApsaraDB RDS resources. For more information, see Authorize a RAM user to manage ApsaraDB RDS instances.\nIdentity\nSupported\nAlibaba Cloud account\nYes\nRAM user (recommended)\nYes\nRAM role (recommended)\nYes\nIdentity, credential, and authorization\nThrottling and quota management\nApsaraDB RDS provides various integration methods such as Alibaba Cloud SDKs, Terraform, ROS, and custom encapsulation. You can select an integration method based on your business requirements.\nCalling method\nSupported\nAlibaba Cloud SDK\nYes\nAlibaba Cloud CLI\nYes\nROS\nYes\nTerraform\nYes\nCustom encapsulation\nYes\nSDKs are the most recommended method to call API operations because SDKs can be easily integrated.\nAlibaba Cloud provides SDKs in multiple programming languages, including Java, C#, Go, Python, TypeScript, Node.js, PHP, and C++. You can integrate SDKs into your applications to directly call API operations. SDKs encapsulate various information, including the data signing logic, timeout mechanism, and retry mechanism. SDKs return structured response objects based on specifications to facilitate development. For more information, see Alibaba Cloud SDKs.\nYou can use Alibaba Cloud SDKs to call the API operations of ApsaraDB RDS. For more information about supported languages and dependencies, go to OpenAPI Explorer.\nAlibaba Cloud CLI allows you to run aliyun commands to interact with Alibaba Cloud services and manage cloud service resources. For more information, see What is Alibaba Cloud CLI?\nYou can use Alibaba Cloud CLI to call the API operations of ApsaraDB RDS. For more information, see Generate a command.\nROS is an Alibaba Cloud service that simplifies the management of cloud computing resources. You can create a template to describe the cloud computing resources that you require, such as Elastic Compute Service (ECS) and ApsaraDB RDS instances, and the relationship between the resources. ROS automatically creates and configures all resources based on the template to implement automated deployment and O&M. For more information, see What is ROS?\nYou can use ROS to call the API operations of ApsaraDB RDS. For more information about the supported resources and data, see ApsaraDB RDS resources supported by ROS.\nTo make native HTTP calls, you must construct custom requests and sign the requests. For more information about the signature mechanism, see List of operations by function and Request syntax and signature method V3.\nIf an error is returned after you call an API operation of ApsaraDB RDS, check whether the input parameters and values are valid based on the returned error code. For more information, see Public error codes.\nYou can also use Alibaba Cloud OpenAPI Diagnostics to perform self-service diagnostics based on the returned request ID or SDK error information."
    },
    "238": {
        "title": "ApsaraDB RDS:Support",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-sql-server/support/",
        "content": "This Product\nApsaraDB RDS:Support"
    },
    "239": {
        "title": "ApsaraDB RDS:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/product-overview/",
        "content": "This Product\nApsaraDB RDS:Product Overview"
    },
    "240": {
        "title": "ApsaraDB RDS:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/getting-started/",
        "content": "This Product\nApsaraDB RDS:Getting Started"
    },
    "241": {
        "title": "ApsaraDB RDS:User Guide",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/user-guide/",
        "content": "This Product\nApsaraDB RDS:User Guide"
    },
    "242": {
        "title": "ApsaraDB RDS:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/use-cases/",
        "content": "This Product\nApsaraDB RDS:Use Cases"
    },
    "243": {
        "title": "ApsaraDB RDS:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/developer-reference/",
        "content": "This Product\nApsaraDB RDS:Developer Reference"
    },
    "244": {
        "title": "ApsaraDB RDS:Support",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/support/",
        "content": "This Product\nApsaraDB RDS:Support"
    },
    "245": {
        "title": "ApsaraDB RDS:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/getting-started/",
        "content": "This Product\nApsaraDB RDS:Getting Started"
    },
    "246": {
        "title": "ApsaraDB RDS:Data migration",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/overview-of-data-migration-methods-1",
        "content": "This Product\nApsaraDB RDS:Data migration\nThis topic describes the methods that you can use to migrate data between a self-managed database in a data center and an ApsaraDB RDS instance, between a database in a third-party cloud and an RDS instance, and between different RDS instances with no downtime.\nScenario\nReferences\nMigrate data from a self-managed database in a data center to an RDS instance\nMigrate the data of a self-managed instance that runs MySQL 5.7 or MySQL 8.0 to an ApsaraDB RDS for MySQL instance\nMigrate data from a self-managed MySQL database to an ApsaraDB RDS for MySQL instance\nMigrate data from a self-managed MySQL database connected over Express Connect, VPN Gateway, or Smart Access Gateway to an ApsaraDB RDS for MySQL instance\nMigrate data from a self-managed Db2 database to an ApsaraDB RDS for MySQL instance\nUse the mysqldump extension to migrate data from a self-managed MySQL instance to an ApsaraDB RDS for MySQL instance\nMigrate data from a self-managed Oracle database to an ApsaraDB RDS for MySQL instance\nMigrate data from a database in a third-party cloud to an RDS instance\nMigrate data from an Amazon RDS for MySQL instance to an ApsaraDB RDS for MySQL instance\nMigrate data from an Amazon RDS for Oracle instance to an ApsaraDB RDS for MySQL instance\nMigrate data from an Amazon Aurora MySQL cluster to an ApsaraDB RDS for MySQL instance\nMigrate data from a Google Cloud SQL for MySQL instance to an ApsaraDB RDS for MySQL instance\nMigrate data between RDS instances\nMigrate data between ApsaraDB RDS instances\nSynchronize or migrate data between databases of different names\nMigrate data between RDS instances of different Alibaba Cloud accounts\nDatabase clone\n"
    },
    "247": {
        "title": "ApsaraDB RDS:Data migration",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/overview-of-data-migration-methods-2",
        "content": "This Product\nApsaraDB RDS:Data migration\nThis topic describes the methods that you can use to migrate data among self-managed data centers, third-party clouds, and ApsaraDB RDS with no downtime.\nThe following table provides links to the documentation that may help you migrate data in different scenarios.\nScenario\nReferences\nMigrate data from a PostgreSQL database in a self-managed data center to an ApsaraDB RDS for PostgreSQL instance\nUse pg_dump and pg_restore to migrate data from a self-managed PostgreSQL instance to an ApsaraDB RDS for PostgreSQL instance\nUse DTS to migrate data from a self-managed PostgreSQL database to an ApsaraDB RDS for PostgreSQL instance\nMigrate data from a PostgreSQL database on a third-party cloud to an ApsaraDB RDS for PostgreSQL instance\nMigrate incremental data from an Amazon RDS for PostgreSQL instance to an ApsaraDB RDS for PostgreSQL instance\nMigrate full data from an Amazon RDS for PostgreSQL instance to an ApsaraDB RDS for PostgreSQL instance\nMigrate data between ApsaraDB RDS for PostgreSQL instances\nUse DTS to migrate data between ApsaraDB RDS for PostgreSQL instances\nUse the cloud migration feature to migrate data between ApsaraDB RDS for PostgreSQL instances\nMigrate data from an ApsaraDB RDS for PostgreSQL instance to an on-premises PostgreSQL database\nUse DTS to migrate data between ApsaraDB RDS for PostgreSQL instances\nUse the cloud migration feature to migrate data between ApsaraDB RDS for PostgreSQL instances\nCompatibility issues may occur when you migrate data between RDS instances that run different versions of PostgreSQL. Therefore, we recommend that you test your business on the destination RDS for PostgreSQL instance and make sure that your business can normally run on the destination instance before you migrate data.\nElastic Compute Service (ECS) instances in the classic network will reach end of life (EoL) on February 28, 2025. If your database is deployed on an ECS instance in the classic network, we recommend that you migrate the ECS instance from the classic network to a VPC. For more information about the EoL of ECS instances in the classic network, see EOL notice for Alibaba Cloud ECS instances in the classic network. For more information about how to migrate the ECS instance, see Migrate ECS instances from the classic network to a VPC."
    },
    "248": {
        "title": "ApsaraDB RDS:Data migration",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/data-migration/",
        "content": "This Product\nApsaraDB RDS:Data migration"
    },
    "249": {
        "title": "ApsaraDB RDS:Change instance specifications",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/change-the-specifications-of-an-apsaradb-rds-for-mariadb-instance",
        "content": "This Product\nApsaraDB RDS:Change instance specifications\nThis topic describes how to change the specifications, including the instance type and storage capacity, of an ApsaraDB RDS for MariaDB instance.\nThese specification change methods are supported for both subscription RDS instances and pay-as-you-go RDS instances. After you change the specifications, the new specifications immediately take effect.\nApsaraDB RDS for MariaDB does not support the serverless feature.\nItem\nDescription\nInstance type\nYou can change the instance types of all RDS instances.\nStorage capacity\nYou can expand the storage capacity of all RDS instances. The storage capacity of an RDS instance cannot be decreased.\nThe new storage capacity that you specify for your RDS instance must be within the storage capacity range that is supported by the instance type of the RDS instance. For more information, see Primary ApsaraDB RDS instance types.\nIf the storage capacity range that is supported by the instance type of an RDS instance does not meet your business requirements, we recommend that you select another instance type.\nThe endpoints of an RDS instance remain unchanged after you change the preceding specifications of the RDS instance.\nFor more information, see Pricing.\nYour Alibaba Cloud account does not have unpaid renewal orders.\nWhen the new specifications are being applied, a 30-second transient connection may occur and most of the operations on databases, accounts, and network settings are unavailable. We recommend that you change specifications during off-peak hours or make sure that your application is configured to automatically reconnect to the RDS instance.\nLog on to the ApsaraDB RDS console.\nIn the top navigation bar, select the region in which your RDS instance resides.\nFind the RDS instance for which you want to change specifications and click the instance ID.\nIn the Configuration Information section of the page that appears, click Change Specifications.\nIn the dialog box that appears, select a specification change method and click Next. This step is required only when the RDS instance uses the subscription billing method.\nChange the specifications of the RDS instance. For more information, see Change items.\nConfigure the Switching Time parameter. Valid values:\nExecute Immediately: The specification change triggers a data migration to a new RDS instance. If you select this option, ApsaraDB RDS immediately applies the specification change and switches your workloads over to the new RDS instance after the migration is complete.\nSwitch Within Maintenance Window: When the new specifications are being applied, a 30-second transient connection may occur and most of the operations on databases, accounts, and network settings are unavailable. We recommend that you change the specifications within the maintenance window.\nIf you want to change the maintenance window, perform the following operations:\nClick Modify to the right of the Switch Within Maintenance Window option.\nIn the Configuration Information section of the page that appears, select a maintenance window and click Yes.\nGo to the Change Specifications page, refresh the page, and then continue to change specifications.\nRead and select Terms of Service, confirm the settings, and complete the payment.\nIf I only increase the storage capacity of my RDS instance, does ApsaraDB RDS migrate the data of my original RDS instance to a new RDS instance?\nThis depends on whether the host on which your RDS instance resides has sufficient storage. If the host has sufficient storage, no data migration is required. Otherwise, ApsaraDB RDS migrates the data to a host that has sufficient storage."
    },
    "250": {
        "title": "ApsaraDB RDS:Modify parameters",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/set-instance-parameters",
        "content": "This Product\nApsaraDB RDS:Modify parameters\nApsaraDB RDS for MariaDB allows you to view and modify the parameters of an ApsaraDB RDS for MariaDB instance in the ApsaraDB RDS console or by calling API operations. You can also view the parameter modification history.\nThe modification of some parameters triggers a restart of your RDS instance. After you modify the parameters and click Apply Changes, your RDS instance immediately restarts. To check whether the modification of a parameter triggers a restart, you can log on to the ApsaraDB RDS console, go to the Editable Parameters tab, and then view the value in the Force Restart column for the parameter. If the value is Yes, the modification of the parameter triggers a restart. If the value is No, the modification of the parameter does not trigger a restart. We recommend that you modify parameters during off-peak hours and make sure that your application is configured to automatically reconnect to your RDS instance.\nTo ensure instance stability, you can modify specific parameters in the ApsaraDB RDS console.\nWhen you modify the parameters of your RDS instance, you can view the valid values of a parameter in the Value Range column of the parameter on the Editable Parameters tab of the Parameters page in the ApsaraDB RDS console.\nLog on to the ApsaraDB RDS console.\nIn the top navigation bar, select the region in which your RDS instance resides.\nFind the RDS instance and click the instance ID.\nIn the left-side navigation pane, click Parameters.\nOn the Editable Parameters tab, modify the parameters of the RDS instance based on your business requirements.\nModify a single parameter of the RDS instance.\nFind the parameter and click the  icon.\nEnter a new value and click OK.\nIn the upper part of the page, click Apply Changes.\nIn the dialog box that appears, click OK.\nModify multiple parameters at a time.\nClick Export Parameters to download the parameter settings of your RDS instance as a file to your computer.\nOpen the file and modify the parameters.\nClick Import Parameters.\nIn the Import Parameters dialog box, paste the parameter settings that you have copied from the file. Then, click OK.\nConfirm the values of the modified parameters and click Apply Changes. In the dialogue box that appears, click OK.\nLog on to the ApsaraDB RDS console.\nIn the top navigation bar, select the region in which the RDS instance resides.\nFind the RDS instance and click the instance ID.\nIn the left-side navigation pane, click Parameters.\nClick the Edit History tab.\nSelect a time range and click OK.\nFor more information, see MariaDB parameters.\nDoes the modification of instance parameters take effect immediately? Do I need to restart my RDS instance?\nAfter you modify the parameters of your RDS instance, the new values of some parameters take effect in approximately 5 minutes even if you do not restart your RDS instance. However, the new values of some parameters take effect only after you restart your RDS instance. You can check the values in the Force Restart column on the Editable Parameters tab of the Parameters page in the ApsaraDB RDS console to view the parameters that require instance restart.\nAfter I modify the parameters of my RDS instance, why do the new values of the parameters not take effect?\nMake sure that you click Apply Changes after you modify the parameters.\nOperation\nDescription\nModifyParameter\nModifies the parameters of an instance.\nDescribeParameterTemplates\nQueries the parameter templates that are available for an instance.\nDescribeParameters\nQueries the parameter settings of an instance."
    },
    "251": {
        "title": "ApsaraDB RDS:Modify or reset account permissions",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/modify-the-permissions-of-a-standard-account-on-an-apsaradb-rds-for-mariadb-instance",
        "content": "This Product\nApsaraDB RDS:Modify or reset account permissions\nThis topic describes how to modify the permissions of a standard account on an ApsaraDB RDS for MariaDB instance. You can reset the permissions of a privileged account to the default settings.\nLog on to the ApsaraDB RDS console. In the left-side navigation pane, click Instances. In the top navigation bar, select the region in which the RDS instance resides and then click the ID of the instance.\nIn the left-side navigation pane of the page that appears, click Accounts. On the page that appears, find the privileged account for which you want to reset permissions and click Reset Permissions in the Actions column.\nIn the dialog box that appears, enter and confirm the new password, and click OK.\nLog on to the ApsaraDB RDS console. In the left-side navigation pane, click Instances. In the top navigation bar, select the region in which the RDS instance resides and then click the ID of the instance.\nIn the left-side navigation pane of the page that appears, click Accounts. On the page that appears, find the account for which you want to modify permissions and then click Change Permissions.\nIn the Edit Account Permissions panel,  select the database and click the  or   icon.\nSelect the Read/Write (DDL + DML), Read-only, DDL Only, or DML Only permissions in the Authorized Databases section.\nYou can use SQL statements to modify the permissions of a standard account at higher levels of granularity.\nClick OK."
    },
    "252": {
        "title": "ApsaraDB RDS:View the Enhanced Monitoring metrics",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/view-the-enhanced-monitoring-metrics-of-an-apsaradb-rds-for-postgresql-instance",
        "content": "This Product\nApsaraDB RDS:View the Enhanced Monitoring metrics\nApsaraDB RDS for PostgreSQL provides abundant Enhanced Monitoring metrics, including the operating system metrics and database metrics. This topic describes how to view the Enhanced Monitoring metrics of an ApsaraDB RDS for PostgreSQL instance in the ApsaraDB RDS console.\nIn the left-side navigation pane, click Monitoring and Alerts.\nOn the Enhanced Monitoring tab, click Manage Metrics. On the OS Metrics tab and the Database Metrics tab of the Manage Metrics dialog box, select the metrics that you want to view. For more information, see References.\n\nA maximum of 30 metrics can be displayed on the Enhanced Monitoring tab.\nYou can apply the selected metrics to all RDS instances in the region of the current RDS instance. This includes the existing RDS instances and all new RDS instances that you create at a later time.\nIf the current RDS instance uses cloud disks, you can apply the selected metrics to all RDS instances that use cloud disks in the region of the current RDS instance.\nIf the current RDS instance uses local disks, you can apply the selected metrics to all RDS instances that use local disks in the region of the current RDS instance.\nClick Update Metrics. On the Enhanced Monitoring tab, view the metrics that you selected.\nOn the Enhanced Monitoring tab, specify query criteria based on which you want to query monitoring data.\nNo.\nFeature\nDescription\n1\nTime range\nYou can query monitoring data over a preset time range or a custom time range.\nThe preset time range can be 30 minutes, 1 hour, 2 hours, 6 hours, 1 day, 7 days, or 30 days.\nThe custom time range is specified by a start time and an end time in the following format: YYYY-MM-DD hh:mm:ss - YYYY-MM-DD hh:mm:ss.\n2\nAggregation method\nYou can specify the method based on which ApsaraDB RDS aggregates monitoring data. The following aggregation methods are supported:\nAverage\nMaximum\nMinimum\n3\nLayout\nYou can adjust the layout in which charts displayed. The following layouts are supported:\nOne column\nTwo columns\nThree columns\nFour columns\n4\nTime granularity\nYou can specify the time granularity of the x-axis in each chart that is displayed.\nThe time granularity varies based on the time range that you specify. The following relationships exist between the time granularity and the time range:\nIf the time range is less than or equal to 1 hour, the time granularity is 5 seconds.\nIf the time range is greater than 1 hour and less than or equal to 2 hours, the time granularity is 10 seconds.\nIf the time range is greater than 2 hours and less than or equal to 6 hours, the time granularity is 30 seconds.\nIf the time range is greater than 6 hours and less than or equal to 12 hours, the time granularity is 1 minute.\nIf the time range is greater than 12 hours and less than or equal to 1 day, the time granularity is 2 minutes.\nIf the time range is greater than 1 day and less than or equal to 5 days, the time granularity is 10 minutes.\nIf the time range is greater than 5 days and less than or equal to 15 days, the time granularity is 30 minutes.\nIf the time range is greater than 15 days and less than or equal to 30 days, the time granularity is 1 hour.\n5\nPointer link\nYou can turn on Pointer Link. When you move the pointer over a specific point in time on the x-axis of a chart, all charts on the Enhanced Monitoring tab display the monitoring data that is collected at that specific point in time.\n6\nRefresh\nYou can manually refresh the Enhanced Monitoring tab to update monitoring data.\nThe following table describes the operating system metrics and database metrics that are supported. In the following table, ticks (\ufe0f) indicate that a metric is supported, and crosses () indicate that a metric is not supported.\nOS Metrics\nCategory\nMetric name\nDescription\nUnit\nRDS instance that uses local disks\nRDS instance that uses cloud disks\nNetwork traffic\nAverage value: os.network.rx.avg\nMaximum value: os.network.rx.max\nMinimum value: os.network.rx.min\nThe throughput of inbound traffic of the server.\nMB/s\n\u274c\n\u2714\ufe0f\nAverage value: os.network.tx.avg\nMaximum value: os.network.tx.max\nMinimum value: os.network.tx.min\nThe throughput of outbound traffic of the server.\nMB/s\n\u274c\n\u2714\ufe0f\nCPU utilization\nAverage value: os.cpu_usage.sys.avg\nMaximum value: os.cpu_usage.sys.max\nMinimum value: os.cpu_usage.sys.min\nThe system CPU utilization. The value of this metric is calculated based on the following formula: System CPU utilization = CPU resources consumed to run kernel code/Total CPU resources.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_usage.user.avg\nMaximum value: os.cpu_usage.user.max\nMinimum value: os.cpu_usage.user.min\nThe user CPU utilization. The value of this metric is calculated based on the following formula: User CPU utilization = CPU resources consumed to run code in user mode/Total CPU resources.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_usage.total.avg\nMaximum value: os.cpu_usage.total.max\nMinimum value: os.cpu_usage.total.min\nThe CPU utilization for the server. The value of this metric is calculated based on the following formula: CPU utilization for the server = CPU resources consumed to both run kernel code and run code in user mode/Total CPU resources\n%\n\u2714\ufe0f\n\u2714\ufe0f\nCPU consumption by process\nAverage value: os.cpu_process.backend.avg\nMaximum value: os.cpu_process.backend.max\nMinimum value: os.cpu_process.backend.min\nThe CPU utilization for the backend process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the backend process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.bgwriter.avg\nMaximum value: os.cpu_process.bgwriter.max\nMinimum value: os.cpu_process.bgwriter.min\nThe CPU utilization for the bgwriter process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the bgwriter process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.checkpoint.avg\nMaximum value: os.cpu_process.checkpoint.max\nMinimum value: os.cpu_process.checkpoint.min\nThe CPU utilization for the checkpoint process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the checkpoint process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.logger.avg\nMaximum value: os.cpu_process.logger.max\nMinimum value: os.cpu_process.logger.min\nThe CPU utilization for the logger process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the logger process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.pgstat.avg\nMaximum value: os.cpu_process.pgstat.max\nMinimum value: os.cpu_process.pgstat.min\nThe CPU utilization for the pgstat process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the pgstat process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.walwriter.avg\nMaximum value: os.cpu_process.walwriter.max\nMinimum value: os.cpu_process.walwriter.min\nThe CPU utilization for the walwriter process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the walwriter process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.autovacuum.avg\nMaximum value: os.cpu_process.autovacuum.max\nMinimum value: os.cpu_process.autovacuum.min\nThe CPU utilization for the autovacuum process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the autovacuum process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.walsender.avg\nMaximum value: os.cpu_process.walsender.max\nMinimum value: os.cpu_process.walsender.min\nThe CPU utilization for the walsender process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the walsender process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.cpu_process.postmaster.avg\nMaximum value: os.cpu_process.postmaster.max\nMinimum value: os.cpu_process.postmaster.min\nThe CPU utilization for the postmaster process. If one CPU is consumed, the CPU utilization is 100%. If two CPUs are consumed, the CPU utilization is 200%. In this way, you can calculate the CPU utilization for the postmaster process.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nMemory details\nAverage value: os.mem_size.spec.avg\nMaximum value: os.mem_size.spec.max\nMinimum value: os.mem_size.spec.min\nThe memory size of the instance type.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_size.used.avg\nMaximum value: os.mem_size.used.max\nMinimum value: os.mem_size.used.min\nThe amount of the memory that is used.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_size.cache.avg\nMaximum value: os.mem_size.cache.max\nMinimum value: os.mem_size.cache.min\nThe amount of the memory that is used as page cache.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_size.mapped_file.avg\nMaximum value: os.mem_size.mapped_file.max\nMinimum value: os.mem_size.mapped_file.min\nThe amount of the shared memory that is used.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_size.rss.avg\nMaximum value: os.mem_size.rss.max\nMinimum value: os.mem_size.rss.min\nThe amount of the RSS memory that is used.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_size.hugetlb_usage_2m.avg\nMaximum value: os.mem_size.hugetlb_usage_2m.max\nMinimum value: os.mem_size.hugetlb_usage_2m.min\nThe amount of the huge-page memory that is used. For this metric, the size of a huge page is 2 MB.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nMemory used by process\nAverage value: os.mem_process.backend.avg\nMaximum value: os.mem_process.backend.max\nMinimum value: os.mem_process.backend.min\nThe amount of the memory that is used by the backend process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.bgwriter.avg\nMaximum value: os.mem_process.bgwriter.max\nMinimum value: os.mem_process.bgwriter.min\nThe amount of the memory that is used by the bgwriter process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.checkpoint.avg\nMaximum value: os.mem_process.checkpoint.max\nMinimum value: os.mem_process.checkpoint.min\nThe amount of the memory that is used by the checkpoint process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.logger.avg\nMaximum value: os.mem_process.logger.max\nMinimum value: os.mem_process.logger.min\nThe amount of the memory that is used by the logger process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.pgstat.avg\nMaximum value: os.mem_process.pgstat.max\nMinimum value: os.mem_process.pgstat.min\nThe amount of the memory that is used by the pgstat process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.walwriter.avg\nMaximum value: os.mem_process.walwriter.max\nMinimum value: os.mem_process.walwriter.min\nThe amount of the memory that is used by the walwriter process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.autovacuum.avg\nMaximum value: os.mem_process.autovacuum.max\nMinimum value: os.mem_process.autovacuum.min\nThe amount of the memory that is used by the autovacuum process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.walsender.avg\nMaximum value: os.mem_process.walsender.max\nMinimum value: os.mem_process.walsender.min\nThe amount of the memory that is used by the walsender process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.mem_process.postmaster.avg\nMaximum value: os.mem_process.postmaster.max\nMinimum value: os.mem_process.postmaster.min\nThe amount of the memory that is used by the postmaster process.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nMemory usage\nAverage value: os.mem_usage.total.avg\nMaximum value: os.mem_usage.total.max\nMinimum value: os.mem_usage.total.min\nMemory usage\n%\n\u2714\ufe0f\n\u2714\ufe0f\nIOPS\nAverage value: os.iops.total.avg\nMaximum value: os.iops.total.max\nMinimum value: os.iops.total.min\nThe disk read and write IOPS of the server.\nCounts/s\n\u274c\n\u2714\ufe0f\nAverage value: os.iops.read.avg\nMaximum value: os.iops.read.max\nMinimum value: os.iops.read.min\nThe disk read IOPS of the server.\nCounts/s\n\u274c\n\u2714\ufe0f\nAverage value: os.iops.write.avg\nMaximum value: os.iops.write.max\nMinimum value: os.iops.write.min\nThe disk write IOPS of the server.\nCounts/s\n\u274c\n\u2714\ufe0f\nAverage value: os.iops.data.avg\nMaximum value: os.iops.data.max\nMinimum value: os.iops.data.min\nThe IOPS of the local data disk.\nCounts/s\n\u2714\ufe0f\n\u274c\nAverage value: os.iops.wal.avg\nMaximum value: os.iops.wal.max\nMinimum value: os.iops.wal.min\nThe IOPS of the local log disk.\nCounts/s\n\u2714\ufe0f\n\u274c\nI/O throughout\nAverage value: os.iothroughput.total.avg\nMaximum value: os.iothroughput.total.max\nMinimum value: os.iothroughput.total.min\nThe disk read and write throughput of the server.\nMB/s\n\u274c\n\u2714\ufe0f\nAverage value: os.iothroughput.read.avg\nMaximum value: os.iothroughput.read.max\nMinimum value: os.iothroughput.read.min\nThe disk read throughput of the server.\nMB/s\n\u274c\n\u2714\ufe0f\nAverage value: os.iothroughput.write.avg\nMaximum value: os.iothroughput.write.max\nMinimum value: os.iothroughput.write.min\nThe disk write throughput of the server.\nMB/s\n\u274c\n\u2714\ufe0f\nAverage value: os.iothroughput.data.avg\nMaximum value: os.iothroughput.data.max\nMinimum value: os.iothroughput.data.min\nThe read and write throughput of the local data disk.\nMB/s\n\u2714\ufe0f\n\u274c\nAverage value: os.iothroughput.wal.avg\nMaximum value: os.iothroughput.wal.max\nMinimum value: os.iothroughput.wal.min\nThe read and write throughput of the local log disk.\nMB/s\n\u2714\ufe0f\n\u274c\nDisk usage\nAverage value: os.fs_usage.total.avg\nMaximum value: os.fs_usage.total.max\nMinimum value: os.fs_usage.total.min\nThe disk usage of the server.\n%\n\u274c\n\u2714\ufe0f\nDisk space\nAverage value: os.fs_size.used.avg\nMaximum value: os.fs_size.used.max\nMinimum value: os.fs_size.used.min\nThe used disk space of the server.\nMB\n\u274c\n\u2714\ufe0f\nAverage value: os.fs_size.total.avg\nMaximum value: os.fs_size.total.max\nMinimum value: os.fs_size.total.min\nThe total disk space of the server.\nMB\n\u274c\n\u2714\ufe0f\nAverage value: os.fs_size.log_dir.avg\nMaximum value: os.fs_size.log_dir.max\nMinimum value: os.fs_size.log_dir.min\nThe size of log files. This includes audit log files, error log files, and slow SQL log files.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.fs_size.wal_dir.avg\nMaximum value: os.fs_size.wal_dir.max\nMinimum value: os.fs_size.wal_dir.min\nThe size of WAL files.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: os.fs_size.base_dir.avg\nMaximum value: os.fs_size.base_dir.max\nMinimum value: os.fs_size.base_dir.min\nThe size of data files. This excludes log files and WAL files.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nDatabase metrics\nFor more information about database metrics, see PostgreSQL documentation.\nCategory\nMetric name\nDescription\nUnit\nRDS instance that uses local disks\nRDS instance that uses cloud disks\nConnections\nAverage value: db.connections.active.avg\nMaximum value: db.connections.active.max\nMinimum value: db.connections.active.min\nThe number of connections in the active state.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.connections.waiting.avg\nMaximum value: db.connections.waiting.max\nMinimum value: db.connections.waiting.min\nThe number of connections in the waiting state.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.connections.idle.avg\nMaximum value: db.connections.idle.max\nMinimum value: db.connections.idle.min\nThe number of connections in the idle state.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.connections.total.avg\nMaximum value: db.connections.total.max\nMinimum value: db.connections.total.min\nThe total number of connections.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.connections.spec.avg\nMaximum value: db.connections.spec.max\nMinimum value: db.connections.spec.min\nThe maximum number of connections that are allowed.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nSQL\nAverage value: db.sql.tup_returned.avg\nMaximum value: db.sql.tup_returned.max\nMinimum value: db.sql.tup_returned.min\nThe number of rows that are returned per second.\nTuples/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.sql.tup_fetched.avg\nMaximum value: db.sql.tup_fetched.max\nMinimum value: db.sql.tup_fetched.min\nThe number of rows that are read per second.\nTuples/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.sql.tup_inserted.avg\nMaximum value: db.sql.tup_inserted.max\nMinimum value: db.sql.tup_inserted.min\nThe number of rows that are inserted per second.\nTuples/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.sql.tup_deleted.avg\nMaximum value: db.sql.tup_deleted.max\nMinimum value: db.sql.tup_deleted.min\nThe number of rows that are deleted per second.\nTuples/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.sql.tup_updated.avg\nMaximum value: db.sql.tup_updated.max\nMinimum value: db.sql.tup_updated.min\nThe number of rows that are updated per second.\nTuples/s\n\u2714\ufe0f\n\u2714\ufe0f\nSlow SQL statements\nAverage value: db.slow_sql.one_second.avg\nMaximum value: db.slow_sql.one_second.max\nMinimum value: db.slow_sql.one_second.min\nThe number of SQL statements that have been running for 1 second.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.slow_sql.three_seconds.avg\nMaximum value: db.slow_sql.three_seconds.max\nMinimum value: db.slow_sql.three_seconds.min\nThe number of SQL statements that have been running for 3 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.slow_sql.five_seconds.avg\nMaximum value: db.slow_sql.five_seconds.max\nMinimum value: db.slow_sql.five_seconds.min\nThe number of SQL statements that have been running for 5 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nLong transactions\nAverage value: db.long_transactions.active_one_second.avg\nMaximum value: db.long_transactions.active_one_second.max\nMinimum value: db.long_transactions.active_one_second.min\nThe number of transactions that have been running for 1 second.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.active_three_seconds.avg\nMaximum value: db.long_transactions.active_three_seconds.max\nMinimum value: db.long_transactions.active_three_seconds.min\nThe number of transactions that have been running for 3 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.idle_one_second.avg\nMaximum value: db.long_transactions.idle_one_second.max\nMinimum value: db.long_transactions.idle_one_second.min\nThe number of transactions that have been idle for 1 second.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.idle_three_seconds.avg\nMaximum value: db.long_transactions.idle_three_seconds.max\nMinimum value: db.long_transactions.idle_three_seconds.min\nThe number of transactions that have been idle for 3 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.idle_five_seconds.avg\nMaximum value: db.long_transactions.idle_five_seconds.max\nMinimum value: db.long_transactions.idle_five_seconds.min\nThe number of transactions that have been idle for 5 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.two_pc_one_second.avg\nMaximum value: db.long_transactions.two_pc_one_second.max\nMinimum value: db.long_transactions.two_pc_one_second.min\nThe number of two-phase transactions that have been running for 1 second.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.two_pc_three_seconds.avg\nMaximum value: db.long_transactions.two_pc_three_seconds.max\nMinimum value: db.long_transactions.two_pc_three_seconds.min\nThe number of two-phase transactions that have been running for 3 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.long_transactions.two_pc_five_seconds.avg\nMaximum value: db.long_transactions.two_pc_five_seconds.max\nMinimum value: db.long_transactions.two_pc_five_seconds.min\nThe number of two-phase transactions that have been running for 5 seconds.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nTemporary files\nAverage value: db.temp.temp_files.avg\nMaximum value: db.temp.temp_files.max\nMinimum value: db.temp.temp_files.min\nThe number of temporary files that are generated per second.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nTemporary file size\nAverage value: db.temp.temp_bytes.avg\nMaximum value: db.temp.temp_bytes.max\nMinimum value: db.temp.temp_bytes.min\nThe size of temporary files that are generated per second.\nBytes/s\n\u2714\ufe0f\n\u2714\ufe0f\nMaximum transaction ID\nAverage value: db.age.max_age.avg\nMaximum value: db.age.max_age.max\nMinimum value: db.age.max_age.min\nThe maximum transaction ID on the RDS instance.\nxids\n\u2714\ufe0f\n\u2714\ufe0f\nSynchronization latency to read-only instances\nAverage value: db.ro_replica.replay_lag.avg\nMaximum value: db.ro_replica.replay_lag.max\nMinimum value: db.ro_replica.replay_lag.min\nThe latency at which the attached read-only RDS instances replay logs.\ns\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.ro_replica.write_lag.avg\nMaximum value: db.ro_replica.write_lag.max\nMinimum value: db.ro_replica.write_lag.min\nThe latency at which the attached read-only RDS instances write data.\ns\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.ro_replica.flush_lag.avg\nMaximum value: db.ro_replica.flush_lag.max\nMinimum value: db.ro_replica.flush_lag.min\nThe latency at which the attached read-only RDS instances flush data.\ns\n\u2714\ufe0f\n\u2714\ufe0f\nDatabase memory distribution\nAverage value: db.mem_size.spec.avg\nMaximum value: db.mem_size.spec.max\nMinimum value: db.mem_size.spec.min\nThe memory size of the instance type.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.mem_size.shared_buffer.avg\nMaximum value: db.mem_size.shared_buffer.max\nMinimum value: db.mem_size.shared_buffer.min\nThe amount of the shared_buffer memory that is used.\nThe level 1 cache memory remains unchanged after up to 25% of cache memory is used.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.mem_size.rss.avg\nMaximum value: db.mem_size.rss.max\nMinimum value: db.mem_size.rss.min\nThe amount of the resident set size (RSS) memory that is used.\nThe memory allocated to the PostgreSQL process by calling the malloc function varies based on the number of established connections and running SQL statements. The PostgreSQL process and the page cache indicated by db.mem_size.cache share 75% of all memory. In most cases, the PostgreSQL process occupies 10% of the shared memory.\nIf the memory allocated to the PostgreSQL process exceeds 75% of all memory, an out-of-memory (OOM) error occurs in the PostgreSQL process.\nIf the memory allocated to the PostgreSQL process increases, the memory indicated by db.mem_size.cache decreases.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.mem_size.free.avg\nMaximum value: db.mem_size.free.max\nMinimum value: db.mem_size.free.min\nThe amount of the free memory.\nThe free memory will gradually be used up. PostgreSQL allocates the free memory to db.mem_size.cache as much as possible. This helps make full use of the instance memory.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.mem_size.cache.avg\nMaximum value: db.mem_size.cache.max\nMinimum value: db.mem_size.cache.min\nThe amount of the memory that is used as page cache.\nThe level-2 cache and the page cache indicated by db.mem_size.rss share 75% of all memory. In most cases, the level-2 cache occupies 65% of the shared memory.\nThe memory occupied by the level-2 cache can be reclaimed to prevent OOM errors.\nTo improve memory usage, db.mem_size.cache makes full use of the memory that is specified by db.mem_size.free.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nAvailable database memory\nAverage value: db.mem_available.size.avg\nMaximum value: db.mem_available.size.max\nMinimum value: db.mem_available.size.min\nThe amount of the available database memory.\nYou can calculate the available memory by using the following formula: Available memory = Free memory + Cache memory that can be quickly reclaimed. When the value of db.mem_size.rss continuously increases, the available memory is used to prevent OOM errors.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nDatabase memory availability ratio\nAverage value: db.mem_available.ratio.avg\nMaximum value: db.mem_available.ratio.max\nMinimum value: db.mem_available.ratio.min\nThe availability ratio of the database memory.\nThe proportion of the memory indicated by db.mem_available.size to all memory varies based on the Memory Usage metric of the alerting feature that is provided by CloudMonitor. The sum of the values of db.mem_available.size and Memory Usage is equal to 1. If the available memory is less than 20%, you must increase the ratio of available memory by reducing the number of idle connections, optimizing SQL statements, or increasing the memory capacity.\nFor more information about how to calculate the memory usage, see [Product changes/Feature changes] Optimization of the Memory Usage metric for an ApsaraDB RDS for PostgreSQL instance with cloud disks.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nShared buffer hit ratio\nAverage value: db.buffers.hit_ratio.avg\nMaximum value: db.buffers.hit_ratio.max\nMinimum value: db.buffers.hit_ratio.min\nThe proportion of requests for which the requested content is hit in the shared buffers.\n%\n\u2714\ufe0f\n\u2714\ufe0f\nShared buffer hits\nAverage value: db.buffers.blks_hit.avg\nMaximum value: db.buffers.blks_hit.max\nMinimum value: db.buffers.blks_hit.min\nThe number of requests for which the requested content is hit in the shared buffers per second.\nBlocks/s\n\u2714\ufe0f\n\u2714\ufe0f\nI/O\nAverage value: db.io.blks_read.avg\nMaximum value: db.io.blks_read.max\nMinimum value: db.io.blks_read.min\nThe number of operations that are performed by the backend process per second to read data from the disks to the buffers.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.io.buffers_backend.avg\nMaximum value: db.io.buffers_backend.max\nMinimum value: db.io.buffers_backend.min\nThe number of operations that are performed by the backend process per second to write data from the buffers to the disks.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.io.buffers_checkpoint.avg\nMaximum value: db.io.buffers_checkpoint.max\nMinimum value: db.io.buffers_checkpoint.min\nThe number of operations that are performed by the checkpoint process per second to write data from the buffers to the disks.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.io.buffers_clean.avg\nMaximum value: db.io.buffers_clean.max\nMinimum value: db.io.buffers_clean.min\nThe number of operations that are performed by the bgwriter process per second to write data from the buffers to the disks.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.io.buffers_backend_fsync.avg\nMaximum value: db.io.buffers_backend_fsync.max\nMinimum value: db.io.buffers_backend_fsync.min\nThe number of times that the backend process calls the fsync() function on the disks per second.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nCheckpoint quantity\nAverage value: db.checkpoint.checkpoints_timed.avg\nMaximum value: db.checkpoint.checkpoints_timed.max\nMinimum value: db.checkpoint.checkpoints_timed.min\nThe number of checkpoint processes that are scheduled by the database engine per second.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.checkpoint.checkpoints_req.avg\nMaximum value: db.checkpoint.checkpoints_req.max\nMinimum value: db.checkpoint.checkpoints_req.min\nThe number of checkpoint processes that are requested by the user per second.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nTPS\nAverage value: db.transactions.xact_commit.avg\nMaximum value: db.transactions.xact_commit.max\nMinimum value: db.transactions.xact_commit.min\nThe number of write transactions that are committed per second.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.transactions.xact_rollback.avg\nMaximum value: db.transactions.xact_rollback.max\nMinimum value: db.transactions.xact_rollback.min\nThe number of write transactions that are rolled back per second.\nCounts/s\n\u2714\ufe0f\n\u2714\ufe0f\nTransaction statuses\nAverage value: db.transactions.active.avg\nMaximum value: db.transactions.active.max\nMinimum value: db.transactions.active.min\nThe number of transactions in the active state.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.transactions.waiting.avg\nMaximum value: db.transactions.waiting.max\nMinimum value: db.transactions.waiting.min\nThe number of transactions in the waiting state.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.transactions.idle.avg\nMaximum value: db.transactions.idle.max\nMinimum value: db.transactions.idle.min\nThe number of transactions in the idle state. We recommend that you check and process these transactions at the earliest opportunity.\nCounts\n\u2714\ufe0f\n\u2714\ufe0f\nSwell point in time\nAverage value: db.swell.swell_time.avg\nMaximum value: db.swell.swell_time.max\nMinimum value: db.swell.swell_time.min\nThe execution duration of the longest transaction.\ns\n\u2714\ufe0f\n\u2714\ufe0f\nReplicationSlot latency\nAverage value: db.slots.max_slot_wal_delay.avg\nMaximum value: db.slots.max_slot_wal_delay.max\nMinimum value: db.slots.max_slot_wal_delay.min\nThe maximum latency that is allowed for the replication slot to replicate WAL records. The WAL records that follow the replication start position must be retained. If the replication start position indicates a WAL record that has a relatively high log sequence number (LSN), WAL records may pile up. In this case, we recommend that you make sure these WAL records are processed at the earliest opportunity.\nMB\n\u2714\ufe0f\n\u2714\ufe0f\nCheckpoint write duration\nAverage value: db.checkpoint.checkpoints_sync_time.avg\nMaximum value: db.checkpoint.checkpoints_sync_time.max\nMinimum value: db.checkpoint.checkpoints_sync_time.min\nThe amount of time that the checkpoint process spends per second in running the fsync() function on the disks.\nms/s\n\u2714\ufe0f\n\u2714\ufe0f\nAverage value: db.checkpoint.checkpoints_write_time.avg\nMaximum value: db.checkpoint.checkpoints_write_time.max\nMinimum value: db.checkpoint.checkpoints_write_time.min\nThe amount of time that the checkpoint process spends per second in writing data from the buffers to the disks.\nms/s\n\u2714\ufe0f\n\u2714\ufe0f\nPgBouncer connections\nAverage value:\ndb.pgbouncer.client_connections.active.avg\nMaximum value:\ndb.pgbouncer.client_connections.active.max\nMinimum value:\ndb.pgbouncer.client_connections.active.min\nThe number of active connections on the client.\nYou can view connection pool-related metrics on the Enhanced Monitoring tab only after you enable the connection pooling feature. For more information, see Enable or disable the connection pooling feature.\nCounts\n\u274c\n\u2714\ufe0f\nAverage value:\ndb.pgbouncer.client_connections.waiting.avg\nMaximum value:\ndb.pgbouncer.client_connections.waiting.max\nMinimum value:\ndb.pgbouncer.client_connections.waiting.min\nThe number of waiting connections on the client.\nCounts\n\u274c\n\u2714\ufe0f\nAverage value:\ndb.pgbouncer.server_connections.active.avg\nMaximum value:\ndb.pgbouncer.server_connections.active.max\nMinimum value:\ndb.pgbouncer.server_connections.active.min\nThe number of active connections on the server.\nCounts\n\u274c\n\u2714\ufe0f\nAverage value:\ndb.pgbouncer.server_connections.idle.avg\nMaximum value:\ndb.pgbouncer.server_connections.idle.max\nMinimum value:\ndb.pgbouncer.server_connections.idle.min\nThe number of idle connections on the server.\nCounts\n\u274c\n\u2714\ufe0f\nAverage value:\ndb.pgbouncer.total_pooled_connections.avg\nMaximum value:\ndb.pgbouncer.total_pooled_connections.max\nMinimum value:\ndb.pgbouncer.total_pooled_connections.min\nThe total number of connections in a connection pool.\nCounts\n\u274c\n\u2714\ufe0f\nAverage value:\ndb.pgbouncer.num_pools.avg\nMaximum value:\ndb.pgbouncer.num_pools.max\nMinimum value:\ndb.pgbouncer.num_pools.min\nThe number of connection pools.\nCounts\n\u274c\n\u2714\ufe0f\nOperation\nDescription\nDescribeDBInstancePerformance\nQueries the performance data of an instance.\nDescribeAvailableMetrics\nQueries the list of available Enhanced Monitoring metrics.\nModifyDBInstanceMetrics\nModifies displayed Enhanced Monitoring metrics.\nDescribeDBInstanceMetrics\nQueries enabled Enhanced Monitoring metrics."
    },
    "253": {
        "title": "ApsaraDB RDS:View the resource metrics and engine metrics",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/view-the-resource-metrics-and-engine-metrics-of-an-apsaradb-rds-for-mariadb-instance",
        "content": "This Product\nApsaraDB RDS:View the resource metrics and engine metrics\nThis topic describes how to view the resource metrics and engine metrics of an ApsaraDB RDS for MariaDB instance in the ApsaraDB RDS console.\nLog on to the ApsaraDB RDS console.\nIn the left-side navigation pane, click Instances. In the top navigation bar, select the region of your RDS instance.\nFind the RDS instance and click the instance ID.\nIn the left-side navigation pane, click Monitoring and Alerts.\nOn the Standard Monitoring tab, click Resource Monitoring or Engine Monitoring and specify a time range to view the monitoring data. The following table describes the metrics.\nSection\nMetric\nDescription\nResource Monitoring\nIOPS\nThe numbers of input/output operations per second (IOPS) of the data and log disks.\nCPU Utilization and Memory Usage (%)\nThe CPU utilization and memory usage of the RDS instance.\nDisk Space (MB)\nThe disk usage of the RDS instance. The disk usage provides the following information:\nDisk Space Used\nData Space Used\nLog Space Used\nTemporary File Space Used\nSystem File Space Used\nUnit: MB.\nTotal Connections\nThe number of active connections to your RDS instance and the total number of connections to your RDS instance.\nNetwork Traffic (KB)\nThe volumes of inbound and outbound traffic of the RDS instance per second. Unit: KB.\nEngine Monitoring\nTransactions per Second (TPS)/Queries per Second (QPS)\nThe average number of transactions per second (TPS) and the average number of SQL statements that are executed per second.\nInnoDB Buffer Pool Read Hit Ratio, Usage Ratio, and Dirty Block Ratio (%)\nThe read hit ratio, usage, and dirty ratio of the InnoDB buffer pool.\nInnoDB Read/Write Volume (KB)\nThe amount of data that InnoDB reads and writes per second. Unit: KB.\nInnoDB Buffer Pool Read/Write Frequency\nThe number of read and write operations that InnoDB performs per second.\nInnoDB Log Reads, Writes, and fsync() Operations\nThe average frequency of physical writes to log files per second by InnoDB, the frequency of log write requests, and the average frequency of fsync writes to log files.\nTemporary Tables Automatically Created on Hard Disk when MySQL Statements Are Executed\nThe number of temporary tables that are automatically created on the hard disk when SQL statements are executed.\nMySQL_COMDML\nThe number of SQL statements that the database executes per second. The following SQL statements are included:\nInsert\nDelete\nInsert_Select\nReplace\nReplace_Select\nSelect\nUpdate\nMySQL_RowDML\nThe number of operations that InnoDB performs per second. The following items are included:\nThe number of physical writes to log files per second.\nThe number of rows on which InnoDB performs operations per second. This includes the number of rows that are read from InnoDB tables per second, the number of rows that are updated in InnoDB tables per second, the number of rows that are deleted from InnoDB tables per second, and the number of rows that are inserted into InnoDB tables per second.\nMyISAM Reads and Writes\nThe number of reads from the buffer pool by MyISAM per second, the number of writes to the buffer pool by MyISAM per second, the number of reads from the hard disk by MyISAM per second, and the number of writes to the hard disk by MyISAM per second.\nMyISAM Key Buffer Read/Write/Usage Ratio (%)\nThe read hit ratio, write hit ratio, and usage of the MyISAM key buffer per second."
    },
    "254": {
        "title": "ApsaraDB RDS:What are database proxies?",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/what-are-database-proxies",
        "content": "This Product\nApsaraDB RDS:What are database proxies?\nIf your primary ApsaraDB RDS for PostgreSQL instance is heavily loaded due to an excessively large number of connections or your workloads require read/write splitting, you can use the database proxy feature of ApsaraDB RDS for PostgreSQL. This feature provides capabilities such as read/write splitting and transaction splitting to offload requests from the primary RDS instance. This feature is easy to use and maintain and provides high availability and high performance.\nA database proxy serves as a network proxy that resides between your database system and your application and receives all requests from your application. You can connect to your RDS instance by using a database proxy endpoint to use various capabilities of the database proxy feature. This simplifies the connection management of the RDS instance. For more information, see Use a database proxy endpoint to connect to an ApsaraDB RDS for PostgreSQL instance.\nThe primary RDS instance is heavily loaded due to a large number of requests that are encapsulated in transactions.\nThe primary RDS instance is heavily loaded due to an excessively large number of connections.\nRead/write splitting is required.\nYou need to process read-only workloads and isolate workloads.\nAssume that your database system consists of one primary RDS instance and four read-only RDS instances, and you have two applications, Application A and Application B. Application A initiates only read requests, and Application B initiates both read and write requests. You want to connect Application A and Application B to the database system. You can bind two read-only RDS instances to Proxy Terminal A that has the Read-only attribute to process the requests from Application A and bind the primary RDS instance and the other two read-only RDS instances to Proxy Terminal B that has the Read/Write attribute to process the requests from Application B. This way, Application A and Application B are physically isolated from each other in your database system.\ndatabase proxy endpoint (formerly known as proxy terminal)\nDatabase proxy endpoints are the core of database proxies. You can configure connection settings for a database proxy endpoint based on your business requirements, the prefix of the database proxy endpoint, and the port that is associated with the database proxy endpoint. If you use a database proxy endpoint to connect to an RDS instance, you can use the advanced capabilities of the database proxy feature.\nEach RDS instance with the database proxy feature enabled supports up to seven database proxy endpoints. You can apply for one internal endpoint and one public endpoint for each database proxy endpoint. You can also configure connection settings for each database proxy endpoint to meet different business requirements and improve service flexibility. \nFor more information, see Configure the connection settings for a database proxy endpoint and Use a database proxy endpoint to connect to an ApsaraDB RDS for PostgreSQL instance.\nread/write splitting\nRead/write splitting indicates that database proxy endpoints can be used to automatically forward read and write requests.\nIf your database system receives a large number of read requests and a small number of write requests, the primary RDS instance may fail to efficiently process read requests and your workloads may be interrupted. The read/write splitting feature allows the system to forward write requests to the primary RDS instance and read requests to the read-only RDS instances. This reduces the loads on the primary RDS instance. For more information, see What is read/write splitting?\ntransaction splitting\nThe transaction splitting feature is automatically enabled for a database proxy. This feature allows the system to forward the read requests prior to write operations in a transaction to the read-only RDS instances of your database system. This reduces the loads on the primary RDS instance. For more information, see Transaction splitting.\nExplicit transactions cannot be split. These explicit transactions include the transactions that are started by executing the BEGIN or START statement.\nIf the transaction splitting feature is enabled, global consistency cannot be ensured. Before you use this feature, we recommend that you evaluate whether this feature is suitable for your workloads.\nThe transaction splitting feature cannot be disabled.\nApsaraDB RDS for PostgreSQL provides general-purpose and dedicated database proxies.\nGeneral-purpose: Database proxies share physical CPU resources and are provided free of charge. This type of database proxy is cost-effective.\nDedicated: Database proxies exclusively occupy the allocated physical CPU resources and are charged based on the pay-as-you-go billing method. This type of database proxy delivers stable performance.\nThe following table describes the differences between the two types of database proxies.\nItem\nGeneral-purpose database proxy\nDedicated database proxy\nBilling method\nFree of charge.\nPay-as-you-go. For more information, see Billing rules for database proxies.\nResource type\nShares physical CPU resources.\nExclusively occupies physical CPU resources to deliver high performance and stability.\nProxy specifications\nHighest: 16 cores (8 database proxies).\nHighest: 32 cores (16 database proxies).\nRDS edition\nRDS High-availability Edition.\nArchitecture\nHigh-availability redundant architecture.\nRead/write splitting\nSupported.\nTransaction splitting\nSupported.\nNumber of database proxy endpoints\nOne to seven. You can apply for one internal endpoint and one public endpoint for each database proxy endpoint.\nThe following calculation describes the relationship between the specification of database proxies and the number of database proxies: Specification of database proxies = Unit specification of a database proxy \u00d7 Number of database proxies. In this calculation, the unit specification of a database proxy is fixed as 2 CPU cores. For example, if the number of database proxies is 3, the specification of the database proxies is 6 CPU cores. The value is obtained based on the following calculation: 2 x 3 = 6.\nFor more information, see Usage notes of database proxies.\nFor more information, see Billing rules for database proxies.\nFor more information, see Use the database proxy feature."
    },
    "255": {
        "title": "ApsaraDB RDS:Apply for or release a public endpoint",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/apply-for-or-release-a-public-endpoint-for-an-apsaradb-rds-for-mariadb-instance",
        "content": "This Product\nApsaraDB RDS:Apply for or release a public endpoint\nApsaraDB RDS supports two types of endpoints: internal endpoints and public endpoints. By default, you are provided with an internal endpoint that is used to connect to your ApsaraDB RDS for MariaDB instance. If you want to connect to your RDS instance over the Internet, you must apply for a public endpoint.\nEndpoint type\nDescription\nInternal endpoint\nBy default, an internal endpoint is provided. You do not need to apply for the internal endpoint. You cannot release the internal endpoint. However, you can change the network type.\nIf the Elastic Compute Service (ECS) instance on which your application is deployed resides in the same region and has the same network type as your RDS instance, these instances can communicate over an internal network, and you do not need to apply for a public endpoint. For more information, see Network types.\nFor security and performance purposes, we recommend that you connect to your RDS instance by using the internal endpoint.\nPublic endpoint\nYou must manually apply for a public endpoint for your RDS instance. You can release the public endpoint if it is no longer needed.\nIf you cannot connect to your RDS instance by using the internal endpoint, you must apply for a public endpoint. You need to apply for a public endpoint in the following scenarios:\nConnect to your RDS instance from an ECS instance that resides in a different region or has a different network type than your RDS instance. For more information, see Network types.\nConnect to your RDS instance from a device outside Alibaba Cloud.\nYou are not charged for applying for a public endpoint. You are also not charged for the traffic that is generated after you use the public endpoint to connect to your RDS instance over the Internet.\nIf you use a public endpoint to connect to an RDS instance, data security is compromised. Proceed with caution.\nFor faster transmission and higher security, we recommend that you migrate your application to an ECS instance that resides in the same region and has the same network type as the RDS instance. This way, you can connect to the RDS instance by using the internal endpoint.\nApply for or release a public endpoint.\nIf you have not applied for a public endpoint, you can click Apply for Public Endpoint.\nIf you have applied for a public endpoint, click Disable Public Endpoint.\nIn the message that appears, click OK.\n"
    },
    "256": {
        "title": "ApsaraDB RDS:Performance optimization and diagnosis",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/das-overview",
        "content": "This Product\nApsaraDB RDS:Performance optimization and diagnosis\nDuring daily O&M of ApsaraDB RDS for MySQL instances, you can use Database Autonomy Service (DAS) to handle instance failures, optimize instance performance, improve efficiency, and reduce O&M costs. DAS is a cloud service that is developed based on machine learning and expert experience. DAS provides self-awareness, self-healing, self-optimization, self-O&M, and self-securing capabilities to simplify database O&M tasks and ensure the stability, security, and efficiency of database services.\nDAS provides the following features for ApsaraDB RDS for MySQL:\nDiagnostics\nThis feature diagnoses your ApsaraDB RDS for MySQL instance and provides visualized diagnostic results.\nAutonomy center\nThis feature allows you to specify a time range and view events such as exceptions, optimization events, and auto scaling events within the specified time range.\nSession management\nThis feature allows you to view or terminate sessions on your RDS instance. You can also export statistics on the sessions or perform 10-second SQL analysis, SQL throttling, or SQL optimization.\nReal-time monitoring\nThis feature allows you to view the trends and data of performance metrics for your RDS instance in real time.\nDeadlock analysis\nThis feature allows you to view and analyze the latest deadlock in a database.\nCapacity assessment\nThis feature allows you to view the capacity assessment suggestions, performance capacity, storage usage, and the estimated service time of available storage. This feature can also use machine learning and capacity algorithms to predict storage usage.\nStorage analysis\nThis feature allows you to view the storage usage of your RDS instance. For example, you can view the remaining days for which storage is available, the storage usage of individual tables, the tablespace fragments, and the storage exception diagnosis. You can use this feature to identify the storage exceptions at the earliest opportunity to ensure business stability.\nParameter diagnostics\nThis feature allows you to query the static parameter diagnostic results and parameter modification history within the last seven days.\nNew performance insight\nThis feature uses the Performance Schema feature to collect statistics on SQL statements, evaluate the database load, identify the root causes of issues, and provide handling suggestions to improve business stability.\nOriginal performance insight\nThis feature allows you to evaluate the loads of your instance and identify the root causes of performance issues. This improves the stability of your instance.\nDashboard\nThis feature provides various performance metrics and allows you to create custom charts. This feature provides powerful diagnostic capabilities to detect events on your RDS instance at the earliest opportunity and automatically diagnose the events to identify root causes and provide suggestions. You can also specify a time range to manually diagnose the RDS instance to understand the instance performance within the specified time range.\nSlow query log analysis\nThis feature allows you to view the trends of slow SQL queries, the execution status of slow SQL queries, and optimization suggestions for slow SQL queries.\nQuery governance\nThis feature uses the offline data analysis technology to collect statistics on slow SQL queries and analyze the slow SQL queries that are generated on all RDS instances in the previous day at 01:00 every day and automatically adds tags to the slow SQL queries. This way, you can configure settings to automatically classify and prioritize slow SQL queries. This feature also provides governance suggestions and allows you to export data.\nSQL Explorer and Audit\nThis feature is developed based on the full request feature and the SQL Audit feature and provides the following capabilities: Search, SQL Explorer, Security Audit, and Traffic Playback and Stress Test. You can use this feature to obtain information about the SQL statements that are executed. You can use the information to troubleshoot various performance issues, identify the sources of high risks, and verify the instance specifications.\nDiagnostics reports\nThis feature allows you to generate diagnostic reports or view automatically generated reports about instance health, alerts, and slow queries.\nInspection and scoring\nThis feature inspects and scores all RDS instances at regular intervals. You can specify the RDS instances that you want the feature to inspect and score and select the inspection methods. You can also manually trigger instance scoring. This way, you can understand the performance of your RDS instances.\nMonitoring dashboard\nThis feature allows you to specify RDS instances and metrics to monitor and compare the metrics of the RDS instances. You can also configure metric linkage. This way, you can monitor your RDS instances.\nEvent subscription\nThis feature sends you notifications when related events are detected. You can specify a notification method based on your business requirements.\nAutomatic SQL optimization\nThis feature automatically analyzes and optimizes your SQL queries and creates indexes. This way, you can quickly resolve issues about slow SQL queries and ensure the optimal performance of your RDS instance.\nAutomatic SQL throttling\nThis feature allows you to specify conditions to trigger automatic SQL throttling. If the specified conditions are met, automatic SQL throttling is triggered to manage the number of requests to your RDS instance and the number of concurrent SQL queries to ensure service availability.\nAutomatic storage expansion\nThis feature monitors the storage of your RDS instance. When the storage is insufficient, the system automatically expands the storage capacity to ensure business stability.\nAutomatic performance scaling\nThis feature automatically scales up your RDS instance to handle traffic peaks and ensure business stability. This feature also monitors the CPU utilization of the RDS instance in real time. If the CPU utilization per unit of time decreases, this feature automatically scales down the RDS instance.\nAutomatic fragment reclamation\nThis feature is used to optimize the usage of tablespace. After you enable this feature for your RDS instance, the OPTIMIZE TABLE or ALTER TABLE statement is automatically executed on the primary RDS instance to reclaim tablespace fragments.\nPrediction-based auto scaling\nThis feature predicts the values of metrics in the subsequent 24 hours based on the historical data in the most recent 10 days.\nScheduled auto scaling\nThis feature scales up the specifications of your RDS instance based on the configured policy and scales down the specifications to the original specifications after the specified scale-up period ends. This feature helps you manage predictable periodic changes in instance loads and reduce costs while meeting business requirements.\nTo use the features of DAS, you must grant required permissions to RAM users.\nAttach a system policy to grant required permissions to RAM users. For more information, see Grant permissions to RAM users.\nThe following system policies are provided for DAS:\nAliyunHDMFullAccess: grants the RAM user full permissions to manage DAS.\nAliyunHDMReadOnlyAccess: grants the RAM user read-only permissions on DAS.\nAliyunHDMReadOnlyWithSQLLogArchiveAccess: grants the RAM user read-only permissions on DAS and the permissions to use the search capability of the SQL Explorer and Audit feature. The search capability allows you to export data.\nCreate a custom policy to grant required permissions to RAM users. For more information, see Create a custom policy.\nThe following example describes how to grant RAM users read-only permissions on DAS.\nWhat is DAS?"
    },
    "257": {
        "title": "ApsaraDB RDS:Performance optimization and diagnosis",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/overview-of-das",
        "content": "This Product\nApsaraDB RDS:Performance optimization and diagnosis\nDuring daily O&M of ApsaraDB RDS for PostgreSQL instances, you can use Database Autonomy Service (DAS) to handle instance failures, optimize instance performance, improve efficiency, and reduce O&M costs. DAS is a cloud service that is developed based on machine learning and expert experience. DAS provides self-awareness, self-healing, self-optimization, self-O&M, and self-securing capabilities to simplify database O&M and ensure the stability, security, and efficiency of database services.\nAutonomy services that are provided by ApsaraDB RDS for PostgreSQL have the following features:\nAutonomy center\nThis feature allows you to specify a time range and view events such as exceptions, optimization events, and auto scaling events within the specified time range.\nSession management\nThis feature is used to view, export, and close the sessions of your RDS instance.\nReal-time monitoring\nThis feature is used to view the real-time performance of your RDS instance.\nStorage analysis\nThis feature allows you to view the storage usage of your RDS instance. For example, you can view the remaining days for which storage is available, the storage usage of individual tables, the tablespace fragments, and the storage exception diagnosis. You can use this feature to identify the storage exceptions at the earliest opportunity to ensure business stability.\nPerformance insight\nThis feature is used to monitor loads, analyze data, and optimize performance. You can use this feature to evaluate the loads of your RDS instance and identify the root causes of performance issues to improve the stability of your RDS instance.\nPerformance trend\nThis feature allows you to view performance trends over specified time ranges, compare performance trends, and customize charts to view the performance trends of your RDS instance.\nSlow SQL statement analysis\nThis feature is used to check the trends, execution, and optimization suggestions for slow query logs of your RDS instance.\nSQL Explorer and Audit\nThis feature is based on the full request analysis and security audit capabilities and is integrated with the SQL statement search feature and the SQL Explorer feature. You can use the SQL Explorer and Audit feature to query information about the SQL statements that are executed on your RDS instance. Then, you can use the information to troubleshoot various performance issues.\nMonitoring dashboard\nThis feature allows you to specify RDS instances and metrics to monitor and compare the metrics of the RDS instances. You can also configure metric linkage. This helps you monitor your RDS instances.\nEvent alerting\nThis feature is used to send you notifications when specified events occur. You can specify a notification method based on your business requirements.\nAutomatic SQL optimization\nThis feature is used to automatically analyze and optimize your SQL queries and create indexes. This helps you quickly resolve issues related slow SQL queries and ensure the optimal performance of your RDS instance.\nAutomatic storage expansion\nThis feature is used to automatically expand the storage capacity of your RDS instance when the used storage of your RDS instance is greater than or equal to the specified threshold. This helps ensure the business stability."
    },
    "258": {
        "title": "ApsaraDB RDS:Backup",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/methods-to-back-up-an-apsaradb-rds-for-mariadb-instance",
        "content": "This Product\nApsaraDB RDS:Backup\nThis topic describes the methods that can be used to back up an ApsaraDB RDS for MariaDB instance.\nScenario\nMethod\nReferences\nPerform backups\nPerform an automatic backup.\nBack up MariaDB data\nPerform a data backup.\nPerform a log backup.\nDownload backup files\nDownload log backup files.\nYou cannot download the data backup files of your RDS instance. However, you can use the restoration feature to restore the data of your RDS instance to the same RDS instance or to a new RDS instance.\nDownload the log backup files of an ApsaraDB RDS for MariaDB instance\nRestore data\nRestore the data of your RDS instance to a new RDS instance.\nRestore data\nView the free quota\nView the free quota on the backup storage of your RDS instance.\nView the free quota for backup storage of an ApsaraDB RDS for MariaDB instance"
    },
    "259": {
        "title": "ApsaraDB RDS:Restore data",
        "url": "https://www.alibabacloud.com/help/en/rds/apsaradb-rds-for-mariadb/restore-the-data-of-an-apsaradb-rds-for-mariadb-instance",
        "content": "This Product\nApsaraDB RDS:Restore data\nIf a backup set is created for an ApsaraDB RDS for MariaDB instance, you can use the backup set to restore the backup data to a new RDS instance. This method is suitable for the analysis of historical data and the restoration of data on which unintended operations are performed.\nApsaraDB RDS for MariaDB allows you to restore data from backup sets. The entire restoration process consists of the following steps:\nRestore the backup data of the original RDS instance to a new RDS instance.\nLog on to the new RDS instance and verify the data on the new RDS instance.\nMigrate the data from the new RDS instance to the original RDS instance.\nThe original RDS instance meets the following requirements:\nThe RDS instance is in the Running state and is not locked.\nNo ongoing migration tasks exist.\nAt least one backup set is complete. This requirement must be met if you want to restore data from backup sets.\nThe new RDS instance has the same IP address whitelists, backup settings, and parameter settings as the original RDS instance.\nThe information about the data of the new RDS instance is the same as the information about the data in the backup set that you select.\nThe new RDS instance contains the account information in the backup set that you select.\nYou are charged for the new RDS instance. You can view the price of the new RDS instance when you create the instance.\nIf you want to temporarily use an RDS instance, you can create a pay-as-you-go RDS instance. After data is restored to the new RDS instance, you can migrate the data to the original RDS instance and then release the new RDS instance. For more information, see Migrate data between ApsaraDB RDS instances and Release or unsubscribe from an ApsaraDB RDS for MariaDB instance.\nYou are immediately charged for the new RDS instance after the instance is created.\nLog on to the ApsaraDB RDS console and go to the Instances page. In the top navigation bar, select the region in which the RDS instance resides. Then, find the RDS instance and click the instance ID.\nIn the left-side navigation pane of the page that appears, click Backup and Restoration.\nIn the upper-left corner of the page that appears, click Restore Database.\nConfigure the following parameters.\nParameter\nDescription\nBilling Method\nSubscription: A subscription RDS instance is an instance for which you pay an upfront fee. The subscription billing method is more cost-effective than the pay-as-you-go billing method. You are offered lower prices for longer subscription durations.\nPay-As-You-Go: A pay-as-you-go RDS instance is billed per hour based on your actual resource usage. The pay-as-you-go billing method is suitable for short-term use. If you no longer require a pay-as-you-go RDS instance, you can release the pay-as-you-go instance to reduce costs.\nRestore Mode\nThe method that is used to restore data. Only By Backup Set is supported.\nBy Backup Set\nThe backup set that you want to use to restore data.\nEdition\nHigh-availability Edition: The database system adopts the classic high-availability architecture that consists of one primary RDS instance and one secondary RDS instance.\nThe available RDS editions vary based on the region and database engine version that you select. For more information, see Overview of ApsaraDB RDS editions.\nProduct Type\nThe default value is Standard. For more information, see Product types.\nZone of Primary Node\nThe zone of the primary RDS instance.\nDeployment Method\nMulti-zone Deployment: The primary RDS instance and the secondary RDS instance reside in different zones to provide zone-disaster recovery. We recommend that you use this deployment method.\nSingle-zone Deployment: The primary RDS instance and the secondary RDS instance reside in the same zone.\nNo significant differences exist between the zones in the same region.\nIf the RDS instance resides in the same zone as the Elastic Compute Service (ECS) instance on which your application is deployed, these instances can deliver optimal performance. If the RDS instance and the ECS instance reside in different zones in the same region, the performance of the RDS instance and the ECS instance is slightly lower than the performance of the RDS instance and the ECS instance that reside in the same zone.\nIf Sold Out appears in the upper-right corner of a zone name, this zone does not have sufficient resources. In this case, change the zone.\nZone of Secondary Node\nIf you select Multi-zone Deployment for the Deployment Method parameter, you must select the zone in which the secondary RDS instance resides.\nInstance Type\nGeneral-purpose Instance Types: entry-level instance types. You can select a shared or general-purpose instance type. A shared or general-purpose RDS instance exclusively occupies the allocated memory and I/O resources, but shares CPU and storage resources with the other general-purpose RDS instances that are deployed on the same server.\nDedicated Instance Types: enterprise-level instance types. You can select a dedicated or a dedicated host instance type. A dedicated RDS instance exclusively occupies the allocated CPU, memory, storage, and I/O resources. The dedicated host instance family is the highest specifications of the dedicated instance family. A dedicated host RDS instance occupies all the CPU, memory, storage, and I/O resources on the host on which the instance is deployed.\nCapacity\nThe storage capacity is provisioned to store data files, system files, log files, and transaction files in the RDS instance. You can adjust the storage capacity at a step size of 5 GB.\nA dedicated RDS instance that uses local SSDs exclusively occupies the allocated resources, and its storage capacity varies based on the instance type. For more information, see Primary ApsaraDB RDS instance types.\nClick Next: Instance Configuration.\nConfigure the following parameters.\nParameter\nDescription\nNetwork Type\nThe network type of the RDS instance. ApsaraDB RDS for MariaDB supports virtual private clouds (VPCs). A VPC is an isolated network that provides higher security and better performance than the classic network.\nThe network type of the new RDS instance must be the same as the network type of the ECS instance that you want to connect. If the new RDS instance and the ECS instance reside in VPCs, make sure that the instances reside in the same VPC. If the new RDS instance and the ECS instance reside in different VPCs, these instances cannot communicate over an internal network.\nResource Group\nThe resource group to which the new RDS instance belongs.\nClick Next: Confirm Order.\nConfirm the settings in the Parameters section, configure the Purchase Plan and Duration parameters, read and select Terms of Service, click Pay Now, and then complete the payment. You must specify the Duration parameter only when the RDS instance uses the Subscription billing method.\nFor more information about how to log on to an RDS instance, see Connect to an ApsaraDB RDS for MariaDB instance.\nAfter you verify the data on the new RDS instance, you can migrate the data from the new RDS instance to the original RDS instance. For more information, see Migrate data between ApsaraDB RDS instances.\nData migration indicates the process of replicating the data of the source RDS instance to the destination RDS instance. Data migration does not interrupt the workloads on the source RDS instances."
    },
    "260": {
        "title": "ApsaraDB RDS:Terraform",
        "url": "https://www.alibabacloud.com/help/en/apsaradb-for-rds/latest/terraform-summary",
        "content": "This Product\nApsaraDB RDS:Terraform\nTerraform is an open source tool that allows you to preview, configure, and manage cloud infrastructure and resources in a secure and efficient manner.\nTerraform is a tool provided by HashiCorp to automate IT infrastructure orchestration. Terraform allows you to use code to manage and maintain IT resources. Terraform also allows you to define infrastructure resources such as virtual machines (VMs), storage accounts, and network interfaces in the configuration files that describe cloud resource topologies. The CLI of Terraform allows you to use a template syntax to define, preview, and deploy infrastructure in Alibaba Cloud. You can use Terraform to create, modify, and delete cloud resources, such as Elastic Compute Service (ECS) instances, virtual private clouds (VPCs), ApsaraDB RDS instances, and Server Load Balancer (SLB) instance. For more information, visit HashiCorp Terraform.\nThis document describes how to use Terraform to create and use an ApsaraDB RDS for PostgreSQL instance.\nMulti-cloud infrastructure deployment\nTerraform is suitable for multi-cloud scenarios in which similar infrastructure is deployed on Alibaba Cloud, clouds of other providers, and data centers. Terraform allows developers to use the same tools and similar configuration files to manage infrastructure resources that are built on clouds of different providers.\nAutomated infrastructure management\nTerraform can create configuration file templates to define and provision ECS resources in a repeatable and predictable manner. This reduces human errors during deployment and management. Terraform can deploy the same template multiple times to create identical development, test, and production environments.\nInfrastructure as code\nIn Terraform, you can use code to manage and maintain resources. Terraform stores a copy of the current state of your infrastructure. This way, you can track changes made to components in the infrastructure as code (IaC) and share infrastructure configurations with other users.\nReduced development costs\nYou can use Terraform to create development and deployment environments based on your business requirements. This way, your development and deployment costs can be reduced. In addition, you can evaluate development costs before you make changes to your system.\nFor information about the use scenarios of Terraform, see IaC - Terraform Solution.\nAlibaba Cloud provider\nAlibaba Cloud GitHub\nAlibaba Cloud modules in Terraform Registry\nApsaraDB RDS documentation on Terraform"
    },
    "261": {
        "title": "Virtual Private Cloud:What is a VPC?",
        "url": "https://www.alibabacloud.com/help/en/vpc/product-overview/virtual-private-cloud-overview/",
        "content": "This Product\nVirtual Private Cloud:What is a VPC?\nA virtual private cloud (VPC) is a dedicated private network on the cloud that allows you to configure and manage a logically isolated network. You have complete control over the VPC you have created, including selecting IP address ranges, creating vSwitches, and configuring route tables and gateways.\nVPCs offer the security and configurability that closely resemble a traditional data center, combined with the elasticity and scalability of cloud computing. Within your VPC, you can deploy cloud resources, such as Elastic Compute Service (ECS), ApsaraDB RDS, and Server Load Balancer (SLB) instances.\nVPCs are recognized for their security, reliability, flexibility, ease of use, and scalability.\nSecure and reliable: Each VPC is assigned a unique tunnel ID, which corresponds to a virtualized network. VPCs are isolated from one another by these tunnel IDs.\nFine-grained control: Flexibly manage the inbound and outbound traffic of cloud resources in your VPC by using security group rules and network access control lists (ACLs).\nEase of use: Set up and manage VPCs on the console. A system route table is automatically created after the VPC creation.\nScalable: Create multiple vSwitches to deploy different services. VPCs can be connected to on-premises data centers and other VPCs to expand the network architecture.\nThe following figure illustrates the basic topology of a VPC, which typically includes a private CIDR block, vSwitches, and a route table:\nPrivate CIDR block: IP addresses for your VPC that are represented in the Classless Inter-Domain Routing (CIDR) form. You must specify a private CIDR block for your VPC and vSwitches upon creation.\nRoute table: A set of routes that control the traffic flow in the VPC. A system route table is automatically created for your VPC by default and a system route is added for traffic management.\nvSwitch: Segments a VPC into one or more subnets and connects cloud resources in the VPC. vSwitches in the same VPC can communicate with each other. You can deploy applications across different zones to enhance service availability.\nWith a variety of features available for VPC, you can choose the most appropriate scenario based on your business requirements.\nDeploy applications: When deploying an Internet-facing application in your VPC, you can create vSwitches to divide a VPC into subnets and implement security groups and network ACLs for isolation.\nSeparate business systems: To ensure strict isolation and business security, you can deploy businesses in separate VPCs and enable connectivity between VPCs by leveraging products such as VPC peering connection and Cloud Enterprise Network.\nCreate hybrid cloud: Create a hybrid cloud with Express Connect or VPN Gateway to migrate applications to the cloud and extend your network architecture.\nWhen deploying VPCs, consider factors such as isolation, high availability, disaster recovery, cost, the current business scale, and future expansion plans. For more information, see Plan networks.\nChoose other cloud services to create connectivity tailored to your business and address diverse needs, such as Internet access, VPC peering, and hybrid cloud deployment. For more information, see Network connectivity.\nCreate a VPC with an IPv4 or IPv6 CIDR block through one-click deployment or on the console. For more information, see Create a VPC with an IPv4 CIDR block and Create a VPC with an IPv6 CIDR block.\nYou can manage your VPC with your Alibaba Cloud account in the following ways:\nVPC console: A web interface where you can create, manage, and delete VPCs. For more information, see Create and manage a VPC.\nAlibaba Cloud SDKs: SDKs for programming languages such as Java, Go, PHP, and Python.\nOpenAPI Portal: Allows you to retrieve and call APIs, and dynamically generate SDK sample codes.\nTerraform: An open-source tool that helps you implement version control. You can configure files to orchestrate resources on Alibaba Cloud and other cloud platforms that support Terraform.\nWhile setting up a VPC is free, there are charges associated with features such as VPC peering connections, traffic mirroring, and flow logs.\nDeploying other cloud resources in the VPC, such as ECS or SLB instances, will incur additional costs. For more billing information, see ECS billing, EIP billing, Billing of Internet NAT gateways, and SLB billing."
    },
    "262": {
        "title": "Virtual Private Cloud:Release notes",
        "url": "https://www.alibabacloud.com/help/en/vpc/product-overview/release-notes",
        "content": "This Product\nVirtual Private Cloud:Release notes\nThis topic describes the release notes for virtual private clouds (VPCs) and provides links to references.\nFeature\nType\nDescription\nReference\nIP Address Manager (IPAM)\nUpdate\nWhen an organization has multiple accounts, business accounts can share resource discoveries with the network administrator for centralized management of addresses.\nShared resource discovery for address management\nFeature\nType\nDescription\nReference\nVPC peering connection\nUpdate\nInter-region connections now support two link types, Platnium and Gold, with different levels of network performance.\nVPC peering connections\nFeature\nType\nDescription\nReference\nIPAM\nUpdate\nWhen setting up virtual private clouds (VPCs), you can utilize the control policies of the resource directory to limit accounts to allocating IP addresses only from a common IPAM pool. This standardizes address usage and streamlines management.\nUnified VPC creation from IPAM pools using control policies\nFeature\nType\nDescription\nReferences\nNetwork ACL\nUpdate\nBatch importing and exporting network access control lists (ACLs) is supported to ensure data consistency and configuration efficiency.\nCreate and manage a network ACL\nVPC peering connection\nUpdate\nYou can use PrivateLink to access the OpenAPI services of VPC peering connections.\nUse VPC peering connection for private communication\n\nFeature\nType\nDescription\nReferences\nRoutes\nUpdate\nCustom routes now support Gateway Load Balancer (GWLB) as the next hop.\nRoute tables\nUse custom route tables to manage network traffic\nUpdate\nYou can modify the next hop of custom route entries to dynamically manage network traffic.\nVPC\nUpdate\nYou can configure private domain name resolution for Elastic Compute Service (ECS) instances in VPCs. The private domain names of ECS instances are only effective when DNS hostnames are enabled for the VPC. If DNS hostnames are disabled, the private domain names will become inactive.\nCreate and manage a VPC\nPrivate domain name access in VPC\nFlow logs\nUpdate\nYou can configure the traffic to be captured for specific scenarios. The available options include All Traffic, Traffic Through IPv4 Gateway, Traffic Through NAT Gateway, Traffic Through VPN Gateway, Traffic Through Transit Router, Traffic That Accesses Cloud Service Through Gateway Endpoint, and Traffic That Accesses Express Connect Circuit Through Virtual Border Router (VBR).\nFlow logs\nFeature\nType\nDescription\nReferences\nIPAM\nUpdate\nResource discovery is automatically enabled and associated with the IPAM when you create an IPAM. You can use it to manage the IP addresses of VPCs and vSwitches.\nIPAM\nCreate and manage an IPAM\nUpdate\nYou can monitor IP address usage to manage capacity and scale out resources as needed. This helps to ensure network stability and security.\nIPAM\nCreate and manage an IPAM\nCreate and manage an IPAM pool\nUpdate\nThe resource owner of an IPAM pool can share the pool with other Alibaba Cloud accounts, known as principals. Principals can allocate resources from the shared IPAM pool when creating a VPC.\nUse resource management to share IPAM pools\nRoutes\nUpdate\nA VPC can advertise static routes to an Express Connect Router (ECR). You can advertise a custom route of a VPC system route table to an ECR to implement dynamic route advertisement. If no route conflicts occur, the data center associated with the ECR can learn the route.\nRoute tables\nAdvertise static routes to an ECR to implement dynamic route advertisement\nNetwork ACL\nUpdate\nThe following regions now support IPv6 network access control lists (ACLs): China (Hangzhou), China (Shanghai), China (Qingdao), China (Shenzhen), and US (Silicon Valley).\nNetwork ACLs\nIPv6\nUpdate\nUK (London) now supports IPv6 network ACLs.\nCreate and manage a VPC\n\n\nFeature\nType\nDescription\nReferences\nPrefix list\nUpdate\nThe following regions now support associating security groups with prefix lists: China (Hangzhou), China (Shanghai), China (Nanjing - Local Region) , China (Qingdao), China (Beijing), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), China (Wuhan - Local Region), China (Fuzhou - Local Region), South Korea (Seoul), Singapore, Thailand (Bangkok), UAE (Dubai), and Saudi Arabia (Riyadh).\nPrefix list use cases\nNetwork ACL\nUpdate\nThe following regions now support IPv6 network ACLs: China (Beijing), China (Hohhot), China (Ulanqab), China (Guangzhou), China (Chengdu), China (Hong Kong), South Korea (Seoul), Thailand (Bangkok), UAE (Dubai), and Saudi Arabia (Riyadh).\nNetwork ACLs\n\nFeature\nType\nDescription\nReferences\nIPv4 gateway\nUpdate\nPublic mode is now available for IPv4 gateway deletion, allowing for Internet access with your public IP address. This enhances product functionality by addressing the Internet access issue.\nIPv4 gateway\nCreate and manage an IPv4 gateway\nPrefix list\nUpdate\nThe following regions now support associating security groups with prefix lists: China (Hohhot), Japan (Tokyo), Indonesia (Jakarta), Philippines (Manila), Germany (Frankfurt), UK (London), US (Silicon Valley), and US (Virginia).\nPrefix list use cases\nTraffic mirroring\nUpdate\nChina (Ulanqab) now supports traffic mirroring.\nTraffic mirroring\nNetwork ACL\nUpdate\nThe following regions now support IPv6 network ACLs: Japan (Tokyo), Malaysia (Kuala Lumpur), Indonesia (Jakarta), and US (Virginia).\nNetwork ACLs\nUpdate\nNetwork ACLs support adding rules to a network with several CIDR blocks. The feature streamlines configuration and ensures a consistent security policy for unified access control.\nCreate and manage a network ACL\nFeature\nType\nDescription\nReferences\nFlow log\nUpdate\nThailand (Bangkok) now supports flow flogs.\nFlow logs\nIPv6\nUpdate\nChina (Nanjing - Local Region) now supports IPv6.\nCreate and manage a VPC\n\nRoute table\n\nUpdate\nThe option to turn on or off Accept Advertised Routes is now available.\nCreate and manage route table\nYou can find route sources in route tables.\nRoute tables\nIPAM\nNew\nIPAM is a tool that automates the allocation and tracking of IP addresses, making it easier to plan and manage IP addresses.\nIPAM\nCreate and manage a VPC\nFeature\nType\nDescription\nReferences\nPrefix list\nUpdate\nPrefix lists can be associated with Elastic Compute Service (ECS) security groups.\nPrefix list use cases\nGateway endpoint\nUpdate\nThe following regions now support gateway endpoints: Singapore, UK (London), Indonesia (Jakarta), Japan (Tokyo), Germany (Frankfurt), US (Silicon Valley), and US (Virginia).\n\nRegions that support VPC features\nGateway endpoints\nVPC peering connection\nUpdate\nChina (Wuhan - Local Region) now supports VPC peering connections.\nRegions that support VPC features\nVPC peering connections\nNetwork ACL\nUpdate\nGermany (Frankfurt) now supports IPv6 network ACLs.\nNetwork ACLs\nCreate and manage a network ACL\nFeature\nType\nDescription\nReferences\nRoute table\nUpdate\nThe next hop type of a custom route supports Express Connect Router (ECR).\nRoute tables\nCreate and manage a route table\nNetwork ACL\nUpdate\nNetwork ACLs support IPv4 and IPv6 quotas.\nCreate and manage a network ACL\nAdvanced VPC features\nUpdate\nThe Advanced VPC Feature tab is discontinued and advanced VPC features are irrelevant to ECS instance families.\nLimits and quotas\nCreate and manage a VPC\nCreate and manage a route table\nCreate and manage an IPv4 gateway\nDHCP options sets\nCreate and manage a network ACL\nVPC peering connection\nNew\nYou can use the reachability analyzer to check the connectivity of a VPC peering connection and troubleshoot connection errors.\nUse the reachability analyzer for troubleshooting\nUpdate\nVPC peering connections support inter-region and intra-region quotas.\nLimits and quotas\nVPC peering connections\nUpdate\nUAE (Dubai) now supports VPC peering connections.\nRegions that support VPC features\nVPC peering connections\nFlow log\nUpdate\nChina (Fuzhou - Local Region), South Korea (Seoul), and Philippines (Manila) now support flow logs.\nRegions that support VPC features\nFlow logs\nFeature\nType\nDescription\nReferences\nTraffic mirroring\nUpdate\nChina (Fuzhou - Local Region), China East 1 Finance, and China East 2 Finance now support traffic mirroring.\nTraffic mirroring\n\nFeature\nType\nDescription\nReferences\nPrefix list\nUpdate\nIPv6 prefix lists are supported in all regions.\nPrefix lists\nVPC\nUpdate\nThe following new regions support IPv6 CIDR blocks: US (Silicon Valley) and Thailand (Bangkok).\nCreate and manage a VPC\nFlow log\nUpdate\nThe following new region supports flow logs: Saudi Arabia (Riyadh).\nFlow logs\nTraffic mirroring\nUpdate\nThe following new region supports traffic mirroring: Saudi Arabia (Riyadh).\nTraffic mirroring\nFeature\nType\nDescription\nReferences\nPrefix list\nUpdate\nPrefix lists support IPv6 CIDR blocks.\nThis feature is only available in Philippines (Manila).\nPrefix lists\nCreate and manage a prefix list\nUpdate\nPrefix lists support instance import and clone in batches.\nCreate and manage a prefix list\nNetwork ACL\nUpdate\nInbound and outbound rules of network ACLs support IPv6 CIDR blocks.\nThis feature is only available in Philippines (Manila).\nCreate and manage a network ACL\nVPC\nUpdate\nThe IPv6 feature is supported in China (Wuhan - Local Region) and Malaysia (Kuala Lumpur).\nCreate and manage a VPC\nFeature\nType\nDescription\nReferences\nVPC peering connection\nUpdate\nVPCs with IPv6 enabled support VPC peering connections.\nVPC peering connections\nUse VPC peering connection for private communication\nExamples of VPC peering connections\nFeature\nType\nDescription\nReferences\nReserved CIDR block\nNew\nYou can add reserved CIDR blocks to vSwitches.\nAdd a reserved CIDR block\nFeature\nType\nDescription\nReferences\nIPv4 gateway\nNew\nAn IPv4 gateway is a network component that connects a VPC to the Internet by handling routing and converting private IPs to public IPs. A VPC can access the Internet through an IPv4 gateway.\nIPv4 gateway\nCreate and manage an IPv4 gateway\nCreate and enable an IPv4 gateway in a VPC associated with an Internet NAT gateway\nFAQ\nFeature\nType\nDescription\nReferences\nPrefix list\nNew\nA prefix list consists of one or more CIDR blocks. You can use prefix lists to facilitate the configuration and management of VPC route tables and Cloud Enterprise Network (CEN) route tables. You can share prefix lists with other Alibaba Cloud accounts by using the Resource Management service.\nPrefix lists\nCreate and manage a prefix list\nPrefix list use cases\n\nFeature\nType\nDescription\nReferences\nVPC peering connection\nNew\nYou can create peering connections to connect VPCs that are in the same or different regions and belong to the same or different Alibaba Cloud accounts.\nVPC peering connections\nUse VPC peering connection for private communication\nExamples of VPC peering connections\nMonitoring and O&M for VPC peering connections\n\nFeature\nType\nDescription\nReferences\nDHCP options set\nUpdate\nThe DHCP options set feature is released.\nDHCP options sets\nFeature\nType\nDescription\nReferences\nTraffic mirroring\nNew\nThe traffic mirroring feature can mirror packets that flow through an elastic network interface (ENI) and that meet specific filters. You can use traffic mirroring to mirror network traffic from an ECS instance in a VPC and forward the traffic to a specified ENI or an internal-facing Classic Load Balancer (CLB) instance. This feature can be used in scenarios such as content inspection, threat monitoring, and troubleshooting.\nTraffic mirroring\nWork with traffic mirroring\nNetwork ACL\nUpdate\nThe DHCP options set feature is released.\nNetwork ACLs\nFeature\nType\nDescription\nReferences\nVPC sharing\nNew\nMultiple Alibaba Cloud accounts can create cloud resources in a centrally managed and shared VPC.\nVPC sharing\nFeature\nType\nDescription\nReferences\nVPC\nNew\nSpecification checks for ECS instances in VPCs are supported.\n\nFeature\nType\nDescription\nReferences\nHigh-availability virtual IP address (HAVIP)\nNew\nHAVIPs can be associated with ENIs.\nAssociate with and disassociate from an ECS instance or an ENI\nFeature\nType\nDescription\nReferences\nVPC\nNew\nAvailable in new regions.\nCreate and manage a VPC\nFeature\nType\nDescription\nReferences\nNetwork ACL\nNew\nNetwork ACLs allow you to implement access control for VPCs. You can create network ACL rules and associate a network ACL with a vSwitch to control inbound and outbound traffic of ECS instances attached to the vSwitch.\nNetwork ACLs\nCommon scenarios\nCreate and manage a network ACL\nBest practices\nFeature\nType\nDescription\nReferences\nVPC\nNew\nIPv4 and IPv6 CIDR blocks are supported.\nCreate and manage a VPC\nFeature\nType\nDescription\nReferences\nFlow log\nUpdate\nThe log analytics report feature can be enabled when a flow log is created.\nCreate and manage a flow log\nFeature\nType\nDescription\nReferences\nvSwitch\nUpdate\nvSwitches can be queried by zone in the VPC console.\nCreate and manage a vSwitch\nFlow log\nNew\nVPC now provides the flow log feature, which records information about inbound and outbound traffic of an ENI. You can check access control rules, monitor network traffic, and troubleshoot network errors with flow logs.\nFlow logs\nBilling of flow logs\nCreate and manage a flow log\nExamples\nFeature\nType\nDescription\nReferences\nRoute table\nNew\nYou can create a custom route table in a VPC and associate it with a vSwitch to manage the routing for that vSwitch, which is referred to as subnet routing. This allows for flexible network management.\nCreate and manage a route table\nRoute table\nNew\nENIs can be specified as the next hops of custom routes.\nCreate and manage a route table\nFeature\nType\nDescription\nReferences\nVPC\nNew\nVPC is available for all Alibaba Cloud users for free.\nCreate and manage a VPC\nFeature\nType\nDescription\nReferences\nVPC\nUpdate\nThe quota of VPCs is assigned based on the region instead of the Alibaba Cloud account.\nManage resource quotas\nFeature\nType\nDescription\nReferences\nClassicLink feature\nNew\nVPC provides the ClassicLink feature, which allows ECS instances in classic networks to communicate with cloud resources deployed in VPCs.\nUse ClassicLink to connect a classic network and a VPC\nFeature\nType\nDescription\nReferences\nvSwitch\nUpdate\nAPI operations can be called to query the vSwitches in a region.\nVPCs and vSwitches\n"
    },
    "263": {
        "title": "Virtual Private Cloud:Announcements",
        "url": "https://www.alibabacloud.com/help/en/vpc/product-overview/product-bulletin/",
        "content": "This Product\nVirtual Private Cloud:Announcements"
    },
    "264": {
        "title": "Virtual Private Cloud:Beginner guide",
        "url": "https://www.alibabacloud.com/help/en/vpc/getting-started/getting-started",
        "content": "This Product\nVirtual Private Cloud:Beginner guide\nCreating a virtual private cloud (VPC) is the first step in cloud adoption. Planning your VPC with business scale and potential expansion in mind is crucial. You can tailor your network design to your specific business needs and select appropriate connectivity solutions for fast VPC deployment. This document provides a brief overview of what a VPC is and its features, guiding you through network planning and network connectivity. It aims to equip you with a thorough understanding before VPC deployment.\nA VPC is your private cloud network that gives you full control over configurations such as IP address ranges, routes, and gateways. You can create resources in the VPC, such as Elastic Compute Service (ECS), Server Load Balancer (SLB), and ApsaraDB RDS. For more information about VPCs and their benefits, see VPC overview and Benefits.\nThe following diagram illustrates the basic topology of a VPC, which includes three essential components: a private CIDR block, a vSwitch, and a route table. For more information, see Service architecture.\nPrivate CIDR block: When creating a VPC and vSwitches, specify a private CIDR block for the VPC.\nSystem route table: After creating a VPC, the system automatically creates a system route table and adds routes to manage traffic.\nvSwitch: vSwitches connect cloud resources in a VPC. You can deploy applications in vSwitches of different zones to improve availability.\nWhile VPCs are free of charge, you are billed for features such as VPC peering connections, traffic mirroring, and flow logs. For more information, see VPC peering connection, Traffic mirroring billing, and Flow log billing.\nAny other resources you deploy in the VPC will incur additional fees. For more information, see ECS billing, EIP billing, NAT gateway billing, and SLB billing.\nVPCs have a wide variety of features available to meet your needs, whether you are building a complex network architecture or implementing fine-grained security policies.\nScenario\nFeature\nDescription\nAddress planning and management\nIP Address Manager (IPAM)\nAutomates the allocation and tracking of IP addresses and detects address conflicts when you enable this feature, thereby reducing the workload of administrators.\nVPC connection\nVPC peering connection\nEnables network communication between two VPCs, whether they belong to the same account or different accounts, and whether they are in the same or different regions.\nMulti-account management\nVPC sharing\nAllows you to share cloud resources across accounts without creating and maintaining a VPC for each account. This simplifies network configuration and management.\nInternet access control\nIPv4 gateway/IPv6 gateway\nCentralizes the management of instance access to the Internet in a VPC. This enhances security protection by controlling Internet access.\nTraffic control\nCustom route table\nYou can create custom route tables and add route entries for flexible network management.\nPrefix list\nSimplifies the configuration and management of route tables and security groups.\nAccess control\nNetwork ACL\nYou can customize network access control list (ACLs) rules and bind them to vSwitches to manage the traffic access for ECS instances in the vSwitches.\nOM and monitoring\nFlow logs\nRecord the traffic information of an elastic network interface (ENI) in the VPC, facilitating the access control review, network traffic monitoring, and troubleshooting.\nTraffic mirroring\nMirrors packets that pass through ENIs based on specified filters. This is useful for content inspection, threat monitoring, and troubleshooting.\nHigh availability architecture\nHAVIP\nWith the high-availability virtual IP address (HAVIP) feature, you can build a high-availability architecture on the cloud based on the Address Resolution Protocol (ARP) using Keepalived or Heartbeat software. This ensures that the service IP remains unchanged during the master-replica switchover.\nWhen deploying your cloud network using VPCs, you need to consider factors such as isolation, high availability, disaster recovery, and cost efficiency. By planning your network architecture, you can align it with both your current scale and expansion needs. For more information, see Plan networks.\nItem\nSuggestion\nRegion and zone\nSelect the appropriate region and zone based on your requirements on latency and high availability, the types and quantities of cloud resources to be deployed, and your budget.\nAccount\nAs your business grows, it is vital to create an account architecture for user permission allocation and secure environment isolation. This design should consider factors such as effective isolation, security compliance, log management, operation and maintenance, and cost efficiency.\nNumber of VPCs\nDecide how many VPCs are needed based on your business scale and the need for strong security isolation or disaster recovery.\nNumber of vSwitches\nTo enhance security, we recommend that you create vSwitches that correspond to business modules, dividing the network into multiple subnets. For example, creating separate vSwitches for the web layer, logic layer, and data layer will help achieve hosting of standard web application architecture.\nWe also recommend that you deploy cloud services to different vSwitches based on whether they need direct access to the Internet. This separates public and private networks and ensures secure access of cloud services.\nCIDR block\nAvoid network conflicts and ensure network scalability when configuring CIDR block, as improper planning results in high reconstruction costs.\nYou can use IPAM to enhance planning efficiency.\nDepending on the context, you can strategically combine your VPC with cloud resources to enable network connections for features such as Internet access, VPC connections, and hybrid cloud deployment. For more information, see Network connectivity.\nScenario\nDescription\nSolution\nInternet access\nThe Internet accesses applications deployed on the cloud, or the other way round.\nUse Elastic IP Address to configure public IP addresses for application servers.\nDeploy Server Load Balancer to have a unified entry for incoming traffic from the Internet.\nCreate a central gateway for outgoing traffic to the Internet with the SNAT feature of the NAT gateway.\nUse IPv4 gateway and IPv6 gateway for centralized access control.\nVPC connection\nEstablish secure, efficient private network communication between resources in different VPCs.\nConnect two VPCs:\nVPC peering connection is a budget-friendly, low-latency solution. It is free of charge if the VPCs are in the same region. However, it does not support route propagation and configuration can be complex.\nVPN Gateway provides a secure connection through an encrypted tunnel, but it usually comes with higher latency.\nConnect and manage multiple VPCs: Use Cloud Enterprise Network (CEN) to connect network instances through a transit router, which forwards traffic between instances in the same region or across regions. It supports route propagation with reduced configuration complexity.\nSecure private network access in the same region: Use PrivateLink to create connections between VPCs in which endpoints are deployed. Connections across regions are not supported.\nHybrid cloud\nConnect on-premises data centers to VPCs to build a hybrid cloud.\nFast, stable, and highly available hybrid cloud: Utilize Express Connect to establish a reliable, secure, and fast connection between the on-premises data centers and VPCs.\nSimple and fast hybrid cloud: Leverage VPN gateway to deploy hybrid cloud through an encrypted tunnel.\nEnterprise-level hybrid cloud: Use CEN to connect multiple network instances such as VPC, virtual border routers (VBR), and IPsec-VPN connection to build an enterprise-level network.\nYou can choose quick deployment or use the console to create VPCs with IPv4 and IPv6 CIDR blocks.\nIf you need to create a VPC with only an IPv4 CIDR block, see Create a VPC with an IPv4 CIDR block.\nIf you need to create a dual-stack VPC with IPv4 and IPv6 CIDR blocks, see Create a VPC with an IPv6 CIDR block.\nIf you have knowledge of network service protocols and programming languages, you can call APIs to manage your cloud resources and develop your applications. For more information, see API Overview.\nOpenAPI can dynamically generate SDK codes as needed, making it easy to use the SDK.\nTo enhance your experience, please share your feedback or seek technical support in one of the following ways if you have any questions while using VPCs:\nPre-sales support: Learn about products or get a consultation by using Alibaba Cloud pre-sales service or contacting your account manager. For more information, see Pre-sales Consultation.\nAfter-sales support: If you have problems while using products or services, you can call the Alibaba Cloud after-sales service or submit a ticket. For more information, see After-sales Support.\nDocumentation feedback: If you find documentation issues such as links, information, and API errors, you can click Feedback in the floating menu on the right side of the documentation page to provide feedback."
    },
    "265": {
        "title": "Virtual Private Cloud:Plan networks",
        "url": "https://www.alibabacloud.com/help/en/vpc/getting-started/network-planning",
        "content": "This Product\nVirtual Private Cloud:Plan networks\nIf you want to use Virtual Private Cloud (VPC) to deploy your services, you need to plan networks for your VPC based on your current business requirements and expected expansion in the future. This ensures that your current services can run as expected and allows business growth.\nTo ensure service stability and network scalability, you need to consider security isolation, disaster recovery, and O&M costs. Improperly designed networks are not suitable for future business growth and may even bring unexpected risks. If the existing network architecture does not meet your business growth requirements, network reconstruction will cause high costs and may affect your current business. Therefore, it is essential to properly design your networks from multiple levels and dimensions. To ensure network stability and scalability, you can perform the following steps to plan your VPC.\nInstances in different zones within a region can communicate with each other. Even if one zone is down, other zones can work as expected. The network latency between instances in the same zone is low. You can plan regions and zones based on the following information.\nItem\nDescription\nLatency requirement\nIf user locations are close to the regions where the resources are deployed, the network latency is low and the access is fast.\nSupported regions and zones\nDifferent Alibaba Cloud services are supported by different regions and zones. You can select a zone and a region based on the service that you require.\nCost\nThe price of a cloud service may vary with the region. We recommend that you select a region based on your requirements.\nHigh availability and disaster recovery\nIf your services require high disaster recovery capabilities, you can deploy your services in different zones within the same region. You can also deploy your services in multiple regions to implement inter-region disaster recovery.\nCompliance\nYou need to select a region that meets the data compliance requirements and business filing policies of your country or region.\nA VPC cannot be deployed across regions. If you want to deploy your services across regions, you must create a VPC in each region. You can use VPC peering connections or Cloud Enterprise Network (CEN) to enable communication among VPCs in different regions. vSwitches are zone-level resources. When you use vSwitches, take note of the following information:\nIf you select multiple zones due to the Elastic Compute Service (ECS) inventory factor, you need to reserve sufficient CIDR blocks in advance and take into account the latency increase caused by traffic detours between zones.\nSome regions provide only one zone, such as China (Nanjing - Local Region). If you have requirements for intra-region disaster recovery, we recommend that you cautiously consider selecting this region.\nAfter you plan the regions and zones, you can create VPC resources. In this process, you need to consider your business scale and security isolation requirements for account planning, VPC planning, and vSwitch planning. This optimizes resource usage and reduces costs.\nIf your business scale is small, you can use one Alibaba Cloud account or one RAM user to manage resources. In this case, you can skip this section. When your business scale increases, you need to plan accounts based on the user permissions and security isolation requirements.\nItem\nDescription\nDepartment isolation\nWe recommend that you create independent accounts for different business departments to facilitate management for resources, costs, and permissions. If your project requires specific resources and permissions, we recommend that you create an independent account for the project.\nSystem isolation\nIf your business has isolation requirements, such as isolation between the production environment and staging environment, you can create independent accounts.\nSecurity compliance\nTo meet specific security compliance requirements, we recommend that you keep sensitive data or workloads to independent accounts.\nBill management\nYou can use multiple accounts to isolate resources. This facilitates cost tracking and billing management.\nLog management and O&M\nYou can use an independent account to store log data of all accounts. This facilitates security auditing.\nThe network complexity increases as the numbers of VPCs and accounts increase. You can use the VPC sharing feature to reduce network complexity while maintaining network security and stability.\nVPC provides a secure and flexible network environment in the cloud. Different VPCs are isolated from each other. Instances in a VPC can communicate with each other. You can plan the number of your VPCs based on your business requirements.\n\nScenarios\nOne VPC\nYour service is deployed in one region and the business scale is small. In addition, you do not have requirements for network isolation.\nIf you use VPC for the first time, we recommend that you use one VPC to quickly get started.\nYou focus on costs and do not want to pay for multiple VPCs.\nMultiple VPCs\nYour services need to be deployed in different regions and the business scale is large.\nServices in one region need to be isolated.\nThe business architecture is complex, and each department needs independent management.\nSuitable scenarios for multiple VPCs\nWe recommend that you use multiple VPCs in the following scenarios:\nInter-region deployment\nA VPC cannot be deployed across regions. Therefore, if you want to deploy your application systems in different regions, you must create multiple VPCs. You can use VPC peering connections, CEN, and VPN gateways to connect VPCs that are deployed in different regions.\nService isolation\nIf your services have isolation requirements, such as isolation between the production and staging environment, you can deploy your services in different VPCs. You can also use VPC peering connections, CEN, and VPN gateways to connect VPCs deployed in the same region.\n\nLarge-scale business system\nIf your business architecture is complex and each department needs to independently manage VPC resources.\nBy default, you can create at most 10 VPCs in each region. You can go to the Quota Management page or Quota Center page to request a quota increase.\nvSwitches are zone-level resources. All instances in VPCs are deployed in vSwitches. vSwitch division helps you properly plan IP addresses. vSwitches in a VPC can communicate with each other by default.\nItem\nDescription\nLatency\nThe latency between zones in the same region is low. However, complex system calls and cross-zone calls may increase the latency.\nHigh availability and disaster recovery\nWe recommend that you create at least two vSwitches in a VPC and deploy the vSwitches in different zones to implement cross-zone disaster recovery. You can deploy services in multiple zones and configure security rules in a unified manner. This improves the system availability and disaster recovery capability.\nBusiness scale and division\nTypically, you can deploy different service modules in different vSwitches. For example, you can deploy the web layer, logic layer, and data layer in different vSwitches to create a standard web architecture.\nYou can plan vSwitches based on the following information:\nWhen you use a VPC, we recommend that you deploy at least two vSwitches in different zones. This way, when one vSwitch is down, the other vSwitch in another zone can take over, which implements cross-zone disaster recovery.\nThe latency between zones in the same region is low. However, the latency needs to be adapted and verified by the business system. The network latency may be increased due to the complex network topology. We recommend that you optimize and adapt the system to meet your requirements for high availability and low latency.\nIn addition, the scale and planning of your service system must also be taken into consideration when you determine the number of vSwitches to be created. In normal cases, you can plan vSwitches based on your business attributes. For example, Internet services need to deployed in a public vSwitch, and other services can be deployed accordingly. After your services are deployed in multiple zones, you can configure security policies in a unified manner.\nBy default, you can create at most 150 vSwitches in each VPC. You can go to the Quota Management page or Quota Center page to request a quota increase.\nWhen you create a VPC and vSwitch, you need to specify the VPC CIDR block and the vSwitch CIDR block. The size of the CIDR block determines the amount of resources that can be deployed. Proper CIDR block planning avoids address conflicts and ensures the network scalability, whereas improper planning may cause high costs for network reconstruction.\nAfter you specify a vSwitch CIDR block, you cannot modify it.\nIf the address space is insufficient due to improper planning, you can add secondary CIDR blocks to expand the address space. You cannot modify secondary CIDR blocks.\nWe provide the following suggestions for planning VPC CIDR blocks and vSwitch CIDR blocks:\nWe recommend that you use private IPv4 CIDR blocks defined by RFC 1918 and use the /16 network mask for VPC. To expand a VPC address space, we recommend that you add secondary CIDR blocks to the VPC.\nIf you deploy your services in one VPC, we recommend that you use a large-size network mask to reserve sufficient addresses for later use.\nWe recommend that you avoid CIDR block overlap when you plan CIDR blocks for VPCs.\nWe also recommend that you avoid CIDR block overlap when you plan zones for disaster recovery.\nAs the network scale increases, CIDR block planning becomes more complex and difficult. You can use IP Address Manager (IPAM) to automatically assign IP addresses and detect potential IP address conflicts. This improves the efficiency of CIDR block planning. For more information, see IP Address Manager (IPAM).\nWe provide the following suggestions on using IPAM:\nDesign different IPAM pools for different environments, such as the development environment, and the production environment.\nWhen you use IPAM pools to allocate private CIDR blocks to VPCs, make sure that the CIDR blocks do not overlap with each other.\nYou can view the information about VPC CIDR blocks and address usage by using IPAM.\n\nYou can use the standard RFC CIDR blocks: 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16, or their subsets as the VPC CIDR blocks. You can also specify custom VPC CIDR blocks.\nVPC CIDR block\nIP address range\nMask range\nVPC CIDR block example\n10.0.0.0/8-24\n10.0.0.0 to 10.255.255.255\n8 to 24\n10.0.0.0/16\n172.16.0.0/12-24\n172.16.0.0 to 172.31.255.255\n12 to 24\n172.30.0.0/16\n192.168.0.0/16-24\n192.168.0.0 to 192.168.255.255\n16 to 24\n192.168.0.0/24\nWhen you specify CIDR blocks for VPCs, take note of the following rules:\nIf you have only one VPC and the VPC does not need to communicate with a data center, you can specify one of the RFC CIDR blocks or their subsets as the VPC CIDR block.\nIf you have multiple VPCs or want to set up a hybrid cloud environment between a VPC and your data center, we recommend that you specify the subsets of the RFC CIDR blocks for your VPCs. In this case, we recommend that you set the subnet mask length to 16 bits or less. Make sure that the CIDR blocks of the VPCs and your data center do not overlap.\nYou cannot specify 100.64.0.0/10, 224.0.0.0/4, 127.0.0.0/8, 169.254.0.0/16, or one of their subsets as the custom CIDR block.\nYou must check whether a classic network is used before you specify a CIDR block for your VPC. If the classic network is used and you want to connect ECS instances in the classic network to your VPC, do not specify 10.0.0.0/8 as the VPC CIDR block because the CIDR block of the classic network is 10.0.0.0/8.\nYou can use IPAM to plan pools and specify a default network mask for allocations. You can also view the address usage of a VPC by using IPAM.\nThe CIDR block of a vSwitch must be a subset of the CIDR block of the VPC to which the vSwitch belongs. For example, if the CIDR block of the VPC is 192.168.0.0/24, the network mask of vSwitches in the VPC must be /25 to /29.\nWhen you specify CIDR blocks for vSwitches, take note of the following limits:\nThe network mask of the IPv4 CIDR block for a vSwitch must be /16 to /29, which can provide 8 to 65,536 IP addresses.\nMake sure that the vSwitch CIDR block is different from the VPC CIDR block.\nWhen you plan the CIDR block of a vSwitch, you need to consider the number of ECS instances and other cloud resources that can be allocated to the vSwitch. We recommend that you specify a large CIDR block to reserve sufficient IP addresses for later use. However, if the CIDR block is too large, you cannot expand it. If a VPC CIDR block is 10.0.0.0/16, the VPC supports 65,536 IP addresses. Because ECS instances and ApsaraDB RDS instances need to be deployed in vSwitches, we recommend that you specify /24 as the vSwitch network mask, which supports 256 IP addresses. A VPC with a CIDR block of 10.0.0.0/16 can be divided into at most 256 vSwitches with a mask of /24. You can make appropriate adjustments based on the preceding suggestions.\nIf a vSwitch is assigned an IPv4 CIDR block, the first IPv4 address and last three IPv4 addresses are reserved by the system. If a vSwitch is assigned an IPv6 CIDR block, the first IPv6 address and last three IPv6 addresses are reserved by the system. The following table provides an example.\n\nvSwitch CIDR block\nReserved IP addresses\nIPv4 CIDR block\n192.168.1.0/24\n192.168.1.0\n192.168.1.253\n192.168.1.254\n192.168.1.255\nIPv6 CIDR block\n2001:XXXX:XXXX:1a00/64\n2001:XXXX:XXXX:1a00::\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fff7\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fff8\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fff9\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fffa\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fffb\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fffc\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fffd\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:fffe\n2001:XXXX:XXXX:1a00:ffff:ffff:ffff:ffff\nIf multiple VPCs are deployed and a vSwitch needs to communicate with another vSwitch in a different VPC or a data center, make sure that the vSwitch CIDR block does not overlap with the peer CIDR block. Otherwise, communication fails.\nThe ClassicLink feature allows ECS instances in the classic network to communicate with ECS instances in a VPC whose CIDR block is 10.0.0.0/8, 172.16.0.0/12, or 192.168.0.0/16. If the CIDR block of the VPC to communicate with the classic network is 10.0.0.0/8, the CIDR block of the vSwitch that belongs to the VPC must be 10.111.0.0/16. For more information, see Overview of ClassicLink.\nA route table consists of routes. A route consists of the destination CIDR block, next hop type, and next hop. Routes are used to forward traffic to specific destinations. Each VPC can contain a maximum of 10 route tables, including the system route table. You can refer to the following suggestions to plan the number of route tables.\nIf the traffic paths of vSwitches are not significantly different, you can use one route table. After you create a VPC, the system automatically creates a system route table and adds system routes to the table. You cannot create or delete a system route table. However, you can create custom routes in a system route table to route traffic to specific destinations.\nIf the traffic paths of vSwitches are significantly different, for example, you need to control Internet access for some instances, you can use multiple route tables. You can deploy public vSwitches and private vSwitches. Instances in private vSwitches can use an Internet NAT gateway to access the Internet. This ensures unified control for Internet access and meets isolation requirements.\nEach VPC supports at most nine custom route tables. You can go to the Quota Management or Quota Center page to request a quota increase.\nAlibaba Cloud provides a secure and scalable cloud network and supports high-speed and secure connections between the cloud and data centers. You can use a VPC to access the Internet, another VPC, and a data center. You can use VPC and other services for networking based on your requirements.\nWe provide the following suggestions on communication with the Internet:\nIf your service deployed in an ECS instance needs to communicate with the Internet, you need to configure a public IP address for the ECS instance. The public IP address can be a static public IP address or an elastic IP address (EIP). We recommend that you associate an EIP with the ECS instance.\nIf only one ECS instance is used to provide services over the Internet, a single point of failure (SPOF) may occur, which affects the system availability. In actual scenarios, we recommend that you use a Server Load Balancer (SLB) instance as the unified Internet traffic ingress and associate multiple ECS instances with the SLB instance. This prevents SPOFs and improves service availability.\nIf multiple ECS instances need to access the Internet, you can use the SNAT feature of an Internet NAT gateway to allow the ECS instances share EIPs to access the Internet. This saves public IP address resources.\nIf your ECS instances provide services over the Internet, you can use IPv4 gateways and IPv6 gateways to manage Internet access for the ECS instances in a unified manner.\nYou can use the following services to enable communication among VPCs.\nIf you use a small number of VPCs (generally no more than five), you can use VPC peering connections to enable communication between VPCs.\nIf your network architecture is complex and use many VPCs, you can use CEN to manage VPCs in a efficient and unified way. This facilitates O&M and ensures secure data transmission.\nWhen you access an Alibaba Cloud service such as Object Storage Service (OSS) through the Internet, sensitive data may be leaked. To prevent data leakage, you can use PrivateLink to connect the VPC where the endpoint resides to the VPC where the endpoint service resides. This minimizes security risks when you access services over the Internet.\nYou can also use a VPN gateway to establish a secure connection between two VPCs, but the network latency is high.\nYou can use the following services to connect a data center to a VPC to build a hybrid cloud.\nIf you require high security and low latency, you can use Express Connect circuits to connect your data center to a VPC.\nIf you want to reduce costs, you can use a VPN gateway to connect your data center to a VPC through an encrypted tunnel.\nIf you want to connect a VPC to another VPC or a data center, make sure that the CIDR blocks do not overlap with each other. Take note of the following rules when you plan CIDR blocks:\nYou can use subnets of standard CIDR blocks to increase the available number of CIDR blocks supported by a VPC. We recommend that you specify non-overlapping CIDR blocks for different VPCs.\nIf you cannot ensure non-overlapping CIDR blocks for different VPCs, we recommend that you configure non-overlapping CIDR blocks for vSwitches in different VPCs.\nIf you cannot ensure non-overlapping CIDR blocks for vSwitches in different VPCs, we recommend that you configure non-overlapping CIDR blocks for vSwitches that need to communicate with each other.\nThe following figure describes a scenario where VPC1, VPC2, and VPC3 are deployed in the China (Hangzhou), China (Beijing), and China (Shenzhen) regions. VPC1 and VPC2 communicate with each other through VPC peering connections. Currently, VPC3 does not need to communicate with other VPCs. However, VPC3 may need to communicate with VPC2 in the future. In addition, a data center in China (Hangzhou) needs to communicate with VPC1 in the same region through Express Connect circuits. Currently, VPC3 does not need to communicate with other VPCs. However, we still recommend that you configure non-overlapping CIDR blocks for each VPC for further business expansion.\nYou can create three regional pools in an IPAM pool to ensure that sufficient IP addresses can be assigned in each region. You need to create a custom allocation and mark that 10.0.2.0/24 is dedicated to the data center. This prevents IP address conflicts and ensures that the IP addresses will not be misused.\nSecurity isolation includes service isolation, resource isolation, and network isolation. You need to consider security isolation requirements when you plan regions, zones, accounts, and CIDR blocks. Creating RAM users can isolate resources and creating vSwitches for a VPC can isolate networks. Resource isolation and network isolation are methods to implement service isolation. You can implement isolation based on your requirements.\nSecurity layer\nSuggestion\nWithin VPC\nIf you deploy multiple services in a VPC, we recommend that you create a vSwitch for each service and use security groups and network ACLs to implement security isolation.\nVPC border\nWe recommend that you create public vSwitches and private vSwitches based on your requirements. You can deploy services that require direct Internet access in public vSwitches and deploy services that do not require direct Internet access in private vSwitches. In addition, we recommend that you use one vSwitch for as the Internet traffic ingress and another vSwitch as the internet traffic egress.\nWe recommend that you use IPv4 gateways or IPv6 gateways for unified access control and use subnet routes or gateway routes together with firewalls for security protection.\nWe recommend that you configure egress-only rules for the Internet traffic egress to deny access from the Internet.\nYou can use the flow log feature and the traffic mirroring feature to monitor VPCs and troubleshoot issues. This improves the system stability and reliability.\nMonitoring information\nDescription\nFlow log\nYou can use the flow log feature to collect traffic data and analyze traffic logs to optimize bandwidth and reduce network bottlenecks.\nTraffic mirroring\nThe traffic mirroring feature can mirror specific packets that go through ENIs and can be used for content inspection, threat monitoring, and troubleshooting.\n\nYou can plan disaster recovery based on your service architecture to ensure data security and service availability.\nIf you have high requirements for disaster recovery, you can deploy VPCs in different regions and deploy vSwitches in different zones. This implements cross-region and cross-zone disaster recovery.\nIf your service requires fast response, high concurrency, and enhanced data security, you can use SLB to implement cluster recovery, session persistence, and cross-zone deployment.\nIf you need to connect your data centers to VPCs through high-speed and stable connections, you can use Express Connect circuits. This ensures data synchronization, prevents SPOFs, and improves service availability.\nIf you have high requirements for service availability, you can use the high-availability virtual IP address (HAVIP) feature together with Keepalived or Heartbeat to create a high-availability network architecture. This ensures that service IP addresses remain unchanged during switchover and improves service availability.\nYou can focus on the disaster recovery capability of cloud services. For example, ApsaraDB RDS uses the active/standby architecture. Active endpoints and standby endpoints can be deployed in the same zone or different zones in a region. If you want to improve service availability, you can deploy endpoints in different zones to implement cross-zone disaster recovery.\nThe following figure shows how to upgrade a single-zone architecture to an active/standby architecture, which provides higher security and availability.\nBefore you create a VPC, make sure that you take the following items into account: current business scale and future expansion, security isolation, service availability and disaster recovery, costs, numbers of VPCs and vSwitches, and CIDR blocks allocated to VPCs and vSwitches. For more information, see Create and manage a VPC.\n"
    },
    "266": {
        "title": "Virtual Private Cloud:Create a VPC with an IPv4 CIDR block",
        "url": "https://www.alibabacloud.com/help/en/vpc/getting-started/create-vpc-with-ipv4",
        "content": "This Product\nVirtual Private Cloud:Create a VPC with an IPv4 CIDR block\nThis topic describes how to create a virtual private cloud (VPC) with an IPv4 CIDR block and associate an elastic IP address (EIP) with an Elastic Compute Service (ECS) instance in the VPC to access the Internet.\nA company is migrating its business  to the cloud and plans\u00a0to\u00a0enable IPv4 services hosted in its VPC to access the Internet. The structure is illustrated in the following figure:\nBefore you deploy cloud resources in a VPC, you must plan the CIDR blocks. For more information, see Plan networks.\nYou can create a VPC with an IPv4 CIDR block in the Resource Orchestration Service (ROS) console or in the VPC console.\nClick Create Stack to go to the ROS console. You are automatically redirected to the Create Stack page.\nSet the parameters based on the instructions and click Create.\nIf the status on the Stack Information changes from Creating to Created, the VPC is created.\nClick the Output tab to view information about the VPC, EIP, and ECS instances.\nLog on to the VPC console.\nIn the top navigation bar, select the region where the VPC is deployed.\nThe VPC and the cloud resources that you want to deploy must belong to the same region. China (Qingdao) is selected in this example.\nOn the VPCs page, click Create VPC.\nOn the Create VPC page, set the following parameters and click OK.\n\nOnly parameters that are closely related to this topic are listed below, while others are kept at their default values. For more information about parameters, see Create and manage a VPC.\nVPC:\nIPv4 CIDR Block: Select Manually enter an IPv4 CIDR block or IPv4 CIDR block allocated by IPAM.\nEnter an IPv4 CIDR Block: Enter a primary IPv4 CIDR block for the VPC. You can refer to Suggestions on CIDR Block Configurations. After a VPC is created, modification of the IPv4 CIDR block is not allowed. But you can Add a secondary CIDR block.\nIn scenarios where multiple VPCs are used or in hybrid cloud scenarios where data centers and VPCs are used, we recommend that you use subsets of standard RFC CIDR blocks as VPC CIDR blocks with subnet masks no more than 16 bits in length. Make sure that the CIDR blocks do not overlap between VPCs and between VPCs and data centers.\nIPv6 CIDR Block: Do Not Assign is chosen in this case, as this topic is a quick guide on how to set up a VPC with an IPv4 CIDR block.\nvSwitch:\nZone: The supported cloud resources vary based on the zone and the created time. The instances provided in this topic are for reference only. The actual instances on the buy page shall prevail.\nIPv4 CIDR Block: Configure the IPv4 CIDR blocks based on Suggestions on CIDR Block Configuration. After a vSwitch is created, you cannot modify its CIDR block.\nIf a vSwitch is required to communicate with vSwitches in other VPCs or with data centers, make sure that the CIDR block of the vSwitch does not overlap with the destination CIDR blocks.\nIf you need to create multiple vSwitches for the VPC, click Add below the vSwitch section and set the parameters.\nIn the left-side navigation pane, click vSwitch. In the top navigation bar, select the region where the vSwitch is deployed. In this example, China (Qingdao) is selected.\nOn the vSwitch page, find the vSwitch that you want to manage, and choose Add Cloud Service > ECS Instance in the Actions column.\nOn the Custom Launch tab, set the following parameters based on Create an instance by using the wizard:\nRegion and Zone: Select a region and a zone.\nPublic IP Address: Clear the check box.\nSecurity Group: Use the default security group.\nClick Create Order and complete the payment. Log on to the ECS console. You can view the ECS instance on the Instances page.\nAn EIP is a public IP address that you can purchase and use as an independent resource. You can associate an EIP with an ECS instance in a VPC to enable the ECS instance to access the Internet.\nIn the top navigation bar, select the region where you want to create the EIP. In this example, China (Qingdao) is selected.\nOn the Elastic IP Addresses page, click Create EIP. Configure EIP and complete purchase.\nOn the Elastic IP Addresses page, find the EIP and click Associate with Resource in the Actions column. Set the following parameters and click OK.\nInstance Type: Select ECS Instance.\nSelect an instance to associate: Select the ECS instance that you created in Step 2.\nLog on to the ECS instance. For more information, see Connection methods.\nRun the ping command to test the connectivity between the ECS instance and the Internet.\nThe test result shows that the ECS instance can communicate with the Internet.\n"
    },
    "267": {
        "title": "Virtual Private Cloud:Create a VPC with an IPv6 CIDR block",
        "url": "https://www.alibabacloud.com/help/en/vpc/getting-started/create-vpc-with-ipv4-ipv6",
        "content": "This Product\nVirtual Private Cloud:Create a VPC with an IPv6 CIDR block\nTo enable private IPv6 communication among Elastic Compute Service (ECS) instances in a virtual private cloud (VPC), you can create ECS instances with IPv6 addresses in the VPC. Make sure that IPv6 is enabled for the VPC.\nArea\nRegion\nChina\nChina (Hangzhou), China (Shanghai), China (Nanjing - Local Region), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), Hong Kong (China), China (Fuzhou - Local Region)\nAsia Pacific\nJapan (Tokyo), South Korea (Seoul), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), Thailand (Bangkok)\nEurope & Americas\nGermany (Frankfurt), UK (London), US (Silicon Valley), US (Virginia)\nMiddle East\nSAU (Riyadh - Partner Region)\nThe SAU (Riyadh - Partner Region) region is operated by a partner.\nThe following scenario is used as an example. You want to enable IPv6 communication among ECS instances in Hangzhou Zone H.\nYou can create a VPC with an IPv6 CIDR block in China (Hangzhou) and create two ECS instances (ECS01 and ECS02) with IPv6 addresses. This way, ECS01 and ECS02 can communicate with each other through IPv6 addresses.\nBefore you use cloud resources in a VPC, you must plan your networks. For more information, see Plan networks.\nThe following section describes the general procedure.\nCreate a VPC with an IPv6 CIDR block and create a vSwitch\nBefore you assign an IPv6 address to an ECS instance, you must create a VPC with an IPv6 CIDR block and create a vSwitch.\nCreate and configure an ECS instance\nYou need to assign an IPv6 address to the ECS instance.\nConfigure security group rules\nYou can add security group rules to allow or deny ECS instances to access IPv6 addresses.\nTest the network connectivity\nYou can log on to one of the ECS instances to test whether the ECS instances can communicate with each other through IPv6 addresses.\n(Optional) Delete the IPv6 gateway\nClick Create Stack to go to the Resource Orchestration Service (ROS) console. You are automatically redirected to the Create Stack page.\nSet the parameters based on the instructions and click Create.\nOn the Stacks page, if the status of the stack changes from Creating to Created, the VPC with IPv6 CIDR blocks is created.\nClick the Output tab to view the created VPC, vSwitch, and ECS instances.\nLog on to the VPC console.\nIn the top navigation bar, select the region where you want to create the VPC. In this example, China (Hangzhou) is selected.\nOn the VPC page, click Create VPC.\nOn the Create VPC page, set the following parameters and click OK.\nIn this example, Assign (Alibaba Cloud) is selected for the IPv6 CIDR Block parameter. After the VPC is created, the system automatically assigns a /56 IPv6 CIDR block to the VPC and creates an IPv6 gateway. You can use the IPv6 gateway to control IPv6 traffic. For more information, see What is an IPv6 gateway?\nParameter\nDescription\nVPC\nRegion\nThe region where you want to create the VPC is displayed. In this example, China (Hangzhou) is displayed.\nName\nEnter a name for the VPC.\nIPv4 CIDR Block\nEnter a primary IPv4 CIDR block for the VPC. In this example, 192.168.0.0/16 is used.\nAfter you create the VPC, you cannot change its primary IPv4 CIDR block. However, you can add a secondary IPv4 CIDR block for the VPC. For more information, see the Add a secondary CIDR block section of the Create and manage a VPC topic.\nIPv6 CIDR Block\nSpecify whether to assign an IPv6 CIDR block to the VPC. In this example, Assign BGP (Multi-ISP) is selected.\nIf you select Assign (Alibaba Cloud), the system automatically assigns a /56 IPv6 CIDR block, for example, 2xx1:db8::/56, to the VPC and creates an IPv6 gateway. By default, IPv6 addresses are used only for communication within private networks.\nAfter you create the VPC, you cannot change the IPv6 CIDR block.\nDescription\nEnter a description for the VPC.\nResource Group\nSelect the resource group to which the VPC belongs.\nTag Key\nSelect or enter a tag key. You can use tags to group VPCs.\nTag Value\nSelect or enter a tag value.\nvSwitch\nName\nEnter a name for the vSwitch.\nZone\nSelect a zone for the vSwitch from the drop-down list. In this example, Hangzhou Zone H is selected.\nIPv4 CIDR Block\nEnter an IPv4 CIDR block for the vSwitch. In this example, 192.168.24.0/24 is entered.\nWhen you specify an IPv4 CIDR block for the vSwitch, take note of the following limits:\nThe CIDR block of a vSwitch must be a subset of the CIDR block of the VPC to which the vSwitch belongs.\nFor example, if the CIDR block of a VPC is 192.168.0.0/16, the CIDR block of a vSwitch in the VPC can range from 192.168.0.0/17 to 192.168.0.0/29.\nThe first IP address and the last three IP addresses of a vSwitch CIDR block are reserved.\nFor example, if a vSwitch CIDR block is 192.168.1.0/24, the IP addresses 192.168.1.0, 192.168.1.253, 192.168.1.254, and 192.168.1.255 are reserved.\nIf a vSwitch is required to communicate with vSwitches in other VPCs or with data centers, make sure that the CIDR block of the vSwitch does not overlap with the destination CIDR blocks.\nAfter you create the vSwitch, you cannot change its CIDR block.\nIPv6 CIDR Block\nEnter an IPv6 CIDR block for the vSwitch.\nBy default, the subnet mask of the IPv6 CIDR block for the vSwitch is /64. You can enter a decimal number from 0 to 255 to define the last 8 bits of the IPv6 CIDR block.\n(Optional): If you need to add more vSwitches for the VPC, click Add below the vSwitch list and set the parameters.\nYou can create at most 10 vSwitches in each VPC.\nClick OK.\nAfter you create a VPC and a vSwitch with IPv6 CIDR blocks, create ECS instances with IPv6 IP addresses. In this example, the ECS instances are named ECS01 and ECS02. After you create the ECS instances, assign IPv6 IP addresses to the ECS instances.\nLog on to the VPC console.\nIn the left-side navigation pane, click vSwitch.\nSelect the region where the vSwitch resides. In this example, China (Hangzhou) is selected.\nOn the vSwitch page, find the vSwitch that you want to manage, and choose Add Cloud Service > ECS Instance in the Actions column.\nOn the Custom Launch tab of the ECS instance buy page, set the parameters and complete the payment. For more information, see Create an instance by using the wizard.\nSet the Quantity and IPv6 parameters based on the following information:\nQuantity: Specify 2 Units.\nIPv6: Select Assign IPv6 Address Free of Charge.\nGo to the Instances page of the ECS console, click the instance IDs to view the assigned IPv6 addresses, and change the instance names to ECS01 and ECS02.\nConfigure the IPv6 addresses of ECS01 and ECS02.\nFor more information, see Configure an IPv6 address for an ECS instance that runs Windows and Configure an IPv6 address for an ECS instance that runs Linux.\nIf the security group rules cannot meet your business requirements, you need to configure IPv6 security group rules for ECS01 and ECS02.\nAn inbound rule that allows Internet Control Message Protocol (ICMP) version 6 (ICMPv6) traffic to support operations such as running the ping6 command on ECS instances.\nAn inbound rule that allows traffic on SSH port 22 and Remote Desktop Protocol (RDP) port 3389 to access ECS instances, and that allows traffic on HTTP port 80 and HTTPS port 443 to access the web services provided by ECS instances.\nLog on to the ECS console.\nIn the left-side navigation pane, choose Network & Security > Security Groups.\nIn the top navigation bar, select a region from the drop-down list.\nFind the security group and click Add Rules in the Actions column.\nConfigure security group rules.\nEnter the IPv6 CIDR block that you want to authorize in the Authorization Object field. For example, enter ::/0 to authorize all IPv6 addresses.\nFor more information about the configurations and common use cases of security group rules, see Add a security group rule and Security groups for different use cases.\nAfter you complete the preceding operations, ECS01 and ECS02 in the VPC can communicate with each other through IPv6 addresses. You can perform the following operations to test the network connectivity between ECS01 and ECS02, and between ECS01 and IPv6 Internet.\nIn this example, ECS01 and ECS02 run the Alibaba Cloud Linux operating system. For more information about how to use the ping6 command in other operating systems, see the manual of the operating system that you use.\nTest whether ECS01 and ECS02 can communicate with each other by using IPv6 addresses.\nLog on to ECS01 and ECS02. For more information, see Connection method overview.\nRun the ping6 command on ECS01 to send ICMP version 6 (ICMPv6) echo request packets to the IPv6 address of ECS02.\nIf ECS01 can receive ICMPv6 echo reply packets, the connection is established. The test result shows that ECS01 can access ECS02 by using the IPv6 address.\nRun the ping6 command on ECS02 to send ICMPv6 echo request packets to the IPv6 address of ECS01.\nIf ECS02 can receive ICMPv6 echo reply packets, the connection is established. The test result shows that ECS02 can access ECS01 by using the IPv6 address.\nIf you no longer need a VPC with an IPv6 CIDR block, you can delete the IPv6 gateway.\nLog on to the VPC console.\nIn the left-side navigation pane, choose Access to Internet > IPv6 Gateway.\nIn the Delete IPv6 Gateway message, click OK.\n"
    },
    "268": {
        "title": "Virtual Private Cloud:VPCs and vSwitches",
        "url": "https://www.alibabacloud.com/help/en/vpc/user-guide/overview-of-proprietary-networks-and-switches/",
        "content": "This Product\nVirtual Private Cloud:VPCs and vSwitches\nYou can use Alibaba Cloud resources in your virtual private cloud (VPC) and create multiple vSwitches in your VPC to create subnets. By default, the subnets in a VPC can communicate with each other. This topic describes the concepts and features of VPCs, vSwitches, and vRouters. This topic also describes the features of IPv4 and IPv6, and their differences.\nYour VPCs are dedicated for your use. You can deploy cloud resources in vSwitches (subnets) in your VPC.\nA vSwitch is a basic network device in a VPC and is used to connect cloud resources. You can deploy a VPC only in one region and cannot deploy a VPC across regions. However, a VPC covers all zones of the region to which the VPC belongs. You can create one or more vSwitches in a zone to create one or more subnets for the VPC.\nVPCs support both IPv4 and IPv6. By default, VPCs use IPv4. You can enable IPv6 based on your business requirements. For more information, see Enable IPv6 for a VPC.\nVPCs support the dual-stack mode. In dual-stack mode, resources in a VPC can communicate through both IPv4 and IPv6 addresses. IPv4 and IPv6 addresses are independent of each other. Therefore, you must configure routes and security groups for both IPv4 and IPv6 addresses.\nThe following table lists the differences between IPv4 and IPv6 addresses.\nItem\nIPv4 VPC\nIPv6 VPC\nIP address format\nAn IPv4 address is 32 bits in length and contains four groups. Each group consists of at most three decimal digits.\nAn IPv6 address is 128 bits in length and contains eight groups. Each group consists of four hexadecimal digits.\nFeature status\nBy default, IPv4 is enabled for all VPCs.\nYou can manually enable IPv6.\nVPC CIDR block size\nThe subnet mask of a VPC CIDR block can range from /8 to /28.\nThe subnet mask of a VPC CIDR block is /56.\nvSwitch CIDR block size\nThe subnet mask of a vSwitch CIDR block can range from /16 to /29.\nThe subnet mask of a vSwitch CIDR block is /64.\nWhether you can specify a CIDR block\nYou can specify an IPv4 CIDR block.\nYou cannot specify an IPv6 CIDR block. The system automatically assigns an IPv6 CIDR block to your VPC from the IPv6 address pool.\nSupported instance families\nSupported by all instance families.\nNot supported by specific instance families.\nFor more information, see Instance families.\nWhether ClassicLink connections are supported\nClassicLink connections are supported.\nClassicLink connections are not supported.\nWhether elastic IP addresses (EIPs) are supported\nIPv4 EIPs are supported.\nIPv6 EIPs are not supported.\nWhether gateways are supported\nVPN gateways and NAT gateways are supported.\nVPN gateways and NAT gateways are not supported.\nBy default, IPv4 and IPv6 addresses provided for VPCs support only communication over private networks. Cloud resources deployed in different vSwitches that belong to the same VPC can communicate with each other over private networks.\nIf you want to connect a VPC to another VPC, you can create VPC peering connections or use Cloud Enterprise Network (CEN) or VPN gateways.\nIf you want to connect a VPC to a data center, you can purchase VPN gateways, Express Connect circuits, or Smart Access Gateway (SAG) devices.\nFor more information, see Network connection overview.\nTo enable cloud resources in a VPC to communicate with the Internet, configure the following items:\nThrough IPv4 addresses\nYou can configure NAT gateways or associate EIPs with Elastic Compute Service (ECS) instances in a VPC. This way, the ECS instances can communicate with the Internet through IPv4 addresses.\nFor more information, see Associate an EIP with an ECS instance and Use the SNAT feature of an Internet NAT gateway to access the Internet.\nThrough IPv6 addresses\nTo enable cloud resources in a VPC to communicate with the Internet through IPv6 addresses, you must purchase an IPv6 Internet bandwidth plan. You can configure egress-only rules for IPv6 addresses. This allows cloud resources in the VPC to access the Internet through IPv6 addresses. However IPv6 clients cannot access the cloud resources over the Internet.\nFor more information, see Enable and manage IPv6 Internet bandwidth and Create and manage egress-only rules.\nThe system automatically creates a system route table and adds system route entries to control the traffic of the VPC. A VPC has only one system route table. You cannot create or delete a system route table.\nYou can create and associate custom route tables with vSwitches to facilitate network management. A vSwitch can be associated with only one route table. For more information, see Create and manage route tables.\nYou can also add a custom route entry to route traffic to a specified destination. When multiple routes in a route table can match the destination IP address, the longest prefix matching algorithm is used. The route with the longest (most accurate) mask is used and the next hop is determined based on the route. For more information, see Add and delete route entries.\nFor more information about how to create and manage a route table, see Create and manage a route table.\n"
    },
    "269": {
        "title": "Virtual Private Cloud:IPAM",
        "url": "https://www.alibabacloud.com/help/en/vpc/user-guide/ip-address-management-ipam/",
        "content": "This Product\nVirtual Private Cloud:IPAM\nManual IP address assignment and management through spreadsheets can be cumbersome and inefficient for network planning. As businesses expand, IP address conflicts may lead to network restructures that would have otherwise been avoided, which inflates costs and disrupts business operations. The IP Address Manager (IPAM) feature in virtual private clouds (VPCs) helps prevent address conflicts and streamline network planning by automating IP address allocation and management.\nIPAM is a tool that automates IP address assignment and management, thereby simplifying network management and preventing address conflicts. The following features are available in IPAM.\nAutomated IP address assignment: Automatically allocates IP addresses from the designated pool for VPCs based on rules that are aligned with business scenarios.\nCIDR block management for VPCs and vSwitches: Resource discovery is automatically enabled and associated with the IPAM when you create an IPAM, which allows you to manage VPC and vSwitch addresses effectively.\nIP address conflict detection: Automatically identifies potential address conflicts and compliance status, which mitigates network failure risks.\nIP address usage monitoring: Monitors IP address usage to manage capacity and scale out resources as needed. This helps to ensure network stability and security.\nCentralized network planning for multi-account architecture: Corporate network administrators can share IPAM pools with other accounts in the same organization, which centralizes address allocation and management while preventing conflicts.\nIPAM has three key components, scopes, IPAM pools, and CIDR allocations. The system generates two scopes by default upon creating an IPAM.\nScope: the highest-level container within IPAM. Each scope represents an independent IP address space. After an IPAM is created, the system creates a private scope and a public scope by default. The private scope applies to all private spaces, while the public scope applies to all public spaces (the latter is currently unavailable). Scopes enable you to reuse IP addresses across multiple unconnected networks without causing IP address overlaps or conflicts. You can create IPAM pools within a scope.\nIPAM pool: a collection of contiguous IP address ranges (CIDR blocks). You can create a top-level pool within a private scope and create multiple subpools within a top-level pool. IPAM pools can assign and manage IP addresses based on network traffic destinations and security policies. For example, development and production environments may require different routing policies and security policies. To isolate network traffic between the two types of environments, you can create a pool for each environment and specify different routing and security policies.\nYou can specify an IPAM pool to assign IP addresses to a VPC. IPAM automatically checks whether IP address conflicts or overlapping occur.\nAllocation: a CIDR assignment from an IPAM pool to another resource or IPAM pool. When you create a VPC, you can specify an IPAM pool to allocate a CIDR block from provisioned CIDR blocks to the VPC.\nFigure 1 shows the logical structure of an IPAM pool and Figure 2 illustrates the hierarchy when CIDR blocks are allocated to a VPC.\nFigure 1. IPAM pool structure\n\nFigure 2. Hierarchical structure of assigning resources from IPAM pools to VPCs\n\nIPAM supports essential features like automated IP address assignment, resource sharing, and monitoring. It enables efficient IP address resource planning and utilization monitoring across various business scenarios and multi-account architectures.\nBy using IPAM, you can flexibly manage pools. IPAM pools support different hierarchical structures for different departments, application environments, and geographical areas. This ensures effective assignment and management of IP addresses.\nYou can divide a top-level pool into smaller subpools, which can be used for specific departments, applications, or regions. You can perform the following steps to create subpools for different departments in different regions. You can determine the IPAM pool to which a specific CIDR block is allocated based on the pool usage.\nCreate an IPAM and a private IPAM scope. For more information, see Create and manage an IPAM.\nCreate a top-level pool, a regional pool, and a development pool in sequence, and provision CIDR blocks to the pools. For more information, see Create and manage an IPAM pool.\nView the pool usage of a regional pool and CIDR blocks allocated from the regional pool to other pools. For more information, see View pool usage.\nFigure 1 and Figure 2 show the structure of pools in different regions and the structure of pools for different departments.\nFigure 1. Hierarchical structure of address pools in different regions\n\nFigure 2. Hierarchical structure of address pools for different business departments\n\nAfter you create different development pools in Scenario 1, you can use these pools to create VPCs to isolate network traffic without the need to worry about IP address conflicts or security policy conflicts.\nWhen you create a VPC, you can allocate a CIDR block to the VPC based on allocation rules so that the CIDR block of the VPC does not overlap with the CIDR blocks of other resources. You can also use the IPAM console to view the VPCs associated with a pool and the management status and compliance status of the VPCs. You can perform the following steps to allocate a CIDR block from a pool when you create a VPC:\nAllocate a CIDR block from a pool when you create a VPC. For more information, see Create and manage a VPC.\nCheck the CIDR block management status and compliance status of VPCs associated with a pool. For more information, see Create and manage an IPAM.\nThe following figure shows the pool structure of VPCs associated with different development pools.\n\nIn a multi-account architecture, centralized control of network resources is challenging when IP addresses are configured independently by each business account, leading to increased configuration and maintenance costs. To address this, you can share planned IPAM pools with other accounts through the resource management feature to centrally plan addresses.\nAs shown in the following figure, the network administrator can share the subpools with accounts A, B, and C through resource sharing. Account C can then allocate resources from the shared IPAM pool when creating VPCs.\n\nComprehensive monitoring capabilities are available in IPAM to help you effectively plan and allocate resources, enhancing network stability and security.\nMonitor the address usage rate of VPCs or vSwitches. You can scale out resources of high usage rates in a timely manner to ensure adequate addresses for new VPCs or vSwitches.\nMonitor the address compliance status. You can identify potential issues and resolve them in advance to reduce network failures.\n\n\nIPAM is free of charge during the beta test.\nArea\nRegions\nAsia Pacific - China\nChina (Hangzhou), China (Shanghai), China (Nanjing - Local Region), China (Qingdao), China (Beijing), China (Zhangjiakou), China (Hohhot), China (Ulanqab), China (Shenzhen), China (Heyuan), China (Guangzhou), China (Chengdu), China (Hong Kong), China (Wuhan - Local Region), and China (Fuzhou - Local Region)\nAsia Pacific - Others\nJapan (Tokyo), South Korea (Seoul), Singapore, Malaysia (Kuala Lumpur), Indonesia (Jakarta), Philippines (Manila), and Thailand (Bangkok)\nEurope & Americas\nGermany (Frankfurt), UK (London), US (Silicon Valley), and US (Virginia)\nMiddle East\nUAE (Dubai) and Saudi Arabia (Riyadh - Partner Region)\nThe SAU (Riyadh - Partner Region) region is operated by a partner.\nName/ID\nDescription\nDefault value\nipam_quota_per_region\nMaximum number of IPAMs that can be created by each account in each region\n1\nipam_scope_quota_per_ipam\nMaximum number of IPAM scopes supported in each IPAM\n5\nipam_pool_quota_depth\nMaximum depth of each pool\n10\nipam_cidr_quota_per_ipam_pool\nMaximum number of CIDR blocks that can be provisioned to each pool\n50\nipam_sub_pool_quota_per_ipam_pool\nMaximum number of subpools that can be created from a source pool\n50\nipam_pool_quota_per_scope\nMaximum number of IPAM pools that can be created by each private scope\n500\ncustom_ipam_resource_discovery_quota_per_region\nMaximum number of custom resource discovery that can be created by each account in each region\n1\nresource_share_quota_per_ipam_resource_discovery\nMaximum number of shared resources that can be created by each resource discovery\n100\nshared_ipam_resource_discovery_quota_per_user\nMaximum number of shared resources that can be owned by each user\n100\nresource_share_quota_per_ipam_pool\nMaximum number of resources that can be shared from each IPAM pool\n100\nshared_ipam_pool_quota_per_user\nMaximum number of shared address pools for each user\n100\n\n"
    },
    "270": {
        "title": "Virtual Private Cloud:Flow Control",
        "url": "https://www.alibabacloud.com/help/en/vpc/user-guide/flow-control/",
        "content": "This Product\nVirtual Private Cloud:Flow Control"
    },
    "271": {
        "title": "Virtual Private Cloud:Network connections",
        "url": "https://www.alibabacloud.com/help/en/vpc/user-guide/network-connection/",
        "content": "This Product\nVirtual Private Cloud:Network connections\nAlibaba Cloud offers a secure and scalable cloud network that supports high-speed and secure connections between the cloud and data centers. You can utilize a VPC to access the Internet, other VPCs, and data centers, tailoring networking solutions to your specific needs with VPC and other services.\nTo enable Internet communication for services deployed on an ECS instance, you must configure a public IP address. Public IP addresses come in two types: static public IP addresses and Elastic IP Addresses (EIPs).\nStatic public IP address: Assigned automatically when creating an ECS or CLB instance, this IP address supports Internet access and is accessible from the Internet. However, it is fixed upon creation and can only be released along with the instance, limiting flexibility in management and unbinding.\nElastic IP Address (EIP): An EIP is a standalone public IP address resource that can be dynamically associated with or dissociated from an instance, offering flexible management. It is advisable to link an EIP with the application server when configuring a public IP address.\nDirectly using a public IP on a single backend server to provide services can lead to a single point of failure, compromising system availability.\nIn real-world scenarios, it is recommended to employ load balancing products to centralize public traffic ingress and connect multiple backend servers across various zones. This approach distributes traffic to different backend services, enhancing the application system's service throughput, eliminating single points of failure, and boosting system availability.\nServer Load Balancer (SLB) encompasses Application Load Balancer (ALB), Network Load Balancer (NLB), and Classic Load Balancer (CLB). Select the suitable load balancing product based on your specific requirements.\nWhile a single server can access the Internet using a public IP, multiple servers doing so would necessitate additional public IP resources. To conserve public IP resources, multiple ECS instances within a VPC can share an EIP for Internet access via the SNAT feature of a NAT Gateway.\nAppropriate access control is crucial when ECS instances offer services over the Internet to prevent unwanted or potentially harmful access.\nFor instance, for centralized access control to an ECS server within a VPC, consider the following options:\nAn IPv4 gateway serves as the Internet IPv4 traffic gateway for a VPC. Without this feature, an ECS instance with a public IP can access the Internet. However, once the IPv4 gateway is established and activated, Internet access from the VPC is governed by the IPv4 gateway. Combine the IPv4 gateway with subnet routing to centrally control Internet IPv4 access.\nAn IPv6 gateway acts as the Internet IPv6 traffic gateway for a VPC. By default, an IPv6 address in a VPC is limited to IPv6 private network communication. To enable Internet communication, activate IPv6 Internet bandwidth for the IPv6 address within the IPv6 gateway. You can also configure an egress-only rule to restrict the IPv6 address to outbound Internet access only.\nYou can integrate the above scenarios and select the appropriate cloud product resources or features to suit your business requirements. The features and advantages are summarized as follows:\nSuitable scenarios\nCloud product\nFeature description\nAdvantages and limitations\nConfigure public IP for application servers\nStatic public IP\nWhen creating an ECS instance, you can choose to assign a public address. The system automatically assigns an IP address that supports Internet access and can be accessed from the Internet.\nUse Internet Shared Bandwidth and Data Transfer Plan to reduce Internet costs.\nStatic public IP cannot be dynamically disassociated from a VPC ECS instance. You can convert a static public IP to an EIP.\nElastic IP Address (EIP)\nCan be dynamically associated with or disassociated from an ECS instance. Supports ECS instance access to the Internet (SNAT) and being accessed from the Internet (DNAT).\nEIPs can be associated with or disassociated from ECS instances at any time.\nUse Internet Shared Bandwidth and Data Transfer Plan to reduce Internet costs.\nUnified public traffic ingress\nServer Load Balancer (SLB)\nProvides Layer 4 and Layer 7 load balancing based on ports. Supports users accessing ECS from the Internet through SLB.\n\nSLB distributes traffic to multiple ECS instances, expanding the external service capability of the application system and improving availability by eliminating single points of failure.\nSLB does not support ECS actively accessing the Internet through SLB.\nUnified public traffic egress\nNAT Gateway\nSupports multiple ECS instances accessing the Internet and being accessed from the Internet.\nNAT Gateway can be used for communication between multiple ECS instances and the Internet, while an EIP can only be used for communication between one ECS instance and the Internet.\nCompared to SLB, NAT Gateway itself does not have traffic balancing capabilities.\nInternet access control\nIPv4 gateway\n/IPv6 gateway\nAs a public traffic gateway, it centrally controls public access traffic of instances in a VPC, enhancing security protection within the VPC and strictly controlling Internet access.\nControls Internet access capabilities through routing, reducing security risks associated with direct Internet access using public IPs.\nIngress routing policy control can be combined with virtual firewalls for security protection.\nFor straightforward and rapid network interconnection between two VPCs, VPC peering is the recommended method, providing high-speed and secure network connections.\nVPC peering enables private network communication between two VPCs. Create peering connections between VPCs within the same or different regions, under the same or different accounts. Once a VPC peering connection is established, configure routing entries for both the requester and accepter VPCs to facilitate interconnection.\nEnterprises managing numerous VPCs across various global regions and carrying critical operations can use Cloud Enterprise Network (CEN) to unify these VPCs into a single network architecture. CEN establishes stable, secure, and high-speed connections, enabling efficient resource sharing, flexible scheduling, and meeting the demands for cross-region and cross-account data synchronization and application migration in multicloud environments. This significantly reduces network management complexity and enhances operational efficiency.\nCEN connects network instances through TransitRouter (TR), routing traffic within the same region or across regions. A VPC simply joins the TransitRouter as a network instance, and the TransitRouter automatically synchronizes routes. Each region can have only one TransitRouter, and different TransitRouters are needed for cross-region connections. Utilize CEN and the enterprise edition TransitRouter for interregional and cross-account VPC interconnections.\nThe CEN management console offers a visual monitoring and operation interface, allowing you to quickly understand the network's operational status and enhance network management efficiency.\nTo offer cloud services deployed within a VPC to other VPCs, use PrivateLink to avoid creating a NAT Gateway, EIP, or other public network egress. Data interaction occurs within the private network, ensuring higher security and network quality. PrivateLink establishes a secure and stable private connection between the VPC hosting the endpoint and the VPC with the endpoint service, simplifying the network architecture and enabling private network service access while mitigating Internet-related security risks.\nSelect the suitable VPC peering solution based on your business needs and scenarios. For more information, see VPC peering.\nSuitable scenarios\nOptions\nFeature description\nAdvantages and limitations\nSimple peering between two VPCs\nVPC peering\nVPC peering enables private network communication between two VPCs. VPC peering supports interconnection between VPCs across regions and accounts.\nLow network latency.\nLow cost. No charge for the same region.\nDoes not support route propagation.\nHigh configuration complexity. Difficult to manage on a large scale.\nInterconnection and management among multiple VPCs\nCloud Enterprise Network (CEN)\nSupports interconnection between VPCs across regions and accounts, providing stable, secure, and high-speed network connections.\nSupports route propagation.\nSupports fast connection of multi-region networks.\nSupports systematic management. High network operation and maintenance efficiency.\nProvides low-latency, high-speed network transmission capabilities.\nConnection redundancy and disaster recovery.\nConnects networks through nearby access points.\nSecure access to private VPCs in the same region\nPrivateLink\nConnects the VPC where the endpoint is located with the VPC where the endpoint service is located through an endpoint connection, providing cloud services deployed in a VPC for use by other VPCs.\nLow network latency.\nIndependent networks for both service provider and service consumer, improving network reliability.\nSecure and controllable. Source authentication through adding security group rules and setting endpoint policies.\nSimple management. Supports flexible cross-account and cross-VPC service access methods, avoiding complex routing and security configurations.\nSupports flow log function. Real-time monitoring and analysis of traffic information entering and leaving the endpoint elastic network interface (ENI), ensuring transparent and controllable network communication.\nDoes not support cross-region connections. Only supports interconnection within the same region.\nBased on business requirements, select the appropriate solution to connect networks such as data centers to a VPC, taking into account network performance, data security, cost-effectiveness, and scalability to swiftly establish a hybrid cloud.\nFor scenarios requiring reliable, secure, and high-speed connections between data centers and VPCs, Express Connect is the recommended choice:\nUse Express Connect for stable and high-speed network connections during large-scale data migration or frequent data synchronization between data centers and VPCs, minimizing data transmission time.\nFor critical operations in data centers demanding high availability, establish multiple leased line connections at various access points for elastic expansion and disaster recovery, while maintaining tight integration with data centers.\n\nVPN Gateway, based on Internet communication, is subject to network latency and availability. For scenarios with less stringent latency requirements, considering cost and setup time, VPN Gateway provides secure and reliable connections between enterprise data centers, office networks, Internet clients, and Alibaba Cloud through encrypted tunnels.\nVPN Gateway offers two types of connections: IPsec-VPN and SSL-VPN, each suitable for different networking scenarios:\nIPsec-VPN establishes connections between enterprise data centers or office networks and VPCs.\nSSL-VPN connects Internet clients (remote clients) to VPCs, allowing them to access VPC resources after establishing the connection.\nFor large, complex, and diverse network architectures, Cloud Enterprise Network (CEN) facilitates unified management and monitoring of globally distributed network resources, enhancing network operational efficiency. CEN supports multicloud connectivity and interconnections between cloud and on-premises networks, enabling a flexible hybrid cloud architecture to meet varied business requirements.\nChoose the appropriate hybrid cloud deployment solution based on your business needs and scenarios. The features and advantages are summarized as follows:\nSuitable scenarios\nCloud product\nFeature description\nAdvantages and limitations\nHigh-speed, stable, and highly available hybrid cloud networking\nExpress Connect\nConnects local IDC networks and VPCs through connection over an Express Connect circuit.\nBased on carrier backbone networks. Low latency.\nHigh communication quality. Secure and reliable leased line connections.\nLong construction period. High construction cost.\nSimple and fast hybrid cloud networking\nVPN Gateway\nEstablishes IPsec-VPN to connect local IDC networks and VPCs.\nEstablishes SSL-VPN to connect local clients and VPCs.\nSecure, stable, and highly available. Low cost.\nRequires forwarding over the Internet. Higher latency compared to private network access.\nEnterprise-level hybrid cloud networking\nCloud Enterprise Network (CEN)\nInterconnects with local IDC: Supports loading the virtual border router (VBR) associated with the local IDC to the created CEN instance to build an interconnected network.\nInterconnects multiple VPCs and IDCs: Supports loading multiple network instances (VPC and VBR) to the created CEN instance to build an enterprise-level interconnected network.\nSupports route propagation.\nSupports fast connection of multi-region networks.\nSupports systematic management. High network operation and maintenance efficiency.\nProvides low-latency, high-speed network transmission capabilities.\nConnection redundancy and disaster recovery.\nConnects networks through nearby access points."
    },
    "272": {
        "title": "Virtual Private Cloud:Access control",
        "url": "https://www.alibabacloud.com/help/en/vpc/user-guide/access-control/",
        "content": "This Product\nVirtual Private Cloud:Access control\nVirtual private clouds (VPCs) can implement access control not only through network access control lists (ACLs) but also by leveraging the access control capabilities of cloud resources. For example, Elastic Compute Service (ECS) uses security groups, whereas Server Load Balancer (SLB) and ApsaraDB RDS employ whitelists for access control. This topic describes various ways to achieve access control.\nAccess control within a VPC can be implemented using the following methods:\nNetwork ACL: A network ACL is a feature within VPC that provides network access control. By creating network ACL rules and associating them with a vSwitch, you can manage inbound and outbound traffic for ECS instances connected to the vSwitch.\nSecurity group: A security group acts as a virtual firewall with status detection and packet filtering capabilities and allows you to segment security domains in the cloud. You can configure security group rules to manage inbound and outbound traffic for one or more ECS instances within the group.\nRDS whitelist: To access an ApsaraDB RDS instance in a VPC, you need to add the IP address of the cloud server to the whitelist of the RDS instance. This grants the cloud server access to the RDS instance while blocking access from other IP addresses.\nSLB whitelist: The SLB distributes the inbound traffic across multiple backend cloud servers according to forwarding rules. You can configure a SLB listener to allow only specific IP addresses to forward requests to your application. This is applicable in scenarios where you want to restrict access by permitting requests only from designated IP addresses.\nNetwork ACLs manage data flow through associated vSwitches, whereas security groups control data flow through connected ECS instances. The following table compares network ACLs and security groups:\nItem\nNetwork ACL\nSecurity group\nApplication scope\nvSwitches\nECS instances\nStatus of returned traffic\nStateless: Returned data must be allowed by rules.\nStateful: Returned data is automatically allowed and not affected by any rules.\nWhether rules are evaluated\nNot all rules are evaluated. Rules are processed in the order they take effect.\nAll rules are evaluated before execution.\nAssociation with ECS Instances\nA vSwitch can only be associated with one network ACL.\nAn ECS instance can be associated with multiple security groups.\nThe following diagram illustrates how network ACLs and security groups are applied to ensure network security:"
    },
    "273": {
        "title": "Virtual Private Cloud:Operation, Maintenance and Monitoring",
        "url": "https://www.alibabacloud.com/help/en/vpc/user-guide/operation-maintenance-and-monitoring/",
        "content": "This Product\nVirtual Private Cloud:Operation, Maintenance and Monitoring"
    },
    "274": {
        "title": "Virtual Private Cloud:Migrate from classic network to VPC",
        "url": "https://www.alibabacloud.com/help/en/vpc/use-cases/migrate-a-classic-network-to-a-vpc/",
        "content": "This Product\nVirtual Private Cloud:Migrate from classic network to VPC\nThis topic describes how to migrate resources from the classic network to a virtual private cloud (VPC), and the benefits of migration. VPCs are isolated from each other and provide higher security than the classic network.\nVPCs are private networks in the cloud. You can use Alibaba Cloud resources in your VPC. VPC has the following benefits:\nSecure network environment\nVPCs use tunneling technology and can implement isolation at Layer 2. Your VPCs are secure and isolated on Alibaba Cloud. Different VPCs are completely isolated from each other.\nFlexible network configurations\nYou have full control over your VPCs. For example, you can specify CIDR blocks, and configure route tables and gateways for your VPCs. This allows you to deploy resources and implement routing as needed. In addition, you can connect a VPC to a data center by using an Express Connect circuit or a VPN gateway. This allows you to smoothly migrate applications and extend your data center.\nAlibaba Cloud discontinues services for Elastic Compute Service (ECS) instances on classic networks starting February 28, 2025. We recommend that you migrate existing classic network instances to VPCs to avoid unintentional resource release or unavailability.\nAlibaba Cloud provides hybrid access and hybrid attachment solutions. You can use the solutions independently or in combination.\nIf your applications depend on services such as ApsaraDB RDS and Classic Load Balancer (CLB), you can use the solutions in combination. This allows you to smoothly migrate resources to a VPC and ensures service availability.\nYou can also use ClassicLink to allow ECS instances in the classic network to access cloud resources in the VPC. For more information, see Overview of ClassicLink.\nBoth the hybrid access and hybrid attachment solutions support smooth migration, which allows you to create resources such as ECS instances in a VPC, and then migrate resources from the classic network to the VPC. After all resources are migrated, you can release them in the classic network. For more information, see Migrate cloud resources from a classic network to a VPC.\nHybrid attachment\nTo use this solution, specify ECS instances in the classic network and ECS instances in a VPC as backend servers of a CLB instance to receive requests forwarded by listeners. vServer groups are also supported.\nThis solution applies to Internet-facing and internal-facing CLB instances.\nIn scenarios where ECS instances in the classic network and ECS instances in a VPC are specified as backend servers of an internal-facing CLB instance in a VPC, if the listeners use TCP or UDP, the IP addresses of clients cannot be retrieved on the ECS instances in the classic network. However, the IP addresses of clients can be retrieved on the ECS instances in the VPC. This does not apply to listeners that use HTTP or HTTPs.\nCLB instances created after March 23, 2021 cannot be associated with ECS instances in classic networks, while earlier instances are not affected.\nHybrid access\nServices such as ApsaraDB RDS and Object Storage Service (OSS) can be accessed by ECS instances in the classic network and ECS instances in a VPC. Such a service typically provides two endpoint types. One is the classic network endpoint and the other is the VPC endpoint.\nWhen you use this solution, take note of the following rules:\nThis solution applies to most migration scenarios. If the ECS instances in the classic network need to communicate with the ECS instances in a VPC, you can use ClassicLink.\nThis solution applies only to the migration from the classic network to a VPC."
    },
    "275": {
        "title": "Virtual Private Cloud:Use a resource directory to share a VPC with multiple Alibaba Cloud accounts",
        "url": "https://www.alibabacloud.com/help/en/vpc/use-cases/use-resource-directories-and-shared-vpcs-to-implement-multi-account-network-interworking",
        "content": "This Product\nVirtual Private Cloud:Use a resource directory to share a VPC with multiple Alibaba Cloud accounts\nThe Resource Directory service helps you manage resources in different Alibaba Cloud accounts and allows you to share virtual private clouds (VPCs) with other Alibaba Cloud accounts. This establishes network communication among multiple Alibaba Cloud accounts and improves the IT management efficiency of your organization because each department can focus on its own business.\nAs cloud computing becomes popularized, an increasing number of enterprises deploy services in the cloud and purchase more and more cloud resources. An issue arises: How can enterprises manage cloud resources in an efficient manner? Enterprises have high requirements for the division of business, business isolation, and multiple payment methods. The single-account mode can no longer support the sustainable development of enterprises. To resolve this issue, enterprises can use the multi-account mode to meet business development requirements. However, the following issues may arise during the use of the multi-account mode:\nEnterprises may not be able to manage multiple isolated Alibaba Cloud accounts in a centralized manner. Therefore, more refined management is required.\nEnterprises can use Cloud Enterprise Network (CEN) to connect VPCs that belong to different accounts. This way, cloud resources within different accounts can communicate with each other. However, as the business complexity increases, the following issues may occur:\nThe network of an enterprise can be large and complex because the network resources may be deployed and managed by different accounts. As a result, it is difficult for O&M personnel to manage an enterprise network in a centralized manner.\nO&M and instance costs increase due to frequent VPC configurations by different accounts.\nTo meet business requirements, more and more VPCs need to be deployed. As a result, issues such as complex network, difficult management, and resource quota limits arise. For example, the number of VPCs attached to a CEN instance may reach the upper limit.\nTo address the preceding issues, you can use the Resource Directory service to manage resources in different Alibaba Cloud accounts. For example, you can share resources and VPCs to establish network communication among Alibaba Cloud accounts.\nDuring workload production, an enterprise may use multiple accounts to divide and isolate workloads. To better manage these accounts, the enterprise uses resource directories to deploy, configure, and manage VPCs based on the organization structure or workload status. For example, the enterprise can share VPCs to share the vSwitches, excluding the default vSwitches, among different departments. This helps the enterprise control the network O&M cost and network topology when workload complexity increases.\nThe business department can view and manage only the resources deployed in the shared vSwitches. In addition, the business department can create or delete resources in the shared vSwitches, such as cloud instances and databases, based on business requirements.\nThe Resource Directory service provided by Alibaba Cloud allows you to manage the relationships among multiple levels of resources and accounts. You can construct a resource directory by creating subdirectories based on your business requirements. Then, you can deploy Alibaba Cloud accounts of your enterprise on the subdirectories as required. This way, you can manage the accounts and resources in a centralized manner based on their relationship in the organization. In addition, your requirements for finance, security, audit, and compliance can be met. For more information, see Resource Directory overview.\nWithin a resource directory, an enterprise can use the Resource Sharing service to share specified resources within an account (resource owner) with one or more accounts (principals) by creating resource shares. For more information, see Resource Sharing overview.\nAn enterprise can use the Resource Sharing service to share the VPC vSwitches, excluding the default vSwitches, with other members (principals) in the resource directory. Resource directory members can deploy resources, such as Elastic Compute Service (ECS) instances, Server Load Balancer (SLB) instances, and ApsaraDB RDS instances, in the same VPC. This facilitates resource management. The resources created by the resource owner and principals can communicate with each other within the shared VPC.\nIf you want to isolate the vSwitches in some scenarios, use the following methods:\nConfigure a network access control list (ACL) to isolate the vSwitches.\nConfigure a security group to isolate the instances in the vSwitches. You can also use security groups that belong to other accounts.\nCustom VPC vSwitches can be shared among multiple accounts. You do not need to create a separate VPC for each account. You can use fewer VPCs to control your expenses on network resources and reduce network complexity.\nFor more information about the permissions on shared vSwitches and resources, see Overview of VPC sharing.\nThe administrator or a member of a resource directory can share resources with all members in the resource directory, all members in a specific folder of the resource directory, or a specific member in the resource directory.\nFor more information, see Enable VPC sharing.\nUse a resource directory to manage multiple accounts\nEnable resource sharing\nCreate a resource share as a resource owner\nBy default, after the resource owner shares a vSwitch, a principal can use the shared vSwitch without further authorization. Principals can view the vSwitches that other accounts share with them. They can also create cloud resources, such as ECS instances, SLB instances, and ApsaraDB RDS instances, in the shared vSwitches.\nFor more information, see Create cloud resources in a shared vSwitch as a principal.\n"
    },
    "276": {
        "title": "Virtual Private Cloud:Select a private network service",
        "url": "https://www.alibabacloud.com/help/en/vpc/use-cases/select-services-to-gain-access-to-private-network",
        "content": "This Product\nVirtual Private Cloud:Select a private network service\nA virtual private cloud (VPC) is a private network in the cloud. Alibaba Cloud provides different services to access VPCs, such as Express Connect, VPN Gateway, Cloud Enterprise Network (CEN), and Smart Access Gateway (SAG).\nThe following table describes the connection solutions for each scenario.\nConnect VPCs\nService\nDescription\nBenefit\nLimit\nCEN\nYou can establish connections among VPCs that belong to different regions and Alibaba Cloud accounts.\nEase of use. Automatic route learning and advertising are supported.\nLow latency and high speed.\nNetwork instances, such as VPCs, virtual border routers (VBRs), and Cloud Connect Network (CCN) instances, that are attached to the same CEN instance can communicate with each other.\nNone\nVPC peering connection\nYou can establish peering connections between two VPCs.\nIf the two VPCs are deployed in the same region, data transfer is free of charge.\nNone\nConnect a data center to a VPC\nService\nDescription\nBenefit\nLimit\nVPN gateway\nYou can connect a data center to a VPC by using an encrypted IPsec-VPN tunnel over the Internet.\nLow cost.\nSecurity.\nThe configuration immediately takes effect.\nThe network latency and availability vary based on the Internet.\nCEN\nAutomatic route learning and advertisement are supported. To enable communication among resources that are attached to the same CEN instance, you need to only attach the VBR that is associated with the data center to the CEN instance.\nEase of use. Automatic route learning and advertising are supported.\nLow latency and high speed.\nNetwork instances, such as VPCs and VBRs, that are attached to the same CEN instance can communicate with each other.\nNone\nSAG and CEN\nYou can connect a data center to Alibaba Cloud by using SAG.\nReady-to-use. Automatic configuration is supported.\nData transmitted over the Internet between the data center and the VPC is encrypted.\nYou can connect to nearby access points in a MAN. Branch offices can be connected to Alibaba Cloud by using active and standby access devices or connections.\nNone\nExpress Connect\nYou can connect a data center to a VPC by using Express Connect circuits.\nHigh network quality.\nHigh bandwidth.\nHigh costs.\nService activation is time-consuming.\nVPN software deployment\nYou can purchase a VPN gateway and deploy the VPN gateway in a VPC. Then, you can connect a data center to the VPC by using an encrypted IPsec-VPN tunnel over the Internet.\nSecurity.\nDifferent types of VPN software are available.\nThe configuration immediately takes effect.\nVPN gateways must be manually deployed and maintained.\nThe network latency and availability depend on the Internet.\n\nConnect multiple sites\nService\nDescription\nBenefit\nLimit\nVPN gateway\nEstablishes secure connections among multiple sites. The VPN-Hub feature enables communication among different sites, or between sites and VPCs.\nLow cost.\nReady-to-use.\nThe configuration immediately takes effect.\nNone\nSAG\nYou can purchase SAG instances for branch offices and attach the SAG instances to a CCN instance. Then, the branch offices can communicate with each other.\nReady-to-use. Automatic configuration is supported.\nData transmitted over the Internet between the data center and the VPC is encrypted.\nYou can connect to nearby access points in a MAN. Branch offices can be connected to Alibaba Cloud by using active and standby access devices or connections.\nNone\nVPN Gateway and VPC peering connection\nYou can connect application systems and offices around the world by using a combination of VPN gateways and VPC peering connections.\nHigh network quality.\nReady-to-use. The service takes effect immediately after configuration.\nThe network latency and availability depend on the Internet.\nRemote access to a VPC\nService\nDescription\nBenefit\nLimit\nVPN Gateway (with SSL-VPN)\nYou can connect a client to a VPC by using the SSL-VPN feature.\nLost cost.\nReliability.\nEasy configuration and deployment.\nNone\nSSL-VPN software deployment\nYou can purchase SSL-VPN software and deploy the SSL-VPN software in a VPC. Then, you can connect to the VPN server from a client.\nMultiple types of SSL-VPN software and images are supported.\nLow reliability.\nHigh costs.\nManual deployment and maintenance.\nYou can deploy applications in VPCs in different regions. This way, services can be provided to the nearest regions and the network latency is low. Services in the VPCs can back up each other, which improves the availability of the system.\nYou can use CEN or VPC peering connections to connect VPCs in the same region or different regions.\nCEN\nYou can use CEN to establish private network connections between VPCs in different regions, or between VPCs and data centers. CEN supports automatic route advertisement and learning, which speeds up network convergence, improves the quality and security of cross-network communication, and connects all network resources. CEN helps you build enterprise-class networks that provide high-performance network communication.\n\nFor more information, see the following topics:\nUse Enterprise Edition transit routers to connect VPCs across regions and accounts\nUse Basic Edition transit routers to connect VPCs in the same region\nUse Basic Edition transit routers to connect VPCs across regions and accounts\nVPC peering connection\nA VPC peering connection is a private network connection between two VPCs. You can enable multiple VPCs to communicate with each other by establishing VPC peering connections. If you want to connect more than two VPCs by using VPC peering connections, you must establish a peering connection for every pair of the VPCs.\n\nFor more information, see Examples of VPC peering connections.\nYou can connect a data center to a VPC to build a hybrid cloud. After a secure and reliable connection is established between your data center and the VPC, you can seamlessly migrate on-premises IT infrastructure resources to Alibaba Cloud by using computing, storage, networking, CDN, and BGP resources that are provided by Alibaba Cloud. This helps you to handle business fluctuations.\nYou can connect a data center to a VPC by using Express Connect circuits, VPN gateways, and CEN instances.\nVPN gateway\nVPN Gateway can be used to connect data centers, office networks, and terminals to VPCs by using an encrypted tunnel in a secure and reliable manner. By default, VPN Gateway supports the active-standby mode in which two VPN gateways are used. In this mode, the system performs failovers when one VPN gateway becomes faulty. You can use VPN gateways to establish IPsec-VPN connections between your data center and VPCs.\n\nFor more information, see IPsec-VPN overview.\nCEN\nCEN supports automatic route advertisement and learning to connect resources in a hybrid cloud. After you attach the VBR that is associated with your data center to a CEN instance, the data center can communicate with other network instances that are attached to the CEN instance, such as VPCs and VBRs.\n\nFor more information, see Use Enterprise Edition transit routers to enable intra-region communication between on-premises and cloud networks.\nSAG\nSAG is an all-in-one solution that can be used to connect your workloads to Alibaba Cloud. You can use SAG to connect private networks to Alibaba Cloud over the Internet. The connections established by SAG are secure and reliable.\nYou can purchase SAG instances for your data center and attach the CCN instance that is associated with the SAG instances to the CEN instance. This allows you to connect your data center to Alibaba Cloud.\n\nFor more information, see Deploy an SAG device in inline mode.\nExpress Connect\nExpress Connect provides dedicated circuits to establish connections. After an Express Connect circuit is used to connect to Alibaba Cloud, you can create a VBR and connect your data center to Alibaba Cloud. This way, you can build a hybrid cloud and access your data center over a private network.\nAn Express Connect circuit connects your data center to Alibaba Cloud over a private network. Compared with Internet-based connections, connections over Express Connect circuits reduce network latency, enhance security, and improve reliability.\n\nFor more information, see Connect a data center to a VPC by using an Express Connect circuit.\nVPN software deployment\nAlibaba Cloud provides various types of VPN software and images. You can purchase VPN software and deploy the VPN software on an ECS instance. Then, you can connect your data center to the VPC over the Internet by using an elastic IP address (EIP).\n\nYou can connect multiple sites by using SAG or the VPN-Hub feature of VPN Gateway.\nVPN gateway\nThe IPSec-VPN feature of VPN Gateway provides site-to-site VPN connections. Each VPN gateway supports at most 10 IPsec-VPN connections. You can purchase a VPN gateway and establish connections among up to 10 data centers or branch offices in different regions.\nYou can create multiple site-to-site IPsec connections among sites, or between sites and VPCs by using VPN-Hub. VPN-Hub allows large enterprises to establish private connections across branch offices that run business in different regions.\nBy default, the VPN-Hub feature is enabled. You need only to configure an IPsec-VPN connection between each branch office and Alibaba Cloud. No additional configurations or payments are required. Each VPN gateway supports up to 10 IPsec-VPN connections, which indicates that you can connect up to 10 branch offices in different regions by using one VPN gateway. The following figure shows how to establish connections among the branch offices in Shanghai, Hangzhou, and Ningbo by using a VPN gateway.\n\nFor more information, see Connect multiple offices to each other and to a VPC.\nSAG\nSAG is an all-in-one solution that can be used to connect your workloads to Alibaba Cloud. You can use SAG to connect private networks to Alibaba Cloud over the Internet. The connections established by SAG are secure and reliable.\nYou can purchase SAG instances for branch offices and attach the SAG instances to a CCN instance. Then, the branch offices can communicate with each other.\n\nBuild a high-speed global network\nYou can establish connections among applications and branch offices worldwide by using VPC peering connections and VPN gateways. This solution ensures secure communication and optimal network quality, and minimizes your costs.\nThe following figure shows how to establish connections among the branch offices that are connected to the VPC in the US (Virginia) region and the VPC in the China (Shanghai) region. You can deploy applications in both VPCs and connect the two VPCs by using a VPC peering connection. Then, you can connect the branch offices to each VPC by using the IPsec-VPN tunnel.\n\nThe SSL-VPN feature of VPN Gateway provides point-to-site VPN connections. You can use a client to access a VPC without the need to configure a gateway. You can deploy internal applications in a VPC and enable access to the applications by using SSL-VPN connections over internal networks. For example, on-site IT staff must connect to the VPC over an internal network to perform O&M operations. Remote access is allowed for the applications in the VPC.\nVPN gateways and VPN software and images from Alibaba Cloud Marketplace can be used to achieve remote access to VPCs.\nVPN Gateway (SSL-VPN)\nYou can use the SSL-VPN feature to connect a client to applications and services that are deployed in a VPC. After you deploy the applications and services, you can load the SSL client certificate to your client and initiate an SSL-VPN connection between the client and the VPC. By default, VPN gateways support the active-standby mode in which two VPN gateways are used. In this mode, the system automatically performs failovers when one VPN gateway becomes faulty.\n\nFor more information, see Connect a client to a VPC.\nInstallation and deployment of SSL-VPN software\nFor more information, see Connect a client to a VPC."
    },
    "277": {
        "title": "Virtual Private Cloud:Select a service to access the Internet",
        "url": "https://www.alibabacloud.com/help/en/vpc/use-cases/select-a-product-to-gain-access-to-the-internet",
        "content": "This Product\nVirtual Private Cloud:Select a service to access the Internet\nYou can use the following Internet services to enable Elastic Compute Service (ECS) instances in a virtual private cloud (VPC) to access the Internet: Elastic IP Address (EIP), NAT Gateway, Server Load Balancer (SLB), and static public IP addresses. This topic describes the features and use cases of the preceding Internet services.\nThe Internet services have a variety of public IP address forms, including static public IP addresses of ECS instances in a VPC, public IP addresses of a NAT service plan, public IP addresses of Internet-facing SLB instances, and public IP addresses of VPN gateways. You can associate EIPs with ECS instances in a VPC, NAT gateways, and internal-facing SLB instances. This facilitates public IP address management.\nYou can associate EIPs with Internet Shared Bandwidth instances and data transfer plans to handle traffic fluctuation and reduce costs.\nThe following table describes the features of the Internet services.\nAlibaba Cloud provides Internet Shared Bandwidth and data transfer plans to help you reduce costs. You can select an Internet service based on your business requirements.\nService\nFeature\nBenefits\nStatic public IP address\nWhen you create an ECS instance in a VPC, you can specify whether you want the system to assign a public IPv4 address to the ECS instance. The ECS instance can use the public IP address to communicate with the Internet.\nYou cannot disassociate the public IP address from the ECS instance. However, you can convert the public IP address to an EIP. For more information, see Convert the static public IP address of an ECS instance in a VPC to an EIP.\nYou can purchase data transfer plans for an ECS instance that is assigned a public IP address. You can also purchase an Internet Shared Bandwidth instance for an ECS instance after you convert the public IP address of the ECS instance to an EIP. For more information, see What is Internet Shared Bandwidth? and What is a data transfer plan?\nEIP\nYou can associate EIPs with or disassociate EIPs from ECS instances anytime. ECS instances in a VPC can use EIPs in SNAT entries to access the Internet and use EIPs in DNAT entries to provide Internet-facing services.\nYou can associate EIPs with or disassociate EIPs from ECS instances anytime.\nYou can use Internet Shared Bandwidth and data transfer plans to reduce the cost of data transfer over the Internet.\nInternet NAT gateway\nECS instances in a VPC can use SNAT entries to access the Internet and use DNAT entries to provide Internet-facing services.\nInternet NAT gateways do not provide load balancing services. To balance the loads of ECS instances, use SLB.\nAn Internet NAT gateway allows multiple ECS instances in a VPC to communicate with the Internet. However, each EIP can be used by only one ECS instance.\nSLB\nSLB provides load balancing services at Layer 4 and Layer 7. You can specify the ports on which SLB listens to distribute requests from the Internet to ECS instances. Alibaba Cloud provides two types of SLB instances: CLB and ALB.\nECS instances that are deployed in VPCs cannot access the Internet through SLB. In this case, SNAT is not supported.\nSLB supports DNAT. Each port on an SLB instance can be mapped to one or more ECS instances.\nSLB distributes network traffic across multiple ECS instances to prevent single points of failure. This improves the availability of application systems.\nAfter you associate an EIP with an SLB instance, you can purchase Internet Shared Bandwidth instances and data transfer plans to reduce costs.\nUse one ECS instance to provide services\nIf you have only one application that has a small volume of workloads, you can deploy only one ECS instance. You can deploy all workloads, including applications, databases, and files, on the ECS instance. Then, you can associate an EIP with the ECS instance to enable the ECS instance to provide services over the Internet.\n\nProvide Layer 4 services with load balancing\nIf you have a high volume of workloads, you may need to deploy more than one ECS instance and enable load balancing. To meet this requirement, you can create an Internet-facing SLB instance, create a Layer 4 TCP or UDP listener, and add multiple ECS instances to the SLB instance.\n\nProvide Layer 7 services with load balancing\nIf you want to distribute network traffic to different backend servers, you can create Layer 7 listeners and create URL-based forwarding rules. To meet this requirement, you can create an Internet-facing SLB instance, create a Layer 7 HTTP or HTTPS listener, and add multiple backend ECS instances.\n\nAssociate with EIPs\nIf you have a small number of ECS instances, you can associate an EIP with each ECS instance. Then, ECS instances in VPCs can use their EIPs to access the Internet. If you want to disable Internet access for the ECS instances, disassociate them from the EIPs.\n\nAssociate with a NAT gateway and create an SNAT entry\nIf you have a large number of ECS instances, associating them with EIPs increases the O&M cost. In addition, security risks may arise because the ECS instances are exposed to the Internet. To address this issue, we recommend that you create a public NAT gateway and SNAT entries, as shown in the following figure. Do not create DNAT entries.\n"
    },
    "278": {
        "title": "Virtual Private Cloud:Deploy cloud services in a VPC",
        "url": "https://www.alibabacloud.com/help/en/vpc/use-cases/deploy-cloud-services-in-a-vpc",
        "content": "This Product\nVirtual Private Cloud:Deploy cloud services in a VPC\nMost Alibaba Cloud services support virtual private clouds (VPCs). You can choose to use a VPC when you create a cloud resource. You can also create a VPC, and then create cloud resources in the VPC.\nA VPC is an isolated private network. By default, VPCs cannot communicate with each other. Elastic Compute Service (ECS) instances in a VPC cannot access the Internet or be accessed over the Internet. A VPC cannot communicate with a classic network over a private network. However, most Alibaba Cloud services can be accessed over the Internet or a private network. More than 95% of Alibaba Cloud services support VPCs.\nCloud resources that need to communicate with each other over a private network must be of the same network type. For example, if an ECS instance in a VPC needs to access a Classic Load Balancer (CLB) instance or an ApsaraDB RDS instance over a private network, the CLB instance or the ApsaraDB RDS instance must be deployed in a VPC.\nHow you use a VPC varies based on the service:\nSelect VPC as the network type on the buy page\nYou can use this method for services that allow you to create instances, such as ECS, ApsaraDB RDS, and CLB. You can select VPC as the network type on the buy page of these services. This way, the instance that you purchase is created in a VPC or a VPC endpoint is provided for the instance. The endpoint is resolved to an IP address that falls within the CIDR block of the VPC.\nConfigure VPC access in the console\nYou can use this method for services such as Tablestore (OTS), Container Service for Kubernetes (ACK), E-MapReduce (EMR), and File Storage NAS.\nFor OTS, you can configure a VPC endpoint for an OTS instance in the console. For ACK or EMR, you can select VPC as the network type when you create an ACK cluster or an EMR cluster in the console. For NAS, you can add a VPC as a mount target in the console.\nView the VPC endpoints of different services\nThe following topics describe how to view the VPC endpoints of Log Service, Object Storage Service (OSS), and ECS:\nVPC endpoints of Log Service\nVPC endpoints of OSS\nVPC endpoints of ECS\nTo query the VPC endpoints of other services, you can use Alibaba Cloud DNS PrivateZone to call API operations. For more information, see Activate Alibaba Cloud DNS PrivateZone.\nFor some cloud services that allow you to create instances, such as ApsaraDB RDS, you can change the network type from classic network to VPC in the console.\nFor CLB instances, you cannot change the network type from classic network to VPC. You can create a new CLB instance that uses VPC and associate ECS instances in a VPC with the CLB instance.\nFor more information, see Overview of the migration solution."
    },
    "279": {
        "title": "Virtual Private Cloud:Security system overview",
        "url": "https://www.alibabacloud.com/help/en/vpc/security-and-compliance/overview-of-security-system",
        "content": "This Product\nVirtual Private Cloud:Security system overview\nAlibaba Cloud is committed to providing you with stable, reliable, secure, and compliant cloud computing services to ensure the confidentiality, integrity, and availability of your systems and data. This topic describes the security system of Virtual Private Cloud (VPC) and how the security control mechanism works.\nA VPC is a private network in the cloud. VPCs are logically isolated from each other. VPCs are isolated from each other based on tunneling technology. Each VPC is identified by a unique tunnel ID, which corresponds to a virtual network.\nData packets are encapsulated with a unique tunnel ID and transmitted over a physical network between Elastic Compute Service (ECS) instances in a VPC.\nData packets transmitted over ECS instances in different VPCs have different tunnel IDs. Therefore, ECS instances in different VPCs cannot communicate with each other.\nVPC supports the following features to ensure the security and reliability of cloud services.\nFeature\nDescription\nECS security group\nSecurity groups act as virtual firewalls and provide Stateful Packet Inspection (SPI) and packet filtering capabilities. You can use security groups to define security domains in the cloud. You can configure security group rules to control the inbound and outbound traffic of one or more ECS instances in a group. For more information, see Overview of security groups.\nNetwork access control list (ACL)\nYou can use a network ACL to regulate access control for a VPC. You can create network ACL rules and associate a network ACL with a vSwitch. This allows you to control inbound and outbound traffic of ECS instances in the vSwitch. For more information, see Overview of network ACLs.\nFlow log\nVPC provides the flow log feature. The feature records information about inbound and outbound traffic of an elastic network interface (ENI). You can check access control rules, monitor network traffic, and troubleshoot network errors based on the flow logs. For more information, see Overview of flow logs.\nTraffic mirroring\nThe traffic mirroring feature can mirror packets that pass through an ENI and that meet specific filter conditions. The traffic mirroring feature mirrors network traffic from an Elastic Compute Service (ECS) instance in a VPC and forwards the traffic to a specified ENI or an internal-facing Classic Load Balancer (CLB) instance. You can use this feature in scenarios such as content inspection, threat monitoring, and troubleshooting. For more information, see Overview of traffic mirroring.\nYou can use RAM policies to regulate access control for VPCs.\nYou can specify permissions in a RAM policy to grant the permissions to a RAM user, a user group, or a RAM role. You can use RAM policies to specify the scope of resources that RAM users and RAM roles can access or manage.\nYou can use the following common RAM policies to regulate access control for VPCs. For more information, see RAM authorization (VPC) and RAM authorization (VPC peering connection).\nPermission policies\nDescription\nAliyunVPCFullAccess\nGrants a RAM user the permissions to manage VPCs.\nAliyunVPCReadOnlyAccess\nGrants a RAM user the read-only permissions on VPCs.\nYou can attach system RAM policies to a RAM user. If the system RAM policies cannot meet your requirements, you can create custom RAM policies. For more information about how to create a custom RAM policy, see Use RAM roles to manage VPC permissions."
    },
    "280": {
        "title": "Virtual Private Cloud:Use RAM to enable access control",
        "url": "https://www.alibabacloud.com/help/en/vpc/security-and-compliance/identity-management-and-access-control/",
        "content": "This Product\nVirtual Private Cloud:Use RAM to enable access control"
    },
    "281": {
        "title": "Virtual Private Cloud:Infrastructure security",
        "url": "https://www.alibabacloud.com/help/en/vpc/security-and-compliance/infrastructure-security",
        "content": "This Product\nVirtual Private Cloud:Infrastructure security\nThis topic describes the infrastructure security of Virtual Private Cloud (VPC).\nA virtual private cloud (VPC) is a private network on Alibaba Cloud. VPCs are isolated from each other.\nvSwitches are basic components in VPCs and are used to connect different instances. You can create multiple vSwitches to divide a VPC and deploy Elastic Compute Service (ECS) instances in different vSwitches. You can isolate vSwitches from each other. Each vSwitch has a CIDR block and a route table. You can use a route table to enable access control.\nYou can control the network traffic of a VPC by using one of the following methods:\nWhen you create an ECS instance in a VPC, you can use the default security group rule or add the ECS instance to a custom security group to control inbound and outbound traffic. A security group serves as a virtual firewall that can enable fine-grained access control for ECS instances. In addition, you can create a custom network access control list (ACL) and associate the network ACL with a vSwitch to enable access control for ECS instances in the vSwitch. A network ACL can apply to all ECS instances in a vSwitch. You can use network ACLs in scenarios where you need to control traffic for large-scale applications. You can use security groups and network ACLs to improve the security and stability of resources in VPCs. For more information, see Security group overview and Network ACL overview.\nAn IPv4 gateway is a network component that connects a VPC to the Internet. An IPv4 gateway can enable a VPC to access the Internet by routing IPv4 traffic and translating private IP addresses to public IP addresses. When a VPC accesses the Internet by using an IPv4 gateway, IPv4 traffic flows through the IPv4 gateway. For more information, see IPv4 gateway overview.\nAn IPv6 gateway is used to control IPv6 traffic of a VPC. You can configure IPv6 Internet bandwidth and egress-only rules to control inbound and outbound IPv6 traffic. For more information, see What is an IPv6 gateway?\nYou can create a custom route table in a VPC, add custom routes to the route table, and then associate the route table with a vSwitch to control the traffic of the vSwitch. For more information, see Subnet routing.\nYou can use a VPN gateway to connect a VPC to a data center over the Internet in a secure manner. You can use VPN gateways to establish site-to-site connections over IPsec-VPN or connect clients to servers over SSL-VPN. For more information, see What is a VPN gateway?\nYou can establish high-speed, low-latency, and reliable connections between data centers and VPCs by using Express Connect circuits. You can use an Express Connect circuit to connect multiple VPCs to a data center. For more information, see What is Express Connect?\nYou can establish VPC peering connections to enable data transfer and resource sharing for VPCs. You can use VPC peering connections to enable communication and resource sharing between VPCs. For more information, see VPC peering connections.\nYou can use Cloud Enterprise Network (CEN) to enable communication among multiple VPCs. You can use CEN to create a flexible, reliable, and large-scale cloud network where you can connect all VPCs in your enterprise. For more information, see What is CEN?\nA gateway endpoint serves as a virtual gateway device. You can create a gateway endpoint in your VPC for an endpoint service and associate the endpoint with a route table. Then, the system automatically adds a route that points to the gateway endpoint to the VPC route table. This way, your VPC can access the endpoint service. For more information, see Gateway endpoints.\nYou can use the flow log feature to capture inbound and outbound traffic of the elastic network interface (ENI) of an ECS instance in a VPC. You can use the flow log feature to check access control rules, monitor network traffic, and troubleshoot network errors. For more information, see Flow log overview.\nNetwork ACLs control data transmitted through associated vSwitches while security groups control data transmitted through associated ECS instances. The following table describes the differences between network ACLs and security groups.\nItem\nNetwork ACL\nSecurity group\nFeature\nYou can configure network ACL rules and associate a network ACL with a vSwitch to control traffic of ECS instances in the vSwitch.\nA security group serves as a virtual firewall that applies to ENIs and ECS instances.\nApplication scope\nvSwitches.\nECS instances.\nStatus of returned traffic\nStateless: Returned traffic must be allowed by inbound rules.\nStateful: Returned traffic is automatically allowed and not affected by rules.\nWhether rules are evaluated\nThe system attempts to match requests against rules in descending order of priority. Not all rules are matched.\nThe system matches a request against all rules before a rule is applied.\nAssociation with ECS instances\nThe vSwitch to which an ECS instance belongs can be associated with only one network ACL.\nEach ECS instance can be added to more than one security group."
    },
    "282": {
        "title": "Virtual Private Cloud:Data security",
        "url": "https://www.alibabacloud.com/help/en/vpc/security-and-compliance/data-security",
        "content": "This Product\nVirtual Private Cloud:Data security\nVirtual private clouds (VPCs) are deployed in regions while vSwitches are deployed in zones. You can deploy VPCs in different regions and vSwitches in different zones to implement cross-region and cross-zone backup and disaster recovery.\nThe global infrastructure of Alibaba Cloud is deployed in Alibaba Cloud regions and zones. Each Alibaba Cloud region consists of multiple physically independent and isolated zones. These zones are connected to each other through low-latency, high-throughput, and highly redundant networks. You can deploy applications and databases in zones to automatically perform failover across zones. Compared with a single data center or multiple data centers, zones support higher availability, fault tolerance, and scalability.\nFor more information about regions and zones, see Regions and zones.\n\n\n"
    },
    "283": {
        "title": "Virtual Private Cloud:Monitoring and logging",
        "url": "https://www.alibabacloud.com/help/en/vpc/security-and-compliance/monitoring-and-logging",
        "content": "This Product\nVirtual Private Cloud:Monitoring and logging\nYou can use monitoring and logging services to monitor the health status of the resources in your virtual private clouds (VPCs). This ensures the availability and stability of the resources. You can use monitoring services to collect monitoring data. Alibaba Cloud provides a variety of monitoring and auditing services, such as CloudMonitor and Cloud Config. These services can monitor resource usage and service performance in real time, generate alerts, and notify you of anomalies.\nWe recommend that you keep track of the health status of your Alibaba Cloud resources so that you can handle exceptions at the earliest opportunity. For more information, visit Alibaba Cloud status.\nOn the Alibaba Cloud Resource Healthiness Updates page, you can check the health status of every service in each region, and find the methods to subscribe to Really Simple Syndication (RSS) feeds about service exceptions.\nVPC is integrated with Cloud Config, which provides a free trial. You can use Cloud Config to track the configuration history of your cloud resources and configure compliance auditing. This ensures the compliance of your infrastructure resources.\nCloud Config can audit the operations performed by your Alibaba Cloud account and all RAM users created by your Alibaba Cloud account. By default, configuration changes are recorded every 10 minutes.\nCloud Config provides rules based on the specifications in Baseline for Classified Protection of Cybersecurity 2.0 (CCSP 2.0) and uses the rules to evaluate the compliance of resources. You can enable the compliance pre-check for CCSP 2.0 with a few clicks. The feature then continuously evaluates resource compliance. You can also download the compliance pre-check result and submit it to an inspection agency.\nYou can deliver the historical configuration changes and non-compliant events of your resources to a Logstore of Simple Log Service. This way, you can query and analyze the logs in a centralized manner. For more information, see Deliver resource data to a Log Service Logstore.\nVPC is integrated with ActionTrail, which can monitor and record the operations performed by Alibaba Cloud accounts. In addition, ActionTrail can analyze security risks, detect intrusions, track changes, and perform compliance auditing.\nActionTrail can generate logs of cloud service access by using the Alibaba Cloud console, API operations, and developer tools. For more information about the events supported by ActionTrail, see Audit events of VPC.\nBy default, ActionTrail tracks and retains events from the last 90 days. If you need to retain events for a longer period of time, create a trail to deliver events to Log Service or OSS. For more information, see Getting Started.\nAfter you create a trail to deliver events to a Logstore of Simple Log Service or an OSS bucket, you can query or analyze the events in the Simple Log Service or OSS console. For more information, see Query events in the Log Service or OSS console.\nIf you want to track historical events, you can create a historical event delivery task to deliver data to Log Service. For more information, see Create a historical event delivery task.\nVPC provides the flow log feature. The feature records information about inbound and outbound traffic of an elastic network interface (ENI). You can check access control rules, monitor network traffic, and troubleshoot network errors based on the flow logs. For more information about flow logs, see Overview of flow logs.\nWhen you enable the flow log feature, you need to log on to the Log Service product page to activate Log Service. For more information, see Create and manage flow logs.\nYou can use flow logs to monitor traffic in the following scenarios:\nQuery the traffic of an Elastic Compute Service (ECS) instance in a VPC\nLocate ECS instances with high traffic flowing through a NAT gateway\nQuery traffic between VPCs\nView the traffic of an Express Connect circuit in a hybrid cloud\nYou can use the traffic mirroring feature to mirror packets that pass through an ENI and that meet specific filter conditions. The traffic mirroring feature mirrors network traffic from an ECS instance in a VPC and forwards the traffic to a specified ENI or an internal-facing Classic Load Balancer (CLB) instance. You can use this feature in scenarios such as content inspection, threat monitoring, and troubleshooting. For more information about traffic mirroring, see Overview of traffic mirroring.\nIf you use the traffic mirroring feature for the first time, log on to the Traffic Mirroring page to enable the traffic mirroring feature. For more information, see Create and manage traffic mirroring sources.\n"
    },
    "284": {
        "title": "Virtual Private Cloud:Use OpenAPI",
        "url": "https://www.alibabacloud.com/help/en/vpc/developer-reference/using-openapi",
        "content": "This Product\nVirtual Private Cloud:Use OpenAPI\nFor more information about how to call the API operations of Alibaba Cloud, see Use OpenAPI. This topic describes the basic information about the Virtual Private Cloud (VPC) API, including the versions, API endpoint, API style, and call method.\nAPI version\nDescription\n2016-04-28\nWe recommend that you use this version.\nVPC OpenAPI supports multiple endpoints. For more information, see the following topics:\nEndpoints\nEndpoints (VPC peering connection)\nUser identity\nSupported\nAlibaba Cloud account\nYes\nRAM user (recommended)\nYes\nRAM role (recommended)\nYes\nThe API operations of VPC are called in the remote procedure call (RPC) style. For more information, see OpenAPI styles.\nMethod\nSupported\nReferences\nAlibaba Cloud SDK (recommended)\nYes\nFor more information about the supported programming languages and installment methods of the VPC SDK, see VPC SDK.\nFor more information about how to integrate Alibaba Cloud SDKs, see Alibaba Cloud SDKs.\nAlibaba Cloud CLI\nYes\nFor more information about how to use Alibaba Cloud CLI to call API operations, see Alibaba Cloud CLI.\nCloud Shell\nYes\nFor more information about how to use Cloud Shell to call API operations, see Cloud Shell.\nTerraform\nYes\nFor more information about how to use Terraform to call API operations, see Terraform.\nResource Orchestration Service (ROS)\nYes\nFor more information about how to use ROS to call API operations, see ROS.\nCustom encapsulation\nYes\nYou can encapsulate API requests based on your business requirements. For more information, see Custom encapsulation.\n"
    },
    "285": {
        "title": "Virtual Private Cloud:API Reference",
        "url": "https://www.alibabacloud.com/help/en/vpc/developer-reference/api-reference-new/",
        "content": "This Product\nVirtual Private Cloud:API Reference"
    },
    "286": {
        "title": "Virtual Private Cloud:API Reference (VPC Peering Connection)",
        "url": "https://www.alibabacloud.com/help/en/vpc/developer-reference/api-reference-peer-to-peer-connection/",
        "content": "This Product\nVirtual Private Cloud:API Reference (VPC Peering Connection)"
    },
    "287": {
        "title": "Virtual Private Cloud:API Reference (IP Address Manager)",
        "url": "https://www.alibabacloud.com/help/en/vpc/developer-reference/api-reference/",
        "content": "This Product\nVirtual Private Cloud:API Reference (IP Address Manager)"
    },
    "288": {
        "title": "CDN:Product Introduction",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/product-introduction/",
        "content": "This Product\nCDN:Product Introduction"
    },
    "289": {
        "title": "CDN:Announcements and Updates",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/announcements-and-updates/",
        "content": "This Product\nCDN:Announcements and Updates"
    },
    "290": {
        "title": "CDN:Billing",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/billing/",
        "content": "This Product\nCDN:Billing"
    },
    "291": {
        "title": "CDN:For beginners",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/getting-started",
        "content": "This Product\nCDN:For beginners\nThis topic describes how to get started with Alibaba Cloud CDN.\nWhat is Alibaba Cloud CDN?\nCommon scenarios\nCompetitive advantages of Alibaba Cloud CDN\nHow it works\nLimits\nTerms\nYou are billed for basic services (required) and value-added services (optional) in Alibaba Cloud CDN. Choose a metering method based on your business requirements. For more information, see Billing overview.\nAlibaba Cloud CDN provides cost-effective resource plans. For more information, see Guidelines for choosing resource plans.\nThe following figure shows how to get started with Alibaba Cloud CDN.\n\nComplete ICP filing: According to the laws of China and the requirements of the Ministry of Industry and Information Technology (MIIT), you must complete an ICP filing for domain names that are resolved to websites and apps whose servers are located in the Chinese mainland before the websites and apps can provide services. If you have completed an ICP filing for the domain name, you can proceed to the next step.\nActivate Alibaba Cloud CDN: Log on to the Alibaba Cloud console and activate Alibaba Cloud CDN.\nAdd a domain name: After you add a domain name in the Alibaba Cloud CDN console, the system pushes the configuration of the domain name to all points of presence (POPs). The first time you add a domain name to Alibaba Cloud CDN, you need to verify the ownership of a domain name by using a DNS record of the domain name. Once the domain passes the verification, its subdomains do not require separate ownership verification.\n(Optional) Configure system-recommended features: After you add a domain name to Alibaba Cloud CDN, we recommend that you configure features, such as cache expiration, bandwidth cap, and HTML optimization, for the domain name. This improves the cache hit ratio, security, and access performance of Alibaba Cloud CDN.\n(Optional) Test domain name accessibility: After you add a domain name to Alibaba Cloud CDN, we recommend that you perform a local test on the domain name to verify that the domain name is accessible and then map the DNS record of the domain name to the CNAME. This ensures that DNS updates do not affect the services.\nAdd a CNAME record for a domain name: After you add a domain name, Alibaba Cloud CDN assigns a CNAME to the domain name. You need to add a CNAME record in the system of your DNS service provider to map the domain name to the CNAME before acceleration can take effect.\nVisitor location\nAcceleration performance\nAcceleration region\nChinese mainland\nAll requests are redirected to points of presence (POPs) that are deployed in the Chinese mainland. Requests from outside the Chinese mainland are redirected to POPs that are managed by China Telecom (East China Division).\nChinese Mainland Only\nOutside the Chinese mainland\nAll requests are redirected to POPs that are deployed outside the Chinese mainland. Requests from the Chinese mainland are redirected to POPs that are deployed in Japan, Singapore, or Hong Kong (China).\nGlobal (Excluding the Chinese Mainland)\nGlobal\nAll requests are redirected to the nearest POPs.\nGlobal\nFor more information, see User Guide and Best Practices.\nOrigin settings\nCache settings\nPurge and prefetch resources\nHTTPS\nUse Alibaba Cloud CDN to accelerate the delivery of resources from OSS buckets\nFAQ\nIf you have questions or suggestions about Alibaba Cloud CDN, you can report them through the following methods. Alibaba Cloud customer service will follow up on your feedback.\nIf you find errors in the documentation, including link errors, content errors, and API operation errors, you can click the Feedback icon on the right side of the page to report the errors.\nIf you have questions about Alibaba Cloud CDN, submit a ticket."
    },
    "292": {
        "title": "CDN:Get started with CDN",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/quick-access-to-alibaba-cloud-cdn",
        "content": "This Product\nCDN:Get started with CDN\nThis topic describes the working mechanism of CDN, as well as key configurations and their functionalities, to help you quickly activate and configure CDN.\nIn this topic, www.example.com is used as the domain name, and 10.10.10.1 is the corresponding IP address.\nIf you are new to CDN, we recommend that you spend a few minutes to read this section. If you are already familiar with the working mechanism of CDN, you can skip this section.\nHow CDN accelerates content delivery\nWhen you enter a URL in a browser, almost instantly, a web page, image, video, or audio file appears on your screen. This process involves a complex set of software and hardware parsing and forwarding operations. The following part breaks down a simple example request to demonstrate how CDN accelerates content delivery.\nA client accesses the www.example.com domain to obtain an image. The browser cannot directly resolve the IP address of the server that hosts the image from the domain name. In this case, the browser first queries a DNS server to obtain the IP address 10.10.10.1 that is mapped to the domain name. Then, the browser uses the IP address to locate the server and fetches the required image.\nA domain name is like the name of a person, and an IP address is the address of the person. Just like you need to use the name of a person to look up the address of the person, a network request uses a domain name to find the relevant IP address.\nA DNS server acts as a large database that stores mappings between domain names and IP addresses. For more information about DNS servers and domain names, see Terms.\nAs the number of requests destined for images by using www.example.com increases, the server may respond increasingly slowly due to factors such as the server configuration and network environment. This is where CDN comes in. It provides an effective solution to accelerate response time.\nCDN works as a cache system that sits between the server and client in the network topology. When a client initiates a request to CDN, the system first checks whether the requested image is cached. If yes, the cached image is directly returned to the browser. If no, CDN requests the image from the server, caches it, and then sends the response to the client that initiated the request.\nAccelerating content delivery is only the basic feature of CDN. For more information about CDN and its advanced features, see What is CDN?\nCDN accelerates content delivery beyond the server architecture. Therefore, no impacts on the server are imposed and no business code modifications are required.\nThe actual request process is much more complex. The simplified process in this topic is intended only to explain how CDN works.\nCompared with other acceleration methods, CDN does not require any modifications to the business code of the server. You can enable content delivery acceleration with only a few configurations. This section describes how to configure CDN by using the preceding example domain name and IP address.\nBefore you add a domain name to CDN, complete the following operations:\nCreate an Alibaba Cloud account and perform real-name verification.\nActivate CDN.\nTo enable acceleration for your domain name, you must add your domain name to CDN.\nAdd a domain name\nLog on to the CDN console.\nIn the left-side navigation pane, click Domain Names.\nClick Add Domain Name. In the Specify Domain Name Information step, configure Region, Domain Name to Accelerate, and Business Type. Keep the default settings for other parameters.\n\n\nDomain Name to Accelerate: the website or resource domain name that you want CDN to speed up for end user access. In this example, www.example.com is specified.\nRegion: the service location where you want CDN to speed up the domain name. Select a service location based on your business requirements. In this example, Chinese Mainland Only is selected.\nBusiness Type: the business type. Select a type based on your business requirements. In this example, Image and Small File is selected.\nFor more information about the configuration items, see Step 1: Configure business information.\nTo make sure that the domain name you added belongs to you, CDN needs to verify the ownership of the domain name. If you have previously completed the verification or the verification prompt is not displayed when you configure the domain name, skip this step.\nVerify the domain ownership\nDo not close the Verification page before the verification is complete.\nOn the verification page, click the Method 1: DNS Settings tab and record the values of the Host and Value parameters.\n\nAdd a TXT record in the system of your DNS provider. The following example shows how to add a TXT record to Alibaba Cloud DNS. You can use similar methods to add TXT records to other DNS providers, such as Tencent Cloud and Xinnet.\nConfigure a TXT record\nLog on to the Alibaba Cloud DNS console.\nOn the DNS resolution page, find the root domain example.com and click DNS Settings in the Actions column.\nClick Add DNS Record. In the dialog box that appears, select TXT for Record Type parameter, set Hostname and Record Value to the values that are obtained in Step 1. Keep the default settings for other parameters.\n\nClick OK.\nA root domain is the main address of a website. It is the most basic level of a website's online presence. All webpages, email servers, and other services are built on a root domain. For example, in shop.example.com and blog.example.com, example.com is the root domain, and \"shop.\" and \"blog.\" are subdomains that extend the functionality of the root domain.\nAfter the TXT record takes effect, go to the CDN console and click Verify.\nIf the domain name fails the verification, check whether the TXT record is entered correctly. Wait for the TXT record to take effect and try again. In the following examples, the domain name www.example.com is used to check whether the TXT record is valid.\nOpen Command Prompt in Windows and run the nslookup -type=TXT verification.example.com command. You can check whether the TXT record is valid based on the output.\n\nOpen Terminal in macOS or Linux and run the nslookup -type=TXT verification.example.com command. You can check whether the TXT record is valid based on the output.\n\nIn the nslookup command, you must replace the hostname in the domain name with \"verification\". For example, if the domain name is help.aliyun.com, enter verification.aliyun.com in the nslookup command.\nIf you add a TXT record, the TXT record immediately takes effect. If you modify a TXT record, the amount of time that is required for the update to take effect is based on the time to live (TTL). The default TTL is 10 minutes.\nIf nslookup is not installed on Linux, run the yum install bind-utils command on CentOS or the apt-get install dnsutils command on Ubuntu to install nslookup.\nOn the verification page, click the Method 2: Verification File tab.\n\nDownload the verification.html file.\nUpload the verification file to the root directory on the server of the root domain. The server can be an Elastic Compute Service (ECS) instance, an Object Storage Service (OSS) bucket, a Cloud Virtual Machine (CVM) instance, a Cloud Object Storage (COS) instance, or an Elastic Compute Cloud (EC2) instance. For example, if the domain name is www.example.com, you need to upload the file to the root directory of example.com.\nAfter you make sure that the verification file is accessible from http://example.com/verification.html, click Verify.\nCDN accesses http://example.com/verification.html on your server for verification.\nIf the record value in the file is the same as the record value in the verification file, the verification is successful.\nOtherwise, the verification fails. Make sure that the preceding URL is accessible and that the uploaded file is valid.\nAn origin server is a web server on which you run your business. You need to configure the origin information. This way, CDN can retrieve resources from your origin server when the requested resources are not cached.\nSet up an origin server\nAfter you configure the business information for the domain name, click Add Origin Server in the Origin Servers section.\nIn the Add Origin Server dialog box, select the type of the origin and enter the origin address.\nConfigure the Port parameter based on the port number of your origin. If you do not know the port number of your origin or you do not have any special requirements, keep the default setting.\n\nIn this example, 10.10.10.1 is used as the IP address of the origin server.\nIf you want to speed up the distribution of resources stored in an OSS bucket, select OSS Domain for Origin Info.\nIf the resource that you want to accelerate is deployed on an ECS instance, select IP for Origin Info and enter the public IP address of the ECS instance.\nIf the resource that you want to accelerate is hosted on a server and cannot be accessed by using an IP address, select Site Domain for Origin Info and enter the domain name of the origin server. The origin domain name must be different from the accelerated domain name. Otherwise, a DNS resolution loop occurs, and requests cannot be redirected to the origin server.\nIf the resource that you want to accelerate is an Alibaba Cloud Function Compute instance, select Function Compute Domain for Origin Info. Then, select the region and domain name as needed.\nFor more information about the configuration items, see Set up origin servers.\nFor information about the best practices of using CDN for OSS, see Use CDN to accelerate the delivery of resources from OSS buckets.\nAfter you add a domain name to CDN, we recommend that you test whether the domain name is accessible before you update the CNAME record of the domain name. This ensures that DNS updates do not affect the services of the domain name.\nDuring the test, requests are sent to points of presence (POPs). You are charged for basic services and value-added services of CDN that you use. The billing rules of CDN apply in the test. For more information, see Billable items.\nVerify the domain name\nObtain the CNAME assigned to the domain name.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and copy the CNAME.\nCopy the CNAME of a domain name that is in the Normal state.\n\nObtain the IP address of the CNAME. Run the nslookup  command for the CNAME of the domain name in a CLI, such as Command Prompt, PowerShell, or Terminal, to obtain the IP address of the CNAME. Example:\n\nAdd the IP address and domain name to the hosts file of the on-premises machine.\nYou must add the IP address obtained in the previous step and the domain name to the hosts file of the on-premises machine. Make sure that you add the IP address before the domain name. The following examples describe how to add the IP address 192.168.0.1 and the domain name to the hosts file of the on-premises machine:\nGo to the C:\\Windows\\System32\\drivers\\etc directory and use Notepad to open the hosts file as the administrator.\nEdit the hosts file. The file content may be similar to the following text:\nAdd the obtained IP address and the domain name to the end of the file. Example:\nSave the changes. After you edit the file, choose File > Save or press Ctrl+S to save changes.\n(Optional) Refresh the DNS cache to ensure that the DNS resolution changes immediately take effect.\nOpen Command Prompt as the administrator and run the following command:\nOpen Terminal and run the following command to open the hosts file as an administrator.\nEdit the hosts file. The file content may be similar to the following text:\nAdd the obtained IP address and the domain name to the end of the file. Example:\nSave the changes and exit.\nPress Esc to exit the insert mode, enter :wq, and then press Enter to save the file and exit the Vim editor.\n(Optional) Refresh the DNS cache to ensure that the DNS resolution changes immediately take effect.\nRun the following command in Terminal:\nTest whether the domain name is accessible.\nAfter you add the IP address and domain name to the hosts file, you can open the browser and enter the accelerated domain name in the address bar to test the connectivity. You can view the test result by using the developer tool embedded in the browser.\nIf the IP address in the Remote Address field is the same as the one that you added to the hosts file, the configuration is valid. You can configure the CNAME on the management console provided by the DNS service provider.\nIf the IP address in the Remote Address field is different from the one that you added to the hosts file, the configuration is invalid. Make sure that you add the IP address of the CNAME to the hosts file.\nAfter you access the domain name, you can also test other features by using the on-premises machine.\nBefore you connect your domain name to CDN, a request for the domain name is directly sent to the origin server. After you connect the domain name to CDN, a request is first sent to the nearest POP. Then, CDN determines whether to route the request to the origin server. To ensure a seamless transition from direct origin access to CDN-enabled access, you must configure a CNAME record.\nA CNAME record is a type of DNS record that points one domain name to another. For more information about CNAME records, see CNAME record overview.\nAdd a CNAME record\nLog on to the CDN console and navigate to the Domain Names page, find the domain name that you added, and copy the CNAME of the domain name. If no value is available in the CNAME column, wait 5 seconds and refresh the page.\n\nAdd a CNAME record to the DNS settings of the domain name. The procedure to add a CNAME record varies with your DNS provider. In this topic, Alibaba Cloud and Tencent Cloud are used as examples.\nIf your DNS provider is Alibaba Cloud, perform the following steps to add a CNAME record for the domain:\nLog on to the Alibaba Cloud DNS console by using the Alibaba Cloud account to which the domain name belongs.\nOn the DNS resolution page, find the root domain example.com and click DNS Settings in the Actions column.\nClick Add DNS Record to add a record.\nSet the Record Type parameter to CNAME.\n\nHostname is the prefix of a domain name. For example, the hostname of www.example.com is www. If the domain name that you want to accelerate is the root domain example.com, enter @ in the Hostname field.\nA CNAME record cannot share the same hostname with an A record. If the domain that you want to accelerate has an A record with the same hostname, you must suspend or delete the A record before you configure a CNAME record.\nThis will cause the domain to be temporarily inaccessible. To reduce the impact on your domain, we recommend that you configure a CNAME record during off-peak hours.\nClick OK.\nIf your DNS provider is Tencent Cloud, perform the following steps to add a CNAME record for the domain:\nLog on to the DNSPod console.\nOn the DNSPod page, click Add Records to add a CNAME record.\nParameter\nDescription\nExample\nHostname\nFor subdomains, enter the prefix of the subdomain.\nFor wildcard domains, enter *.\nFor root domains, enter @.\nFor more information about subdomains, see Terms.\n\nSubdomains:\nIf the domain name to be accelerated is example.aliyundoc.com, enter example.\nIf the domain name to be accelerated is www.example.aliyundoc.com, enter www.example.\nWildcard domains:\nIf the domain name to be accelerated is .aliyundoc.com, enter *.\nIf the domain name to be accelerated is *.example.aliyundoc.com, enter *.example.\nRoot domains: If the root domain is aliyundoc.com and the domain name to be accelerated is aliyundoc.com, enter @.\nDomain name resolution settings apply to the domain name that you register, such as aliyundoc.com, or the left part of the domain name. When you specify the Hostname parameter, enter the part to be resolved. For example, if the domain name to be accelerated is example.aliyundoc.com, enter example.\nRecord Type\nSelect CNAME.\nCNAME\nDNS Request Source\nSelect Default from the drop-down list.\nWe recommend that you keep the default setting.\nRecord Value\nEnter the CNAME of the domain name.\nFor example, example.aliyundoc.com, and www.example.aliyundoc.com correspond to different CNAMEs. If you want to accelerate a subdomain, add the second-level domain to Alibaba Cloud CDN. Alibaba Cloud then assigns a CNAME to the subdomain. Alternatively, you can add a wildcard domain name to Alibaba Cloud CDN. Subdomains that match the wildcard domain name are mapped to the CNAME of the wildcard domain name. For more information, see Add a domain name.\nwww.example.com.w.kunlunsl.com\nWeight\nYou do not need to specify this parameter.\nN/A\nMX\nYou do not need to specify this parameter.\nN/A\nTTL\nEnter a TTL value for the CNAME record. A smaller value specifies that the record is updated quicker.\nWe recommend that you keep the default setting.\nClick OK.\nCheck whether the configured CNAME takes effect.\nLog on to the CDN console and navigate to the Domain Names page.\nFind the domain name and move the pointer over the CNAME Status column. If the status is Configured, the CNAME has taken effect.\n\nThe CNAME Status may remain Pending Configuration after your configuration. Refresh the page or check the status 5 minutes later.\nStart Command Prompt in Windows or Terminal in macOS or Linux.\nEnter nslookup -type=CNAME domainName (example: nslookup -type CNAME www.example.com). If the returned result is the same as the CNAME of the domain name in the CDN console, the CNAME has taken effect.\n\nWindows: Press Windows + R, type cmd in the Run box that appears, and press Enter. The Command Prompt window is displayed.\nmacOS: Open Terminal.\nRun the check commands.\nRun the ping domainName command, such as ping www.example.com.\n\nRun the dig domainName command, such as dig www.example.com.\n\nView the CNAME in the output. If the CNAME is www.example.com.w.kunlun.com, CDN has taken effect for the domain.\nIf an IP address is returned, as shown in the preceding figure, use the IP address check tool of CDN to check whether the IP address belongs to an CDN POP.\nCheck whether an IP address belongs to an CDN POP\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Tools.\n\nIn the IP Address Check section, click Try Now.\n\nEnter the IP addresses that you want to check and click Check.\nBoth IPv4 and IPv6 addresses are supported. You can check up to 20 IP addresses at a time. Separate IP addresses with commas (,).\nView the check result.\nIf the checked IP address belongs to an CDN POP, the value of CDN Node is Yes and the values of Region and Provider are the actual region and ISP to which the IP address belongs.\nIf the checked IP address does not belong to an CDN POP, the value of CDN Node is No, and the values of Region and Provider are Unknown.\n\nFor more information about CNAME configurations, see Add a CNAME record for a domain name.\nIf your domain already supports HTTPS access before you connect it to CDN, you must configure an SSL certificate to enable subsequent HTTPS access.\nIf your domain does not support HTTPS access and does not require it, skip this section.\nConfigure an SSL certificate\nAfter you enable HTTPS access, you are charged for HTTPS requests. HTTPS request fees cannot be offset by data transfer plans. To avoid service suspension, make sure that you have sufficient balance in your Alibaba Cloud account, or purchase resource plans for HTTPS requests. For more information, see Billing of HTTPS requests for static content.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click HTTPS.\nIn the HTTPS Certificate section, click Modify.\nIn the Modify HTTPS Settings dialog box, turn on HTTPS Secure Acceleration, and configure other relevant parameters.\n\nIf you have purchased a certificate from Alibaba Cloud Certificate Management Service, set the Certificate Source parameter to SSL Certificates Service and select the purchased certificate from the Certificate Name drop-down list.\nIf you use a certificate that is issued by a third-party CA, set the Certificate Source parameter to Custom Certificate (Certificate+Private Key). After you configure the Certificate Name parameter, configure the Certificate (Public Key) and Private Key parameters. Then, the certificate is saved in Alibaba Cloud Certificate Management Service. You can check the certificate on the SSL Certificates page.\nVerify that the HTTPS configuration takes effect.\nAfter you upload an SSL certificate, the certificate takes effect within 1 minute. To check whether the SSL certificate takes effect, you can send HTTPS requests to access resources. If the URL is displayed with an HTTPS icon in the address bar of the browser, such as Google Chrome, HTTPS acceleration is working as expected. After you configure an SSL certificate, take note of the expiration time of the certificate. You need to configure a new certificate before the certificate expires.\n\nFor more information about how to configure an SSL certificate, see Configure an SSL certificate.\nCheck whether resources can be cached on CDN\nWindows: Press Windows + R, type cmd in the Run box that appears, and press Enter. The Command Prompt window is displayed.\nmacOS: Open Terminal.\nRun the curl -I resourceURL command, such as ping www.example.com/10.JPG.\n\nView the response header. If it contains Age, X-Cache, X-Swift-SaveTime, and X-Swift-CacheTime, CDN has taken effect for the domain.\nX-Cache: If the value of this field is MISS, the cache is missed and the request is redirected to the origin server. If the value of this field is HIT, the cache is hit and the cached resource is returned.\nAge: the period of time for which the resource has been cached on POPs. Unit: seconds. If the resource is refreshed or accessed for the first time, this field is not included in the response header. A value of 0 in this field indicates that the cache is expired and the request must be redirected to the origin server.\nX-Swift-SaveTime: the time when the resource was first cached on POPs. The time is displayed in UTC. You can convert the time to UTC+8.\nX-Swift-CacheTime: the TTL period of a resource that is cached on POPs. If the value is 0, resources cannot be cached.\nIf the domain fails to be accessed or exceptions occur during the access process after you complete the preceding steps, see Service unavailability and exceptions.\nAfter the preceding configurations are complete, your website is accelerated by CDN. To ensure secure and stable operations of the website, we strongly recommend that you configure security features and cache policies.\nMalicious attacks and fraudulent traffic are ubiquitous and can cause sudden spikes in bandwidth consumption or excessive amounts of data transmission. This can result in unexpectedly high costs for your website. We strongly recommend that you configure appropriate security measures to prevent such risks.\nConfigure security settings\nEnable log monitoring\nCDN supports offline logs and real-time logs. By analyzing the collected logs, you can quickly identify business and security issues and make prompt adjustments. For more information about logs, see Logs and reports.\nLog category\nLog delay\nBilling\nBest practice\nOffline logs\nWithin 24 hours\nFree of charge\nAnalyze offline logs\nReal-time logs\nWithin 3 minutes\nCharged (Billing rules)\nDeliver CDN real-time logs to SLS for analysis\nConfigure a Referer whitelist or blacklist\nReferer-based hotlink protection refers to access control based on the Referer header. You can configure a Referer whitelist or blacklist to control access, protecting your resources from unauthorized access.\nYou can configure a Referer whitelist to allow only requests from specific domains, such as domains that are related to your website system. This way, you can identify and filter visitors to prevent unauthorized use of website resources. For more information, see Configure a Referer whitelist or blacklist to enable hotlink protection.\nConfigure real-time bandwidth monitoring\nYou can use CloudMonitor to monitor the peak bandwidth of CDN domains in real time. When the bandwidth of a domain reaches the specified threshold, you will be notified of the potential risks. For more information, see Configure alert rules.\nThe following tables describe other security policies that you can configure.\nOther security policies\nFeature\nDescription\nURL signing\nURL signing allows POPs to work with your origin servers to protect origin resources from unauthorized use. For more information, see Configure URL signing.\nRemote authentication\nAfter you enable remote authentication, POPs redirect user requests to a specific authentication server. The authentication server verifies the user requests to prevent resources from being accessed by unauthorized users. For more information, see Configure remote authentication.\nIP address blacklist or whitelist\nAfter a malicious attack or traffic spike occurs, you can use the real-time log analysis feature to check whether your domain is frequently accessed by an IP address. If a malicious IP address is identified, you can add it to a blacklist. For more information, see Configure an IP address blacklist or whitelist.\nUser-Agent blacklist or whitelist\nAfter a malicious attack or traffic spike occurs, you can use the real-time log analysis feature to identify the User-Agent headers associated with malicious requests. Then, you can configure a User-Agent blacklist or whitelist to block future requests that contain the identified User-Agent header. For more information, see Configure a User-Agent blacklist or whitelist.\n\nFeature\nDescription\nBandwidth cap\nTo limit the amount of bandwidth resources that a domain name can consume, you can specify a bandwidth cap for the domain name. After the bandwidth of the domain name reaches the specified bandwidth cap, CDN disables acceleration for the domain name and the domain name is resolved to an invalid address. This prevents unexpected high bills. For more information, see Configure a bandwidth cap.\nTraffic throttling for individual requests\nTraffic throttling for individual requests allows you to limit the downstream speed for all requests that are sent to POPs. This feature can be used in website operations, such as game releases. This way, you can limit the overall peak bandwidth of accelerated domain names. For more information, see Configure traffic throttling for individual requests.\nBandwidth throttling\nIf the daily peak bandwidth of your domain name is greater than 10 Gbit/s and you want to throttle CDN bandwidth for the domain name, submit a ticket.\nBandwidth throttling applies to the overall bandwidth of all services that are hosted by the domain name. To ensure the accuracy of bandwidth throttling, the bandwidth limit must be at least 10 Gbit/s.\nAfter the bandwidth limit, such as 10 Gbit/s, is reached, CDN limits the bandwidth of the accelerated domain name. The response to all requests is slower, and packet loss may also occur.\nBandwidth throttling is triggered by the real-time monitoring data of the accelerated domain name. Because the data comes with a delay of approximately 10 minutes, bandwidth throttling starts approximately 10 minutes after the bandwidth limit is reached. In this case, the bandwidth of the accelerated domain name may exceed the limit.\n\nIf your domain experiences an attack or has an unexpectedly high bill, troubleshoot the issue by referring to Prevent data transmission abuse.\nAfter you add a domain name to CDN, we recommend that you configure a cache TTL and HTML optimization. These features help increase the cache hit ratio, reinforce security, and improve content retrieval efficiency.\nRecommended configurations\nCache TTL and request parameter ignoring\nIn most cases, slow content delivery is related to low cache hit ratios. We recommend that you specify a proper cache TTL and configure query parameter ignoring to increase the cache hit ratio.\nScenario\nDescription\nReference\nLow cache hit ratio and slow content retrieval\nThe time-to-live (TTL) value for cached content is smaller than required or no cache expiration rule is created, which causes requests to be frequently redirected to the origin server. In this case, you need to specify a proper TTL value to increase the cache hit ratio and accelerate content retrieval.\nWe recommend that you specify a TTL value based on the following rules:\nSpecify a TTL value of one month or longer for static files that are infrequently updated, such as images and application packages.\nSpecify a TTL value based on your actual workloads for static files that are frequently updated, such as JavaScript and CSS files.\nCreate a cache rule for resources\nBy default, client requests are redirected to the origin server with the complete URLs retained, including parameters that follow the question mark (?). After you enable the parameter ignoring feature, the parameters that follow the question mark (?) in the request URL are ignored when the client retrieves resources from the origin server. This improves the cache hit ratio and reduces the number of origin requests.\nIgnore parameters\nBandwidth monitoring and alerts\nTo prevent bandwidth spikes caused by attacks, you can configure the monitoring and alerting features to monitor bandwidth values. Alternatively, you can specify a bandwidth cap.\nScenario\nDescription\nReference\nPrevent high bandwidth values\nYou can specify a bandwidth cap. If a bandwidth value during a statistical period exceeds the bandwidth cap, CDN suspends acceleration and resolves the domain name to an invalid address offline.***.com, which cannot be accessed.\nConfigure bandwidth caps\nYou can configure alert rules in CloudMonitor to monitor bandwidth values. This allows you to detect and manage bandwidth anomalies at the earliest opportunity.\nConfigure alert rules\nResource prefetch\nThe first time a user requests a resource that you connect to CDN, the system retrieves the resource on the origin server and then caches the resource on POPs. This reduces the speed of the first request. The speed of subsequent requests is not affected. In this case, you can use the resource prefetch feature to cache the resource on POPs in advance and speed up access. For more information, see Purge and prefetch resources.\nFAQ\nWhat is CDN?\nCompetitive advantages of CDN\nCustomer use cases"
    },
    "293": {
        "title": "CDN:Domain name management",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/domain-name-management/",
        "content": "This Product\nCDN:Domain name management\n\nIf you have multiple origins and want to direct requests meeting specific criteria to a designated origin, Alibaba Cloud CDN offers the conditional origin feature. This allows you to route requests to different origins based on predefined rules. For more information, see Configure conditional origin.\nAlibaba Cloud CDN also provides a suite of back-to-origin configuration features. For instance, when using multiple origins, you can set distinct back-to-origin hosts for each. This includes the ability to add, modify, or delete back-to-origin request headers and response headers, along with to rewrite the back-to-origin URL and parameters. For more information, see Back-to-origin overview.\nProper cache configuration can reduce access latency, enhance user experience, and alleviate origin load. Alibaba Cloud CDN offers various cache options to tailor to your needs. For more information, see What is cache.\nAlibaba Cloud CDN supports HTTPS encrypted access, which necessitates an HTTPS certificate configuration. It also supports HTTP Strict Transport Security (HSTS), HTTP/2, and additional features. For more information, see What is HTTPS acceleration.\nTo secure your site, Alibaba Cloud CDN offers protection measures such as Referer hotlink protection, URL signing, and IP blacklist or whitelist configurations tailored to your business scenario. For more information, see Resource Access Management overview.\nCross-account migration of CDN domain names\nCreate CDN alert rules\nUse tags to manage domain names\nBasic configuration overview\nBack-to-origin configuration overview\nCache configuration overview\nHTTPS configuration\nResource Access Management overview\nPerformance optimization overview\nVideo optimization overview\nTraffic limit configuration\nConfigure QUIC protocol\nRules engine configuration\nBack-to-origin FAQ\nCache-related FAQ\nHTTPS-related FAQ\nResource Access Management FAQ\nCDN acceleration for OSS resources\nCDN acceleration for ECS resources\nCDN acceleration for portal websites\nBest practices for preventing traffic abuse\nImprove CDN cache hit ratio\nSolution for excessive redirection after CDN acceleration"
    },
    "294": {
        "title": "CDN:Monitoring and usage analytics",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/monitoring-and-usage-analytics/",
        "content": "This Product\nCDN:Monitoring and usage analytics"
    },
    "295": {
        "title": "CDN:Purge and prefetch",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/refresh-and-prefetch/",
        "content": "This Product\nCDN:Purge and prefetch"
    },
    "296": {
        "title": "CDN:Tools",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/tools/",
        "content": "This Product\nCDN:Tools"
    },
    "297": {
        "title": "CDN:Security and Protection",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/security-and-protection/",
        "content": "This Product\nCDN:Security and Protection"
    },
    "298": {
        "title": "CDN:Application",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/application/",
        "content": "This Product\nCDN:Application"
    },
    "299": {
        "title": "CDN:Resource usage",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/resource-usage/",
        "content": "This Product\nCDN:Resource usage"
    },
    "300": {
        "title": "CDN:Logs and reports",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/logs-and-reports/",
        "content": "This Product\nCDN:Logs and reports"
    },
    "301": {
        "title": "CDN:Permissions and Quotas",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/permissions-and-quotas/",
        "content": "This Product\nCDN:Permissions and Quotas"
    },
    "302": {
        "title": "CDN:Best Practices",
        "url": "https://www.alibabacloud.com/help/en/cdn/use-cases/best-practices/",
        "content": "This Product\nCDN:Best Practices"
    },
    "303": {
        "title": "CDN:Use RAM to implement access control",
        "url": "https://www.alibabacloud.com/help/en/cdn/security-and-compliance/identity-management-and-access-control-1/",
        "content": "This Product\nCDN:Use RAM to implement access control"
    },
    "304": {
        "title": "CDN:EdgeRoutine",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgeroutine-2/",
        "content": "This Product\nCDN:EdgeRoutine"
    },
    "305": {
        "title": "CDN:EdgeScript",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgescript/",
        "content": "This Product\nCDN:EdgeScript"
    },
    "306": {
        "title": "CDN:Announcement on discontinuation of 2014 API",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/announcement-on-discontinuation-of-2014-api",
        "content": "This Product\nCDN:Announcement on discontinuation of 2014 API\nBeginning 00:00:00 (UTC+8) on February 25, 2021, Alibaba Cloud started discontinuing 2014 API. If your system uses 2014 API, we recommend that you upgrade to 2018 API at the earliest opportunity to prevent service unavailability. If you have any question, submit a ticket.\n2014 API operation\nDescription\n2018 API operation\nDescribeDomainBpsData\nQueries the bandwidth data.\nDescribeDomainBpsData\nDescribeDomainBpsDataByTimeStamp\nQueries the bandwidth data at a specified point in time for an accelerated domain name.\nDescribeDomainBpsDataByTimeStamp\nDescribeDomainHitRateData\nQueries the byte hit ratios. Byte hit ratios are measured in percentage.\nDescribeDomainHitRateData\nDescribeDomainHttpCodeData\nQueries the total number of HTTP status codes and the proportion of each HTTP status code.\nDescribeDomainHttpCodeData\nDescribeDomainQpsData\nQueries the number of queries per second (QPS). Data is collected every 5 minutes.\nDescribeDomainQpsData\nDescribeDomainReqHitRateData\nQueries the request hit ratios. Request hit ratios are measured in percentage.\nDescribeDomainReqHitRateData\nDescribeDomainSrcBpsData\nQueries the bandwidth data during back-to-origin routing.\nDescribeDomainSrcBpsData\nDescribeRangeDataByLocateAndIspService\nQueries the bandwidth data by Internet service provider (ISP) and region.\nDescribeRangeDataByLocateAndIspService\nDescribeDomainSrcFlowData\nQueries the monitoring data of origin traffic.\nDescribeDomainSrcTrafficData\nDescribeDomainFlowData\nQueries the monitoring data of network traffic.\nDescribeDomainTrafficData\nDescribeDomainPathData\nQueries monitoring data including the amount of network traffic and the number of visits by path. Monitoring data is collected every 5 minutes.\nBy default, this feature is no longer available in 2018 API. To use this feature, submit a ticket.\nDescribeExtensiveDomainData\nQueries the network monitoring data of a wildcard domain name.\nThis feature is no longer available in 2018 API.\nDescribeCdnMonitorData\nQueries the monitoring data of Alibaba Cloud CDN.\n2014 API operation\nDescription\n2018 API operation\nDescribeDomainRealTimeBpsData\nQueries the bandwidth data of one or more accelerated domain names. Data is collected every minute.\nDescribeDomainRealTimeBpsData\n2014 API operation\nDescription\n2018 API operation\nDescribeDomainPvData\nQueries the number of page views (PVs) to an accelerated domain name.\nDescribeCdnReport\nDescribeDomainUvData\nQueries the number of unique visitors (UVs) to an accelerated domain name.\nDescribeDomainTopUrlVisit\nQueries frequently requested URLs.\nDescribeDomainTopReferVisit\nQueries frequently requested web pages and sorts the web pages.\nDescribeDomainRegionData\nQueries the distribution of users by region.\nDescribeDomainISPData\nQueries the bandwidth values of different Internet service providers (ISPs) in different regions at a specified time point for an accelerated domain name.\nDescribeTopDomainsByFlow\nQueries the top N accelerated domain names that are ranked by network traffic.\nDescribeDomainFileSizeProportionData\nQueries the proportions of file sizes.\nThis feature is no longer available in 2018 API.\n2014 API operation\nDescription\n2018 API operation\nDescribeDomainsUsageByDay\nQueries the monitoring data of an accelerated domain name. Data is collected on a daily basis.\nDescribeDomainsUsageByDay\n2014 API operation\nDescription\n2018 API operation\nBatchSetCdnDomainConfig\nConfigures one or more accelerated domain names.\nBatchSetCdnDomainConfig\nSetCcConfig\nConfigures protection against HTTP flood attacks.\nSetForceRedirectConfig\nConfigures the URL redirection feature.\nSetHttpsOptionConfig\nConfigures the HTTP 2.0 feature.\nSetOptimizeConfig\nConfigures the HTML optimization feature.\nSetPageCompressConfig\nConfigures the intelligent compression feature.\nSetPathCacheExpiredConfig\nConfigures the time-to-live (TTL) feature for a directory.\nSetRefererConfig\nConfigures a Referer whitelist or blacklist to prevent hotlinking.\nSetReqAuthConfig\nConfigures the access authentication feature.\nSetReqHeaderConfig\nConfigures a custom origin header.\nSetSourceHostConfig\nSpecifies an origin host for an accelerated domain name.\nSetIpBlackListConfig\nConfigures an IP address blacklist for an accelerated domain name.\nSetHttpHeaderConfig\nConfigures a custom HTTP header.\nDeleteCacheExpiredConfig\nDeletes configurations of multiple accelerated domain names at a time.\nBatchDeleteCdnDomainConfig\nAddCdnDomain\nAdds a domain name to Alibaba Cloud CDN.\nAddCdnDomain\nDeleteCdnDomain\nRemoves a domain name from Alibaba Cloud CDN.\nDeleteCdnDomain\nDescribeCdnDomainDetail\nQueries the basic information about a specified accelerated domain name.\nDescribeCdnDomainDetail\nDescribeDomainsBySource\nQueries domain names by origin server.\nDescribeDomainsBySource\nDescribeUserDomains\nAll accelerated domain names within your Alibaba Cloud account and their status are queried.\nDescribeUserDomains\nStartCdnDomain\nEnables a domain name.\nStartCdnDomain\nStopCdnDomain\nDisables a domain name.\nStopCdnDomain\nDescribeDomainConfigs\nQueries the configurations of an accelerated domain name.\nDescribeCdnDomainConfigs\n2014 API operation\nDescription\n2018 API operation\nDescribeCdnDomainLogs\nQueries the address where you can download offline logs of a specific domain name.\nDescribeCdnDomainLogs\n2014 API operation\nDescription\n2018 API operation\nDescribeCdnUserQuota\nQueries the maximum and remaining quotas.\nDescribeCdnUserQuota\nPreloadObjectCaches\nPrefetches content from origin servers to Alibaba Cloud CDN points of presence (POPs).\nPushObjectCache\nPushObjectCache\nRefreshes the cached content on Alibaba Cloud CDN POPs.\nPurgeObjectCaches\nRefreshes files on Alibaba Cloud CDN POPs.\nRefreshObjectCaches\nRefreshObjectCaches\nRefreshes the latest file content on the origin to the cache POPs.\nDescribeRefreshQuota\nQueries the quota of URLs and directories that can be refreshed and prefetched.\nDescribeRefreshQuota\nDescribeRefreshTasks\nQueries the status of refresh or prefetch tasks.\nDescribeRefreshTasks\n2014 API operation\nDescription\n2018 API operation\nDescribeCdnRegionAndIsp\nQueries the most recent region and ISP lists.\nDescribeCdnRegionAndIsp\nDescribeCdnService\nQueries the status of Alibaba Cloud CDN.\nDescribeCdnService\nOpenCdnService\nActivates Alibaba Cloud CDN.\nOpenCdnService\n2014 API operation\nDescription\n2018 API operation\nDescribeDomainCertificateInfo\nQueries certificate information about an accelerated domain name.\nDescribeDomainCertificateInfo\nSetCdnDomainSSLCertificate\nSpecifies whether to enable the SSL certificate for a domain name and update the certificate information.\nSetCdnDomainSSLCertificate\n2014 API operation\nDescription\n2018 API operation\nDescribeUserVipsByDomain\nQueries virtual IP addresses of Alibaba Cloud CDN POPs by domain name.\nDescribeUserVipsByDomain\nDescribeIpInfo\nChecks whether an IP address belongs to an Alibaba Cloud CDN POP.\nDescribeIpInfo\nDescribeL2VipsByDomain\nQueries the virtual IP addresses of POPs for a specific domain name.\nDescribeL2VipsByDomain\nBlockObjectCaches\nBlocks specified URLs on Alibaba Cloud CDN POPs.\nBy default, this feature is no longer available in 2018 API. To use this feature, submit a ticket.\nThe ApsaraVideo Live API operations that are included in 2014 API of Alibaba Cloud CDN are no longer included in 2018 API of Alibaba Cloud CDN. The features of these API operations are provided by Alibaba Cloud ApsaraVideo Live.\n2014 API operation\nDescription\nApsaraVideo Live API operation\nDescribeLiveStreamTranscodeStreamNum\nQueries the number of transcoded streams in real time.\nDescribeLiveStreamTranscodeStreamNum\nThis operation is available only to users in the whitelist.\nDescribeLiveStreamsFrameRateAndBitRateData\nQueries the frame rate and bitrate of a live stream in real time.\nDescribeLiveDomainFrameRateAndBitRateData\nDeleteLivePullStreamInfo\nDeletes a stream pulling configuration.\nDeleteLivePullStreamInfoConfig\nDescribeLiveStreamsPublishList\nQueries historical stream ingest records.\nDescribeLiveStreamsPublishList\nDescribeLiveStreamRecordContent\nQueries live recordings.\nDescribeLiveStreamRecordContent\nDescribeLiveStreamRecordIndexFile\nQueries the information about an index file.\nDescribeLiveStreamRecordIndexFile\nDescribeLiveStreamSnapshotInfo\nQueries the snapshots that are captured within a specific period of time.\nDescribeLiveStreamSnapshotInfo\nDescribeLivePullStreamConfig\nQueries the stream pulling configurations of a domain name.\nDescribeLivePullStreamConfig\nAddLivePullStreamInfo\nCreates a configuration that triggers stream pulling.\nAddLivePullStreamInfoConfig\nDescribeLiveStreamPushData\nQueries monitoring data of stream ingest quality.\nThis feature is no longer available in ApsaraVideo Live API.\nCreateLiveStreamRecordIndexFiles\nCreates an index file for a recording.\nResumeLiveStream\nThe ingest of a live stream is resumed.\nResumeLiveStream\nForbidLiveStream\nDisables the ingest of a live stream.\nForbidLiveStream\nDescribeLiveStreamsOnlineList\nQueries the information about all active streams under a specified domain name or the active streams of an application under a specified domain name.\nDescribeLiveStreamsOnlineList\nDescribeLiveStreamRecordIndexFiles\nQueries information about all index files within a specific period of time.\nDescribeLiveStreamRecordIndexFiles\nDescribeLiveStreamOnlineUserNum\nQueries the number of online users at a specified point in time for all live streams under a specified domain name.\nDescribeLiveDomainOnlineUserNum"
    },
    "307": {
        "title": "CDN:Integration overview",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/using-openapi",
        "content": "This Product\nCDN:Integration overview\nThis topic describes basic information about the Alibaba Cloud CDN API.\nAlibaba Cloud provides OpenAPI Explorer for developers to understand and use the API operations of various Alibaba Cloud services in a quick and efficient manner. OpenAPI Explorer integrates multiple features related to API operations, including intelligent search, documentation, online debugging, SDK download, sample code, error diagnostics, and call statistics. In OpenAPI Explorer, you can call the API operations of Alibaba Cloud services and view API requests and responses. In addition, OpenAPI Explorer automatically generates the corresponding SDK sample code to facilitate use of Alibaba Cloud services. For more information, see What is an API?\nVersion\nDescription\n2018-05-10\nWe recommend that you use this version.\nAlibaba Cloud CDN provides features such as API debugging in OpenAPI Explorer. Before you call API operations, make sure that you are familiar with the following information about Alibaba Cloud CDN: versions, endpoints, and integration methods.\n\nAccess OpenAPI Portal.\nSelect an endpoint based on the region where your resource resides to reduce latency. For example, the public endpoint of Alibaba Cloud CDN in the China (Shanghai) region is cn-shanghai.aliyuncs.com.\nFor more information, see Endpoints.\nBy default, after you log on to OpenAPI Explorer with your Alibaba Cloud account, the Alibaba Cloud account is used to perform online debugging. An Alibaba Cloud account has permissions on all API operations. If you use an Alibaba Cloud account to call API operations, security risks may arise. We strongly recommend that you call API operations or perform routine O&M by using a RAM user. Before you call API operations as a RAM user, grant the required permissions to the RAM user based on your business requirements. The RAM user must have the permissions to manage Alibaba Cloud CDN resources. For more information, see Use RAM to implement access control.\nIdentity\nSupported\nAlibaba Cloud account\nYes\nRAM user (recommended)\nYes\nRAM role (recommended)\nYes\nIdentity, credential, and authorization\nThrottling and quota management\nAlibaba Cloud CDN provides various integration methods such as SDK and CLI. You can select a method based on your business requirements.\nIntegration method\nSupported\nAlibaba Cloud SDK (recommended)\nYes\nAlibaba Cloud CLI\nYes\nTerraform\nYes\nROS\nYes\nCustom API encapsulation\nYes\nAlibaba Cloud provides SDKs in multiple programming languages, including Java, C#, Go, Python, TypeScript, Node.js, PHP, and C++. You can integrate SDKs into your applications to directly call API operations. The SDKs encapsulate information such as the signature logic, timeout mechanism, and retry mechanism, and return structured response objects based on specifications. This provides convenience for developers. For more information, see Alibaba Cloud SDKs.\nYou can use Alibaba Cloud SDKs to call the API operations of Alibaba Cloud CDN. For more information about supported languages and dependencies, go to OpenAPI Portal.\nYou can use Alibaba Cloud CLI to call the API operations of Alibaba Cloud CDN. For more information, see Sample commands.\nYou can run aliyun commands to interact with Alibaba Cloud services and manage cloud service resources. For more information, see What is Alibaba Cloud CLI?\nTerraform is an open source tool that is used to preview, configure, and manage cloud infrastructure and resources in a secure and efficient manner. Terraform works in a similar way as Resource Orchestration Service (ROS). Terraform calls API operations by interpreting templates. For more information, see What is Terraform?\nYou can use Terraform to manage Alibaba Cloud CDN resources. The following table lists regular resources and data resources.\nResource type\nResource\nDescription\nResources\nalicloud_cdn_domain_config\nProvides domain configuration resources for Alibaba Cloud CDN.\nalicloud_cdn_domain_new\nProvides resources and domain names for Alibaba Cloud CDN.\nalicloud_cdn_fc_trigger\nProvides Function Compute trigger resources for Alibaba Cloud CDN.\nalicloud_cdn_real_time_log_delivery\nProvides real-time log delivery resources for Alibaba Cloud CDN.\nDate Sources\nalicloud_cdn_blocked_regions\nProvides blocked regions for Alibaba Cloud CDN.\nalicloud_cdn_ip_info\nVerifies whether an IP address belongs to an Alibaba Cloud CDN point of presence (POP).\nalicloud_cdn_real_time_log_deliveries\nDeliver real-time logs for the current Alibaba Cloud CDN user.\nalicloud_cdn_service\nAutomatically activates Alibaba Cloud CDN.\nROS is an Alibaba Cloud service that can simplify the management of cloud computing resources. You can create a template to describe the cloud computing resources such as Elastic Compute Service (ECS) and ApsaraDB RDS instances that you need, as well as the relationship between the resources. ROS automatically creates and configures all resources based on the template to implement automated deployment and O&M. For more information, see What is ROS?.\nYou can use ROS to call the API operations of Alibaba Cloud CDN. Resources that can be orchestrated by using ROS include regular resources and data resources.\nRegular resources:\nALIYUN::CDN::Domain: adds a domain name to Alibaba Cloud CDN.\nALIYUN::CDN::DomainConfig: configures multiple domain name settings.\nData resources:\nDATASOURCE::CDN::Domains: queries basic information about Alibaba Cloud CDN-accelerated domain names.\nTo make native HTTP calls, you must construct custom requests and sign the requests. For more information about the signature mechanism, see List of operations by function and Request syntax and signature method V3.\nIf an error is returned after you call an API operation, check whether the request parameters and the parameter values are valid based on the returned error code. For more information, see Service error codes.\nYou can also use the Alibaba Cloud OpenAPI Diagnostics platform to perform self-service diagnostics based on the returned request ID or SDK error information.\n"
    },
    "308": {
        "title": "CDN:API Reference",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/api-reference/",
        "content": "This Product\nCDN:API Reference"
    },
    "309": {
        "title": "CDN:SDK reference",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/sdk-reference/",
        "content": "This Product\nCDN:SDK reference"
    },
    "310": {
        "title": "CDN:Resource integration by using ROS",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/resource-orchestration-ros-integration-example",
        "content": "This Product\nCDN:Resource integration by using ROS\nYou can use Resource Orchestration Service (ROS) to call API operations of Alibaba Cloud CDN. This topic describes how to create an ROS template and use the template to automatically add a domain name to Alibaba Cloud CDN.\nROS is an Alibaba Cloud service that simplifies the management of cloud computing resources. You can create a template to describe the cloud computing resources that you want to use, such as Elastic Compute Service (ECS) and ApsaraDB RDS instances, and the relationship between the resources. ROS automatically creates and configures all resources based on the template to implement automated deployment and O&M. For more information, see What is ROS?\nYou can use ROS to call API operations of Alibaba Cloud CDN. Resources that can be orchestrated by using ROS include regular resources and data resources.\nRegular resources:\nALIYUN::CDN::Domain: adds a domain name to Alibaba Cloud CDN.\nALIYUN::CDN::DomainConfig: configures multiple domain name settings.\nData resources:\nDATASOURCE::CDN::Domains: queries basic information about Alibaba Cloud CDN-accelerated domain names.\nIn this example, you need to add a domain name. By default, Resource Orchestration Service uses the credentials of the user who logs on to the ROS console. The user must be granted the following permissions:\nAliyunCDNFullAccess: full access to Alibaba Cloud CDN resources.\nAn Alibaba Cloud account has permissions on all API operations. Security risks may arise if you use an Alibaba Cloud account to call API operations. We strongly recommend that you call API operations or perform routine O&M as a RAM user. Before you call API operations as a RAM user, grant the required permissions to the RAM user based on your business requirements. The RAM user must have the permissions to manage Alibaba Cloud CDN resources. For more information, see Alibaba Cloud CDN system policies.\nLog on to the ROS console. In the top navigation bar, select a region from the region drop-down list.\nIn the left-side navigation pane, click Stacks. On the Stacks page, choose Create Stack > Use ROS.\nSpecify Template: Select Select an Existing Template.\nTemplate Import Method: Select Enter Template Content.\nTemplate Content: Select ROS and then enter code.\nFor more information about the syntax, description, and examples of how to add a domain name, see ALIYUN::CDN::Domain.\nYAML format\nJSON format\nClick Next.\nIn the Configure Parameters step, configure the parameters and click Create.\nView the created stack.\n\nAfter the stack is created, call API operations, use SDKs, or log on to the Alibaba Cloud CDN console to view the domain name.\n"
    },
    "311": {
        "title": "CDN:Use CLI to manage Alibaba Cloud CDN resources",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/cli-integration-example",
        "content": "This Product\nCDN:Use CLI to manage Alibaba Cloud CDN resources\nAlibaba Cloud CLI is a general-purpose command-line tool that is developed based on OpenAPI. You can use Alibaba Cloud CLI to implement automatic management and maintenance of Alibaba Cloud CDN resources. This topic describes how to use Alibaba Cloud CLI to call Alibaba Cloud CDN API operations.\nGet yourself familiar with Alibaba Cloud CLI. For more information, see What is Alibaba Cloud CLI?\nYou must install Alibaba Cloud CLI before you can use Alibaba Cloud CLI. You can install Alibaba Cloud CLI in the Windows, Linux, and macOS operating systems. You must select an installation package of Alibaba Cloud CLI based on the operating system of your device. For more information, see the following topics:\nWindows operating system: Windows.\nLinux operating system: Linux.\nmacOS operating system: macOS.\nYou can also use Cloud Shell provided by Alibaba Cloud to debug the commands that you want to run in Alibaba Cloud CLI. For more information about Cloud Shell, see What is Cloud Shell?\nAn Alibaba Cloud account has the permissions to manage and access the APIs of all Alibaba Cloud services. If you use an Alibaba Cloud account to call API operations, security risks may arise. We recommend that you create and use a Resource Access Management (RAM) user to call API operations or perform routine O&M operations.\nBefore you use Alibaba Cloud CLI, you must configure information such as identity credentials and region ID in Alibaba Cloud CLI. Alibaba Cloud CLI supports various identity credentials. For more information, see Credential types. In this example, AccessKey credentials are used.\nCreate a RAM user and grant the RAM user the required permissions. For more information, see Create a RAM user and Grant permissions to a RAM user.\nIn this example, you need to attach the AliyunCDNReadOnlyAccess policy to the RAM user. You can use the AliyunCDNFullAccess system policy, which grants the user full access to Alibaba Cloud CDN-accelerated domain names, such as querying and managing domain names. You can also create custom policies. For more information, see Alibaba Cloud CDN custom policies.\nCreate an AccessKey pair for the RAM user and record the AccessKey ID and AccessKey secret for the configuration of identity credentials. For more information, see Create an AccessKey pair.\nObtain and record the ID of an available region for the configuration of identity credentials. Alibaba Cloud CLI uses the specified region ID to initiate API calls. For more information about the available regions, see Request structure.\nWhen you use Alibaba Cloud CLI, you can use the --region option to run a command in a specific region. If you use the option, Alibaba Cloud CLI ignores the region information in the default credential configurations and environment variable settings. For more information, see Command line options for API calls.\nUse the AccessKey pair of the RAM user to configure identity credentials in the configuration file named AkProfile. For more information, see Endpoints.\nGo to the Debugging page of the Alibaba Cloud CDN API.\nIn the left-side search box of the page that appears, search for the operation that you want to call. On the Parameters tab, enter parameter values based on the API document of the API operation. Then, click the CLI Example tab on the right side of the Parameters tab to generate an example that contains configured parameters.\nClick the icon. You are directed to Cloud Shell. You can debug the command in Cloud Shell.\nClick the icon to copy the CLI command to the clipboard and paste the command to the local shell.\nWhen you paste the sample command into your shell for debugging, take note of the formats of parameters. For more information about the parameter formats of Alibaba Cloud CLI, see Parameter formats.\nBy default, OpenAPI Explorer adds the --region option to the generated CLI command. When you copy the command to your shell, Alibaba Cloud CLI ignores the region information in the default identity credential configurations and environment variable settings, and preferentially runs the command in the specified region. You can delete or retain the option based on your business requirements.\nIn Alibaba Cloud CLI, you can use the following syntax to run commands. For more information, see Syntax.\nWhen you use Alibaba Cloud CLI, you can specify command options to change the behaviors of commands or implement the extended features of commands. In most cases, the following command options are used:\n--profile<profileName>: You can use the --profile option and the profileName parameter to specify a configuration profile. After you specify a valid configuration profile, Alibaba Cloud CLI ignores the information in default credential configurations and environment variable settings and preferentially uses the configurations that you specify to run commands.\n--help: You can use the --help option to obtain the help information about a command. For more information, see Use the help command.\nFor more information, see Command line options for API calls.\nThe following example shows how to use Alibaba Cloud CLI to call the DescribeUserDomains operation of Alibaba Cloud CDN to query all domain names in your account and their status. For more information about the DescribeUserDomains operation, see DescribeUserDomains.\nRun the following command:\n\nView the command output.\n\nIf an error is returned after you call an API operation of Alibaba Cloud CDN, check whether the input parameters and values are valid based on the error code.\nYou can also use Alibaba Cloud OpenAPI Diagnostics to perform self-service diagnostics based on the returned request ID or SDK error information.\n"
    },
    "312": {
        "title": "CDN:Appendix",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/apiappendix/",
        "content": "This Product\nCDN:Appendix"
    },
    "313": {
        "title": "CDN:FAQ",
        "url": "https://www.alibabacloud.com/help/en/cdn/support/faq",
        "content": "This Product\nCDN:FAQ\nAlibaba Cloud CDN may return error messages in specific scenarios. You can visit the API Error Center to troubleshoot errors. This topic describes how to identify the causes of errors if you do not receive error messages and provides suggestions on how to fix the errors.\nFor a list of error codes, visit the API Error Center.\nWhat is Alibaba Cloud CDN?\nWhat is DNS resolution?\nWhat are static content and dynamic content?\nWhat are the differences between a CDN node and a mirror?\nWhy is the traffic volume that is found when using the data monitoring feature or the resource usage feature different from the traffic volume that is logged?\nWhy are fees still charged after I disable Alibaba Cloud CDN for my domain name?\nIf my origin server is located outside the Chinese mainland, how am I billed for using Alibaba Cloud CDN POPs that are located in the Chinese mainland?\nBilling of OSS content acceleration\nHow am I billed for data transfer when Alibaba Cloud CDN is used with other Alibaba Cloud services?\nWhere can I view details about resource plans that I have purchased?\nWhy am I still charged for resources after I purchase resource plans of Alibaba Cloud CDN?\nFAQ about the billing of requests\nAfter I change the metering method of Alibaba Cloud CDN, why am I still billed based on the previous metering method?\nCan RAM users change the billing method of Alibaba Cloud CDN?\nAm I charged for data transfer and requests that are generated by attacks or other malicious behaviors such as click farming?\nAm I charged if the requested Alibaba Cloud CDN POP returns a 4xx status code?\nHow do I troubleshoot an HTTP 5xx error that occurs during the back-to-origin process?\nWhy does my website become unavailable after it is accelerated by Alibaba Cloud CDN?\nWhy do users fail to retrieve files from a CDN POP or access my domain name?\nWhy are requests redirected to a blank page instead of the desired URLs after my website is accelerated by Alibaba Cloud CDN?\nHow do I determine whether errors occur on a CDN POP or the origin server?\nWhy is content delivery outside the Chinese mainland not accelerated after I enabled acceleration for regions outside the Chinese mainland?\nWhy are HTML files automatically downloaded when users access HTML files by using my domain name?\nWhy do URL parameters fail to be loaded after my domain name is added to Alibaba Cloud CDN?\nWhat are the impacts on SEO after my website is accelerated by Alibaba Cloud CDN?\nWhy do users fail to access WebSocket objects after my website is accelerated by Alibaba Cloud CDN?\nWhy is the HTTP 304 status code returned when users access the resources that are accelerated by Alibaba Cloud CDN?\nWhy is the HTTP 403 status code returned when users access the resources of Alibaba Cloud CDN?\nWhy is the Content-Type request header changed to Content-Type: application/octet-stream and the page downloaded when a user accesses an HTML page?\nWhy are connections automatically closed when users request large files by using Alibaba Cloud CDN?\nWhy is content delivery of HTTPS-capable websites slow even when the local network works as expected?\nWhy does the 404 Not Found page appear?\nWhat do I do if too many redirects occur after my domain name is accelerated by Alibaba Cloud CDN?\nUndeploy an Alibaba Cloud POP for maintenance\nDoes Alibaba Cloud CDN support wildcard domain names?\nWhat are the impacts if I change the acceleration region of Alibaba Cloud CDN?\nHow can I check whether a CNAME record takes effect?\nGrant the ListRoles permission to a RAM user\nHow do I check whether a CDN POP works as expected?\nWhy does a domain name fail ownership verification the first time that the domain name is added to Alibaba Cloud CDN?\nWhat do I do if my domain name does not have a valid ICP number?\nWhy do users fail to access third-level domain names after I upload a certificate for the wildcard domain name?\nWhy does the error message \"The CNAME binding service is unavailable because no enabled AccessKey pair is detected\" appear when I configure a domain name in Alibaba Cloud CDN?\nHow do I check whether an IP address belongs to an Alibaba Cloud CDN POP?\nWhat can I do if my DNS records conflict with each other?\nWhat can I do if my CNAME record does not take effect?\nCan I use an OSS bucket that belongs to another Alibaba Cloud account as the origin server when I add a domain name to Alibaba Cloud CDN?\nWhy is the cache hit ratio low?\nWhy did the cache hit ratio decrease when URLs in requests carry variables?\nHow do I specify an NGINX cache policy?\nHow do I specify an Apache cache policy?\nHow do I specify an IIS cache policy?\nHow do I disable caching policies for the directories or files of a specified domain name?\nHow do I specify a time-to-live (TTL) value for the origin server when I use Alibaba Cloud CDN to accelerate the delivery of static content?\nWhy is the content retrieved by users before and after content delivery is accelerated by Alibaba Cloud CDN different?\n\nHow are CDN cache POPs classified?\nHow do I handle the error message \"Preload queue is full, please try again later\"?\nHow do I apply cache settings to a specified path?\nWhy is content delivery slow after my website is accelerated by Alibaba Cloud CDN?\nHow can I query IP addresses of POPs for a CDN domain?\nWhy is the amount of back-to-origin network traffic large?\nWhy is the number of requests redirected to the origin server greater than that of user requests?\nWhy is the domain name accessed by users different from the domain name of the origin server that I configured in the Alibaba Cloud CDN console?\nHow do I configure multiple origin servers for a domain name?\nWhat are the differences between an origin server and an origin host?\nWhy do users fail to access my domain name by using cross-origin resource sharing (CORS) and trigger the following error message: The \"Access-Control-Allow-Origin\" header has a value \"xxx\" that is not equal to the supplied origin?\nWhy is the content returned to a back-to-origin request not Gzip compressed?\nHow does CDN process 302 redirects from an origin server?\nWho do I map the domain name of my website to the origin server when I troubleshoot errors?\nWhat is the health check mechanism for origin servers?\nHow do I query the quota on HTTPS requests?\nHow do I configure an intermediate SSL certificate for my accelerated domain name?\nWhy do WeChat mini programs fail certification verification when the mini programs access Alibaba Cloud CDN?\nWhat can I do if my website prompts certificate-related risks?\nWhat can I do if the SSL certificate on the origin server conflicts with the one in Alibaba Cloud CDN?\nHow can I configure an SSL certificate for a wildcard domain name?\nWhich domain names support SSL certificates?\nWhat do I do after individual test certificates (free) expire?\nWhy do requests fail to access resources over HTTPS after I enable Alibaba Cloud CDN?\nHow do I update files without the need to rename the files after my domain name is accelerated by Alibaba Cloud CDN?\nHow do I query the progress of a prefetch task?\nWhy does the error message \"504 Gateway Time-out\" appear when users access my domain name?\nHow do I use scripts to prefetch M3U8 files that are used for on-demand video streaming to CDN POPs?\nHow do I block malicious requests from specified IP addresses?\nWhy is the HTTP 503 status code caused by the security features that are configured for the origin server returned when users access my domain name?\nWhy is the HTTP 403 status code returned to users when hotlink issues are detected?\nWhy can an IP address in the IP blacklist still be used to request resources?\nHow can I protect domain names accelerated by Alibaba Cloud CDN from DDoS or HTTP flood attacks?\nWhy do users fail to access Object Storage Service (OSS) buckets by using CORS when the OSS buckets are accelerated by Alibaba Cloud CDN?\nUse Alibaba Cloud CDN to accelerate the delivery of resources from OSS buckets\nWhy does CORS fail after I use Alibaba Cloud CDN to accelerate the delivery of content in an OSS bucket?\nHow do I enable cross-origin resource sharing (CORS) for my website?\nWhat usage notes do I take note of when I configure CORS?\nWhy do requests destined for my accelerated domain name trigger the error message \"You are forbidden to list buckets\" after access to private OSS buckets is enabled?\nWhat can I do if errors arise after I enable access to private OSS buckets and static website hosting?\nFAQ about the Fetch operation\nFAQ about the waitUntil operation\nFAQ about encoding\nHow do I analyze access logs of Alibaba Cloud CDN?"
    },
    "314": {
        "title": "CDN:Competitive advantages of Alibaba Cloud CDN",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/competitive-advantages-of-alibaba-cloud-cdn",
        "content": "This Product\nCDN:Competitive advantages of Alibaba Cloud CDN\nThis topic describes the competitive advantages of Alibaba Cloud CDN in terms of service performance, technologies, pricing, service bundling, and service support.\nAlibaba Cloud CDN provides the following advantages:\nCutting-edge features\nTechnical advantages\nCompetitive pricing strategies\nExpansive ecosystem services\nService support\nGlobal presence\nAlibaba Cloud CDN global network is made up of more than 3,200 strategically located points of presence (POPs). Spanning over 2,300 POPs are located across 31 provincial regions in the Chinese mainland, and over 900 POPs are located in more than 70 countries and regions, including Hong Kong (China), Macao (China), and Taiwan (China). The total bandwidth capacity of Alibaba Cloud CDN can reach up to 180 Tbit/s. Through leveraging vast network and immense networking capacity, Alibaba Cloud CDN is able to deliver your content to customers around the world with the utmost security, performance, and reliability.\nIndustry-certified capabilities\nChina DJCP (MLPS) Level 3 certification\nPayment Card Industry Data Security Standard (PCI DSS) certification\nListed as a global service provider by Gartner\nIPv6 Enabled CDN Logo certification issued by the global IPv6 Forum\nRich features\nAlibaba Cloud CDN provides a diversified mix of features, which can be accessed through the console and API. Customers can manage and configure all aspects of their content delivery through Alibaba Cloud CDN. The following table describes the key features of Alibaba Cloud CDN.\nCapability\nFeature\nDomain name management\nSupports the following features: accelerated domain name settings, basic settings, origin settings, caching settings, HTTPS settings, access control settings, performance optimization, video-related settings, security settings, traffic throttling, quick UDP Internet connections (QUIC), EdgeScript (ES) settings, and IPv6 settings.\nMonitoring and usage analytics\nSupports the following features: resource monitoring, real-time monitoring, resource usage query, ES monitoring, and security monitoring.\nLog management\nSupports the following features: log export, log storage, real-time log delivery, custom operations reports, and tracking tasks.\nRefresh and prefetch\nSupports the following features: URL refresh, directory refresh, and URL prefetch.\nProgrammable configurations\nAlibaba Cloud CDN provides programmable edge computing capabilities. These capabilities are delivered by using EdgeScript through custom configurations. If the built-in configurations provided by Alibaba Cloud CDN are unable to meet your business requirements, you can use ES to create custom configurations. Custom configurations are helpful in resolving issues in an agile manner.\nCustom routines at the edge\nEdgeRoutine (ER) is a serverless computing environment provided by Alibaba Cloud CDN and Dynamic Content Delivery Network (DCDN). ER allows you to run custom JavaScript code on POPs. After you use the ER command-line interface (CLI) to deploy code to the production environment, Alibaba Cloud CDN automatically runs the code on all POPs. The POPs process requests in different regions worldwide based on the code deployed. For more information, see What is EdgeRoutine?\nPublic API operations\nYou can call API operations to use and manage the features of Alibaba Cloud CDN. For more information, see List of operations by function.\nIntelligent routing\nAlibaba Cloud CDN implements various optimizations to provide superior routing performance:\nDynamic IP library: Alibaba Cloud CDN maintains an IP library that provides information such as regions and Internet service providers (ISPs). The routing system looks up the information whenever a DNS request is sent to Alibaba Cloud CDN. Then, the system routes user requests to the nearest CDN POP that belongs to the same ISP. The IP library is dynamically updated to ensure that the data is up-to-date.\nHTTPDNS (requires compatibility with clients): HTTPDNS allows clients to bypass the local DNS servers of ISPs and directly access the routing system over HTTP. Then, the routing system redirects the requests to the optimal POP for the destination domain names. This prevents security issues such as DNS hijacking.\nNode analytics: The routing system of Alibaba Cloud CDN analyzes the health status of all POPs and routes in the cache network in real time based on the statistics provided by the route quality system. This increases the routing quality of CDN POPs and improves user experience.\nContent-oriented routing: Content-oriented routing increases the cache hit ratio of Alibaba Cloud CDN. 302 redirection, one of the content-oriented routing schemes, is used in scenarios such as large file distribution and on-demand video streaming. The DNS server resolves a request which is then passed to the routing system. After the routing system parses the request, it identifies the POPs where the requested content resides. Then, a 302 redirect is performed to redirect the request to an optimal POP that is selected by the routing system.\nBenefits: The routing system can route requests based on data transfer trends, or route requests in real time to handle traffic spikes.\nExpected results: Alibaba Cloud CDN can monitor the health status of each POP in real time and select an optimal POP for each request based on the self-developed routing system.\nIntelligent caching system\nAccurate caching: Alibaba Cloud CDN uses intelligent object algorithms to cache content based on popularity in a multi-level cache. This mechanism allows Alibaba Cloud CDN to prioritize caching popular objects over less requested content.\nHigh-speed caching: Alibaba Cloud CDN is designed for performance. It makes full use of the underlying technologies by balancing workloads to take advantage of its multi-core processing capabilities, implementing cutting-edge memory management mechanisms, and maximizing the IOPS and throughput of SSDs.\nHigh read and write speeds: All POPs are equipped with SSDs to take advantage of their inherent high read/write speeds and reliability. These advantages allow Alibaba Cloud CDN to help you improve website availability and deliver content faster.\nEfficient origin fetch: Alibaba Cloud CDN provides failover and retransmission mechanisms to ensure efficient origin fetch and information synchronization.\nEfficient transport layer protocol\nQUIC: QUIC is a new transport layer network protocol that combines the best qualities of TCP, TLS, and HTTP/2. QUIC supports encrypted, low-latency, and multiplexed connections to meet the requirements of the transport and application layers.\nIndependently developed algorithms for the TCP protocol suite: Alibaba Cloud utilizes algorithms such as congestion detection and packet loss probing algorithms to improve the performance of TCP. The transmission performance is significantly improved.\nReliable protection capabilities\nAlibaba Cloud CDN is integrated with various security features and services to provide safe and secure content delivery.\nHotlink protection: Alibaba Cloud CDN provides a variety of methods to protect your origin server. Whitelists and blacklists can filter packets based on the Referer header, user-agent header, URLs, and IP addresses. You can also use ES to implement access authorization. Alibaba Cloud CDN also supports remote authentication, which is a two-factor authentication method used to reinforce the security of your origin servers.\nDNS hijacking protection: HTTPDNS allows clients to directly access the DNS maintained by Alibaba Cloud instead of the local DNS maintained by ISPs.\nHTTPS-based transmission: The security of data may be compromised if it is transmitted as plaintext over the Internet. Alibaba Cloud CDN uses TLS to encrypt HTTP messages. You can also configure advanced settings, such as TLS1.3 and HSTS, to better protect your data.\nProtection for origin servers: Alibaba Cloud CDN provides basic security features. If your origin servers require reinforced protection, you can use Secure CDN (SCDN).\nHigh availability of origin servers: Alibaba Cloud CDN supports primary and secondary origin servers, and monitors the health status of the origin servers. If the primary origin server fails, requests are redirected to a secondary origin server.\nAlibaba Cloud CDN provides competitive pricing strategies:\nFlexible metering methods. For more information, see Billing overview.\nCost-effective subscription resource plans. For more information, go to the buy page.\nTailored to fit\nAlibaba Cloud CDN supports multiple metering methods and resource plans that you can mix and match to meet the requirements of your business scenarios. Select a metering method based on your business requirements.\nScenario\nRecommended combination\nLow origin traffic with occasional traffic spikes\nPay-by-data-transfer.\nWe recommend that you purchase resource plans to reduce costs. Alibaba Cloud CDN provides multiple types of resource plans for different acceleration regions. The capacities of these resource plans range from 100 GB to 50 PB. You can select resource plans based on your business requirements.\nFor more information about the metering methods of Alibaba Cloud CDN, visit the CDN Pricing page.\nAlibaba Cloud provides diversified services and products. The following tables describe the services and products that you can use together with Alibaba Cloud CDN in different scenarios.\nYou can use Alibaba Cloud CDN together with other Alibaba Cloud services to fine-tune service performance and improve management efficiency.\nExisting service\nRecommended service\nReason\nECS\nAlibaba Cloud CDN\nAlibaba Cloud CDN accelerates the delivery of content stored on your ECS origin to customers all over the world.\nOSS\nAlibaba Cloud CDN accelerates the delivery of content stored on your OSS origin to customers all over the world. The caching capability of Alibaba Cloud CDN helps reduce the outbound traffic costs of OSS.\nFunction Compute\nAlibaba Cloud CDN accelerates the delivery of content stored on your Function Compute origin to customers all over the world.\nBuilding upon the powerful static content acceleration capabilities, Alibaba Cloud CDN also provides solutions for scenarios where you may also want to accelerate dynamic content or want to harden website security.\nScenario\nRecommended service\nDescription\nAccelerate the delivery of both dynamic and static content\nDCDN\nDCDN is a branch of Alibaba Cloud CDN that can accelerate the delivery of both dynamic and static content. DCDN automatically separates dynamic content from static content and accelerates the delivery of both types of content at the same time.\nIntegrate security with acceleration\nDCDN edge security\nDCDN provides integrated security services on POPs to filter and intercept malicious traffic close to the source. You can enable edge protection in just a few simple steps and start protecting your websites, APIs, and applications.\nIf you have already activated Alibaba Cloud CDN, you can use Alibaba Cloud CDN together with other services to fine-tune it to meet your unique business requirements. The following table describes the services that can be used together with Alibaba Cloud CDN.\nScenario\nRecommended service\nDescription\nAccelerate on-demand audio and video streaming\nApsaraVideo VOD\nVOD is an all-in-one solution for on-demand audio and video streaming. VOD supports audio and video upload, automatic transcoding, media resource management, and content delivery.\nAccelerate live streaming\nApsaraVideo Live\nApsaraVideo Live is an audio and video streaming platform that is based on the next-generation content access and distribution network and supports large-scale and distributed real-time transcoding. ApsaraVideo Live is a low-latency, highly concurrent live streaming service that delivers smooth, high-quality video content.\nRegister a domain name that you want to accelerate by using Alibaba Cloud CDN\nDomain Names\nDomain Names is a domain name management platform that provides domain name registration, transaction, monitoring, and protection services. This platform is integrated with the Alibaba Cloud ICP Filing and Alibaba Cloud DNS services.\nApply for an Internet Content Provider (ICP) number for the domain name that you want to accelerate by using Alibaba Cloud CDN\nAlibaba Cloud ICP Filing\nChina mandates an ICP filing system for non-commercial Internet information services and an ICP licensing system for commercial Internet information services. You must apply for an ICP number for your domain name to comply with Measures for the Administration of Internet Information Services and Registration Administration Measures for Non-Commercial Internet Information Services. Websites that do not have an ICP number or license are prohibited from providing Internet information services. Therefore, all websites must obtain an ICP number before the websites are permitted to operate in the Chinese mainland. You can use the Alibaba Cloud ICP Filing system to apply for ICP numbers, modify ICP filing information, cancel ICP filing applications, and claim ICP numbers.\nEnable and configure HTTPS for a website\nCertificate Management Service\nCertificate Management Service is a digital server certificate service provided by Alibaba Cloud. This service provides digital server certificates issued by certification authorities (CAs). You can obtain free digital certificates or purchase other types of certificates from Alibaba Cloud. Then, you can deploy these certificates in Alibaba Cloud services to enable HTTPS for HTTP-based services in an efficient and convenient manner. This way, your websites can perform identity verification and encryption for data in transit.\nImprove the O&M efficiency, and process large volumes of log data\nSimple Log Service\nSimple Log Service is an all-in-one logging service developed in-house by Alibaba Cloud. As a powerful logging solution, Simple Log Service has been honed to perfection through years of implementation within Alibaba Group. Simple Log Service helps you quickly collect, consume, ship, query, and analyze log data without development work. It improves the O&M efficiency and provides the capability to process large volumes of data.\nMonitor Alibaba Cloud resources and Internet applications\nCloudMonitor\nCloudMonitor monitors Internet applications and Alibaba Cloud resources. CloudMonitor collects metrics of Alibaba Cloud resources. You can use CloudMonitor to monitor the availability of your network and configure alerts for specific metrics.\nAlibaba Cloud CDN provides comprehensive service support, including:\nEnd-to-end and 24/7 monitoring and support systems.\nWell-maintained documentation. For more information, see What is Alibaba Cloud CDN?\nYou can submit feedback and suggestions for pre-sales consultation or after-sales support."
    },
    "315": {
        "title": "CDN:FAQ",
        "url": "https://www.alibabacloud.com/help/en/cdn/support/faq",
        "content": "This Product\nCDN:FAQ\nAlibaba Cloud CDN may return error messages in specific scenarios. You can visit the API Error Center to troubleshoot errors. This topic describes how to identify the causes of errors if you do not receive error messages and provides suggestions on how to fix the errors.\nFor a list of error codes, visit the API Error Center.\nWhat is Alibaba Cloud CDN?\nWhat is DNS resolution?\nWhat are static content and dynamic content?\nWhat are the differences between a CDN node and a mirror?\nWhy is the traffic volume that is found when using the data monitoring feature or the resource usage feature different from the traffic volume that is logged?\nWhy are fees still charged after I disable Alibaba Cloud CDN for my domain name?\nIf my origin server is located outside the Chinese mainland, how am I billed for using Alibaba Cloud CDN POPs that are located in the Chinese mainland?\nBilling of OSS content acceleration\nHow am I billed for data transfer when Alibaba Cloud CDN is used with other Alibaba Cloud services?\nWhere can I view details about resource plans that I have purchased?\nWhy am I still charged for resources after I purchase resource plans of Alibaba Cloud CDN?\nFAQ about the billing of requests\nAfter I change the metering method of Alibaba Cloud CDN, why am I still billed based on the previous metering method?\nCan RAM users change the billing method of Alibaba Cloud CDN?\nAm I charged for data transfer and requests that are generated by attacks or other malicious behaviors such as click farming?\nAm I charged if the requested Alibaba Cloud CDN POP returns a 4xx status code?\nHow do I troubleshoot an HTTP 5xx error that occurs during the back-to-origin process?\nWhy does my website become unavailable after it is accelerated by Alibaba Cloud CDN?\nWhy do users fail to retrieve files from a CDN POP or access my domain name?\nWhy are requests redirected to a blank page instead of the desired URLs after my website is accelerated by Alibaba Cloud CDN?\nHow do I determine whether errors occur on a CDN POP or the origin server?\nWhy is content delivery outside the Chinese mainland not accelerated after I enabled acceleration for regions outside the Chinese mainland?\nWhy are HTML files automatically downloaded when users access HTML files by using my domain name?\nWhy do URL parameters fail to be loaded after my domain name is added to Alibaba Cloud CDN?\nWhat are the impacts on SEO after my website is accelerated by Alibaba Cloud CDN?\nWhy do users fail to access WebSocket objects after my website is accelerated by Alibaba Cloud CDN?\nWhy is the HTTP 304 status code returned when users access the resources that are accelerated by Alibaba Cloud CDN?\nWhy is the HTTP 403 status code returned when users access the resources of Alibaba Cloud CDN?\nWhy is the Content-Type request header changed to Content-Type: application/octet-stream and the page downloaded when a user accesses an HTML page?\nWhy are connections automatically closed when users request large files by using Alibaba Cloud CDN?\nWhy is content delivery of HTTPS-capable websites slow even when the local network works as expected?\nWhy does the 404 Not Found page appear?\nWhat do I do if too many redirects occur after my domain name is accelerated by Alibaba Cloud CDN?\nUndeploy an Alibaba Cloud POP for maintenance\nDoes Alibaba Cloud CDN support wildcard domain names?\nWhat are the impacts if I change the acceleration region of Alibaba Cloud CDN?\nHow can I check whether a CNAME record takes effect?\nGrant the ListRoles permission to a RAM user\nHow do I check whether a CDN POP works as expected?\nWhy does a domain name fail ownership verification the first time that the domain name is added to Alibaba Cloud CDN?\nWhat do I do if my domain name does not have a valid ICP number?\nWhy do users fail to access third-level domain names after I upload a certificate for the wildcard domain name?\nWhy does the error message \"The CNAME binding service is unavailable because no enabled AccessKey pair is detected\" appear when I configure a domain name in Alibaba Cloud CDN?\nHow do I check whether an IP address belongs to an Alibaba Cloud CDN POP?\nWhat can I do if my DNS records conflict with each other?\nWhat can I do if my CNAME record does not take effect?\nCan I use an OSS bucket that belongs to another Alibaba Cloud account as the origin server when I add a domain name to Alibaba Cloud CDN?\nWhy is the cache hit ratio low?\nWhy did the cache hit ratio decrease when URLs in requests carry variables?\nHow do I specify an NGINX cache policy?\nHow do I specify an Apache cache policy?\nHow do I specify an IIS cache policy?\nHow do I disable caching policies for the directories or files of a specified domain name?\nHow do I specify a time-to-live (TTL) value for the origin server when I use Alibaba Cloud CDN to accelerate the delivery of static content?\nWhy is the content retrieved by users before and after content delivery is accelerated by Alibaba Cloud CDN different?\n\nHow are CDN cache POPs classified?\nHow do I handle the error message \"Preload queue is full, please try again later\"?\nHow do I apply cache settings to a specified path?\nWhy is content delivery slow after my website is accelerated by Alibaba Cloud CDN?\nHow can I query IP addresses of POPs for a CDN domain?\nWhy is the amount of back-to-origin network traffic large?\nWhy is the number of requests redirected to the origin server greater than that of user requests?\nWhy is the domain name accessed by users different from the domain name of the origin server that I configured in the Alibaba Cloud CDN console?\nHow do I configure multiple origin servers for a domain name?\nWhat are the differences between an origin server and an origin host?\nWhy do users fail to access my domain name by using cross-origin resource sharing (CORS) and trigger the following error message: The \"Access-Control-Allow-Origin\" header has a value \"xxx\" that is not equal to the supplied origin?\nWhy is the content returned to a back-to-origin request not Gzip compressed?\nHow does CDN process 302 redirects from an origin server?\nWho do I map the domain name of my website to the origin server when I troubleshoot errors?\nWhat is the health check mechanism for origin servers?\nHow do I query the quota on HTTPS requests?\nHow do I configure an intermediate SSL certificate for my accelerated domain name?\nWhy do WeChat mini programs fail certification verification when the mini programs access Alibaba Cloud CDN?\nWhat can I do if my website prompts certificate-related risks?\nWhat can I do if the SSL certificate on the origin server conflicts with the one in Alibaba Cloud CDN?\nHow can I configure an SSL certificate for a wildcard domain name?\nWhich domain names support SSL certificates?\nWhat do I do after individual test certificates (free) expire?\nWhy do requests fail to access resources over HTTPS after I enable Alibaba Cloud CDN?\nHow do I update files without the need to rename the files after my domain name is accelerated by Alibaba Cloud CDN?\nHow do I query the progress of a prefetch task?\nWhy does the error message \"504 Gateway Time-out\" appear when users access my domain name?\nHow do I use scripts to prefetch M3U8 files that are used for on-demand video streaming to CDN POPs?\nHow do I block malicious requests from specified IP addresses?\nWhy is the HTTP 503 status code caused by the security features that are configured for the origin server returned when users access my domain name?\nWhy is the HTTP 403 status code returned to users when hotlink issues are detected?\nWhy can an IP address in the IP blacklist still be used to request resources?\nHow can I protect domain names accelerated by Alibaba Cloud CDN from DDoS or HTTP flood attacks?\nWhy do users fail to access Object Storage Service (OSS) buckets by using CORS when the OSS buckets are accelerated by Alibaba Cloud CDN?\nUse Alibaba Cloud CDN to accelerate the delivery of resources from OSS buckets\nWhy does CORS fail after I use Alibaba Cloud CDN to accelerate the delivery of content in an OSS bucket?\nHow do I enable cross-origin resource sharing (CORS) for my website?\nWhat usage notes do I take note of when I configure CORS?\nWhy do requests destined for my accelerated domain name trigger the error message \"You are forbidden to list buckets\" after access to private OSS buckets is enabled?\nWhat can I do if errors arise after I enable access to private OSS buckets and static website hosting?\nFAQ about the Fetch operation\nFAQ about the waitUntil operation\nFAQ about encoding\nHow do I analyze access logs of Alibaba Cloud CDN?"
    },
    "316": {
        "title": "CDN:What is CDN?",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/what-is-alibaba-cloud-cdn",
        "content": "This Product\nCDN:What is CDN?\nAlibaba Cloud CDN is a global network of points of presence (POPs) that are distributed across the globe. CDN serves to reduce origin traffic. This in turn prevents network congestion and ensures that content is delivered with minimal latency across regions in various use cases.\nCDN global network is made up of more than 3,200 strategically located POPs. Among these POPs, more than 2,300 are distributed across 31 provincial regions in the Chinese mainland and more than 900 are distributed across over 70 countries and regions, including Hong Kong (China), Macao (China), and Taiwan (China). The total bandwidth capacity of CDN can reach up to 180 Tbit/s. For more information about the distribution of main POPs, see POP distribution.\nCDN caches resources from your origin servers on POPs that are located across the globe. When customers access your resources, the resources are served from the nearest POP instead of the origin server. This helps prevent lengthy origin requests and reduce loads on origin servers, delivering a better experience to your customers and reducing origin fetch costs. CDN also provides IPv6 support on specific POPs.\nCDN is a simple and efficient method to deliver content to your customers. As a content provider, you can serve your content by using CDN with just a few clicks in the console. You no longer have to worry about setting up complex configurations or modifying your code to be compatible with your content delivery provider. After you add your domain name to CDN, your content is automatically cached to the global content delivery network. For more information about how to activate and use CDN, see For beginners.\nYou can use CDN to separately accelerate the delivery of static content. CDN provides the following benefits:\nGlobally distributed POPs: CDN redirects requests to the nearest POPs that belong to the same Internet service provider (ISP) as the clients, which eliminates network latency when traffic is passed between different ISPs.\nScalable resources: CDN provides more than 3,200 globally distributed POPs to ensure resource scalability and service availability.\nIntelligent routing: CDN monitors the health status of POPs in real time, and redirects requests to optimal POPs selected by the routing system based on client locations and ISPs.\nIntelligent connections: CDN uses optimization strategies such as protocol optimization and connection optimization to reduce network latency and accelerate content delivery, especially over networks with limited connectivity.\nIntelligent caching: CDN caches popular content across its global network, improving the cache hit ratio on POPs that are closest to clients.\nLower IT costs: Aside from content delivery capabilities, POPs also provide computing, bandwidth, and networking capabilities, which you can make use of to reduce investment in IT hardware.\nHigh bandwidth capacity: CDN provides up to 180 Tbit/s of networking capacity.\nStandardized API: CDN provides a comprehensive suite of user-friendly API operations.\nFor more information, see Competitive advantages of CDN.\nThe following figure shows the architecture of CDN. CDN consists of a routing system, a route quality system, a caching system, and a support system.\nRoute quality system\nThe route quality system monitors the loads and health status of POPs and routes in real time. This information is shared with the routing system, which uses this information to select optimal routes for requests. The routing system also takes additional information included in the origin IP address, such as the ISP and region of the requests, into account when selecting the optimal route.\nRouting system\nThe routing system provides a policy center and supports Domain Name System (DNS) resolution, HTTPDNS, and 302 redirection. When a client sends a request, the request is resolved by DNS resolution and subsequently processed by the routing system.\nCaching system\nThe caching system redirects requests to POPs based on the access points where the requests originate. If the requested resource is already cached on the POPs, the resource is returned to the client. Otherwise, the request is redirected to the origin server. The retrieved resource is then served to the requester and cached on the POPs. Subsequent requests for the resources are directly served from the POPs. CDN uses intelligent object algorithms to cache content based on popularity in a multi-level cache. This mechanism allows CDN to reduce the amount of origin bandwidth resources, and improve user experience.\nSupport system\nThe support system supports Tianyan (an internal health monitoring system), data intelligence, and configuration management. The support system can monitor resources, analyze data, and manage configurations.\nResource monitoring: Tianyan can monitor the status of services that are running in the caching system. For example, Tianyan can monitor the number of queries per second (QPS), bandwidth, and HTTP status codes for a domain name that is accelerated by CDN.\nData analytics: You can analyze data, such as the top N most frequently requested URLs, page views (PVs), and unique visitors (UVs) for a domain name that is accelerated by CDN.\nConfiguration management: You can create and manage cache expiration rules to improve the efficiency of the caching system. For example, you can create a cache expiration rule for a specified type of file or enable parameter filtering.\nIn this example, the domain name that is accelerated by CDN is www.aliyundoc.com. The following figure shows how CDN handles an HTTP request from a client in Beijing.\nWhen the client in Beijing sends a request to retrieve resources from www.aliyundoc.com, a domain name resolution request is sent to the local DNS server (LDNS) to retrieve the IP address of www.aliyundoc.com.\nThe LDNS checks whether the cache contains the IP address that corresponds to www.aliyundoc.com. If yes, the LDNS returns the IP address to the client. If not, the LDNS queries the DNS records of www.aliyundoc.com from the authorized DNS server of the website.\nAfter the authorized DNS server of the website resolves www.aliyundoc.com, the CNAME www.aliyundoc.com.example.com of the domain name is returned.\nThe LDNS sends a request to the DNS routing system of CDN to retrieve the DNS records of www.aliyundoc.com.example.com. Then, the routing system selects an optimal POP and returns the POP IP address to the LDNS.\nThe LDNS receives the IP address that is returned by the routing system.\nThe LDNS returns the IP address to the client.\nThe client initiates a request to the received IP address.\nIf the requested resource is already cached on the POP, the resource is directly served to the client, as shown in Step 8.\nIf the requested resource is not cached on the POP or has expired, the request is redirected to the origin server. The retrieved resource is served to the client and cached on POPs based on the cache expiration rules, as shown in Step 8. For more information about how to configure a cache expiration rule, see Create a cache rule for resources.\nItem\nCDN\nDCDN (Dynamic Content Delivery Network)\nESA (Edge Security Acceleration)\nScenario\nGame updates, app updates for mobile phones, on-demand videos including long and short videos, and infographic websites.\nOnline shops, online payments, online chatting, online education, online multiplayer games, and financial management.\nIncludes but is not limited to\u00a0gaming, e-commerce, finance, and retailing industries.\nAcceleration region\nChinese mainland only\nGlobal\nGlobal (excluding the Chinese mainland)\nChinese mainland only\nGlobal\nGlobal (excluding the Chinese mainland)\nChinese mainland only\nGlobal\nGlobal (excluding the Chinese mainland)\n\nAcceleration method\nAccelerates the delivery of static resources and redirects requests for dynamic resources to origin servers. CDN is suitable for scenarios that require high bandwidth and process a large amount of network traffic.\nDelivers your content by using a global network made up of more than 3,200 strategically located POPs. Your data is cached on the network based on custom cache rules.\nBalances loads on origin servers, distributes requests to origin servers based on weights, reduces origin requests, and reduces costs on origin servers.\nCaches static content such as images and videos on POPs to deliver content from the nearest POPs to clients.\nAccelerates the delivery of dynamic content, or both dynamic and static resources.\nAccelerates the delivery of dynamic content\nIf the requested content is not cached on POPs, the request is redirected to the origin server. The request is routed by the intelligent routing system, which provides the optimal route for the content to be retrieved.\nAccelerates the delivery of both dynamic content and static content\nAlibaba Cloud DCDN intelligently classifies and accelerates static content and dynamic content. Static content is cached on POPs, and can be directly served to customers from the POPs. Requests for dynamic content are redirected to the origin server by using the optimal route that is selected by the intelligent routing system.\nAccelerates the delivery of dynamic and static resources. ESA delivers more advanced features and capabilities.\nCache-based acceleration\nSupports scheduled prefetch, cache reserve, and cache analytics. This increases the cache hit ratio and reduce the consumption of origin traffic.\nDNS\nWith Anycast DNS and POPs around the world, the average DNS resolution takes less than 30 ms.\nTCP/UDP proxy\nSupports acceleration in complex scenarios with multiple ports and protocols.\n\nSupported protocol\nApplication layer: HTTP, HTTPS, and Quick UDP Internet Connections (QUIC)\nNetwork layer: IPv4 and IPv6\nApplication layer: HTTP, HTTPS, and WebSocket\nTransport layer: TCP and UDP\nNetwork layer: IPv4 and IPv6\nApplication layer: HTTP, HTTPS, and WebSocket\nTransport layer: TCP and UDP\nNetwork layer: IPv4 and IPv6\nScheduling mode\nDNS resolution\nHTTPDNS\n302 redirection\nDNS resolution\nHTTPDNS\n302 redirection\nDNS resolution with better performance and security\nHTTPDNS\n302 redirection\nEdge computing\nSupports Edge Script. You can use scripts to customize CDN features on POPs.\nSupports image editing.\nSupports Edge Routine (ER). You can use ER to deploy functions on POPs. For example, you can perform A/B testing and run prefetch tasks.\nSupports Edge Script. You can use scripts to customize CDN features on POPs.\nSupports image editing.\nEdge Routine (ER)\nEdge Routine enables you to deploy JavaScript code across POPs. This way, user requests can be responded to and processed by the POP that is closest to users.\nEdge KV\nEdge KV is the edge storage service based on key-value pairs. You can use Edge KV together with ER to deploy lightweight Blockchain as a Service (BaaS) services and API gateway services.\nEdge Container\nEdge Container provides elastic, easy-to-maintain computing resources based on containerized applications. You do not need to purchase server resources or worry about application scaling and O&M.\nSecurity policies\nReferer-based hotlink protection\nURL signing\nIP blacklist/whitelist\nBasic WAF protection\nAnti-DDoS protection\nBasic bot protection\nWAF supports custom protection rules.\nEnterprise plans have up to Tbit/s of DDoS mitigation capabilities.\nYou can integrate Anti-Bot SDK for JavaScript, Android, or iOS for bot management.\nSupports AI-driven protection.\nSupports origin protection to shield your origin against unauthorized access from external IP addresses.\nLog analysis\nStandard logs\nReal-time log delivery\nStandard logs\nReal-time log delivery\nTraffic analysis\nStandard logs\nReal-time log delivery\nInstant logs\nStatic content refers to files that can be delivered without modifications or processing. The server returns the same file for different requests. Static content includes images, videos, HTML files, CSS files, JavaScript files, software installation packages, Android Package (APK) files, and compressed package files.\nDynamic content refers to content that is delivered on a per-request basis. The server returns different contents for different requests. Dynamic content includes ASP, JSP, PHP, Perl, and CGI files, API requests, and database interactive requests on websites.\nFor more information about static content and dynamic content, see What are static content and dynamic content?\nCDN generates bills for basic services and value-added services.\nBilling rules of basic services: The pay-by-data-transfer and pay-by-peak-bandwidth metering methods are supported. The default metering method is pay-by-data-transfer. For more information, see Billing of basic services.\nBilling rules of value-added services: The billable items include HTTPS requests for static content, QUIC requests for static content, and real-time log entries. For more information, see Billing of value-added services.\nFor more information about pricing, visit the CDN pricing page.\nBefore you activate CDN, we recommend that you get familiar with the billing rules of CDN. For more information, see Activate CDN.\nYou can use your Alibaba Cloud account to manage CDN anywhere by using the following methods:\nCDN console\nThe CDN console is an easy-to-use web console that supports interactive operations. For more information, see User Guide.\nCDN API\nThe CDN API is a remote procedure call (RPC) API that supports GET and POST requests. For more information, see List of operations by function.\nThe following table describes the services that are related to CDN to help you understand the positioning of CDN and how it can be used in combination with other Alibaba Cloud services.\nAlibaba Cloud service\nDescription\nDCDN\nDCDN separately accelerates dynamic content and static content while balancing performance and security capabilities.\nOSS\nIf you use an Object Storage Service (OSS) bucket as an origin server, you can use CDN to accelerate content delivery and reduce Internet data transfer fees.\nApsaraVideo Live\nYou can use CDN together with ApsaraVideo Live to achieve media feed storage, video segmentation and transcoding, access authentication, and content delivery acceleration.\nApsaraVideo VOD\nYou can use CDN together with ApsaraVideo VOD to reduce the buffer time and improve playback smoothness.\nAlibaba Cloud DNS\nYou can use Alibaba Cloud DNS that is highly available and stable to ensure smooth access to resources.\nECS\nYou can use CDN together with Elastic Compute Service (ECS) to improve website availability, protect information about origin servers, and minimize bandwidth usage costs.\nSLB\nYou can specify the IP address of a Server Load Balancer (SLB) instance as the origin address to distribute traffic across multiple servers during the origin fetch process.\nThe following topics describe the best practices:\nAccelerate the retrieval of resources from an OSS bucket\nUse CDN to accelerate the retrieval of resources from an ECS instance\nIncrease the cache hit ratios of CDN\n"
    },
    "317": {
        "title": "CDN:Competitive advantages of Alibaba Cloud CDN",
        "url": "https://www.alibabacloud.com/help/en/alibaba-cloud-cdn/latest/competitive-advantages-of-alibaba-cloud-cdn",
        "content": "This Product\nCDN:Competitive advantages of Alibaba Cloud CDN\nThis topic describes the competitive advantages of Alibaba Cloud CDN in terms of service performance, technologies, pricing, service bundling, and service support.\nAlibaba Cloud CDN provides the following advantages:\nCutting-edge features\nTechnical advantages\nCompetitive pricing strategies\nExpansive ecosystem services\nService support\nGlobal presence\nAlibaba Cloud CDN global network is made up of more than 3,200 strategically located points of presence (POPs). Spanning over 2,300 POPs are located across 31 provincial regions in the Chinese mainland, and over 900 POPs are located in more than 70 countries and regions, including Hong Kong (China), Macao (China), and Taiwan (China). The total bandwidth capacity of Alibaba Cloud CDN can reach up to 180 Tbit/s. Through leveraging vast network and immense networking capacity, Alibaba Cloud CDN is able to deliver your content to customers around the world with the utmost security, performance, and reliability.\nIndustry-certified capabilities\nChina DJCP (MLPS) Level 3 certification\nPayment Card Industry Data Security Standard (PCI DSS) certification\nListed as a global service provider by Gartner\nIPv6 Enabled CDN Logo certification issued by the global IPv6 Forum\nRich features\nAlibaba Cloud CDN provides a diversified mix of features, which can be accessed through the console and API. Customers can manage and configure all aspects of their content delivery through Alibaba Cloud CDN. The following table describes the key features of Alibaba Cloud CDN.\nCapability\nFeature\nDomain name management\nSupports the following features: accelerated domain name settings, basic settings, origin settings, caching settings, HTTPS settings, access control settings, performance optimization, video-related settings, security settings, traffic throttling, quick UDP Internet connections (QUIC), EdgeScript (ES) settings, and IPv6 settings.\nMonitoring and usage analytics\nSupports the following features: resource monitoring, real-time monitoring, resource usage query, ES monitoring, and security monitoring.\nLog management\nSupports the following features: log export, log storage, real-time log delivery, custom operations reports, and tracking tasks.\nRefresh and prefetch\nSupports the following features: URL refresh, directory refresh, and URL prefetch.\nProgrammable configurations\nAlibaba Cloud CDN provides programmable edge computing capabilities. These capabilities are delivered by using EdgeScript through custom configurations. If the built-in configurations provided by Alibaba Cloud CDN are unable to meet your business requirements, you can use ES to create custom configurations. Custom configurations are helpful in resolving issues in an agile manner.\nCustom routines at the edge\nEdgeRoutine (ER) is a serverless computing environment provided by Alibaba Cloud CDN and Dynamic Content Delivery Network (DCDN). ER allows you to run custom JavaScript code on POPs. After you use the ER command-line interface (CLI) to deploy code to the production environment, Alibaba Cloud CDN automatically runs the code on all POPs. The POPs process requests in different regions worldwide based on the code deployed. For more information, see What is EdgeRoutine?\nPublic API operations\nYou can call API operations to use and manage the features of Alibaba Cloud CDN. For more information, see List of operations by function.\nIntelligent routing\nAlibaba Cloud CDN implements various optimizations to provide superior routing performance:\nDynamic IP library: Alibaba Cloud CDN maintains an IP library that provides information such as regions and Internet service providers (ISPs). The routing system looks up the information whenever a DNS request is sent to Alibaba Cloud CDN. Then, the system routes user requests to the nearest CDN POP that belongs to the same ISP. The IP library is dynamically updated to ensure that the data is up-to-date.\nHTTPDNS (requires compatibility with clients): HTTPDNS allows clients to bypass the local DNS servers of ISPs and directly access the routing system over HTTP. Then, the routing system redirects the requests to the optimal POP for the destination domain names. This prevents security issues such as DNS hijacking.\nNode analytics: The routing system of Alibaba Cloud CDN analyzes the health status of all POPs and routes in the cache network in real time based on the statistics provided by the route quality system. This increases the routing quality of CDN POPs and improves user experience.\nContent-oriented routing: Content-oriented routing increases the cache hit ratio of Alibaba Cloud CDN. 302 redirection, one of the content-oriented routing schemes, is used in scenarios such as large file distribution and on-demand video streaming. The DNS server resolves a request which is then passed to the routing system. After the routing system parses the request, it identifies the POPs where the requested content resides. Then, a 302 redirect is performed to redirect the request to an optimal POP that is selected by the routing system.\nBenefits: The routing system can route requests based on data transfer trends, or route requests in real time to handle traffic spikes.\nExpected results: Alibaba Cloud CDN can monitor the health status of each POP in real time and select an optimal POP for each request based on the self-developed routing system.\nIntelligent caching system\nAccurate caching: Alibaba Cloud CDN uses intelligent object algorithms to cache content based on popularity in a multi-level cache. This mechanism allows Alibaba Cloud CDN to prioritize caching popular objects over less requested content.\nHigh-speed caching: Alibaba Cloud CDN is designed for performance. It makes full use of the underlying technologies by balancing workloads to take advantage of its multi-core processing capabilities, implementing cutting-edge memory management mechanisms, and maximizing the IOPS and throughput of SSDs.\nHigh read and write speeds: All POPs are equipped with SSDs to take advantage of their inherent high read/write speeds and reliability. These advantages allow Alibaba Cloud CDN to help you improve website availability and deliver content faster.\nEfficient origin fetch: Alibaba Cloud CDN provides failover and retransmission mechanisms to ensure efficient origin fetch and information synchronization.\nEfficient transport layer protocol\nQUIC: QUIC is a new transport layer network protocol that combines the best qualities of TCP, TLS, and HTTP/2. QUIC supports encrypted, low-latency, and multiplexed connections to meet the requirements of the transport and application layers.\nIndependently developed algorithms for the TCP protocol suite: Alibaba Cloud utilizes algorithms such as congestion detection and packet loss probing algorithms to improve the performance of TCP. The transmission performance is significantly improved.\nReliable protection capabilities\nAlibaba Cloud CDN is integrated with various security features and services to provide safe and secure content delivery.\nHotlink protection: Alibaba Cloud CDN provides a variety of methods to protect your origin server. Whitelists and blacklists can filter packets based on the Referer header, user-agent header, URLs, and IP addresses. You can also use ES to implement access authorization. Alibaba Cloud CDN also supports remote authentication, which is a two-factor authentication method used to reinforce the security of your origin servers.\nDNS hijacking protection: HTTPDNS allows clients to directly access the DNS maintained by Alibaba Cloud instead of the local DNS maintained by ISPs.\nHTTPS-based transmission: The security of data may be compromised if it is transmitted as plaintext over the Internet. Alibaba Cloud CDN uses TLS to encrypt HTTP messages. You can also configure advanced settings, such as TLS1.3 and HSTS, to better protect your data.\nProtection for origin servers: Alibaba Cloud CDN provides basic security features. If your origin servers require reinforced protection, you can use Secure CDN (SCDN).\nHigh availability of origin servers: Alibaba Cloud CDN supports primary and secondary origin servers, and monitors the health status of the origin servers. If the primary origin server fails, requests are redirected to a secondary origin server.\nAlibaba Cloud CDN provides competitive pricing strategies:\nFlexible metering methods. For more information, see Billing overview.\nCost-effective subscription resource plans. For more information, go to the buy page.\nTailored to fit\nAlibaba Cloud CDN supports multiple metering methods and resource plans that you can mix and match to meet the requirements of your business scenarios. Select a metering method based on your business requirements.\nScenario\nRecommended combination\nLow origin traffic with occasional traffic spikes\nPay-by-data-transfer.\nWe recommend that you purchase resource plans to reduce costs. Alibaba Cloud CDN provides multiple types of resource plans for different acceleration regions. The capacities of these resource plans range from 100 GB to 50 PB. You can select resource plans based on your business requirements.\nFor more information about the metering methods of Alibaba Cloud CDN, visit the CDN Pricing page.\nAlibaba Cloud provides diversified services and products. The following tables describe the services and products that you can use together with Alibaba Cloud CDN in different scenarios.\nYou can use Alibaba Cloud CDN together with other Alibaba Cloud services to fine-tune service performance and improve management efficiency.\nExisting service\nRecommended service\nReason\nECS\nAlibaba Cloud CDN\nAlibaba Cloud CDN accelerates the delivery of content stored on your ECS origin to customers all over the world.\nOSS\nAlibaba Cloud CDN accelerates the delivery of content stored on your OSS origin to customers all over the world. The caching capability of Alibaba Cloud CDN helps reduce the outbound traffic costs of OSS.\nFunction Compute\nAlibaba Cloud CDN accelerates the delivery of content stored on your Function Compute origin to customers all over the world.\nBuilding upon the powerful static content acceleration capabilities, Alibaba Cloud CDN also provides solutions for scenarios where you may also want to accelerate dynamic content or want to harden website security.\nScenario\nRecommended service\nDescription\nAccelerate the delivery of both dynamic and static content\nDCDN\nDCDN is a branch of Alibaba Cloud CDN that can accelerate the delivery of both dynamic and static content. DCDN automatically separates dynamic content from static content and accelerates the delivery of both types of content at the same time.\nIntegrate security with acceleration\nDCDN edge security\nDCDN provides integrated security services on POPs to filter and intercept malicious traffic close to the source. You can enable edge protection in just a few simple steps and start protecting your websites, APIs, and applications.\nIf you have already activated Alibaba Cloud CDN, you can use Alibaba Cloud CDN together with other services to fine-tune it to meet your unique business requirements. The following table describes the services that can be used together with Alibaba Cloud CDN.\nScenario\nRecommended service\nDescription\nAccelerate on-demand audio and video streaming\nApsaraVideo VOD\nVOD is an all-in-one solution for on-demand audio and video streaming. VOD supports audio and video upload, automatic transcoding, media resource management, and content delivery.\nAccelerate live streaming\nApsaraVideo Live\nApsaraVideo Live is an audio and video streaming platform that is based on the next-generation content access and distribution network and supports large-scale and distributed real-time transcoding. ApsaraVideo Live is a low-latency, highly concurrent live streaming service that delivers smooth, high-quality video content.\nRegister a domain name that you want to accelerate by using Alibaba Cloud CDN\nDomain Names\nDomain Names is a domain name management platform that provides domain name registration, transaction, monitoring, and protection services. This platform is integrated with the Alibaba Cloud ICP Filing and Alibaba Cloud DNS services.\nApply for an Internet Content Provider (ICP) number for the domain name that you want to accelerate by using Alibaba Cloud CDN\nAlibaba Cloud ICP Filing\nChina mandates an ICP filing system for non-commercial Internet information services and an ICP licensing system for commercial Internet information services. You must apply for an ICP number for your domain name to comply with Measures for the Administration of Internet Information Services and Registration Administration Measures for Non-Commercial Internet Information Services. Websites that do not have an ICP number or license are prohibited from providing Internet information services. Therefore, all websites must obtain an ICP number before the websites are permitted to operate in the Chinese mainland. You can use the Alibaba Cloud ICP Filing system to apply for ICP numbers, modify ICP filing information, cancel ICP filing applications, and claim ICP numbers.\nEnable and configure HTTPS for a website\nCertificate Management Service\nCertificate Management Service is a digital server certificate service provided by Alibaba Cloud. This service provides digital server certificates issued by certification authorities (CAs). You can obtain free digital certificates or purchase other types of certificates from Alibaba Cloud. Then, you can deploy these certificates in Alibaba Cloud services to enable HTTPS for HTTP-based services in an efficient and convenient manner. This way, your websites can perform identity verification and encryption for data in transit.\nImprove the O&M efficiency, and process large volumes of log data\nSimple Log Service\nSimple Log Service is an all-in-one logging service developed in-house by Alibaba Cloud. As a powerful logging solution, Simple Log Service has been honed to perfection through years of implementation within Alibaba Group. Simple Log Service helps you quickly collect, consume, ship, query, and analyze log data without development work. It improves the O&M efficiency and provides the capability to process large volumes of data.\nMonitor Alibaba Cloud resources and Internet applications\nCloudMonitor\nCloudMonitor monitors Internet applications and Alibaba Cloud resources. CloudMonitor collects metrics of Alibaba Cloud resources. You can use CloudMonitor to monitor the availability of your network and configure alerts for specific metrics.\nAlibaba Cloud CDN provides comprehensive service support, including:\nEnd-to-end and 24/7 monitoring and support systems.\nWell-maintained documentation. For more information, see What is Alibaba Cloud CDN?\nYou can submit feedback and suggestions for pre-sales consultation or after-sales support."
    },
    "318": {
        "title": "CDN:Common scenarios",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/scenarios",
        "content": "This Product\nCDN:Common scenarios\nAlibaba Cloud CDN is suitable for various scenarios. You can use Alibaba Cloud CDN to accelerate the delivery of images, small files, large files, and on-demand video and audio content. This topic describes the scenarios that are supported by Alibaba Cloud CDN.\nThe following table describes the scenarios that are supported by Alibaba Cloud CDN.\nScenario\nDescription\nImage and small file distribution\nAccelerates the delivery of small files on websites and applications, such as web portals, e-commerce websites, news websites and applications, and gaming and other entertainment websites.\nLarge file distribution\nAccelerates the delivery of files that are larger than 20 MB in size, such as game installation packages, application updates, ROM updates, and application packages.\nOn-demand audio and video streaming\nAccelerates the delivery of audio and video content on websites and applications, such as film and television websites, online education websites, news websites, and short video websites. Mainstream video formats, including MP4 and FLV, are supported.\nAlibaba Cloud CDN accelerates the delivery of small files on applications and websites, such as web portals, e-commerce websites, news websites, and entertainment websites. You need to separate static content from dynamic content on your origin server. The delivery of static content, such as images, CSS files, and small JavaScript files, is accelerated by Alibaba Cloud CDN. The delivery of dynamic content is accelerated by Dynamic Content Delivery Network (DCDN).\nStatic content refers to files that can be delivered without modifications or processing. The server returns the same file for different requests. Static content includes images, videos, HTML files, CSS files, JavaScript files, software installation packages, Android Package (APK) files, and compressed package files.\nDynamic content refers to content that is delivered on a per-request basis. The server returns different contents for different requests. Dynamic content includes ASP, JSP, PHP, Perl, and CGI files, API requests, and database interactive requests on websites.\nFor more information about static content and dynamic content, see What are static content and dynamic content?\nThis feature addresses the following issues:\nWebsites respond slowly because they contain a large number of small files.\nThe web page loading speed and the quality of web services vary across regions.\nDuring promotions, the origin servers may become unavailable due to traffic spikes. In this case, services are interrupted.\nImages cannot be compressed or optimized to meet client requirements due to complex processing of image formats and resolution.\nAlibaba Cloud CDN accelerates the delivery of files that are larger than 20 MB in size, such as game installation packages, application updates, ROM updates, and application packages.\nThis feature addresses the following issues:\nUsers cannot download files, or the download speed is low.\nDownloads may be interrupted due to unstable network connections. If users redownload data, additional data transfer is required.\nA website is vulnerable to hijacking or hotlinking, which can cause business losses.\nThe origin server requires higher performance to withstand high-concurrent downloads or download spikes. In this case, the bandwidth cost of the origin server is high.\nAlibaba Cloud CDN distributes and accelerates the delivery of audio and video content on websites and applications, such as film and television websites, online education websites, news websites, and short video websites.\nThis feature addresses the following issues:\nErrors or stalling issues that occur when users request video content.\nYour website or application is vulnerable to hijacking or unauthorized downloads of video content. The copyright of the video content requires protection.\nThe origin server requires higher performance to withstand high-concurrent access or access spikes. In this case, the bandwidth cost of the origin server is high.\nIf you want an all-in-one service that can upload, transcode, store, and distribute audio or video content at the same time in addition to the preceding features, you can use ApsaraVideo VOD. For more information, see What is ApsaraVideo VOD?"
    },
    "319": {
        "title": "CDN:POP distribution",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/pop-distribution",
        "content": "This Product\nCDN:POP distribution\nAlibaba Cloud CDN global network consists of more than 3,200 strategically located points of presence (POPs). Among these POPs, more than 2,300 are distributed across 31 provincial regions and first-tier cities in the Chinese mainland and more than 900 are distributed across over 70 countries and regions, including Hong Kong (China), Macao (China), and Taiwan (China). The total bandwidth capacity of Alibaba Cloud CDN can reach up to 180 Tbit/s.\nAlibaba Cloud CDN supports a total bandwidth capacity of up to 180 Tbit/s. Each POP provides 40 TB to 1.5 PB of data storage and 40 Gbit/s to 200 Gbit/s of bandwidth capacity.\nThe widely distributed high-performance POPs can accelerate content delivery and withstand traffic spikes.\nThe following table describes the distribution of major POPs.\nBillable region\nDistribution\nChinese mainland\nNorth China: Beijing, Tianjin, Hebei, Shanxi, and Inner Mongolia\nEast China: Shandong, Jiangsu, Anhui, Zhejiang, Fujian, Shanghai, and Jiangxi\nCentral China: Hubei, Hunan, and Henan\nSouth China: Guangdong, Guangxi, and Hainan\nSoutheast China: Sichuan, Yunnan, Guizhou, Xizang, and Chongqing\nNorthwest China: Ningxia, Xinjiang, Qinghai, Shaanxi, and Gansu\nNortheast China: Liaoning, Jilin, and Heilongjiang\nNorth America\nUnited States (Los Angeles, Ashburn, Miami, New York, Seattle, San Jose, Denver, Dallas, Chicago, and Santa Clara)\nEurope\nUkraine, UK, France, Netherlands, Italy, Sweden, Germany, and Spain\nAsia Pacific 1\nHong Kong (China), Japan (Tokyo and Osaka), Singapore, Thailand (Bangkok), Philippines (Manila), and Malaysia (Kuala Lumpur)\nAsia Pacific 2\nIndonesia (Jakarta, Surabaya, and Batam), Republic of Korea (Seoul), and Pakistan\nAsia Pacific 3\nAustralia (Sydney and Melbourne)\nMiddle East and Africa\nT\u00fcrkiye, UAE, Kuwait, Qatar (Doha), Oman, Nigeria, and South Africa (Johannesburg)\nSouth America\nBrazil (S\u00e3o Paulo and Rio de Janeiro)\n"
    },
    "320": {
        "title": "CDN:Limits",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/limits",
        "content": "This Product\nCDN:Limits\nThis topic describes the requirements and limits that apply to domain names when you use Alibaba Cloud CDN. Make sure that your domain names and the related content conform with the requirements to prevent losses that may result from regulatory violations.\nItem\nDescription\nBurst bandwidth/QPS throttling rules\nAccording to the Alibaba Cloud International Website Product Terms of Service, if you expect traffic or QPS spikes, including but not limited to on stress tests on bandwidth or QPS, promotional activities, and major releases, on CDN-accelerated services, you need to contact your account manager or contact us to apply for burst bandwidth at least 3 business days in advance. For major events including but not limited to the Spring Festival Gala and Double 11 Global Shopping Festival, you need to apply for burst bandwidth at least 1 month in advance.\nIf the application is approved, the availability of your services is guaranteed when the burst bandwidth is within the level agreed upon by both parties.\nIf you do not apply for burst bandwidth or the application is rejected, Alibaba Cloud reserves the right to take measures such as bandwidth throttling to ensure service-level stability for other Alibaba Cloud customers. Bandwidth throttling is not necessarily triggered. Alibaba Cloud determines whether to enable bandwidth throttling based on service conditions and the level of the burst bandwidth. Alibaba Cloud is not responsible for the reduced availability caused by the measures.\nIf you do not apply for burst bandwidth or the application is rejected, the following issues may occur:\nBurst bandwidth may trigger throttling rules of CDN. For more information, see Burst bandwidth.\nBurst QPS may trigger HTTP flood protection rules of CDN. In this case, the domain name may be added to a sandbox. For more information, see Introduction to sandboxes.\nPotential domain attacks or data transmission abuse\nBy default, CDN does not provide access control or security protection capabilities. If your domain name is attacked or abused for data transmission, high bandwidth or traffic spikes may occur. In this case, you may receive bills that are higher than expected.\nHigh bills that are generated by malicious attacks or data transmission abuse cannot be waived or refunded. For information about how to prevent high bills from being generated, see Configure high bill alerts.\nDomain name\nRequirements for domain name formats:\nThe domain name must be 1 to 67 characters in length.\nThe domain name can contain lowercase letters, digits, and hyphens (-). Example: example.com.\nThe domain name cannot contain Chinese characters, uppercase letters, or special characters other than hyphens (-). The domain name cannot be a hyphen (-). The domain name cannot contain consecutive hyphens (-). The domain name cannot start or end with a hyphen (-). If the domain name contains Chinese characters such as \u963f\u91cc\u4e91.\u7f51\u5740, you must perform ICP filing for the Chinese domain name. Then, use the Punycode tool to convert the domain name into English characters such as xn--fiq****.xn--eq****. Specify the converted domain name as the domain name to be accelerated.\nRequirements for wildcard domain names:\nAlibaba Cloud CDN supports wildcard domain names. For information about the limits on wildcard domain names, see Does Alibaba Cloud CDN support wildcard domain names?\nThe wildcard domain name that you specify and the domain names that match the wildcard domain name must belong to the same Alibaba Cloud account. Otherwise, an error message appears when you add domain names.\nIf a wildcard domain name has not been added to an Alibaba Cloud account, you are allowed to add the subdomains of the wildcard domain name to multiple Alibaba Cloud accounts.\nIf you add a wildcard domain name such as .aliyundoc.com and matching specific domain names such as example.aliyundoc.com to Alibaba Cloud CDN, only the first 500 specific domain names can be accelerated by Alibaba Cloud CDN.\nThe first 500 specific domain names that match the wildcard domain name can be accelerated by Alibaba Cloud CDN.\nRequirements for domain name ICP filing and compliance:\nICP filing: If you set the acceleration region of a domain name to Global or Chinese Mainland Only, you must apply for an ICP number for the domain name. We recommend that you use Alibaba Cloud ICP Filing System to apply for ICP numbers. For more information, see Check the instance for ICP filing and access information.\nThe content that is delivered from the domain name must be legal and compliant with the Terms of Service for Alibaba Cloud CDN. For more information, see Limits.\nEach Alibaba Cloud account can add up to 50 domain names to Alibaba Cloud CDN.\nIf the average daily peak bandwidth of your domain names exceeds 50 Mbit/s, you can request to add more domain names by following the method that is described in Quota management. Make sure that the increase in domain names does not cause business risks.\nYou cannot add domain names that have been added to other Alibaba Cloud services. If you want to transfer an Alibaba Cloud CDN-accelerated domain name to another Alibaba Cloud account, verify the ownership of the domain name first. For more information, see Transfer a domain name to another Alibaba Cloud account. If the system prompts that the domain name is added to other Alibaba Cloud services such as ApsaraVideo VOD and DCDN, submit a ticket.\nDomain name reclaiming: If your domain name is disabled for 120 days, Alibaba Cloud CDN deletes the configuration records that are related to the domain name. This rule also applies to domain names that fail ownership verification. If you want to continue using the domain name, you must go to the Alibaba Cloud CDN console to add the domain name again.\nDomain name disabling: For more information, see Rules for disabling accelerated domain names.\nSandbox: If an accelerated domain name is under attack, such as DDoS attacks or HTTP flood attacks, or faces significant increases in bandwidth or QPS due to traffic spikes that have not been reported to Alibaba Cloud, Alibaba Cloud CDN has the right to determine whether to add the attacked domain name to a sandbox based on factors such as the service status of the domain name and the impact of the attack. This ensures that the acceleration services of other users can work as expected. For more information, see Introduction to sandboxes. If the attack is severe, other accelerated domain names in the same account are also added to the sandbox, and new domain names cannot be added to the account.\nAccess region\nIf you set Region to Global (Excluding the Chinese Mainland) for an accelerated domain name, CDN blocks user requests to points of presence (POPs) that are located in the Chinese mainland.\nIoT card\nAccording to the Notice on Printing and Distributing the Trial Implementation Guidelines for the Classification and Security Management of IoT Cards (MIIT Network Security Letter [2020] No. 1173) set forth by the Ministry of Industry and Information Technology (MIIT) of the People's Republic of China, CDN cannot provide acceleration services for devices that use IoT cards in regions in the Chinese mainland. When devices that use IoT cards attempt to access POPs, the devices may fail to establish connections to the IP addresses of the POPs.\nOrigin server\nAddress length: The address of an origin server cannot exceed 67 characters in length.\nMaximum number of origin servers: You can configure up to 20 origin servers for each accelerated domain name.\nOSS Domain\nIf your origin server is an Object Storage Service (OSS) bucket, you can select the public domain name of an OSS bucket that belongs to the current Alibaba Cloud account from the Domain Name drop-down list.\nYou can enter the public domain name of the OSS bucket such as ***.oss-cn-hangzhou.aliyuncs.com. CDN does not support internal domain names of OSS buckets. You can get public domain name of an OSS bucket from the OSS console.\nFor information on best practices of using CDN to accelerate resource delivery from OSS buckets, see Use CDN to accelerate the delivery of resources from OSS buckets.\nDiscounts for data transfer between CDN and OSS:\nIf you want OSS to identify network traffic that is sent from CDN and apply for a discount on the data transfer, you need to set the origin server type to OSS Domain in the CDN console.\nIf you set the origin server type to Site Domain in the CDN console, OSS identifies network traffic that is sent from CDN as outbound data transfer over the Internet. In this case, the discounts do not apply.\nFor more information on billing, see Billing of OSS content acceleration.\nIP\nYou can configure one or more IP addresses for an origin server. Internal IP addresses are not supported. IPv4 addresses and IPv6 addresses are supported. At least one of the IP addresses must be an IPv4 address. If you use a public IP address of an Alibaba Cloud Elastic Compute Service (ECS) instance as the address of the origin server, the IP address is exempt from manual review. You need to enable origin fetch over IPv6 before you configure an IPv6 address. Otherwise, even if you configure an IPv6 address, it does not take effect. As a result, origin fetch fails. For more information, see Configure origin fetch over IPv6.\nFor more information on using an IP for origin server, see Use CDN to accelerate the retrieval of resources from an ECS instance.\nSite Domain: Enter the domain names of one or more origin servers.\nFor more information on using a domain name for origin server, see Use CDN to accelerate the retrieval of resources from an ECS instance.\nThe origin domain name must be different from the accelerated domain name. Otherwise, a DNS resolution loop will occur, as requests are continuously resolved back to the CDN nodes, which leads to failure in back-to-origin routing.\nYou can add the address of an Alibaba Cloud Application Load Balancer (ALB) instance, such as example.hangzhou.alb.aliyuncs.com, as the address of an origin server.\nThe format of the origin domain name:\nThe domain name must be 1 to 67 characters in length.\nThe domain name can contain lowercase letters, digits, and hyphens (-). Example: example.com.\nThe domain name cannot contain Chinese characters, uppercase letters, or special characters other than hyphens (-). The domain name cannot be only a hyphen (-). A hyphen (-) in a domain name cannot be followed by another hyphen (-). The domain name cannot start or end with a hyphen (-). If the domain name contains Chinese characters, such as \u963f\u91cc\u4e91.\u7f51\u5740, you must apply for an ICP number for the domain name in Chinese characters and use the Punycode tool to convert the Chinese characters into English letters, such as xn--fiq****.xn--eq****. Then, you can specify the converted domain name as the domain name that you want to accelerate.\nFunction Compute Domain: Enter a Function Compute domain name that belongs to the current Alibaba Cloud account. If you select this option, you need to configure the Region and Domain Name parameters. For more information, see Configure a custom domain name.\nCNAME\nCNAMEs that are assigned by CDN, DCDN, ApsaraVideo Live, or ApsaraVideo VOD are used only for domain name resolution by CDN. If Alibaba Cloud detects that your CNAME is used for malicious activities, Alibaba Cloud reserves the right to close your Alibaba Cloud account and remove the domain names.\nService quota\nDomain name\nEach Alibaba Cloud account can add up to 50 domain names to CDN. If the average daily peak bandwidth exceeds 50 Mbit/s and your workloads are under protection, you can request a quota increase. For more information, see Quota management.\nCache purge\nPurge by URL: 10,000 URLs per day for each Alibaba Cloud account.\nPurge by directory: 100 directories per day for each Alibaba Cloud account.\nIf your daily peak bandwidth exceeds 200 Mbit/s, you can request a quota increase by following instructions in Quota management. Alibaba Cloud determines whether to approve your application based on your business requirements.\nFile prefetch\nYou can prefetch files only by using URLs. Each Alibaba Cloud account can submit up to 1,000 URLs per day.\nIf your daily peak bandwidth exceeds 200 Mbit/s, you can request a quota increase by following instructions in Quota management. Alibaba Cloud determines whether to approve your application based on your business requirements.\nSecurity violations\nAlibaba Cloud reviews the content served on all accelerated domain names. Domain names that cannot be accelerated by CDN include but are not limited to:\nDomain names of websites whose content is inaccessible or does not provide valid information\nDomain names that point to illegal private game servers\nDomain names of websites that provide multiplayer role-playing games and card games\nDomain names of websites that provide downloads of pirated content, including pirated software, books, videos, and comics\nDomain names of peer-to-peer (P2P) lending websites\nDomain names of unofficial lottery websites\nDomain names of unlicensed hospitals and pharmaceuticals websites\nDomain names of websites that contain illicit content, such as pornography, drugs, and gambling\nYou are legally responsible for the content that is hosted on your accelerated domain names. CDN regularly reviews the content served on accelerated domain names. If CDN detects that illicit content is served on a domain name, the system immediately disables or blocks the domain name. In serious cases, CDN may permanently block all domain names that belong to the Alibaba Cloud account.\nFor example, if you add a wildcard domain name such as *.example.com to CDN and a specific domain name (a.example.com) that matches the wildcard domain name contains illicit content, CDN disables the entire wildcard domain name (*.example.com).\nIf a domain name fails the review, you can check the reason for rejection on the Domain Names page in the CDN console. Then, you can modify the content based on the rejection details and resubmit the domain name for review.\nFile\nFile cache\nResponses whose Cache-Control directives do not allow caching: If the request to a file whose size is larger than 100 MB is a cache miss, CDN closes the connection after the amount of data transmitted from the origin server reaches 100 MB.\nResponses whose Cache-Control directives allow caching: CDN can cache files up to 500 GB in size.\nFile upload\nYou can upload files to origin servers by using CDN. Each file can be up to 300 MB in size.\nEdgeScript\nBy default, you can configure only one script for each domain name. If you want to configure multiple scripts, contact your account manager or contact us.\nOrigin fetch\nThe size of HTTP request headers that you add in the CDN console or by calling an API operation cannot exceed 300 bytes.\nTimeout\nBy default, the timeout period for origin requests that are transmitted over Transmission Control Protocol (TCP) is 10 seconds. The timeout period for origin requests that are transmitted over HTTP is 30 seconds.\nResponse header\nIf the origin server does not return the Content-Type header, CDN automatically adds the Content-Type:application/octet-stream header.\nAutomatic conversion from HEAD to GET for origin requests\nBy default, CDN POPs convert HEAD requests to GET requests before the requests are redirected to the origin server. If you want POPs to redirect HEAD requests to the origin server, you can submit a ticket.\nAfter you add origin request headers in the Custom Request Headers dialog box, the strings are converted to camel case during origin fetch, as shown in the following examples:\nExample 1: The request header ALI-CDN is converted into Ali-Cdn during origin fetch.\nExample 2: The request header ALICDN is converted to Alicdn during origin fetch.\nIf you want to disable automatic case conversion, add the following header in the Custom Request Headers dialog box:\nCustom header: Ali-Swift-Header-Capitalize\nValue: off\nLength of an individual URL or HTTP request header, and total length of URLs and HTTP request headers\nHTTP/2:\nIf the default setting of the NGINX directive is http2_max_field_size=32KB, the length of an individual HTTP request header or an individual URL cannot exceed 32 KB. Otherwise, the HTTP 414 status code is returned.\nIf the default setting of the NGINX directive is http2_max_header_size=128KB, the total size of all HTTP request headers and URLs cannot exceed 128 KB. Otherwise, the HTTP 400 status code is returned.\nHTTP/1.1: For the large_client_header_buffers directive, number is set to 4 and size is set to 64 KB. In this case, the length of an individual HTTP request header or an individual URL cannot exceed 64 KB. Otherwise, the HTTP 414 status code is returned. The total size of all HTTP request headers and URLs cannot exceed 256 KB. Otherwise, the HTTP 400 status code is returned.\nTotal size of origin HTTP response headers\nThe total size of HTTP response headers returned from the origin to POPs cannot exceed 32 KB. Otherwise, the HTTP 502 status code is returned.\nRequest method\nCDN supports the following request methods: GET, PUT, POST, HEAD, and OPTION.\nIf you want your website to support DELETE and PATCH requests, use DCDN to enable dynamic content delivery.\nPUT allows HTTP requests that contain a request body (BODY) or do not contain a request body (Content-Length=0).\nPOST supports chunked encoding and allows HTTP requests that contain a request body (BODY) or do not contain a request body (Content-Length=0).\nFor cached static resources, POPs convert HEAD requests to GET requests before the requests are redirected to the origin server by default. If you want POPs to redirect HEAD requests to the origin server, you can submit a ticket.\nFeature configuration\nYou can add a maximum of 50 configurations, including but not limited to the following features: Custom Request Header, Custom Response Headers, Origin URL Rewrite, Parameter Rewrite, and Cache Expiration.\nGzip compression and Brotli compression\nYou can use the Gzip compression or Brotli compression feature to compress the files only if the size of files on the origin server ranges from 1 KB to 10 MB. Files that are smaller than 1 KB or larger than 10 MB are not compressed.\nAPI call for each account\nEach Alibaba Cloud account can call this API up to 1,000 times per second. If the upper limit is reached, the following message is returned:\n"
    },
    "321": {
        "title": "CDN:Terms",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/terms",
        "content": "This Product\nCDN:Terms\nThis topic describes the terms that are related to Alibaba Cloud CDN. Make sure that you are familiar with the terms to better understand and use Alibaba Cloud CDN.\nAn origin server refers to the server on which your workloads are run. Alibaba Cloud CDN distributes the content hosted on the origin server.\nAn origin server can process and respond to user requests. If the requested content is not cached on points of presence (POPs), the request is redirected to the origin server to retrieve the content. Alibaba Cloud CDN supports the following types of origin servers: Object Storage Service (OSS) buckets, Function Compute, and your own origin servers (IP addresses and domain names).\nA POP is where resources from the origin server are cached. POPs are deployed in different geographical regions to accelerate content delivery.\nAn accelerated domain name refers to a domain name that is accelerated by Alibaba Cloud CDN and accessed by users. For example, if you add aliyundoc.com to Alibaba Cloud CDN, aliyundoc.com is considered as an accelerated domain name.\nAlibaba Cloud CDN retrieves resources from origin servers and caches the resources on POPs to accelerate content delivery. In the Alibaba Cloud CDN documentation, an accelerated domain name is also called a domain name.\nA domain name, also known as a network domain, is an identification string that defines one or more Internet resources, such as computers. A domain name is a numerical address and sometimes also represents a physical location.\nA CNAME record, also called an alias record, maps a domain name to another domain name, which is then resolved to the IP address of the destination server.\nAfter you add a domain name to Alibaba Cloud CDN, Alibaba Cloud CDN generates a CNAME record in the format of *.*kunlun*.com and then assigns the CNAME record to the domain name.\nAlibaba Cloud CDN uses globally distributed POPs to accelerate content delivery. The IP addresses of POPs that are accessed by users in different regions or using different Internet service providers (ISPs) are different. In this case, an accelerated domain name cannot be resolved to a specific IP address by using an A record. To resolve this issue, CNAME records are used.\nAfter you add an accelerated domain name, you need to add the CNAME record that is provided by Alibaba Cloud CDN to the DNS records of the domain name at your DNS provider. After the CNAME record takes effect, all requests destined for the domain name are redirected to POPs. This accelerates content delivery. The Alibaba Cloud CDN routing system nominates the optimal POP based on the region, ISP, and load. Then, the CNAME record is resolved to the IP address of the optimal POP.\nStatic content refers to content that remains unchanged regardless of the number of times the content is requested by users. Static content includes images, videos, web files (such as HTML, CSS, and JavaScript files), software installation packages, APK files, and compressed files.\nAlibaba Cloud CDN caches static content from origin servers to POPs that are distributed around the globe. When your customers request content, the content is served from the POP that is closest to the customers. This helps reduce delays and improve user experience.\nDynamic content refers to content that may change each time the content is requested. Dynamic content includes web files such as ASP, JSP, PHP, PERL, and CGI files, API operations, and database queries.\nIf you want to improve the acceleration performance in dynamic content delivery, we recommend that you use DCDN. For more information, see What is DCDN?\nDomain Name System (DNS) is a service that translates human-readable domain names into machine-readable IP addresses. Domain names are easy-to-identify to humans, but machines identify only IP addresses.\nDomain name resolution is automatically performed by DNS servers. For example, if you enter aliyundoc.com in the address bar of your browser, the domain name is automatically resolved to an IP address, such as 10.10.10.10.\nAlibaba Cloud also provides a DNS resolution service called Alibaba Cloud DNS. For more information, see Alibaba Cloud DNS.\nSecure Sockets Layer (SSL) is a secure communication protocol that improves the integrity and security of data that is transmitted over the Internet. SSL encryption is performed between the TCP/IP protocol stack and application layer protocols. Transport Layer Security (TLS) is the successor of SSL and is a cryptographic protocol at the transport layer. SSL and TLS are collectively known as SSL/TLS.\nThe amount of time required for a client to initiate a request and receive the IP address of the destination host.\nThe amount of time required for a client to establish a TCP connection to the destination server.\nThe amount of time required for a client to establish an SSL connection to a web server.\nThe amount of time required for a client to complete sending a request after SSL handshakes are completed.\nIf a POP uses HTTP to accelerate content delivery, the connection time consists of the DNS time and TCP time. If a POP uses HTTPS to accelerate content delivery, the connection time consists of the DNS time, TCP time, and SSL time. The connection time shows the coverage of POPs and the capabilities of the POPs to deliver content.\nThe amount of time required for a web server to process an HTTP request and return a response to a client.\nThe amount of time required for a client to receive and download the first packet returned from a web server.\nThe amount of time required for a client to send a request and receive the first HTTP packet from a server. The time to first packet shows the overall performance of POPs.\nFor content uploading and downloading, the time to first packet consists of the DNS time, TCP time, SSL time, request time, and response time.\nA new domain name may require a longer period of time for DNS resolution than other existing domain names. However, this does not affect the cache retrieval time.\nThe amount of time required to complete loading the first frame of a stream. The initial load time is determined by the DNS time, connection time, and time to first packet. A shorter initial load time indicates better performance.\nStalling events may occur when a video or audio stream is played or a resource is loaded. The stalling rate is calculated by using the following formula: Number of viewers that have stalling events/100. A lower stalling rate indicates better performance.\nThe rate of lost packets to total packets during transmission.\nThe amount of time required to upload or download an entire file.\nIf a resource that is requested by your customer is not cached on POPs or has expired, the request is redirected to the origin server to retrieve the resource. This process is called origin fetch.\nAn origin host refers to the domain name to which POPs redirect requests during origin fetch. If multiple domain names are hosted on the same origin server, you need to specify the domain name to which POPs redirect requests during origin fetch. For more information, see Configure the default origin host.\nFor example, you want POPs to redirect requests to aliyundoc.com, which is different from the accelerated domain name www.aliyundoc.com. In this case, you need to specify aliyundoc.com as the origin host.\nThe origin protocol policy specifies the protocol that is used to redirect requests to origin servers. The protocol can be the one that is used by the clients to request content. For example, if clients send requests to POPs over HTTPS, you can set the origin protocol policy to HTTPS. If the origin server does not support HTTPS, you can set the origin protocol policy to HTTP. For more information, see Configure the origin protocol policy.\nThe back-to-origin rate is classified into two: back-to-origin request rate and back-to-origin data transfer rate.\nThe back-to-origin request rate refers to the rate of requests for resources that are not cached, have expired, or cannot be cached on POPs to the total number of requests. Back-to-origin request rate = Number of back-to-origin requests from POPs/Total number of requests sent to POPs. A lower back-to-origin request rate indicates better performance. However, if the user requests are fragmented after POPs redirect the requests to the origin servers, the number of back-to-origin requests becomes greater than the total number of requests that are sent to POPs.\nThe back-to-origin data transfer rate refers to the rate of data transfer that is returned by the origin servers to data transfer that is returned by POPs to clients. Back-to-origin data transfer rate = Number of bytes returned from the origin servers to POPs/Number of bytes returned from POPs to clients. A lower data transfer rate indicates better performance.\nServer name indication (SNI) is an extension of SSL/TLS. If multiple domain names are hosted on the same HTTPS server (IP address), you can use SNI to specify the domain name to which requests are redirected.\nIf the IP address of an origin server is associated with multiple domain names and the origin protocol policy is set to HTTPS, you can configure SNI to specify the domain name to which requests are redirected. When requests are redirected to the origin server, the origin server returns the certificate of the requested domain name. For more information, see Configure SNI.\nIf a request that is redirected from POPs to the origin server carries the Range header, the origin server returns the content that is specified by the Range header. This process is called range origin fetch. For example, the Range header can specify that the origin server returns only the first 0 to 100 bytes of data from a specified file.\nIn scenarios where you want to distribute large files, such as on-demand video streaming and software package distribution, range origin fetch is an ideal method to accelerate file distribution, increase cache hit ratios, reduce origin traffic and loads on origin servers, and improve page loading. For more information, see Range origin fetch.\nRange is an HTTP header that specifies the part of content to be retrieved.\n302 redirection allows POPs to process the HTTP 302 status code that is returned from the origin server instead of returning the HTTP 302 status code to clients. 302 redirection simplifies request processing and accelerates content delivery.\nReferer-based hotlink protection refers to access control based on the Referer header. For example, you can configure a Referer whitelist to allow only specified requests to access your resources or a blacklist to block specified requests. Referer-based hotlink protection identifies and filters user identities and protects your resources from unauthorized access. After you configure a Referer whitelist or blacklist, Alibaba Cloud CDN allows or rejects requests based on user identities. For more information, see Configure a Referer whitelist or blacklist to enable hotlink protection.\nThe Referer header is a component of the header section in HTTP requests and contains information about the source address, including the protocol, domain name, and query string. Referer is used to identify the source of a request.\nA bandwidth cap specifies the maximum amount of bandwidth resources that can be consumed to prevent bandwidth usage spikes.\nIf the average bandwidth value of an accelerated domain name during a statistical period (1 minute) reaches the specified bandwidth cap, Alibaba Cloud CDN suspends services and disables the domain name. Then, the domain name is mapped to the invalid domain name offline.***.com. In this case, the domain name becomes inaccessible. For more information, see Configure bandwidth caps.\nTime-to-live (TTL) refers to the amount of time that a resource is cached on POPs. Expired resources are automatically removed from POPs. Requests for expired resources are considered cache misses and redirected to the origin server. The retrieved resources are returned to the clients and cached on POPs. For more information, see Create a cache rule for resources.\nThe cache hit ratios of Alibaba Cloud CDN include the byte hit ratio and request hit ratio. A higher cache hit ratio indicates better performance.\nByte hit ratio = (Total number of bytes returned from POPs to clients - Total number of bytes returned from the origin servers to POPs)/Total number of bytes returned from POPs to clients.\nA lower byte hit ratio indicates a higher volume of origin traffic. A higher volume of outbound traffic from the origin server indicates a larger bandwidth value and heavier workloads of the origin server. Origin traffic represents the amount of workloads on the origin server, and the byte hit ratio is a major concern in actual business scenarios.\nRequest hit ratio = (Total number of requests to POPs - Total number of back-to-origin requests)/Total number of requests to POPs.\nCross-origin resource sharing (CORS) is an access control mechanism that is based on HTTP headers. CORS allows web servers to define the origin servers by specifying the domain name, protocol, and port from which a browser is allowed to retrieve specified resources. For more information, see Configure CORS.\nEdgeScript (ES) allows you to specify custom Alibaba Cloud CDN configurations by running scripts if the built-in configurations provided by Alibaba Cloud CDN cannot meet your business requirements.\nEdgeRoutine (ER) is a JavaScript code runtime environment that runs on globally distributed POPs. ER supports the ES6 syntax and standard Web Service Worker APIs. You can deploy your JavaScript code to ER. This way, your code is propagated across the entire Alibaba Cloud CDN global network. This allows Alibaba Cloud CDN to process requests on the POPs that are closest to the clients.\nHTTP strict transport security (HSTS) is a policy mechanism that allows websites to accept only HTTPS connections. Websites can use HSTS to specify that clients, such as browsers, must use HTTPS. All HTTP requests and untrusted SSL certificates are rejected. HSTS prevents man-in-the-middle (MITM) attacks during the first visits from clients. For more information, see Configure HSTS.\nIf HSTS is disabled and the origin server supports only HTTPS, HTTP user requests are redirected to HTTPS by using 301 redirection or 302 redirection. When users access the origin server over HTTP, HTTP requests may be hijacked or tampered with. This poses security risks. If HSTS is enabled, clients can access the origin server only over HTTPS. This prevents hijacking and tampering of requests.\nQuick UDP internet connections (QUIC) is a general-purpose transport layer network protocol that is built on top of UDP. QUIC provides the same level of security as TLS/SSL but with significantly reduced connection and transmission latency. QUIC reduces network congestion and ensures service availability in scenarios with high packet loss and network latency.\nQUIC can implement different congestion control algorithms at the application layer regardless of the operating system or kernel that is used. Compared with TCP, QUIC supports flexible adjustments based on business requirements. QUIC is a suitable alternative when TCP optimization encounters bottlenecks.\nAn HTTP status code is a numeric code that indicates a server response. You can determine and analyze server status based on HTTP status codes. After a client, such as a browser, sends a request to a server, the server returns a response header that includes an HTTP status code. The HTTP status code indicates the response status.\nHTTP status codes are classified into the following types:\n1xx: messages.\n2xx: successful requests.\n3xx: request redirection.\n4xx: client errors.\n5xx: server errors.\n"
    },
    "322": {
        "title": "CDN:Customer use cases",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/customer-use-cases",
        "content": "This Product\nCDN:Customer use cases\nAlibaba Cloud CDN improves user experience by reducing the load time and improving the responsiveness of your websites. Factors that contribute to these inefficiencies include geographic distance, bandwidth limits, and server performance limits."
    },
    "323": {
        "title": "CDN:Billing overview",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/billing-overview",
        "content": "This Product\nCDN:Billing overview\nThis topic describes the billing methods, billable items, and billing rules for Alibaba Cloud CDN.\nIf the Business Type parameter is set to DCDN when you add a domain name to Alibaba Cloud CDN, you are billed based on the billing rules of Dynamic Content Delivery Network (DCDN). You can log on to the DCDN console to view and manage domain names that are accelerated by DCDN.\nBills for Alibaba Cloud CDN are generated 3 to 4 hours after each billing cycle ends.\nBy default, pay-by-data-transfer meters the amount of outbound data transfer on points of presence (POPs) and pay-by-peak-bandwidth meters the peak bandwidth on POPs.\nAlibaba Cloud CDN charges users by account ID.\nThe following figure shows the procedure of using Alibaba Cloud CDN.\nAlibaba Cloud CDN supports the pay-as-you-go (default) and subscription billing methods. You can use resource plans to offset fees of commonly used resources.\nBilling method\nDescription\nPricing\nPay-as-you-go\nYou are charged for the actual usage of each billable item. Fees are paid after you use resources. This billing method is ideal for scenarios in which resource usage is difficult to predict.\nFor more information about the pricing of each billable item, visit the Alibaba Cloud CDN pricing page.\nSubscription\nYou can purchase resource plans that cover specific billable items at favorable prices. Resources are consumed before fees are offset by resource plans. Resource plans are ideal for scenarios in which resource usage is easy to predict.\nThe subscription billing method is more cost-effective than the pay-as-you-go billing method for long-term usage.\nA resource plan provides a quota for resource usage. If the quota is exceeded, you are charged for the excess resource usage on a pay-as-you-go basis. We recommend that you purchase resource plans based on your workloads and business scale. For more information, see Overview, Guidelines for choosing resource plans, and Rules for applying resource plans.\nAlibaba Cloud CDN outbound data transfer plans are applied only when the pay-by-data-transfer metering method is used. Otherwise, the data transfer plans are suspended until you switch back to the pay-by-data-transfer metering method. For more information about how to change the metering method, see Change the metering method.\nFor more information about the pricing of resource plans, visit the resource plan buy page.\nAlibaba Cloud CDN generates bills for basic services and value-added services. The following figure shows the billable items.\nBasic services (required): You can choose between pay-by-data-transfer and pay-by-bandwidth. For more information, see Billing of basic services.\nValue-added services (optional): You can use one or more value-added services, such as HTTPS requests for static content and QUIC requests. For more information, see Billing of value-added services.\n\nThe following table describes the billing cycles of Alibaba Cloud CDN.\nBilling cycle\nBill release time\nBillable item\nHourly\nYou are charged on an hourly basis. A bill is issued about 3 to 4 hours after the end of a billing cycle. The time when bills are issued is determined by the system.\nBasic services\nPay-by-data-transfer\nValue-added services\nBilling of HTTPS requests for static content\nBilling of QUIC requests for static content\nBilling of real-time log delivery\nDaily\nYou are charged on a daily basis. The bill of the current day is issued around 04:00 on the next day. The time when bills are issued is determined by the system.\nBasic services\nPay-by-peak-bandwidth\nThe data transfer fee is calculated based on the unit price for the billable region where the data transfer is generated. Alibaba Cloud CDN has deployed sufficient redundant POPs in each billable region to ensure that each POP belongs only to one billable region.\nBillable regions are listed in the following table. For more information about the distribution of main POPs, see POP distribution.\nBillable region\nAbbreviation\nRegion/Country\nChinese mainland\nCN\nChinese mainland\nNorth America\nNA\nUnited States\nEurope\nEU\nUkraine, UK, France, Netherlands, Italy, Sweden, Germany, and Spain\nAsia Pacific 1\nAP1\nHong Kong (China), Japan, Singapore, Thailand, Philippines, and Malaysia\nAsia Pacific 2\nAP2\nIndonesia, India, Republic of Korea, and Pakistan\nAsia Pacific 3\nAP3\nAustralia\nMiddle East and Africa\nMEAA\nT\u00fcrkiye, UAE, Kuwait, Qatar, Oman, Nigeria, and South Africa\nSouth America\nSA\nBrazil\nFor more information about the pricing of each billable item, visit the Alibaba Cloud CDN pricing page.\nFor more information about the pricing of resource plans, visit the resource plan buy page.\nWe recommend that you choose resource plans based on the features and services that you want to use, and your business volume. For more information, see Outbound data transfer plan, Guidelines for choosing resource plans, and Rules for applying resource plans.\nAlibaba Cloud CDN outbound data transfer plans are applied only when the pay-by-data-transfer metering method is used. Otherwise, the data transfer plans are suspended until you switch back to the pay-by-data-transfer metering method. For more information about how to change the metering method, see Change the metering method.\nBillable items and billing methods\nBilling of basic services\nBilling of value-added services\nChange the metering method\nAlibaba Cloud CDN pricing\nResource plans\nGuidelines for choosing resource plans\nRules for applying resource plans\nQuery the details of resource plans\nConfigure alerts\nMoney-back guarantees\nMore references\nOverdue payments\nResource usage overview\nBill query\nConfigure high bill alerts\nFAQ about billing"
    },
    "324": {
        "title": "CDN:Billing of basic services",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/billing-rules-of-basic-services",
        "content": "This Product\nCDN:Billing of basic services\nThe basic services of Alibaba Cloud CDN support the pay-by-data-transfer and pay-by-peak-bandwidth metering methods. You can select a metering method based on your business requirements. This topic describes the metering methods and considerations for the basic services of Alibaba Cloud CDN.\nBy default, the pay-by-data-transfer metering method is used to measure the amount of outbound data transfer on points of presence (POPs) and the pay-by-peak-bandwidth metering method is used to measure the peak bandwidth on POPs.\nThe actual amount of data transfer for which you are charged is greater than the amount of data transfer that is recorded in the log. The amount of data transfer that is recorded in the log is equal to the amount of data transfer that is recorded at the application layer. However, additional data is consumed to transmit the additional bytes that are inserted into TCP or IP packet headers and to retransmit TCP packets. Therefore, the actual amount of data transfer is greater than the amount of data transfer that is recorded at the application layer. For more information, see Why is the traffic amount found by using the monitoring and usage analytics feature or the usage statistics feature different from the traffic amount that is logged?\nIn most cases, a bill is generated approximately 3 to 4 hours after the end of a billing cycle. The time when bills are generated is determined by the system.\nScenario\nBilling rule\nWebsites that experience greatly fluctuating traffic and spikes in bandwidth usage, with daily bandwidth usage below 30%\nDescription: You are billed for the monthly outbound data transfer of POPs based on tiered pricing.\nBillable item: traffic.\nBilling method: pay-as-you-go or subscription.\nBilling cycle: You are billed on an hourly basis. A bill is generated about 3 to 4 hours after the end of a billing cycle. The time when bills are generated is determined by the system.\nTo use the pay-by-peak-bandwidth metering method, make sure that the peak bandwidth value within the previous 30 days exceeds 5 Gbit/s and contact your account manager or contact us by other means.\nScenario\nBilling rule\nWebsites whose network traffic is relatively flat and daily bandwidth usage exceeds 30%\nDescription: You are charged based on the daily peak bandwidth. Bandwidth data is collected every 5 minutes, resulting in a total of 288 records per day. The highest bandwidth is used as the billable daily peak bandwidth.\nBillable item: peak bandwidth.\nBilling method: pay-as-you-go.\nBilling cycle: You are charged on a daily basis. The bills of a day are generated and the amount due is deducted after 00:00 on the following day. The time when bills are generated is determined by the system.\nDue to business expansion, data transmission abuse, or attacks, your domain may experience burst bandwidth usage.\nIn the pay-by-peak-bandwidth metering method, the following cases can be considered as burst bandwidth usage for a single Alibaba Cloud account:\nThe total increase in bandwidth usage exceeds 500 Gbit/s within a calendar month.\nThe peak bandwidth recorded in the last calendar month was 0, while the total bandwidth increase in the current calendar month exceeds 200 Gbit/s.\nThe total peak bandwidth usage in the current calendar month is 1.3 times the billable bandwidth of the previous calendar month.\nIn the pay-by-data-transfer metering method, if the peak bandwidth of a single domain exceeds 100 Gbit/s within a calendar month, it can be considered as burst bandwidth usage.\nIf otherwise agreed, the actual rule prevails.\nIf you expect burst bandwidth on Alibaba Cloud CDN-accelerated services, you need to apply for burst bandwidth at least 3 business days in advance. For major events including but not limited to the Spring Festival Gala and Double 11 Global Shopping Festival, you need to apply for burst bandwidth at least 1 month in advance. If the application is approved, the availability of your services is guaranteed when the burst bandwidth is within the level agreed upon by both parties. If you do not apply for burst bandwidth or the application is not approved, Alibaba Cloud reserves the right to take measures such as bandwidth throttling to ensure service-level stability for other Alibaba Cloud customers. Alibaba Cloud is not responsible for the reduced availability caused by the measures.\nTo apply for burst bandwidth, contact your account manager or contact us by other means. After the application is approved, you are billed based on the newly agreed price. If you do not apply for burst bandwidth or the application is rejected, you are billed based on the current price. The final fees are determined by Alibaba Cloud CDN bills.\n"
    },
    "325": {
        "title": "CDN:Billing of value-added services",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/billing-of-value-added-services/",
        "content": "This Product\nCDN:Billing of value-added services"
    },
    "326": {
        "title": "CDN:Rules for applying resource plans",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/rules-for-applying-resource-plans",
        "content": "This Product\nCDN:Rules for applying resource plans\nThis topic describes the rules for applying resource plans.\nFor example, Alice purchased an outbound data transfer plan of 1 TB for the Chinese mainland at 10:30:30 (UTC+8) on August 12, 2021. The data transfer plan was valid for one month. In this case, outbound data transfer fees were offset around 14:00:00 (UTC+8) on August 12, 2021. Outbound data transfer fees were not offset until the system generated the data transfer bill of the billing cycle from 10:00:00 to 11:00:00.\nFor example, Alice purchased two outbound data transfer plans for the Chinese mainland. One of the resource plans expires on July 1, 2021, and the other expires on August 1, 2021. In this case, the resource plan that expires on July 1, 2021 is applied first.\nOutbound data transfer plans can be used to offset only outbound data transfer fees. They cannot be used to offset fees of other billable items such as HTTPS requests.\nFor example, an outbound data transfer plan for the Chinese mainland can be used to offset outbound data transfer fees only in the Chinese mainland. You cannot use it to offset outbound data transfer fees in Hong Kong (China), Macao (China), Taiwan (China), or other countries and regions outside the Chinese mainland."
    },
    "327": {
        "title": "CDN:Configure alerts",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/configure-low-capacity-alerts",
        "content": "This Product\nCDN:Configure alerts\nWhen the remaining capacity of a resource plan drops below a specific value, Alibaba Cloud CDN can notify you by emails or internal messages. This topic describes how to configure low capacity alerts for resource plans.\nAfter you configure remaining quota alerts for your plan, the system notifies you by emails or internal messages when the remaining quota of the plan drops below a specified value.\nLog on to the Alibaba Cloud CDN console.\nIn the top navigation bar, click Expenses. The Expenses and Costs page appears.\nIn the left-side navigation pane, click Manage Reserved Instances.\nOn the Instances tab of the Manage Reserved Instances page, click Set Remaining Quota Alert.\nIn the Set Remaining Quota Alert dialog box, turn on the alert switch for Set Remaining Quota Alert Uniformly, set Remaining Quota Proportion, and then click OK.\nYou can configure to trigger alerts when the remaining quota of your plan falls below a specific threshold based on your requirements, such as 20%.\nAfter you configure expiration alerts for your plan, the system notifies you by emails or internal messages when the plan is about to expire.\nLog on to the Alibaba Cloud CDN console.\nIn the top navigation bar, move the pointer over the  icon and click Message Settings.\nOn the Common Settings page, find Notifications of Product Expiration and select one or more notification methods.\nIf a resource plan is about to expire, Alibaba Cloud sends notifications to the contacts of the current account. You can also click Modify to add a contact.\n\n"
    },
    "328": {
        "title": "CDN:Change the metering method",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/change-the-metering-method",
        "content": "This Product\nCDN:Change the metering method\nAlibaba Cloud CDN does not allow you to manually change the metering method. To change the metering method, Contact your account manager or contact us by other means. For more information, see Contact us.."
    },
    "329": {
        "title": "CDN:Overdue payments",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/overdue-payments",
        "content": "This Product\nCDN:Overdue payments\nThis topic explains the causes of low balance alerts and the suspension of Alibaba Cloud CDN.\nWhen a payment becomes overdue, the system notifies you by text messages or emails.\nYou can check your payment status in Expenses. You can top up your account balance to complete overdue payments. Alibaba Cloud CDN is resumed after overdue payments are completed. Domain names that are disabled due to overdue payments are automatically enabled. Content delivery acceleration is automatically resumed for the domain names."
    },
    "330": {
        "title": "CDN:Billing of OSS content acceleration",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/billing-of-oss-content-acceleration",
        "content": "This Product\nCDN:Billing of OSS content acceleration\nObject Storage Service (OSS) is a cost-effective storage service. Alibaba Cloud CDN can accelerate the delivery of static resources. You can store static content, such as scripts, audio files, video files, images, and attachments, in OSS and use Alibaba Cloud CDN to accelerate the delivery of content in OSS buckets. This reduces storage costs, accelerates content delivery, and reduces loads on origin servers.\nIf the origin server is an OSS bucket, you may be charged Alibaba Cloud CDN service fees and OSS service fees.\nThe billing of Alibaba Cloud CDN is separate from the billing of OSS. For example, data transfer bills for Alibaba Cloud CDN and OSS are separately generated. In addition, the pricing of Alibaba Cloud CDN is different from the pricing of OSS. For more information, see the pricing details of Alibaba Cloud CDN and OSS.\nThe following section describes the billable items and billing rules of Alibaba Cloud CDN and OSS.\nPossible billable items\nBillable item\nDescription\nAlibaba Cloud CDN service fee\nIn most cases, you are charged for outbound data transfer in Alibaba Cloud CDN.\nIn specific cases, you are charged for other items in Alibaba Cloud CDN, such as HTTPS requests for static content. For more information, see Billing overview.\nOSS service fee\nIn most cases, you are charged for data storage in OSS.\nIn specific cases, you are charged for other items in OSS, such as requests. For more information, see Billing overview.\nBilling rules for data transfer\nIf the origin server is an OSS bucket, you may be charged for outbound data transfer from Alibaba Cloud CDN (charged by Alibaba Cloud CDN) and data transfer from OSS to Alibaba Cloud CDN (charged by OSS).\nOutbound data transfer from Alibaba Cloud CDN is the amount of data transfer that is generated when Alibaba Cloud CDN points of presence (POPs) return the requested content to users. In this case, data is transmitted from POPs to clients. You are charged for the data transfer in Alibaba Cloud CDN. For more information, visit the Alibaba Cloud CDN pricing page.\nYou are not charged for data transfer from POPs to OSS.\nData transfer from OSS to Alibaba Cloud CDN is the amount of data transfer that is generated when POPs retrieve content from OSS. In this case, data is transmitted from OSS to POPs. You are charged for the data transfer in OSS. For more information, visit the OSS pricing page.\nPreferential pricing for data transfer between Alibaba Cloud CDN and OSS:\nIf you want to use preferential pricing for traffic between Alibaba Cloud CDN and OSS, you must set the origin server type to OSS Domain in the Alibaba Cloud CDN console.\nIf you set the origin server type to Site Domain in the Alibaba Cloud CDN console, OSS identifies network traffic that is sent from Alibaba Cloud CDN as outbound data transfer over the Internet. In this case, normal charges apply.\nIf the POP and the bucket are located in regions outside the Chinese mainland, you are not charged for data transfer from OSS to POPs.\nOSS and Alibaba Cloud CDN provide resource plans. If you use Alibaba Cloud CDN to accelerate content delivery from OSS, you can use the resource plans to reduce costs. The following table describes the resource plans.\nResource plan\nDescription\nAlibaba Cloud CDN outbound data transfer plan\nYou can use this type of data transfer plan to offset data transfer fees that are generated when POPs distribute content to clients. Data transfer overages are billed based on the pay-as-you-go billing method.\nOSS standard locally redundant storage (LRS) storage plan\nYou can use this type of storage plan to offset standard LRS fees. Data storage overages are billed based on the pay-as-you-go billing method.\nAccelerate the retrieval of resources from an OSS bucket"
    },
    "331": {
        "title": "CDN:Release notes",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/release-notes",
        "content": "This Product\nCDN:Release notes\nThis topic describes the release notes for Alibaba Cloud CDN and provides links to the relevant references.\nFeature\nDescription\nRelease date\nRegion\nReferences\nTraffic throttling for individual requests\nTraffic throttling for individual requests allows you to limit the downstream speed for all requests that are sent to points of presence (POPs). This way, you can limit the overall peak bandwidth of accelerated domain names. This feature is suitable for scenarios such as game releases and software downloads.\n2023-11\nAll regions\nConfigure traffic throttling for individual requests\nSelf-service diagnostics tool\nIf you encounter issues such as page loading failures or page errors when you use Alibaba Cloud CDN, you can use the self-service diagnostics tool to diagnose the issues. The diagnostics tool provides diagnosis results. You can modify configurations of Alibaba Cloud CDN or submit a ticket based on the results.\n2023-10\nAll regions\nSelf-service diagnostics tool\nCache sharing\nCache sharing is added to allow accelerated domain names (one-to-one or one-to-many) in the same Alibaba Cloud account to share resources that are cached on POPs. Cache sharing increases the resource hit ratio of the domain names, improves the acceleration performance of Alibaba Cloud CDN, and reduces origin traffic.\n2023-09\nAll regions\nConfigure cache sharing\nReferer-based hotlink protection\nURL signing\nIP address blacklist and whitelist\nUser-Agent blacklist or whitelist\nIgnore parameters\nRange origin fetch\nParameter rewrite\nExisting features can be used with the rules engine feature to filter user requests based on specified rules. This way, you can configure custom policies in a more efficient manner. For more information, see Rules engine.\n2023-08\nAll regions\nConfigure a Referer whitelist or blacklist to enable hotlink protection\nConfigure URL signing\nConfigure an IP address blacklist or whitelist\nConfigure a User-Agent blacklist or whitelist\nIgnore Parameters\nRange origin fetch\nParameter rewrite\nTTL\nCustom HTTP response headers\nAccess URL rewrite\nOrigin HTTP request headers\nOrigin HTTP response headers\nExisting features can be used with the rules engine feature to filter user requests based on specified rules. This way, you can configure custom policies in a more efficient manner. For more information, see Rules engine.\n2023-07\nAll regions\nCreate a cache rule for resources\nConfigure an HTTP response header\nCreate an access URL rewrite rule\nConfigure HTTP request headers\nConfigure HTTP response headers\n\nUpgrade from Alibaba Cloud CDN to DCDN for a domain name\nUpgrade from Alibaba Cloud CDN to Dynamic Content Delivery Network (DCDN) is supported. DCDN provides application acceleration, edge computing, and security protection capabilities. If you want to upgrade from Alibaba Cloud CDN to DCDN for your domain name, you can perform the upgrade by using the domain name upgrade tool in the Alibaba Cloud CDN console.\n2023-05\nAll regions\nUpgrade from Alibaba Cloud CDN to DCDN for your domain name\nConditional origin\nThe conditional origin feature can be used with the rules engine feature to filter user requests based on the specified rules, such as request header, query string parameter, path, and client ip. Then, requests that meet the rules are redirected to the specified origin server. For more information, see Rules engine. You can add multiple rules so that requests can be redirected to different origin servers based on the rules.\n2023-02\nAll regions\nConfigure a conditional origin\nRules engine\nThe rules engine feature is supported. You can use the graphical user interface that is provided by the rules engine to configure rules. You can configure rules to identify user requests based on the parameters they carry. This helps determine whether a configuration applies to the requests, and provides a more flexible and accurate method to manage the configurations and policies that you set in Alibaba Cloud CDN.\nFor the first time ever, this feature is available to the public. Rules can be referenced by the conditional origin feature. For more information, see Configure a conditional origin.\n2023-02\nAll regions\nRules engine\nDomain name transfer across accounts\nA domain name transfer tool can be used to transfer accelerated domain names across accounts.\n2023-01\nAll regions\nTransfer a domain name to another Alibaba Cloud account\nSpecified origin host\nDifferent origin hosts can be specified for different origin servers if your accelerated domain name has multiple origin servers. POPs use the specified origin host to access the origin server. This feature has a higher priority over the default origin host.\n2023-01\nAll regions\nSpecify the origin host for each origin\nAlibaba Cloud OSS private bucket access\nAccess to private OSS buckets in the same Alibaba Cloud account or a different Alibaba Cloud account is supported.\n2023-01\nAll regions\nGrant Alibaba Cloud CDN access permissions on private OSS buckets\nFeature\nDescription\nRelease date\nRegion\nReferences\nOrigin fetch over IPv6\nAfter you configure Origin fetch over IPv6, requests can be forwarded to origin servers over IPv6 based on different back-to-origin policies.\n2022-11\nAll regions\nConfigure origin fetch over IPv6\nWeb Frontend Performance\nWeb Frontend Performance is a feature launched by Alibaba Cloud CDN and Application Real-time Monitoring Service (ARMS). By introducing monitoring code to web pages, Web Frontend Performance monitors user access data. This helps you monitor your website performance, such as page loading, page stability (JS errors), and success rate of calls to external services.\n2022-09\nAll regions\nWeb Frontend Performance\nCommon Name whitelist\nThe Common Name whitelist feature is supported. After you enable the Common Name whitelist feature, the certificate Common Name returned by the origin server and the SNI value included in an HTTPS request are verified when a POP establishes a connection with the origin server over HTTPS.\n2022-07\nAll regions\nCommon Name whitelist\nStatus code expiration (origin cache policy prioritized)\nA cache rule for HTTP status codes can be configured in the Alibaba Cloud CDN console. For more information, see Create a cache rule for HTTP status codes. When the client requests the same resource again, the POP returns a status code without triggering origin fetch. This reduces loads on origin servers.\nIf you want to follow the status code expiration rule configured on the origin server, you can use this feature.\n2022-07\nAll regions\nCreate a status code expiration rule that honors origin\nRefresh resources based on regular expressions\nA URL that contains a regular expression can be submitted in a refresh task. Alibaba Cloud CDN refreshes all URLs that match the regular expression. This feature enables targeted refresh.\n2022-07\nAll regions\nConfigure URLs that contain regular expressions\nUpgraded console\nAdditional features are added to the Overview page, left-side navigation pane, and Resource Plans page in the Alibaba Cloud CDN console. Console layouts are optimized. This improves user experience.\n2022-06\nAll regions\nNone\nIntegration with Terraform\nTerraform is integrated with Alibaba Cloud CDN. Terraform is an open source tool that supports automatic resource orchestration. Terraform allows you to preview, configure, and manage basic cloud infrastructure and resources in an efficient and secure manner.\n2022-05\nAll regions\nUse Terraform to add and configure a domain name\nApplication center\nTools and value-added services, such as IP query, are provided in the application center of Alibaba Cloud CDN. This allows you to easily find and use services in the application center.\n2022-03\nAll regions\nApplication center\nTag management\nThe tag management feature is improved to support interactive operations and enhance user experience.\n2022-02\nAll regions\nWhat is a tag?\nQUIC\nThe Quick UDP Internet Connections (QUIC) protocol is supported. If QUIC is enabled, data can be transmitted between clients and POPs over QUIC. QUIC secures data transmission and improves transmission efficiency.\n2022-01\nAll regions\nWhat is the QUIC protocol?\n\nFeature\nDescription\nRelease date\nRegion\nReferences\nStatistical analytics\nThe statistical analytics feature is discontinued. The operations report feature can be used to analyze data.\n2021-11\nAll regions\nCustomize an operations report template and create a tracking task\nDomain name management\nAdvanced search conditions are supported. You can search for domain names by origin server and accelerated domain name. If you search for domain names by accelerated domain name, fuzzy match, exact match, prefix match, and suffix match are supported.\n/\nContent moderation for images\nContent moderation for images is discontinued.\n2021-10\nAll regions\n/\nOperations report\nThe operations report feature is supported. The operations report feature provides offline analysis data of accelerated domain names in different periods of time and help you gain data insights from the workload status.\n2021-09\nAll regions\nCustomize an operations report template and create a tracking task\nFree SSL certificates\nApplication for free SSL certificates in the Alibaba Cloud CDN console is disabled. We recommend that you use Certificate Management Service to apply for SSL certificates.\n2021-08\nAll regions\nChanges to free SSL certificates\nCORS\nCross-origin resource sharing (CORS) is supported. You can add custom HTTP response headers to enable CORS.\n2021-07\nAll regions\nConfigure CORS\nCustom cache keys\nCustom cache keys are supported. You can configure a cache key for requests that are destined for the same resource file. This helps save cache space and reduce the number of requests that are redirected to the origin server.\nAll regions\nCreate custom cache keys\n302 redirection\n302 redirection is supported. After you configure 302 redirection on your origin server, POPs process the HTTP 302 status code that is returned by your origin server. This simplifies the processing pipeline and accelerates content delivery.\nAll regions\nConfigure 301/302 redirection\nConfiguration guide for adding domain names\nA configuration guide for adding and configuring domain names that you want to accelerate is supported.\nAll regions\nFor beginners\nLog storage\nLog storage is supported. After the log storage feature is enabled, Alibaba Cloud CDN automatically stores logs in a specified Object Storage Service (OSS) bucket to persist log data for viewing and analysis.\n2021-06\nAll regions\nUse Function Compute to deliver logs\nOrigin server weights\nOrigin servers can be assigned weights. Requests are redirected to the origin servers based on weighted round-robin scheduling.\n2021-04\nAll regions\nAdd a domain name\nES templates and script monitoring\nEdgeScript (ES) templates are supported in the Alibaba Cloud CDN console. You can use the templates to deploy code for different scenarios without the need to make complex modifications. ES templates improve programming efficiency.\nScript monitoring is supported. You can monitor the status of each script and query the error codes that may appear during script execution.\n2021-03\nAll regions\nES monitoring\nRemote authentication\nRemote authentication is supported to reinforce access control. The authentication process involves the user who sends the request, POPs, and the authentication server. You can create custom authentication rules in the Alibaba Cloud CDN console.\nAll regions\nConfigure remote authentication\nPay-by-peak-bandwidth\nThe pay-by-peak-bandwidth metering method is supported. Since January 8, 2021, Alibaba Cloud CDN uses the pay-by-data-transfer metering method by default. If you want to switch to the pay-by-peak-bandwidth metering method, contact your account manager or contact us by other means. For more information, see Contact us.\n2021-01\nAll regions\nBilling rules of basic services\nFeature\nDescription\nRelease date\nRegion\nReferences\nIntegration with Anti-DDoS\nAlibaba Cloud CDN POPs are integrated with Anti-DDoS services to scrub network traffic. This way, Alibaba Cloud CDN can accelerate content delivery and mitigate malicious requests.\n2020-06\nAll regions\nIntegrate Alibaba Cloud CDN with Anti-DDoS\nImage editing\nImage editing is supported. You can resize, crop, sharpen, and rotate images and convert image formats on POPs.\n2020-06\nAll regions\nImage editing overview\nManagement of custom HTTP response headers\nThe custom response header feature is optimized. You can delete, change, and replace custom response headers.\n2020-05\nAll regions\nConfigure an HTTP response header\nRewrite of external links to resolve IPv6 performance issues\nExternal links can be rewritten to resolve the following issues in IPv6 deployment: slow responses, content loading errors, and redirection errors. The preceding challenges are known performance issues of IPv6. If the sites that are linked to your website do not support IPv6, you cannot resolve these issues by applying the dual-stack technology or upgrading your network or applications. Alibaba Cloud CDN provides a solution by rewriting the external links on POPs and accelerating content delivery over IPv6.\n2020-05\nAll regions\nWhat is EdgeRoutine?\nParameter rewrite\nParameters can be rewritten. If you want to modify URL parameters in requests before they are redirected to origin servers, you can create rules to rewrite the parameters.\n2020-04\nAll regions\nParameter rewrite\nURI rewrite\nURI rewrite is supported. If you want to rewrite URIs in requests before they are redirected to origin servers, you can create rules to rewrite URIs.\n2020-04\nAll regions\nRewrite origin URLs\nOrigin HTTP response headers\nCustom HTTP response headers are supported. If you want to rewrite HTTP headers in response URLs before they are returned to POPs, you can create rewrite rules in the Alibaba Cloud CDN console.\n2020-04\nAll regions\nConfigure HTTP response headers\nOrigin HTTP request headers\nCustom HTTP request headers are supported. If you want to rewrite HTTP headers in request URLs before they are redirected to origin servers, you can create rewrite rules in the Alibaba Cloud CDN console.\n2020-04\nAll regions\nConfigure HTTP request headers\nRate limiting\nThe rate limiting feature is supported. When the response time of your website is increased due to HTTP flood attacks, the rate limiting feature can block specific requests that are sent to your website within seconds and improve the security of your website.\n2020-04\nAll regions\nConfigure rate limiting\nEdgeRoutine (ER)\nEdgeRoutine (ER) is supported. ER is a computing environment that allows you to deploy JavaScript code on all POPs at the same time.\n2020-03\nAll regions\nWhat is EdgeRoutine?\nFeature\nDescription\nRelease date\nRegion\nReferences\nIPv6\nIPv6 is supported. After IPv6 is enabled, IPv6 clients can access Alibaba Cloud CDN over IPv6. Alibaba Cloud CDN also carries the IPv6 information when it accesses your origin server.\n2019-10\nAll regions\nConfigure IPv6\nAudio and video preview\nAudio and video preview is supported. A POP can return specific lengths of audio or video files to clients.\nAll regions\nAudio and video preview\nAudio extraction\nAudio extraction is supported. After audio extraction is enabled, POPs extract audio data from a video file and then return the audio data to clients. This reduces data usage.\n2019-09\nAll regions\nAudio extraction\nEdgeScript\nEdgeScript is released. This feature allows you to specify custom Alibaba Cloud CDN and DCDN configurations by running scripts if the built-in configurations provided by Alibaba Cloud CDN or DCDN cannot meet your business requirements.\n2019-07\nAll regions\nEdgeScript overview\nRewrite\nThe URI rewrite feature is supported. This feature allows you to configure URI rewrite rules in the Alibaba Cloud CDN console to customize request processing.\n2019-07\nAll regions\nCreate an access URL rewrite rule\nBrotli compression\nBrotli compression is supported. Brotli is a new open source compression algorithm that can improve download performance by approximately 15% to 25% compared with Gzip compression.\n2019-05\nAll regions\nConfigure Brotli compression\nUser-Agent blacklists and whitelists\nUser-Agent blacklists and whitelists are supported. This feature enables Alibaba Cloud CDN to control access based on the User-Agent request header. You can configure a User-Agent blacklist or whitelist to control access to your resources and block malicious requests.\nAll regions\nConfigure a User-Agent blacklist or whitelist\nChange the acceleration region\nSwitching between accelerated regions is supported. You can change the acceleration region for an accelerated domain name in the Alibaba Cloud CDN console.\n2019-04\nAll regions\nChange the acceleration region\nUpgraded certificate center\nThe certificate center of Alibaba Cloud CDN is upgraded. You can configure SSL certificates for one or more accelerated domain names at the same time.\n2019-03\nAll regions\nConfigure an SSL certificate for multiple domain names\nSNI\nServer Name Indication (SNI) is supported. SNI specifies the name of the requested domain name and enables the origin server to return the correct certificate for the specified domain name.\nAll regions\nConfigure SNI\nFeature\nDescription\nRelease date\nRegion\nReferences\nTLS version and HSTS management\nTLS and HSTS version management is supported. HSTS is used to force clients such as browsers to use HTTPS to establish connections to the server.\nAfter a TLS protocol version is enabled, TLS handshakes are enabled for specified accelerated domain names.\n2018-11\nAll regions\nConfigure HSTS\nConfigure TLS version control\nLatest Alibaba Cloud CDN API\nThe previous API version will no longer be maintained. We recommend that you use the latest API version.\n2018-09\nAll regions\nIntroduction to the API\nUpgraded Alibaba Cloud CDN console\nThe Alibaba Cloud CDN console is upgraded to a later version. The new version supports basic operations, such as domain name configuration, and provides resource monitoring services for real-time data analytics. You can also view your billing information and change the billing method in the upgraded Alibaba Cloud CDN console.\n2018-07\nAll regions\nFeatures\nFeature\nDescription\nRelease date\nRegion\nReferences\nDCDN\nDCDN is supported. DCDN is built based on Alibaba Cloud CDN and can accelerate the delivery of dynamic content or both dynamic and static content from applications and origin servers.\n2017-08\nAll regions\nWhat is DCDN?\nFeature\nDescription\nRelease date\nRegion\nReferences\nSubscription data transfer plans\nSubscription data transfer plans are supported by Alibaba Cloud CDN. A data transfer plan takes effect immediately after the payment is complete. The amount of data transfer that exceeds the quota of the plan is billed based on the pay-as-you-go billing method.\n2016-02\nAll regions\nAlibaba Cloud CDN data transfer plans\nFeature\nDescription\nRelease date\nRegion\nReferences\nCache rules and priorities\nCache rules and priorities are supported. You can configure cache rules for resources of a specific file type or directory. You can specify a time-to-live (TTL) value for cached resources and specify the priority of each cache rule.\n2015-10\nAll regions\nCreate a cache rule for resources\nCustom HTTP response headers\nTen types of HTTP response headers are supported by Alibaba Cloud CDN.\n2015-08\nAll regions\nConfigure an HTTP response header\nFeature\nDescription\nRelease date\nRegion\nReferences\nOfficial release of Alibaba Cloud CDN\nAlibaba Cloud CDN is officially released. Alibaba Cloud CDN is a distributed virtual network that consists of POPs that are deployed in different regions across the world. Alibaba Cloud CDN reduces network traffic on origin servers to prevent network congestion. You can use Alibaba Cloud CDN to accelerate content delivery in different regions and scenarios.\n2014-03\nAll regions\nWhat is Alibaba Cloud CDN?"
    },
    "332": {
        "title": "CDN:For beginners",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/getting-started",
        "content": "This Product\nCDN:For beginners\nThis topic describes how to get started with Alibaba Cloud CDN.\nWhat is Alibaba Cloud CDN?\nCommon scenarios\nCompetitive advantages of Alibaba Cloud CDN\nHow it works\nLimits\nTerms\nYou are billed for basic services (required) and value-added services (optional) in Alibaba Cloud CDN. Choose a metering method based on your business requirements. For more information, see Billing overview.\nAlibaba Cloud CDN provides cost-effective resource plans. For more information, see Guidelines for choosing resource plans.\nThe following figure shows how to get started with Alibaba Cloud CDN.\n\nComplete ICP filing: According to the laws of China and the requirements of the Ministry of Industry and Information Technology (MIIT), you must complete an ICP filing for domain names that are resolved to websites and apps whose servers are located in the Chinese mainland before the websites and apps can provide services. If you have completed an ICP filing for the domain name, you can proceed to the next step.\nActivate Alibaba Cloud CDN: Log on to the Alibaba Cloud console and activate Alibaba Cloud CDN.\nAdd a domain name: After you add a domain name in the Alibaba Cloud CDN console, the system pushes the configuration of the domain name to all points of presence (POPs). The first time you add a domain name to Alibaba Cloud CDN, you need to verify the ownership of a domain name by using a DNS record of the domain name. Once the domain passes the verification, its subdomains do not require separate ownership verification.\n(Optional) Configure system-recommended features: After you add a domain name to Alibaba Cloud CDN, we recommend that you configure features, such as cache expiration, bandwidth cap, and HTML optimization, for the domain name. This improves the cache hit ratio, security, and access performance of Alibaba Cloud CDN.\n(Optional) Test domain name accessibility: After you add a domain name to Alibaba Cloud CDN, we recommend that you perform a local test on the domain name to verify that the domain name is accessible and then map the DNS record of the domain name to the CNAME. This ensures that DNS updates do not affect the services.\nAdd a CNAME record for a domain name: After you add a domain name, Alibaba Cloud CDN assigns a CNAME to the domain name. You need to add a CNAME record in the system of your DNS service provider to map the domain name to the CNAME before acceleration can take effect.\nVisitor location\nAcceleration performance\nAcceleration region\nChinese mainland\nAll requests are redirected to points of presence (POPs) that are deployed in the Chinese mainland. Requests from outside the Chinese mainland are redirected to POPs that are managed by China Telecom (East China Division).\nChinese Mainland Only\nOutside the Chinese mainland\nAll requests are redirected to POPs that are deployed outside the Chinese mainland. Requests from the Chinese mainland are redirected to POPs that are deployed in Japan, Singapore, or Hong Kong (China).\nGlobal (Excluding the Chinese Mainland)\nGlobal\nAll requests are redirected to the nearest POPs.\nGlobal\nFor more information, see User Guide and Best Practices.\nOrigin settings\nCache settings\nPurge and prefetch resources\nHTTPS\nUse Alibaba Cloud CDN to accelerate the delivery of resources from OSS buckets\nFAQ\nIf you have questions or suggestions about Alibaba Cloud CDN, you can report them through the following methods. Alibaba Cloud customer service will follow up on your feedback.\nIf you find errors in the documentation, including link errors, content errors, and API operation errors, you can click the Feedback icon on the right side of the page to report the errors.\nIf you have questions about Alibaba Cloud CDN, submit a ticket."
    },
    "333": {
        "title": ":Activate Alibaba Cloud CDN",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/activate-alibaba-cloud-cdn",
        "content": "This Product\n:Activate Alibaba Cloud CDN\nYou need to activate Alibaba Cloud CDN before you use it for the first time. This topic describes how to activate Alibaba Cloud CDN.\nAn Alibaba Cloud account is created. To create an Alibaba Cloud account, go to the Sign up to Alibaba Cloud page.\nVisit the Alibaba Cloud CDN product page.\nClick Activate Now.\nBy default, Billing Method is Pay-By-Data-Transfer and Quantity is 1. Select Terms of Service.\nFor more information about the pricing of Alibaba Cloud CDN, go to the CDN Pricing page.\nClick Activate Now.\nAfter you activate Alibaba Cloud CDN, click Console on the Alibaba Cloud CDN page to log on to the Alibaba Cloud CDN console.\nAfter you activate Alibaba Cloud CDN, you need to add domain names to Alibaba Cloud CDN. For more information, see add a domain name.\nIf you directly deactivate Alibaba Cloud CDN, your business may be interrupted. Therefore, Alibaba Cloud does not allow you to deactivate Alibaba Cloud CDN in the console. However, if you do not add domain names to Alibaba Cloud CDN or use features such as EdgeRoutine, you are not charged for Alibaba Cloud CDN. For more information, see How do I deactivate or stop the billing of Alibaba Cloud CDN?\nOpenCdnService: activates Alibaba Cloud CDN."
    },
    "334": {
        "title": ":Add a domain name",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/add-a-domain-name",
        "content": "This Product\n:Add a domain name\nIf you want to use Alibaba Cloud CDN to accelerate content delivery for a specific website, you need to configure the server that hosts the website as an origin server and configure an accelerated domain name for the website. Alibaba Cloud CDN uses the accelerated domain name to cache content from the origin server to points of presence (POPs) that are distributed around the world. This significantly reduces the latency for content delivery and speeds up access.\nAn origin server that provides stable performance is deployed. If you do not have an origin server, follow the instructions in Create and manage an ECS instance in the console (express version) or Create a bucket to create one.\nA domain name to be accelerated is prepared.\nIf the acceleration region is Chinese Mainland Only or Global, you need to apply for Internet Content Provider (ICP) filing for the domain name. If the domain name does not have an ICP number, you can perform ICP filing by using Alibaba Cloud ICP Filing System.\nAlibaba Cloud CDN is activated. For information about how to activate Alibaba Cloud CDN, see Activate Alibaba Cloud CDN.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nClick Add Domain Name. In the Specify Domain Name Information step, configure the Region, Domain Name to Accelerate, and Business Type parameters. Keep the default settings for other parameters.\n\nParameter\nDescription\nRegion\nChinese Mainland Only: All requests are redirected to POPs that are deployed in the Chinese mainland. Requests from outside the Chinese mainland are redirected to POPs that are managed by China Telecom (East China Division).\nGlobal: All requests are redirected to the nearest POPs.\nGlobal (Excluding the Chinese Mainland): Requests from outside the Chinese mainland are redirected to the nearest POPs. Requests from the Chinese mainland are redirected to POPs that are deployed in Japan, Singapore, or Hong Kong (China).\nIf you set the Region parameter to Chinese Mainland Only or Global, you must apply for an ICP number for the domain name. We recommend that you apply for ICP numbers by using the Alibaba Cloud ICP Filing System. The Ministry of Industry and Information Technology (MIIT) may not immediately synchronize the filing results after an application is approved. We recommend that you configure the domain name 8 hours after you obtain the ICP filing.\nIf you select Global (Excluding the Chinese Mainland), no ICP filing is required for the domain name.\nThe pricing varies based on the acceleration region. Select an acceleration region based on your business requirements. For more information about the pricing of Alibaba Cloud CDN, visit the CDN pricing page.\nGlobal Resource Plan\nIf you set the Region parameter to Global (Excluding the Chinese Mainland) and enable Global Resource Plan, more POP resources are available for your domain name. For more information, see Enable the global resource plan.\nDomain Name to Accelerate\nSpecify the domain name to accelerate. For more information, see Limits.\nThe first time you add a domain name to Alibaba Cloud CDN, you must prove the ownership of the domain name. For more information, see Verify the ownership of a domain name. If the root domain name has already passed ownership verification, skip this operation.\nBusiness Type\nImage and Small File: accelerates the delivery of small-sized static content on websites, such as e-commerce content and game images.\nLarge File Download: accelerates the delivery of static files that are larger than 20 MB.\nVOD: accelerates the delivery of audio or video content.\nDCDN: accelerates the delivery of static and dynamic content. Dynamic Content Delivery Network (DCDN) can accelerate the delivery of large amounts of dynamic content.\nIf you set the Business Type parameter to DCDN, follow the instructions to go to the DCDN console to add and configure the domain name. For more information, see Add a domain name.\nAfter you configure the Business Type parameter, you cannot modify the parameter.\nAfter you configure the business information for the domain name, click Add Origin Server in the Origin Servers section.\nIn the Add Origin Server dialog box, select the type of the origin and enter the origin address. Keep the default settings for other parameters.\n\nParameter\nDescription\nOrigin Info\nSelect the type of the origin server and enter the address of the origin server. You can select OSS Domain, IP, Site Domain, or Function Compute Domain. OSS Domain is used as an example. For more information about other types of origin servers, see Configure an origin server.\nSet the Origin Info parameter to OSS Domain and select an OSS bucket in the current account from the Domain Name drop-down list. You can also enter the public domain name of an OSS bucket. The internal domain name of an OSS bucket is not supported. Example: ***.oss-cn-hangzhou.aliyuncs.com.\nPriority\nYou can configure priorities to specify primary and secondary origin servers. The primary origin server has a higher priority than the secondary origin server. Alibaba Cloud CDN preferentially redirects requests to the primary origin server. If a fault occurs on the primary origin server, requests are redirected to the secondary origin server. The priority ranges from 0 to 127. A smaller value indicates a higher priority. By default, the priority of the primary origin server is 20, and the priority of the secondary origin server is 30. If you want to specify other values, submit a ticket.\nFor example, you specify Origin Server A as the primary origin server and Origin Server B as the secondary origin server. In this case, Alibaba Cloud CDN preferentially redirects requests to Origin Server A. If Origin Server A fails, Alibaba Cloud CDN redirects user requests to Origin Server B. After Origin Server A recovers, Alibaba Cloud CDN fails back to Origin Server A.\nWeight\nIf origin servers have the same priority, Alibaba Cloud CDN redirects requests to the origin servers based on the weights of the origin servers. This way, loads are balanced among the origin servers. You can specify a weight based on your business requirements.\nThe weight of an origin server ranges from 1 to 100. An origin server that has a higher weight receives more requests.\nDefault value: 10.\nFor example, you specify Origin Server A and Origin Server B as primary origin servers. If the weight of Origin Server A is 80 and the weight of Origin Server B is 20, Alibaba Cloud CDN redirects 80% of requests to Origin Server A and 20% of requests to Origin Server B.\nPort\nThe port on the origin server that processes requests. The default port is port 80. You can specify a port based on the settings of your origin server. Valid values: 1 to 65535.\nDefault value: 80.\nIf you specify port 443, requests are redirected to the origin server over HTTPS. If you specify port 80 or a custom port, requests are redirected to the origin server over HTTP.\nIf you want Alibaba Cloud CDN to redirect HTTPS requests to origin servers over custom ports, configure the origin protocol policy. For more information, see Configure the origin protocol policy.\nIf the Origin Protocol Policy feature is enabled, the port that is specified by this parameter becomes invalid. By default, the feature is disabled. For more information about how to disable the origin protocol policy feature, see Configure the origin protocol policy.\nIf the origin server is an Object Storage Service (OSS) bucket, OSS determines whether you can specify a custom port.\nAfter you complete the preceding configurations, click OK.\nAfter you add an origin server, read and select the compliance commitment, and click Next.\nIn the Recommended Features step, configure features such as Cache Expiration, Ignore Parameters, HTML Optimization, Range Origin Fetch, and Gzip Compression based on your business requirements. These features improve the cache hit ratio and performance of Alibaba Cloud CDN. For more information, see (Optional) Configure system-recommended features.\nYou can click Configure in the lower part of the page. Alibaba Cloud CDN completes relevant configurations. You can also click Back to Domain Management, find the domain name that you want to manage, and then click Recommended Features in the Actions column.\nWait for manual verification.\nIf the domain name does not need to be manually verified, proceed to the next step. In the next step, you can configure the parameters based on your business requirements.\nAfter the domain name passes the verification, the status of the domain name changes to Enabled. In this case, the domain name is added to Alibaba Cloud CDN.\n\nAdd a CNAME record for a domain name: After you add a domain name to Alibaba Cloud CDN, Alibaba Cloud CDN assigns a CNAME to the domain name. You need to add the CNAME record for the domain name before Alibaba Cloud CDN acceleration can take effect.\nWe recommend that you perform the following operations before you add a CNAME record for a domain name:\n(Optional) Configure system-recommended features: You can specify cache expiration rules and bandwidth caps to increase cache hit ratios, reinforce protection, and improve content delivery performance.\n(Optional) Test whether a domain name is accessible: You can perform this operation to ensure that DNS updates do not affect the services of your website.\n"
    },
    "335": {
        "title": "CDN:Create a cache rule for resources",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/add-a-cache-rule",
        "content": "This Product\nCDN:Create a cache rule for resources\nTime-to-live (TTL) is the amount of time that a resource is cached on CDN points of presence (POPs). When the TTL of a cached resource ends, the resource on the POPs expires. Requests that attempt to access expired resources are redirected to the origin server. The retrieved resources are returned to the clients and cached on the POPs. You can create a cache rule for resources based on file directories or file name extensions.\nAfter you add a domain name, you can modify the TTL value. The amount of origin traffic and the fees incurred vary based on the TTL that you specify. The resource TTL affects the origin fetch frequency. Specify a TTL based on your business requirements.\nA short TTL may cause frequent origin fetches and increase loads on the origin server. A long TTL may cause resources on the POPs to become outdated.\nIf a resource that is cached on a POP is infrequently accessed, the resource may be overwritten by frequently accessed resources on the POP before the resource expires.\nIf a POP retrieves a file from an origin server, the POP processes the file based on the priorities of the cache rules. For more information, see Default cache rule and priorities of cache rules.\nWhen you update a file on the origin server, we recommend that you add a version number to the file name to differentiate file versions after updates.\nFor example, you can name a file img-v1.0.jpg before the file is updated and img-v2.1.jpg after an update.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Cache.\nOn the Cache Expiration tab, click Create Rule.\nIn the Create Expiration Rule dialog box, configure the parameters. The following table describes the parameters.\n\nParameter\nDescription\nType\nSelect Directory or File Extension.\nDirectory: creates a cache rule for the resources in the same directory.\nFile Extension: creates a cache rule for the resources that have the same file name extension.\nObject\nSpecify the directory or file name extension for which you want to add the cache rule.\nIf you select Directory, take note of the following rules:\nYou can enter only one directory at a time. You can use a forward slash (/) to specify all directories.\nYou can enter a full path. The path must start with a forward slash (/). Example: /directory/aaa.\nIf you select File Extension, take note of the following rules:\nYou can enter one or more file name extensions. Separate multiple file name extensions with commas (,). Example: jpg,txt.\nFile name extensions are case-sensitive.\nYou cannot use an asterisk (*) as a wildcard character to specify all file types.\nExpire In\nSpecify the TTL. The maximum TTL is three years. Take note of the following rules:\nSpecify a TTL of one month or longer for static files that are infrequently updated, such as images and application packages.\nSpecify a TTL based on your business requirements for static files that are frequently updated, such as JavaScript and CSS files.\nSpecify a TTL of 0 seconds to disable caching for dynamic files, such as PHP, JSP, and ASP files.\nWeight\nSpecify a weight for the cache rule. The weight specifies the priority of the cache rule. Valid values: 1 to 99. A larger value specifies a higher priority.\nIf you create multiple cache rules, we recommend that you specify a unique weight for each cache rule to define the priorities of the cache rules.\nCache rules that have the same weight are prioritized based on the creation time, regardless of the rule type. The rule that has the earliest creation time takes precedence.\nIf you have configured multiple cache rules for a cached resource, only the first matched rule takes effect.\nRule Condition\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\nClick OK.\nYou can click Modify or Delete to modify or delete the cache rule on the Cache Expiration tab.\nAfter a POP retrieves a file from an origin server, the POP processes the file based on the priorities of the following cache rules. A smaller number specifies a higher priority.\nIf the response carries the pragma:no-cache, cache-control:no-cache, no-store, or max-age=0 directive, the file is not cached following the origin's policy.\nCDN follows the TTL for cached resources, or the TTL for HTTP status codes that are configured in the console.\nIf a request matches multiple cache rules, only one rule takes effect based on the following order of priority: weight > creation time.\nIf you create multiple cache rules, we recommend that you specify a unique weight for each cache rule to define the priorities of the cache rules. A higher weight specifies a higher priority.\nCache rules that have the same weight are prioritized based on the creation time, regardless of the rule type. The rule that has the earliest creation time takes precedence.\nCDN follows other cache rules set on the origin server. Headers in responses from the origin server are in the following descending order of priority: Cache-Control > Expires > Last-Modified > ETag.\nThe response carries the Cache-Control header, and the directive is max-age or s-maxage, which is set to a value that is greater than 0, such as Cache-Control:max-age=3600. If both the max-age and s-maxage directives exist, the value of the s-maxage directive prevails.\nThe response carries the Expires header, such as Expires:Tue, 25 Nov 2031 17:25:43 GMT.\nIf the response carries the ETag or Last-modified header, the TTL is calculated based on the following rules:\nIf the response carries the Last-Modified header, TTL = (Current time - Last-Modified) \u00d7 0.1. If the result is from 10 seconds to 3,600 seconds, the result applies. If the result is less than 10 seconds, the TTL is 10 seconds. If the result is greater than 3,600 seconds, the TTL is 3,600 seconds.\nIf the response carries only the ETag header, the TTL is 10 seconds.\nIf the response does not carry the ETag, Last-Modified, Cache-Control, or Expires header, the file is not cached on the POP.\nHTTP provides three types of headers that can be used to control caching behavior.\nCache TTL\nWhen a client requests resources from a server, the client and server define the TTL of the returned resources that are cached on the POPs. The resources expire when the TTL ends.\nHTTP provides the following types of headers that can be used to define the cache TTL.\nHeader\nProtocol version\nDescription\nExample\nType\nPragma\nHTTP/1.0\nThe Pragma header specifies whether a resource is cached. If Pragma is set to no-cache, the resource is not cached. Pragma is compatible with servers that use only HTTP/1.0.\nPragma:no-cache\nRequest and response\nExpires\nHTTP/1.0\nThe Expires header specifies a date and point in time. Cached resources expire at the specified point in time.\nIf Expires is set to an invalid value, such as 0, the resource has expired.\nExpires: Wed, 21 Oct 2022 07:28:00 GMT\nResponse\nCache-Control\nHTTP/1.1\nThe Cache-Control header holds different directives that specify caching policies. Mainstream clients, such as browsers, use the Cache-Control header to control caching behavior.\nThe following directives specify that files are not cached:\nCache-Control:no-cache\nCache-Control:no-store\nCache-Control:max-age=0\nThe following directive specifies that files are cached for 1 hour: Cache-Control:max-age=3600.\nRequest and response\nResource tags\nThe first time a client requests a resource from a server, the server adds a tag to the response headers.\nThe next time the client requests the resource from the server, the tag is used to identify the requested resource. The header of subsequent requests carries this tag. If the server checks this tag and confirms that the requested resource is not updated, the HTTP 304 status code is returned to the client. The client retrieves the resource from the local cache.\nIf the server detects that the tag is different from that of the resource on the server, the server informs the clients that the resource is updated or has expired. In this case, the client must retrieve the latest version of the resource from the server.\nHTTP provides the following types of headers that can be used to control cache versions.\nHeader\nProtocol version\nDescription\nExample\nType\nLast-Modified\nHTTP/1.0\nLast-Modified specifies the time when a resource was last updated.\nLast-Modified: Wed, 21 Oct 2015 07:28:00 GMT\nResponse\nETag\nHTTP/1.1\nThe ETag header is the unique identifier of each version of a resource.\nETag specifies whether a resource is updated. If the resource is updated, the server does not need to return a complete response.\nETag: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\nResponse\nContent negotiation\nCaching software uses keywords to index objects on disks. In HTTP/1.0, URLs are used as keywords. However, different resources may point to the same URL. To differentiate the resources, clients must provide additional information, such as the Accept-Language and Accept-Charset headers. HTTP/1.1 introduced the Vary response header to implement content negotiation. The Vary header lists the request headers that must be included to implement content negotiation.\nIn content negotiation, the Vary header is used to differentiate variants. This way, the clients can retrieve the desired variants.\nHeader\nProtocol version\nDescription\nExample\nType\nVary\nHTTP/1.1\nExamples\nThe server uses Vary: Accept-Encoding to inform the recipient, such as a POP, that the requested resource has two variants. One of the variants is compressed, and the other is not compressed. When the client sends requests to CDN for the same resource, the browser with an outdated version requires the resource to be uncompressed to prevent incompatibility. The browser with the latest version requires the resource to be compressed to reduce data transfer.\nThe server uses Vary: User-Agent to identify the browsers that initiate the requests and inform the recipient, such as a POP, of the browser types. The POP caches variants based on the browser types.\nVary: Accept-Encoding\nVary: Accept-Encoding,User-Agent\nResponse\nExample 1: If you want the POPs to cache TXT files for seven days, create a cache rule for TXT files in the CDN console and set the TTL to seven days.\n\nExample 2: The following cache rules are configured for the accelerated domain name demo.aliyun.com. When the POPs retrieve the resource http://demo.aliyun.com/image/example.png, the two rules are matched. In addition, the rules have the same weight. In this case, the rules are prioritized based on the creation time. The rule that has the earliest creation time has the highest priority. Therefore, the rule that is configured for the /image directory takes effect.\nBatchSetCdnDomainConfig\nFAQ about caching\nWhat is the mechanism for clearing the cache?\nIncrease the cache hit ratios of Alibaba Cloud CDN\nHow do I configure POPs not to cache resources and to retrieve resources from origin servers?"
    },
    "336": {
        "title": "CDN:Refresh and prefetch resources",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/refresh-and-prefetch-resources",
        "content": "This Product\nCDN:Refresh and prefetch resources\nThe refresh feature allows you to remove cached resources from CDN nodes, compelling the CDN nodes to retrieve the most recent resources from the source server. This feature is useful in situations such as updating and releasing resources, removing non-compliant content, or making domain name configuration adjustments. The prefetch feature enables you to preload popular resources onto CDN nodes ahead of high-traffic periods, thereby reducing the burden on the source server and enhancing the user experience.\n\nRefresh: This feature marks the cached resources on all CDN nodes as invalid. When users request these resources again, CDN retrieves the updated content from the origin server and delivers it to the users, simultaneously recaching the resources on the CDN nodes. This process can lead to a reduced cache hit ratio.\nPrefetch: This feature allows the origin server to proactively cache resources on CDN nodes. When you first request these resources, you can directly retrieve the latest versions from the CDN nodes, bypassing the origin server. This process enhances the cache hit ratio.\nFunction\nApplicable scenarios\nRefresh\nResource Updates And Releases\nAfter the old resources on the origin server are updated or upgraded, you can submit the URLs or directories of the corresponding resources for refresh to prevent users from accessing outdated cached resources. Users can then directly access the latest resources, which are cached on CDN nodes.\nRemoval Of Non-compliant Resources\nIf your origin server contains non-compliant content as mentioned in the Limits, after you delete the resources from the origin server, the resources may still be accessible due to caching on CDN nodes. You can use the URL refresh feature to update the cached resources.\nPrefetch\nFirst-time integration with Alibaba Cloud CDN\nAfter you integrate with CDN for the first time, you can choose to prefetch your hot static resources in advance. When users access the resources, the CDN acceleration nodes can directly respond, improving access speed and avoiding slow initial access.\nOperational Activities\nWhen operating a large-scale event, prefetch the static resources involved in the event page to CDN nodes in advance. After the event starts, all static resources accessed by users are cached on CDN acceleration nodes and directly responded to by the acceleration nodes.\nInstallation Packages Or Other Large File Releases\nBefore releasing new version installation packages or upgrade packages, prefetch the resources to CDN acceleration nodes. After the product is officially published, the download requests from many users are directly responded to by CDN acceleration nodes, improving download speed, significantly reducing the load on the origin server, and enhancing user experience.\nSubmitting numerous refresh tasks can significantly clear the cache, leading to an increase in back-to-origin bandwidth and requests, which in turn increases the load on the origin server. It is advisable to perform this operation during periods of low website traffic.\nA refresh task typically takes effect within 5 to 6 minutes of submission. If the cache expiration time for files or directories is less than 5 minutes, there is no need to refresh as the cache will automatically update upon expiration.\nURL refresh, directory refresh, and regex refresh all support shared cache. When a domain name is configured with shared cache, you can submit a refresh task for the primary domain name or any associated domain names to clear the cache.\nAfter you submit and successfully execute a prefetch task, CDN nodes will immediately retrieve the necessary resources from the source server. Consequently, numerous prefetch tasks can lead to a substantial number of concurrent back-to-origin tasks, causing a sharp rise in back-to-origin bandwidth and requests. It is advisable to carry out this operation when your website experiences low traffic.\nEach account has a maximum prefetch queue capacity of 100,000 URLs. CDN processes prefetch requests in the order they were submitted. If the prefetch queue reaches its capacity of 100,000 URLs, CDN will not accept new prefetch tasks.\nThe time required to complete a prefetch task varies depending on the file sizes. It typically takes between 5 to 30 minutes, with smaller files being prefetched more quickly.\nOnce URL refresh or cache prefetch tasks are successfully issued, they cannot be stopped until completion.\nRAM users require authorization to perform refresh and prefetch operations. For more information, see Grant RAM Users Refresh and Prefetch Permissions.\nBoth refresh and prefetch have daily quotas. If your Alibaba Cloud account's daily bandwidth peak exceeds 200 Mbps, you can request an increase in the daily quota through Quota Management. Alibaba Cloud will evaluate and adjust based on your actual business needs.\nFor more information about refresh and prefetch precautions and issues, see FAQ about Refresh and Prefetch.\nIf you experience slow access after configuring CDN, it is recommended to troubleshoot the issue using the suggested document before updating resources with the refresh feature. For more information, see Troubleshoot Slow Website Access after Using Alibaba Cloud CDN Acceleration.\nFor website access issues, see Troubleshoot Inaccessible or Abnormal Access Issues.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Purge and Prefetch.\nOn the Purge/Prefetch tab, select  Refresh  as the operation type.\nSelect the appropriate operation method:  URL,  Directory, or  Regex.\nEnter or upload the data to be processed in the URL field.\nClick Submit.\nView the refresh progress.\nIf you have enabled auto CDN cache update in the OSS console, the auto CDN cache update tasks for OSS will not be visible in the CDN  console.\nOperation method\nRelated introduction\nPrecautions\nURL\nURL refresh refers to refreshing a single file. You need to enter the complete URL path of a single file. Include the protocol header, domain name, path, and file. For example: https://www.example.com/static/picture/earth.jpg\nWhen refreshing multiple URLs, enter one URL per line.\nAn account can submit up to 10,000 URL refreshes per day.\n\nDirectory\nRefresh all files in the folder through the URL path you enter. You need to enter the complete URL directory, which must end with a /. Include the protocol header, domain name, and path. For example: https://www.example.com/static/picture/\nWhen refreshing multiple URL directories, enter one URL per line.\nYou can submit up to 100 directory refreshes at a time, and up to 100 directory refreshes for a domain name per minute.\nDirectory refresh uses the \"refresh changed resources\" method by default. If the Last-Modified information of the resources requested by users has not changed, the old cache information is returned directly without retrieving from the origin server. If you need to force refresh the cache, refer to RefreshObjectCaches - Refresh cache.\nRegex\nRefreshes based on URLs with regular expressions. If the URL you entered matches the regular expression, it will be refreshed. For example: http://www.example.com/static/picture/[0-9][a-z].*.jpg\nAn account can submit up to 20 URLs containing regular expressions per day.\nFor more information about regex refresh, see Regex refresh description.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Purge and Prefetch.\nOn the Purge/Prefetch tab, select Prefetch as the operation type.\nSelect the appropriate  URL  for the operation method.\nEnter or upload the data to be processed in the URL field.\nClick Submit.\nView the prefetch progress.\nOperation method\nRelated introduction\nPrecautions\nURL\nURL prefetch refers to the prefetching of a single file. You need to enter the complete URL path of a single file. Include the protocol header, domain name, path, and file. For example: https://www.example.com/static/video/earth.mp4\nWhen prefetching multiple URLs, enter one URL per line.\nDirectories ending with / are not supported.\nAn account can submit up to 100 URL prefetch tasks at a time and up to 1,000 URL prefetch tasks per day.\n\n\nFor automating refresh or prefetch tasks, see Use Automated Scripts for Refresh and Prefetch.\nManual Query\nYou can view detailed records and monitor the progress of resource refresh or prefetch tasks on the Records tab. A progress indicator at 100% signifies that the task has been completed. Should the volume of prefetch or refresh tasks be excessive, it may slow down the overall completion rate. Your patience is appreciated.\n\nAPI Query\nUse the DescribeRefreshTaskById API to check the status of refresh or prefetch tasks. For more information, see DescribeRefreshTaskById - Query Refresh Prefetch Task by ID.\nExecute the following command to check the prefetch results of the file:\nThe system will display the following result:\n\nIf the X-Cache header is present:\nIf X-Cache shows HIT, this means the request successfully hit the cache and the prefetch was effective.\nIf X-Cache shows MISS, this means the request did not hit the cache, either because the prefetch task is incomplete or it failed. You can try prefetching again.\nIf the X-Cache header is absent:\nThe absence of the X-Cache header indicates that the resource is not using Alibaba Cloud CDN. Integrate the domain name of the URL with Alibaba Cloud CDN before prefetching the resource by referring to Quickly Integrate with Alibaba Cloud CDN.\nWhat to Do if Prefetch Fails?\nTroubleshoot Inaccessible or Abnormal Access Issues.\nWhy Aren't Resources Updated After Using the CDN Refresh Prefetch Feature?\nHow to Update Files with the Same Name After Configuring CDN?\nHow to Check if the Prefetch Task of CDN is Complete?\nYou can call API operations to refresh and prefetch resources. For more information, see Refresh and Prefetch API.\n"
    },
    "337": {
        "title": ":Add a CNAME record for a domain name",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/add-a-cname-record-for-a-domain-name",
        "content": "This Product\n:Add a CNAME record for a domain name\nAfter you add a domain name to Alibaba Cloud CDN, the system assigns a CNAME to the domain name. You need to add a CNAME record in the system of your DNS service provider to map the domain name to the CNAME. After you add a CNAME record, the acceleration takes effect.\nYou have activated CDN. If not, see Activate Alibaba Cloud CDN.\nYou have added a domain name. If not, see Add a domain name.\nCNAME record (Canonical Name Record) serves to map one domain name to another.\nAfter you add a domain name, Alibaba Cloud CDN assigns a CNAME to the domain name. The CNAME is resolved by the DNS service provider and points to points of presence (POPs). To accelerate content delivery, you need to map the original DNS record of the accelerated domain name, such as example.aliyundoc.com, to the assigned CNAME, such as example.aliyundoc.com.w.kunlunle.com. This way, client requests can be redirected to POPs to speed up access. For more information, see How it works.\nDomain name resolution is the process of converting a domain name, such as example.aliyundoc.com, into an IP address of the client. For more information, see What is DNS resolution?\nTo avoid service interruptions, if you have configured an A record for the accelerated domain name, you must verify that the accelerated domain name is accessible by following instructions in (Optional) Test whether a domain name is accessible. Choose one of the following methods to switch to a CNAME:\nReplace the A record with the corresponding CNAME. This ensures service continuity.\nDisable the A record and map the accelerated domain name to the CNAME. This may lead to a temporary service interruption.\nGo to the Domain Names page in the Alibaba Cloud CDN console and copy the CNAME of the accelerated domain name.\n\nThe procedure to add a CNAME record varies with your DNS service provider. In this topic, Alibaba Cloud and Tencent Cloud are used as examples.\nIf you add a CNAME record for a wildcard domain such as *.aliyundoc.com, the second-level domains such as example.aliyundoc.com of the wildcard domain can be accelerated, while the third-level domains cannot. For more information, see Does Alibaba Cloud CDN support wildcard domain names?\nMake sure that the DNS records do not conflict with each other in the same system.\nThe server that Alibaba Cloud CDN uses for domain name resolution is deployed in the Chinese mainland. If you configure region-specific DNS settings for your domain name, for example, you add a CNAME record for your Alibaba Cloud CDN-accelerated domain name only in regions outside the Chinese mainland, including Hong Kong (China), Macao (China), and Taiwan (China), the domain name cannot be mapped to the CNAME. The CNAME status is Pending Configuration in the Alibaba Cloud CDN console. However, acceleration for the domain name is not affected.\nCNAMEs that are assigned by Alibaba Cloud CDN, DCDN, ApsaraVideo Live, and ApsaraVideo VOD can be used only for domain name resolution. If Alibaba Cloud detects that your CNAME is used for unauthorized or malicious activities, Alibaba Cloud reserves the right to close your Alibaba Cloud account and remove the domain names.\nIf your DNS provider is Alibaba Cloud, perform the following steps to add a CNAME record for the domain name:\nLog on to the Alibaba Cloud DNS console with the Alibaba Cloud account to which the domain name belongs.\nOptional. add a domain name that is not registered with Alibaba Cloud.\nIf the domain name is not registered with Alibaba Cloud, you need to add the domain name to Alibaba Cloud DNS before you can add a DNS record for it. For more information, see Manage domain names. If the domain name is registered with Alibaba Cloud, skip this step.\nOn the Domain Name Resolution page, find the domain name that you want to manage and click DNS Settings in the Actions column.\nClick Add DNS Record and add a CNAME record.\nThe CNAME record of a specific domain name takes precedence over that of a wildcard domain name. If you want to accelerate a wildcard domain, where the DNS record contains an asterisk (*), you need to delete all other DNS records of second-level domains that match the wildcard domain.\nParameter\nDescription\nExample\nRecord Type\nSelect CNAME.\nCNAME\nHostname\nFor subdomains, enter the prefix of the subdomain.\nFor wildcard domains, enter *.\nFor root domains, enter @.\nFor more information about subdomains, see Terms.\nSubdomains:\nIf the domain name to be accelerated is example.aliyundoc.com, enter example.\nIf the domain name to be accelerated is www.example.aliyundoc.com, enter www.example.\nWildcard domains:\nIf the domain name to be accelerated is .aliyundoc.com, enter *.\nIf the domain name to be accelerated is *.example.aliyundoc.com, enter *.example.\nRoot domains: If the root domain is aliyundoc.com and the domain name to be accelerated is aliyundoc.com, enter @.\nDomain name resolution settings apply to the domain name that you register, such as aliyundoc.com, or the left part of the domain name. When you specify the Hostname parameter, enter the part to be resolved. For example, if the domain name to be accelerated is example.aliyundoc.com, enter example.\nDNS Request Source\nSelect Default from the drop-down list.\nWe recommend that you keep the default setting.\nRecord Value\nEnter the CNAME of the domain name.\nFor example, example.aliyundoc.com, and www.example.aliyundoc.com correspond to different CNAMEs. If you want to accelerate a subdomain, add the second-level domain to Alibaba Cloud CDN. Alibaba Cloud then assigns a CNAME to the subdomain. Alternatively, you can add a wildcard domain name to Alibaba Cloud CDN. Subdomains that match the wildcard domain name are mapped to the CNAME of the wildcard domain name. For more information, see Add a domain name.\nwww.example.com.w.kunlunsl.com\nTTL\nEnter a time-to-live (TTL) value for the record. A smaller value indicates that the record is updated quicker. The default TTL value is 10 minutes.\nWe recommend that you keep the default setting.\nClick OK.\nIf your DNS service provider is Tencent Cloud, perform the following steps to add a CNAME record for the domain name:\nLog on to the DNSPod console.\nOn the DNSPod page, click Add Records and add a CNAME record.\nParameter\nDescription\nExample\nHost\nFor subdomains, enter the prefix of the subdomain.\nFor wildcard domains, enter *.\nFor root domains, enter @.\nFor more information about subdomains, see Terms.\n\nSubdomains:\nIf the domain name to be accelerated is example.aliyundoc.com, enter example.\nIf the domain name to be accelerated is www.example.aliyundoc.com, enter www.example.\nWildcard domains:\nIf the domain name to be accelerated is .aliyundoc.com, enter *.\nIf the domain name to be accelerated is *.example.aliyundoc.com, enter *.example.\nRoot domains: If the root domain is aliyundoc.com and the domain name to be accelerated is aliyundoc.com, enter @.\nDomain name resolution settings apply to the domain name that you register, such as aliyundoc.com, or the left part of the domain name. When you specify the Hostname parameter, enter the part to be resolved. For example, if the domain name to be accelerated is example.aliyundoc.com, enter example.\nType\nSelect CNAME.\nCNAME\nSplit Zone\nSelect Default from the drop-down list.\nWe recommend that you keep the default setting.\nValue\nEnter the CNAME of the domain name.\nFor example, example.aliyundoc.com, and www.example.aliyundoc.com correspond to different CNAMEs. If you want to accelerate a subdomain, add the second-level domain to Alibaba Cloud CDN. Alibaba Cloud then assigns a CNAME to the subdomain. Alternatively, you can add a wildcard domain name to Alibaba Cloud CDN. Subdomains that match the wildcard domain name are mapped to the CNAME of the wildcard domain name. For more information, see Add a domain name.\nwww.example.com.w.kunlunsl.com\nWeight\nYou do not need to set this parameter.\nN/A\nMX\nYou do not need to set this parameter.\nN/A\nTTL\nEnter a TTL value for the CNAME record. A smaller value indicates that the record is updated quicker.\nWe recommend that you keep the default setting.\nClick Confirm.\nMethod 1: Use the Alibaba Cloud CDN console\nLog on to the Alibaba Cloud CDN console and navigate to the Domain Names page.\nFind the domain name and move the pointer over the CNAME Status column. If the CNAME status is Configured, the CNAME has taken effect.\nIf you add a CNAME record, it takes effect immediately. If you modify a CNAME record, it takes 10 minutes for the update to take effect because the default TTL value of a CNAME record is 10 minutes. During this period, the status of the domain name may be displayed as Pending Configuration in the Alibaba Cloud CDN console until the update takes effect. The actual time period varies based on the TTL value that you specify for the CNAME record.\nMethod 2: Run the nslookup command\nStart Command Prompt in Windows or Terminal in macOS or Linux.\nRun the nslookup -type=CNAME domainName command. If the CNAME in the output is the same as the CNAME that is assigned to the domain name in the Alibaba Cloud CDN console, Alibaba Cloud CDN acceleration takes effect for the domain name.\n"
    },
    "338": {
        "title": ":(Optional) Test domain name accessibility",
        "url": "https://www.alibabacloud.com/help/en/cdn/getting-started/test-whether-a-domain-name-is-accessible",
        "content": "This Product\n:(Optional) Test domain name accessibility\nAfter you add a domain name to Alibaba Cloud CDN, we recommend that you test whether the domain name is accessible before you update the CNAME record of the domain name. This ensures that DNS updates do not affect the services of the domain name. This topic describes how to use an on-premises machine to test whether a domain name is accessible before it is mapped to the CNAME assigned by Alibaba Cloud CDN.\nDuring the test, requests are sent to points of presence (POPs). You are charged for the basic services and value-added services of Alibaba Cloud CDN that you have used. The billing rules of Alibaba Cloud CDN apply in the test. For more information, see Billable items.\nA domain name is added to Alibaba Cloud CDN. If you have not added a domain name to Alibaba Cloud CDN, add one to Alibaba Cloud CDN by following instructions in Add a domain name.\nObtain the CNAME assigned to the domain name.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage, and copy the CNAME.\nCopy the CNAME of a domain name that is in the Normal state.\n\nObtain the IP address of the CNAME. Run the nslookup CNAME of the domain name command in a CLI, such as Command Prompt, PowerShell, or Terminal, to obtain the IP address of the CNAME.\nThe following IP address obtained by running nslookup command is used as an example. The actual IP address of the CNAME obtained by running the nslookup command shall prevail.\n\nAdd the IP address and domain name to the hosts file of the on-premises machine.\nYou must add the IP address obtained from Step 2 and the accelerated domain name to the hosts file of the on-premises machine. Make sure that you add the IP address before the accelerated domain name.\nIn this example, the domain name is example.aliyundoc.com, the CNAME is example.aliyundoc.com.w.kunlunle.com, and the IP address of the CNAME obtained by running nslookup example.aliyundoc.com.w.kunlunle.com is 192.168.0.1.\nGo the C:\\Windows\\System32\\drivers\\etc directory and use Notepad to open the hosts file as the administrator.\nEdit the hosts file.\nThe file content may be similar to the following text:\nAdd the obtained IP address and the domain name to the end of the file. Example:\nSave the changes.\nAfter you edit the file, choose File > Save or press Ctrl+S to save changes.\nOptional. Refresh the DNS cache to ensure that the DNS resolution changes take effect immediately.\nOpen Command Prompt as the administrator and run the following command:\nOpen Terminal and run the following command to open the hosts file as an administrator.\nYou are prompted to enter the administrator password. Enter the password and press Enter.\nEdit the hosts file.\nThe file content may be similar to the following text:\nAdd the obtained IP address and the domain name to the end of the file. Example:\nSave the changes and exit.\nPress Esc to exit insert mode, enter :wq, and then press Enter to save the file and exit the Vim editor.\nOptional. Refresh the DNS cache to ensure that the DNS resolution changes take effect immediately.\nRun the following command in Terminal:\nTest whether the accelerated domain name is accessible.\nAfter you add the IP address and accelerated domain name to the hosts file, you can open the browser and enter the accelerated domain name in the address bar to test the connectivity. You can view the test result by using the developer tool of the browser.\nIf the IP address in the Remote Address field is the same as the one that you add to the hosts file, the configuration is valid. You can configure the CNAME on the DNS service provider side.\nIf the IP address in the Remote Address field is different from the one that you add to the hosts file, the configuration is invalid. Make sure that you add the IP address of the CNAME to the hosts file.\nAfter you access the accelerated domain name, you can also test other features by using the on-premises machine.\nAdd a CNAME record for a domain name: After you add a domain name to Alibaba Cloud CDN, Alibaba Cloud CDN assigns a CNAME to the domain name. You need to add the CNAME record for the domain name before Alibaba Cloud CDN acceleration can take effect.\n"
    },
    "339": {
        "title": "CDN:Performance indicators",
        "url": "https://www.alibabacloud.com/help/en/cdn/product-overview/performance-indicators",
        "content": "This Product\nCDN:Performance indicators\nThis topic describes the major performance indicators that are used to evaluate the performance of content delivery before and after a website is accelerated by Alibaba Cloud CDN.\nYou can make informed business decisions based on the performance indicators. Performance indicators include:\nCommon performance indicators\nPerformance indicators for small file distribution\nPerformance indicators for large file distribution\nPerformance indicators for on-demand video and audio streaming\nYou can monitor the following performance indicators to evaluate the performance of content delivery before and after your website is accelerated by Alibaba Cloud CDN. Common performance indicators include but are not limited to the ones described in this topic.\nAfter a website is accelerated by Alibaba Cloud CDN, the network latency, packet loss rate, and back-to-origin rate are typically reduced, and the cache hit ratio is increased. However, the actual performance may vary based on the business scenario and workload type. The performance indicators that are described in this topic are based on pure statistics.\nThe back-to-origin rate and cache hit ratio that are described in the following table are used to evaluate the performance of content delivery for a website after it is accelerated by Alibaba Cloud CDN. If your website is not accelerated by Alibaba Cloud CDN, the back-to-origin rate is 100%, and the cache hit ratio is 0.\nHow content is delivered to a client\nHow content is downloaded by a client\nPerformance indicator\nDescription\nDNS time\nThe amount of time required for a client to initiate a request and receive the IP address of the destination host.\nTCP time\nThe amount of time required for a client to establish a TCP connection to the destination server.\nSSL time\nThe amount of time required for a client to establish an SSL connection to a web server.\nDelivery time\nThe amount of time required for a client to complete sending a request after SSL handshakes are completed.\nConnection time\nIf a POP uses HTTP to accelerate content delivery, the connection time consists of the DNS time and TCP time. If a POP uses HTTPS to accelerate content delivery, the connection time consists of the DNS time, TCP time, and SSL time. The connection time shows the coverage of POPs and the capabilities of the POPs to deliver content.\nResponse Time\nThe amount of time required for a web server to process an HTTP request and return a response to a client.\nDownload time\nThe amount of time required for a client to receive and download the first packet returned from a web server.\nTime to first packet\nThe amount of time required for a client to send a request and receive the first HTTP packet from a server. The time to first packet shows the overall performance of POPs.\nFor content uploading and downloading, the time to first packet consists of the DNS time, TCP time, SSL time, request time, and response time.\nA new domain name may require a longer period of time for DNS resolution than other domain names. However, this does not affect the cache retrieval time.\nOverall performance\nThe amount of time required to upload or download an entire file.\nPacket loss rate\nThe rate of lost packets to total packets during transmission.\nBack-to-origin rate\nThe back-to-origin rate is classified into two: back-to-origin request rate and back-to-origin data transfer rate.\nThe back-to-origin request rate refers to the rate of requests for resources that are not cached, have expired, or cannot be cached on POPs to the total number of requests. Back-to-origin request rate = Number of back-to-origin requests from POPs/Total number of requests sent to POPs. A lower back-to-origin request rate indicates better performance. However, if the original user requests are fragmented after POPs redirect the requests to the origin servers, the number of back-to-origin requests becomes greater than the total number of requests that are sent to POPs.\nThe back-to-origin data transfer rate refers to the rate of data transfer that is returned by the origin servers to data transfer that is returned by POPs to clients. Back-to-origin data transfer rate = Number of bytes returned from the origin servers to POPs/Number of bytes returned from POPs to clients. A lower data transfer rate indicates better performance.\nCache hit ratio\nThe cache hit ratio of Alibaba Cloud CDN is classified into the byte cache hit ratio and request cache hit ratio. The cache hit ratio of Alibaba Cloud CDN is represented by the byte cache hit ratio. A higher cache hit ratio indicates a higher performance.\nByte hit ratio = (Total number of bytes returned from POPs to clients - Total number of bytes returned from the origin servers to POPs)/Total number of bytes returned from POPs to clients.\nA lower byte hit ratio indicates a higher volume of origin traffic. A higher volume of outbound traffic from the origin server indicates a larger bandwidth value and heavier workloads of the origin server. Origin traffic represents the amount of workloads on the origin server, and the byte hit ratio is a major concern in actual business scenarios.\nRequest hit ratio = (Total number of requests to POPs - Total number of back-to-origin requests)/Total number of requests to POPs.\nSmall files refer to HTML, JavaScript, JPG, and CSS files. The delivery of these types of files is latency-sensitive. Lower latency indicates higher performance. The latency is determined by the following factors:\nTime to first packet (most critical factor)\nConnection time\nDownload time\nAlibaba Cloud CDN provides common scenarios that small file distribution is suitable for. For more information, see Image and small file distribution.\nLarge files refer to files that are larger than 20 MB. The key indicators for large file distribution include:\nDownload rate\nDownload time\nAlibaba Cloud CDN provides common scenarios that large file distribution is suitable for. For more information, see Large file distribution.\nOn-demand audio and video streaming uses FLV, MP4, WMV, and MKV files. The key indicators for on-demand video and audio streaming include:\nInitial load time\nThe amount of time required to complete loading the first frame of a stream. The initial load time is determined by the DNS time, connection time, and time to first packet. A shorter initial load time indicates higher performance.\nStalling rate\nStalling events may occur when a video or audio stream is played or a resource is loaded. The stalling rate is calculated by using the following formula: Number of viewers that have stalling events/100. A lower stalling rate indicates better performance.\nAlibaba Cloud CDN provides common scenarios that on-demand video and audio streaming is suitable for. For more information, see On-demand audio and video streaming."
    },
    "340": {
        "title": "CDN:Copy configurations",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/copy-configurations-to-domain-names",
        "content": "This Product\nCDN:Copy configurations\nIf you want to apply the configurations of a domain name to other domain names in batches, you can use the copy configurations feature to use the same configurations for different domain names. This feature helps reduce costs for manual configuration. For example, if you use multiple domain names to accelerate resources on the same origin server, the configurations of the origin server are the same for the domain names. In this case, you can use this feature to copy the configurations of an existing domain name to destination domain names.\nAfter you copy the configurations of one domain name to another domain name, the copy operation cannot be undone. Make sure that the configurations that you want to copy are correct.\nFor domain names that have high traffic or bandwidth usage, proceed with caution to prevent unexpected financial losses.\nSpecial configurations that are applied by submitting tickets cannot be copied.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name from which you want to copy configurations, and click Copy Configurations.\nSelect the items that you want to copy and click Next.\nYou cannot copy the origin information and basic information, including the CNAME, business type, and acceleration region at the same time.\nYou cannot copy SSL certificates from one domain name to another domain name.\nWhen you copy custom HTTP request headers and response headers, the headers are added to the destination domain name. For example, if Domain Name A has two request headers and you copy five request headers from Domain Name B to Domain Name A, Domain Name A has seven request headers.\nWhen you copy HTTP request headers (new version) and response headers, the headers overwrite the existing headers of the destination domain name. For example, if you set cache_control to private for Domain Name A and to public for Domain Name B. After you copy cache_control from Domain Name B to Domain Name A, cache_control of Domain Name A is set to public.\nWhen you copy the configurations of feature switches, Referer whitelist, Referer blacklist, IP whitelist, or IP blacklist to another domain name, the copied configurations overwrite the existing configurations.\n\nSelect the domain names to which you want to apply the copied configurations and click Next.\nYou can enter a keyword to search for domain names.\nIn the Copy Configurations dialog box, click OK."
    },
    "341": {
        "title": "CDN:Transfer a domain name to another Alibaba Cloud account",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/domain-name-transfer",
        "content": "This Product\nCDN:Transfer a domain name to another Alibaba Cloud account\nYou can use the domain name transfer tool to transfer a domain name that you added to Alibaba Cloud CDN to another Alibaba Cloud account.\n\nYou can use the domain name transfer tool to transfer domain names between Alibaba Cloud accounts in the following scenarios:\nYou have multiple Alibaba Cloud accounts and want to transfer domain names from Account A to Account B.\nYou are prompted that a domain name has been added when you add the domain name to Alibaba Cloud CDN. However, you do not know which account the domain name belongs to, and you want to transfer the domain name to your account.\nIf you want to transfer a domain name that is added to another service, such as ApsaraVideo Live, to Alibaba Cloud CDN, submit a ticket.\nMake sure that the old and new accounts for the domain name transfer have no overdue payments.\nAttach the AliyunCDNFullAccess policy to the RAM user if you transfer a domain name as a RAM user. For more information, see Grant permissions to the RAM user.\nTo ensure security, you can transfer only one domain name at a time.\nIf the number of domain names that you add to an account reaches the upper limit, go to the Quota Center to increase the upper limit before you transfer the domain name. For more information, see Quota management.\nMake sure that the wildcard domain name and the exact match domain name of the same root domain, such as .aliyundoc.com and example.aliyundoc.com, belong to the same account. Otherwise, configuration conflicts may occur. The configuration of the exact match domain name prevails.\nIf the domain name that you want to transfer is still providing services, take note of the following items to prevent business interruptions:\nIf the origin server of the domain name that you want to transfer is an Object Storage Service (OSS) bucket, and you have enabled private bucket access for the domain name and configured a Security Token Service (STS) token to redirect requests to private OSS buckets in the same Alibaba Cloud account, authentication may fail after you transfer the domain name to another account. As a result, origin fetch fails. Therefore, you need to change the authentication method of the domain name to permanent security token before you transfer the domain name. For more information, see Configure access to private OSS buckets.\nIf you have configured an SSL certificate for the domain name that you want to transfer, you are not notified of the certificate expiration after the domain name is transferred to another account. You need to re-upload the certificate to the new account.\nBefore you transfer a domain name, you need to disable features that are enabled for the old account, such as data monitoring, logs, and operations reports. If you do not disable the features, logs and reports continue to be delivered to the old account and fees are continuously generated. After you transfer a domain name to the new account, you need to configure the features for the domain name in the new account.\nAfter you transfer a domain name to the new account:\nYou cannot use the resource plan of the old account to offset traffic fees that are generated by the domain name. Resource plans cannot be transferred to another account.\nThe resource groups and tags that are associated with the domain name also change. If you use resource groups or tags to manage the domain name, you need to configure resource groups or tags in the new account.\nIf your domain name is restricted from being transferred, a message is displayed during the transfer. You can submit a ticket to reach technical support.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nIn the upper-right corner of the Domain Names page, click Transfer Domain Names.\nAfter you read and check the instructions, click OK.\nEnter the domain name that you want to transfer and verify the ownership of the domain name. For more information, see Verify the ownership of a domain name.\nClick Transfer.\nIn the Verify Domain Ownership section, click Method 1: DNS Settings.\nDo not close the verification page before the verification is complete. If DNS record verification fails, you can use Method 2: Upload a verification file to verify the ownership.\n\nAdd a TXT record in the system of your DNS service provider.\nThe following example shows how to add a TXT record to the DNS settings at Alibaba Cloud DNS. You can use similar methods to add TXT records to the systems of other DNS providers, such as Tencent Cloud and Xinnet.\nLog on to the Alibaba Cloud DNS console.\nOn the Domain Name Resolution page, find the root domain example.com and click DNS Settings in the Actions column.\nClick Add DNS Record, set the Record Type parameter to TXT, set the Hostname and Record Value parameters to the values that are obtained in Step 1, and then use the default values for other parameters.\n\nClick OK.\nAfter the TXT record takes effect, log on to the Alibaba Cloud CDN console and click Verify.\nIf a message indicating that the domain name fails the verification appears, check whether the TXT record is correct. Wait for the TXT record to take effect and try again.\nThe accelerated domain name image.example.com is used in the following examples to check whether the TXT record is correct.\nIf you add a TXT record, the TXT record immediately takes effect. If you modify a TXT record, the amount of time that is required for the updates to take effect is based on the TTL. The default TTL is 10 minutes.\nIf nslookup is not installed on Linux, you can run the yum install bind-utils command on CentOS or the apt-get install dnsutils command on Ubuntu to install nslookup.\nOpen Command Prompt in Windows, and then run the nslookup -type=TXT verification.example.com command. You can check whether the TXT record is correct based on the output.\n\nRun the nslookup -type=TXT verification.example.com command. You can check whether the TXT record is correct based on the output.\n\nIn the Verify Domain Ownership section, click Method 2: Verification File.\nDo not close the verification page before the verification is complete.\nDownload the verification.html file.\nUpload the verification file to the root directory on the server of the root domain name. The server can be an Elastic Compute Service (ECS) instance, an Object Storage Service (OSS) bucket, a Cloud Virtual Machine (CVM) instance, a Cloud Object Storage (COS) instance, or an Elastic Compute Cloud (EC2) instance. For example, if the domain name is image.example.com, you need to upload the file to the root directory of example.com.\nAfter you make sure that the verification file is accessible from http://example.com/verification.html, click Verify.\nAlibaba Cloud CDN accesses http://example.com/verification.html on your server for verification.\nIf the record value in the file is the same as the record value in the verification file, the verification is successful.\nOtherwise, the verification fails. Make sure that the preceding URL is accessible and the file that you uploaded is valid.\n\nClick Verify.\n"
    },
    "342": {
        "title": "CDN:Tags",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/tags/",
        "content": "This Product\nCDN:Tags"
    },
    "343": {
        "title": "CDN:Configure an origin server",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-an-origin-server",
        "content": "This Product\nCDN:Configure an origin server\nAlibaba Cloud CDN supports the following types of origin servers: Object Storage Service (OSS) domain names, IP addresses of origin servers, domain names of origin servers, and Function Compute domain names. You can specify one or more origin servers of each type and specify primary and secondary origin servers to balance loads.\nWhen Alibaba Cloud CDN retrieves resources from an origin server, the origin server is billed for data transfer. For example, if the origin server is a data center, the data center is billed for data transfer and bandwidth resources. If the origin server is an OSS bucket, the OSS bucket is billed for data transfer.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the Origin Information section, click Add Origin Sever, or click Modify in the Actions column.\nTo add an origin server, click Add Origin Server in the upper-left corner of the origin server list.\nTo modify the information about an origin server, click Modify in the Actions column.\n\nParameter\nDescription\nOrigin Info\nSelect the type of the origin server and enter the address of the origin server.\nOSS Domain\nIf your origin server is an Object Storage Service (OSS) bucket, you can select or enter the public domain name of the OSS bucket, such as ***.oss-cn-hangzhou.aliyuncs.com. Alibaba Cloud CDN does not support internal domain names of OSS buckets.\nYou can obtain the public domain name of an OSS bucket in the OSS console. You can also select the domain name of an OSS bucket that belongs to the current Alibaba Cloud account from the Domain Name drop-down list.\nDiscounts for data transfer between Alibaba Cloud CDN and OSS:\nIf you want OSS to identify network traffic that is sent from Alibaba Cloud CDN and apply for a discount on the data transfer, you need to set the origin server type to OSS Domain in the Alibaba Cloud CDN console.\nIf you set the origin server type to Site Domain in the Alibaba Cloud CDN console, OSS identifies network traffic that is sent from Alibaba Cloud CDN as outbound data transfer over the Internet. In this case, the discounts do not apply.\nFor more information, see Billing of OSS content acceleration.\nIP: You can configure one or more IP addresses for an origin server. Internal IP addresses are not supported. IPv4 addresses and IPv6 addresses are supported. At least one of the IP addresses must be an IPv4 address. If you use a public IP address of an Alibaba Cloud Elastic Compute Service (ECS) instance as the address of the origin server, the IP address is exempt from manual review. You need to enable origin fetch over IPv6 before you configure an IPv6 address. Otherwise, even if you configure an IPv6 address, it does not take effect. As a result, origin fetch fails. For more information, see Configure origin fetch over IPv6.\nSite Domain: Enter the domain names of one or more origin servers.\nThe origin domain name must be different from the accelerated domain name. Otherwise, a DNS resolution loop will occur, as requests are continuously resolved back to the CDN nodes, which leads to failure in back-to-origin routing.\nThe format of the origin domain name:\nThe domain name must be 1 to 67 characters in length.\nThe domain name can contain lowercase letters, digits, and hyphens (-). Example: example.com.\nThe domain name cannot contain Chinese characters, uppercase letters, or special characters other than hyphens (-). The domain name cannot be only a hyphen (-). A hyphen (-) in a domain name cannot be followed by another hyphen (-). The domain name cannot start or end with a hyphen (-). If the domain name contains Chinese characters, such as \u963f\u91cc\u4e91.\u7f51\u5740, you must apply for an ICP number for the domain name in Chinese characters and use the Punycode tool to convert the Chinese characters into English letters, such as xn--fiq****.xn--eq****. Then, you can specify the converted domain name as the domain name that you want to accelerate.\nYou can add the address of an Alibaba Cloud Application Load Balancer (ALB) instance, such as example.hangzhou.alb.aliyuncs.com, as the address of an origin server.\nFunction Compute Domain: Enter a Function Compute domain name that belongs to the current Alibaba Cloud account. If you select this option, you need to configure the Region and Domain Name parameters. For more information, see Configure a custom domain name.\nPriority\nYou can configure priorities to specify primary and secondary origin servers. The primary origin server has a higher priority than the secondary origin server. Alibaba Cloud CDN preferentially redirects requests to the primary origin server. If a fault occurs on the primary origin server, requests are redirected to the secondary origin server. The priority ranges from 0 to 127. A smaller value indicates a higher priority. By default, the priority of the primary origin server is 20, and the priority of the secondary origin server is 30. If you want to specify other values, submit a ticket.\nFor example, you specify Origin Server A as the primary origin server and Origin Server B as the secondary origin server. In this case, Alibaba Cloud CDN preferentially redirects requests to Origin Server A. If Origin Server A fails, Alibaba Cloud CDN redirects user requests to Origin Server B. After Origin Server A recovers, Alibaba Cloud CDN fails back to Origin Server A.\nWeight\nIf origin servers have the same priority, Alibaba Cloud CDN redirects requests to the origin servers based on the weights of the origin servers. This way, loads are balanced among the origin servers. You can specify a weight based on your business requirements.\nThe weight of an origin server ranges from 1 to 100. An origin server that has a higher weight receives more requests.\nDefault value: 10.\nFor example, you specify Origin Server A and Origin Server B as primary origin servers. If the weight of Origin Server A is 80 and the weight of Origin Server B is 20, Alibaba Cloud CDN redirects 80% of requests to Origin Server A and 20% of requests to Origin Server B.\nIn the following scenarios, the proportion of requests that are redirected to an origin server may not be the same as the weight of the origin server that you specified:\nIf few requests are redirected to origin servers within a period of time, such as less than 10 requests per second, request distribution across origin servers is uneven.\nAll requests are from a specific IP address or a limited number of IP addresses. Requests from the same IP address are sent to the same POP, and a TCP session is maintained between the POP and an origin server.\nIf you want to verify whether the actual proportion of requests that are redirected to an origin server is approximately the same as the weight that you configured for the origin server, you can use a third-party synthetic monitoring tool to initiate a probe task. You can probe clients that are distributed across geographical locations and are served by Internet service providers (ISPs) based on your business requirements. The probe task requires a long period of time to collect sufficient and valid data.\nPort\nThe port on the origin server that processes requests. The default port is port 80. You can specify a port based on the settings of your origin server. Valid values: 1 to 65535.\nDefault value: 80.\nIf you specify port 443, requests are redirected to the origin server over HTTPS. If you specify port 80 or a custom port, requests are redirected to the origin server over HTTP.\nIf you want Alibaba Cloud CDN to redirect HTTPS requests to origin servers over custom ports, configure the origin protocol policy. For more information, see Configure the origin protocol policy.\nIf the Origin Protocol Policy feature is enabled, the port that is specified by this parameter becomes invalid. By default, the feature is disabled. For more information about how to disable the origin protocol policy feature, see Configure the origin protocol policy.\nIf the origin server is an Object Storage Service (OSS) bucket, OSS determines whether you can specify a custom port.\nFor information about health check policies for origin servers, see Origin fetch retry, origin fetch timeout, and origin probing.\nClick OK.\nRetry order:\nThe retry is performed based on the priority of origin addresses in descending order. You can view the origin addresses in the Alibaba Cloud CDN console.\nIf two addresses have the same priority, the retry order is based on the weight ratio.\nRetry granularity:\nRetries are performed for each IP address. If a domain name is specified as an origin address, Alibaba Cloud CDN retries all IP addresses resolved from the domain name and accesses other available origin servers only if all the IP addresses that belong to the domain name are unavailable.\nProbes automatically skip origin servers that are in the dead table.\nRetry status code:\nA CDN POP sends a retry request when it receives an HTTP 5xx status code from the origin server.\nOrigin fetch timeout: The CDN POP sends a retry request after it receives a retry status code from the origin server. If no retry status code is received from the origin server, the timeout processing logic is followed. After the timeout period is reached, the CDN POP is triggered to retry.\nBy default, the timeout period that is required to establish a TCP connection between POPs and an origin server is 10 seconds. To adjust the timeout period, submit a ticket\nThe origin write timeout is the amount of time allocated for data write after the TCP connection is established. By default, the origin write timeout is 30 seconds.\nThe origin read timeout is the amount of time that is required by the origin server to return all content requested by a CDN POP after the TCP connection is established. By default, the origin read timeout is 30 seconds.\nYou can adjust the values of the origin read timeout and origin write timeout by configuring a timeout period for HTTP origin requests.\nOrigin probing:\nAbnormal TCP connection: If the TCP connection between a CDN POP and an origin server fails or times out two times in a row, CDN removes the IP address of the origin server from the list of available origin IP addresses and adds the IP address to the dead table. In this case, subsequent origin requests are no longer sent to the IP address. Then the CDN POP connects to the origin server over TCP to probe the IP address every 5 minutes. If the TCP connection is established, Alibaba Cloud CDN restores the IP address to the list of available origin IP addresses.\nNormal TCP connection: If the TCP connection between a CDN POP and an origin server is normal, but the POP receives a retry status code such as the 5xx status code from the origin server, the IP address of the origin server is not removed from the list of available origin IP addresses. In this case, a retry is triggered and subsequent requests are still sent to the origin server based on the weight ratio. If HTTP request errors occur at Layer 7 when the TCP connection is normal, the IP address of the origin server is not automatically removed from the list of available origin IP addresses. If you want Alibaba Cloud CDN to automatically remove the IP address from the list of available origin IP addresses, submit a ticket\nFor information about origin servers, see origin server.\nIf you use multiple origin servers for acceleration, you can specify different origin hosts. This way, POPs use the origin hosts to retrieve resources from different origin servers. For more information, see Configure the default origin host.\nFor information about how to specify the HTTP or HTTPS protocol for origin fetch, see Configure the origin protocol policy.\nIf your origin server is a private OSS bucket, you need to grant Alibaba Cloud CDN access permissions on the private OSS bucket. For more information, see Configure access to private OSS buckets.\nIf the IP address of the origin server is associated with multiple domain names and POPs access your origin server over HTTPS, you need to configure Server Name Indication (SNI). For more information, see Configure SNI.\n"
    },
    "344": {
        "title": "CDN:Cache settings",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/cache-settings/",
        "content": "This Product\nCDN:Cache settings"
    },
    "345": {
        "title": "CDN:HTTPS",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/https/?spm=a2c63.p38356.0.0.81db583cH7pyWh",
        "content": "This Product\nCDN:HTTPS"
    },
    "346": {
        "title": "CDN:Configure bandwidth caps",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-bandwidth-caps",
        "content": "This Product\nCDN:Configure bandwidth caps\nYou can configure bandwidth caps to prevent unexpected high bills that are caused by malicious attacks or fraudulent traffic.\nA bandwidth cap specifies the maximum bandwidth value and limits the amount of bandwidth resources that can be consumed. If the average bandwidth value of a domain name in a statistical period (1 minute) reaches the specified bandwidth cap, the system suspends CDN services for the domain name and resolves the domain name to offline.***.com, which is considered invalid. In this case, the domain name becomes inaccessible.\nIf the average bandwidth value that is measured during a statistical period is less than the specified bandwidth cap, the domain name can use CDN services as expected.\nIf the bandwidth value of a domain name reaches the specified bandwidth cap due to traffic spikes, the domain name is automatically disabled and resolved to offline.***.com, which is considered invalid. In this case, the domain name becomes inaccessible.\nThe system does not automatically restore the suspended CDN services even if the average bandwidth value drops below the specified bandwidth cap. To restore the suspended CDN services, you need to log on to the CDN console and enable the domain name. For more information, see Restore CDN services.\nYou cannot configure a bandwidth cap for a wildcard domain name. If you configure a bandwidth cap for a wildcard domain name, the bandwidth cap does not take effect.\nAfter you configure a bandwidth cap for a domain name, the domain name is automatically disabled if the bandwidth value that is measured during a statistical period reaches the specified bandwidth cap. Before you configure a bandwidth cap for your domain name, we recommend that you estimate the maximum bandwidth value to ensure service availability.\nThe monitoring data of bandwidth may be delayed by approximately 10 minutes. Therefore, CDN takes approximately 10 minutes to disable a domain name after the bandwidth cap of the domain name is reached. You are charged for the resource that are consumed before the domain name is disabled.\nA RAM user can configure bandwidth caps only after you grant the RAM user the required permissions.\nTo grant the required permissions to a RAM user, log on to the RAM console, create the AliyunCDNFullAccess policy, and then attach the policy to the RAM user.\nA bandwidth cap does not throttle bandwidth. If the average bandwidth value that is measured during a statistical period reaches the specified bandwidth cap, the domain name is automatically disabled. The bandwidth throttling feature throttles bandwidth for a domain name if the bandwidth value reaches the specified upper limit.\nYou can configure bandwidth caps for up to 20 domain names in the CDN console. Each domain name can have only one bandwidth cap. If you configure bandwidth caps for more than 20 domain names after the bandwidth cap feature is enabled, the configuration results for the excess domain names are not displayed in the CDN console. If you want to configure bandwidth caps for more domain names, you need to go to the Alibaba Cloud CloudMonitor console. For more information, see View or modify alert rules in CloudMonitor.\nThe bandwidth cap feature adopts 1-minute real-time monitoring data. The data source of real-time monitoring is the same as that in the CDN console. In most cases, the peak bandwidth in 1 minute is higher than the peak bandwidth in 5 minutes that is collected by using the resource usage query or resource monitoring feature. To prevent the domain names from being disabled due to bandwidth usage spikes, we recommend that you specify a bandwidth cap based on the peak bandwidth that is collected by using the real-time monitoring feature. For more information, see Real-time monitoring, Resource monitoring, and Query resource usage.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Traffic Throttling.\nOptional. The first time you enable the bandwidth cap feature, grant CloudMonitor access permissions on CDN.\nClick Authorize to the right of Role Authorization.\nOn the Cloud Resource Access Authorization page, click Agree to Authorization.\nIf you fail to grant CloudMonitor access permissions on CDN by using the CDN console, you can grant permissions on CDN by using the RAM console. For more information, see Grant permissions on CDN by using the RAM console.\nIn the Bandwidth Cap section, click Modify.\nEnable or disable the bandwidth cap feature based on your business requirements.\nEnable bandwidth cap: Turn on Bandwidth Cap and configure a bandwidth cap.\nThe conversion between two neighboring data units is 1,000. For example, 1 Tbit/s is equal to 1,000 Gbit/s, and 1 Gbit/s is equal to 1,000 Mbit/s.\nDisable bandwidth cap: Turn off Bandwidth Cap.\nClick OK.\nAfter you turn on Bandwidth Cap, CDN uses the monitoring and alerting feature of CloudMonitor. An alert rule is created in CloudMonitor to monitor bandwidth values for CDN. Alerts are sent to the contacts that are specified in CloudMonitor.\nTo change the contacts or view alerts, perform the following steps:\nLog on to the CloudMonitor console.\nIn the left-side navigation pane, choose Alerts > Alert Rules.\n\nChange the contacts or view alerts.\nModify an alert contact or alert contact group\nView the alert history of a specific alert rule\nView the alert rules of a specific domain name.\nTo query the alert rules of a specific domain name, enter the domain name that you want to query in the search box on the Alert Rules page and click the search icon.\nThe system does not automatically restore the suspended CDN services even if the average bandwidth value drops below the specified bandwidth cap. To restore the suspended CDN services, you need to log on to the CDN console and enable the domain name. Perform the following operations:\nLog on to the CDN console and navigate to the Domain Names page. Then, select the domain name that you want to enable and click Enable to enable the domain name.\nLog on to the RAM console.\nIn the left-side navigation pane, choose Permissions > Policies.\nOn the Policies page, click Create Policy.\nClick the JSON tab. In the policy editor, enter the following policy content:\nClick OK, configure the following parameters, and then click OK to save the settings.\nName: AliyunCloudMonitorAccessingCDNRolePolicy.\nDescription: The authorization policy for the CloudMonitor role, including the permission to call the operation for disabling an CDN-accelerated domain.\nIn the left-side navigation pane, choose Identities > Roles.\nOn the Roles page, click Create Role.\nIn the Select Trusted Entity section, select Alibaba Cloud Service and click Next.\nIn the Configure Role step, enter the following information:\nRAM Role Name: AliyunCloudMonitorAccessingCDNRole.\nNote: By default, CloudMonitor uses this role to access resources in CDN.\nSelect Trusted Service: CloudMonitor\nClick OK.\nAfter you create the role, click AliyunCloudMonitorAccessingCDNRole on the Roles page.\nOn the Permissions tab, click Grant Permission.\nIn the Resource Scope section, select Account.\nIn the Policy section, click the Custom Policy tab, select the AliyunCloudMonitorAccessingCDNRolePolicy policy that you created, and then click Grant permissions.\nGo to the Traffic Throttling page in the CDN console. You can see that the role is authorized to use the Bandwidth Cap feature.\nIf you do not want CloudMonitor to have permissions on CDN, you can revoke the permissions of the corresponding role in the RAM console.\nLog on to the RAM console.\nIn the left-side navigation pane, choose Identities > Roles.\nOn the Roles page, click AliyunCloudMonitorAccessingCDNRole.\nOn the Permissions tab, find the policy that you want to manage and click Revoke Permission in the Actions column.\nChoose Identities > Roles, find AliyunCloudMonitorAccessingCDNRole and click Delete Role in the Actions column.\nEnter AliyunCloudMonitorAccessingCDNRole and click Delete Role.\nThe monitoring data of bandwidth may be delayed by approximately 10 minutes. Therefore, CDN takes approximately 10 minutes to disable a domain name after the bandwidth cap of the domain name is reached. You are charged for the traffic, bandwidth, and requests that are consumed before the domain name is disabled. The following examples show how you are charged for resources before the domain name is disabled:\nExample 1: pay-by-peak-bandwidth\nCustomer A selects the pay-by-peak-bandwidth metering method and adds only example.com to CDN. The bandwidth cap of the domain name is set to 10 Gbit/s.\nFrom 21:00:00 (UTC+8) to 21:01:00 (UTC+8) on February 1, 2021, the bandwidth value reached 10 Gbit/s. The domain name was disabled at 21:11:00 (UTC+8) on February 1, 2021 because the monitoring data of bandwidth values is delayed by 10 minutes. Before the domain name was disabled, the actual bandwidth value reached 25 Gbit/s. In this case, the bandwidth fees that are included in the bill for February 1, 2021 are calculated based on the actual peak bandwidth value of 25 Gbit/s.\nExample 2: pay-by-data-transfer\nCustomer B selects the pay-by-data-transfer metering method and adds only example.com to CDN. The bandwidth cap of the domain name is set to 10 Gbit/s.\nFrom 21:00:00 (UTC+8) to 21:01:00 (UTC+8) on February 1, 2021, the bandwidth value reached 10 Gbit/s. During the 1 minute, 30 GB of data transfer was generated. The domain name was disabled at 21:11:00 (UTC+8) on February 1, 2021 because the monitoring data of bandwidth values is delayed by 10 minutes. Before the domain name was disabled, 400 GB of data transfer was generated. In this case, the data transfer fees are included in the bill for the billing cycle from 21:00:00 (UTC+8) to 22:00:00 (UTC+8) on February 1, 2021.\nNo. If you want to prevent excessive traffic, you can use CloudMonitor to monitor the outbound traffic of CDN. If the amount of traffic reaches the threshold that you specify, an alert is sent to the administrator by text message, email, and DingTalk. For more information, see Alert Service.\nNo. A bandwidth cap is configured for only one domain name. You can configure a bandwidth cap separately for each domain name.\nYou can configure bandwidth caps for up to 20 domain names in the CDN console. Each domain name can have only one bandwidth cap. If you configure bandwidth caps for more than 20 domain names after the bandwidth cap feature is enabled, the configuration results for the excess domain names are not displayed in the CDN console. If you want to configure bandwidth caps for more domain names, you need to go to the Alibaba Cloud CloudMonitor console. For more information, see View or modify alert rules in CloudMonitor.\nAfter the bandwidth of the domain name reaches the bandwidth cap, the domain name is automatically disabled. If you do not want to disable the domain name, you can configure traffic throttling for individual requests to limit the overall peak bandwidth of domain names. For more information, see Configure traffic throttling for individual requests.\nNo. Bandwidth caps in Alibaba Cloud are configured for domain names and cannot be configured for specific IP addresses.\nThe bandwidth cap feature of CDN relies on the bandwidth monitoring and alerting feature of CloudMonitor. For more information, see the following CloudMonitor API operations:\nDescribeMetricRuleList\nPutResourceMetricRule\nPutMetricRuleTargets\nDeleteMetricRules\n"
    },
    "347": {
        "title": "CDN:Configure the default origin host",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-the-default-origin-host",
        "content": "This Product\nCDN:Configure the default origin host\nBy default, the value of the HOST header in a back-to-origin request is the accelerated domain name. You can also specify a custom value for the HOST header.\nIf you have multiple accelerated domain names, each of which is used to accelerate different static resources. A common practice is to deploy multiple origin servers. This way, requests that are destined for different accelerated domain names can be redirected to different origin servers.\nIf you have a large number of accelerated domain names and a small amount of origin traffic, deploying multiple origin servers may result in a waste of resources. In this case, you can use virtual hosting.\nVirtual hosting allows you to host multiple websites on a single web server. A server distinguishes and isolates different websites by domain name or hostname. When a user accesses a specific domain name or hostname, the server directs the request to the corresponding virtual site based on the domain name or hostname in the request to retrieve the required content. The following figure shows how virtual hosting works.\nNGINX-related implementations\nNGINX allows you to configure multiple virtual sites by using server blocks. The following sample code provides an example on how to configure multiple virtual sites:\nA project is configured with three virtual sites, which are example.org, example.net and example.com. NGINX determines the destination virtual site based on the value of the HOST header in the HTTP request. If no virtual site is matched, NGINX uses the default virtual site. If no default virtual site is configured, the virtual site that is specified by the first server block is used as the default virtual site.\nIf you access a URL without specifying the HOST header, the value of the HOST header is the host and the port in the URL. However, Alibaba Cloud CDN uses the accelerated domain name as the value of the HOST header by default. You can specify a default value for the HOST header for virtual sites in your origin server.\nYour origin server must support matching different virtual sites based on the value of the HOST header. Otherwise, the feature does not work as expected.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Origin Fetch.\nIn the Default Origin Host section, click Modify.\nTurn on Origin Host and configure the Domain Type parameter.\n\nParameter\nDescription\nCDN Domain\nThe domain name that users visit is used as the origin host.\nOrigin Domain\nThe domain name of the origin server is used as the origin host.\nIf you set the type of the origin server to IP when you add an origin server, Origin Domain is dimmed.\nIf you set the type of the origin server to OSS Domain when you add an origin server, Origin Host is turned on and the Domain Type parameter is set to Origin Domain.\nCustom Domain\nThe domain name that you specify is used as the origin host.\nMake sure that the custom domain name is associated with the origin server. Otherwise, origin fetch fails.\nYour origin server is associated with multiple domain names, and you specify a domain name to which requests are redirected.\nClick OK.\nExample 1: The address of the origin server is a domain name.\nDomain Name\nDescription\nAccelerated domain name:\nimage.example.com\nAddress of the origin server:\nsource.example.com\nBy default, the feature is disabled. You can enable the default origin host feature.\nDescription of domain types:\nCDN Domain: Alibaba Cloud CDN redirects back-to-origin requests to the virtual site image.example.com that is hosted on the origin server source.example.com.\nOrigin Domain: Alibaba Cloud CDN redirects back-to-origin requests to the origin server source.example.com.\nCustom Domain: Alibaba Cloud CDN redirects back-to-origin requests to the specified custom domain name.\nExample 2: The address of the origin server is an IP address.\nDomain Name\nDescription\nAccelerated domain name:\nexample.com\nAddress of the origin server:\n10.10.10.10\nBy default, the feature is disabled. You can enable the default origin host feature.\nDescription of domain types:\nCDN Domain: Alibaba Cloud CDN redirects back-to-origin requests to the virtual site example.com that is hosted on the origin server 10.10.10.10.\nOrigin Domain: If you set the type of the origin server to IP when you add an origin server, Origin Domain is dimmed.\nCustom Domain: Alibaba Cloud CDN redirects back-to-origin requests to the virtual site that uses a custom domain name and that is hosted on 10.10.10.10.\nExample 3: The address of the origin server is an OSS domain name.\nDomain Name\nDescription\nAccelerated domain name:\nexample.com\nAddress of the origin server:\nexample.oss-cn-hangzhou.aliyuncs.com\nIf the address of the origin server is an OSS domain name, Alibaba Cloud CDN automatically enables the origin host feature and sets the Domain Type parameter to Origin Domain.\nDescription of domain types:\nCDN Domain: Alibaba Cloud CDN redirects back-to-origin requests to example.com on the origin server example.oss-cn-hangzhou.aliyuncs.com.\nOrigin Domain: Alibaba Cloud CDN redirects back-to-origin requests to the origin server example.oss-cn-hangzhou.aliyuncs.com.\nCustom Domain: Alibaba Cloud CDN redirects back-to-origin requests to the virtual site that uses a custom domain name and that is hosted on example.oss-cn-hangzhou.aliyuncs.com.\n"
    },
    "348": {
        "title": "CDN:Configure the origin protocol policy",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-the-origin-protocol-policy",
        "content": "This Product\nCDN:Configure the origin protocol policy\nAlibaba Cloud CDN follows the protocol specified by the origin protocol policy to retrieve resources from an origin server. After you configure the origin protocol policy, points of presence (POPs) redirect requests based on the origin protocol policy. You can configure custom HTTP and HTTPS ports.\nBy default, the origin protocol policy feature is disabled. The origin protocol is determined by the origin port that is specified in Configure an origin server.\nIf port 443 is used, requests are redirected to the origin server over HTTPS.\nIf port 80 or another port is used, requests are redirected to the origin server over HTTP.\nAfter you enable the origin protocol policy feature, POPs retrieve resources over the protocol that you configured.\nHTTP: Requests are redirected to the origin server over HTTP.\nHTTPS: Requests are redirected to the origin server over HTTPS.\nFollow:\nIf the request is sent over HTTP, it is redirected to the origin server over HTTP.\nIf the request is sent over HTTPS, it is redirected to the origin server over HTTPS.\nHTTPS protects data from tampering and eavesdropping during transmission. HTTPS encryption consumes additional computing resources on the origin server. If you want to transmit sensitive data such as user identity data over HTTPS, and other data such as image files and video files over HTTP, we recommend that you set the Redirect Type parameter to Follow.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Origin Fetch.\nIn the Origin Protocol Policy section, turn on Origin Protocol Policy.\nIn the Static Origin Protocol Policy dialog box, set Redirect Type to Follow, HTTP, or HTTPS based on your business requirements.\n\nHTTP Port: If you set the Redirect Type parameter to HTTP, port 80 is used by default. You can also configure this parameter to specify a custom port.\nHTTPS Port: If you set the Redirect Type parameter to HTTPS, port 443 is used by default. You can also configure this parameter to specify a custom port.\nClick OK.\nFor information about the API to configure the origin protocol policy, see BatchSetCdnDomainConfig."
    },
    "349": {
        "title": "CDN:Configure a timeout period for HTTP origin requests",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-a-timeout-period-for-back-to-origin-http-requests",
        "content": "This Product\nCDN:Configure a timeout period for HTTP origin requests\nYou can configure a timeout period for HTTP origin requests to efficiently manage the connections between POPs and your origin server. If the timeout period for origin requests is too short, origin requests may fail when network connections are unstable. If the timeout period for origin requests is too long, failed requests will continue to occupy connections until they expire. This may cause normal requests to fail when the maximum number of connections to the origin server is reached. We recommend that you configure the timeout period based on your network connectivity and the maximum number of connections that your origin server can handle to ensure that requests can be redirected to the origin server as expected.\nThe time that is consumed by an HTTP origin request refers to the time that is required to initiate a Layer 7 HTTP request. The time that is consumed by an HTTP origin request does not include the time that is required to establish a Layer 4 TCP connection.\nThe maximum timeout period that you can configure for CDN cannot exceed 36 seconds. The period includes the time consumed by links between CDN points of presence (POPs) and links between CDN POPs and origin servers.\nRetry order:\nThe retry is performed based on the priority of origin addresses in descending order. You can view the origin addresses in the Alibaba Cloud CDN console.\nIf two addresses have the same priority, the retry order is based on the weight ratio.\nRetry granularity:\nRetries are performed for each IP address. If a domain name is specified as an origin address, Alibaba Cloud CDN retries all IP addresses resolved from the domain name and accesses other available origin servers only if all the IP addresses that belong to the domain name are unavailable.\nProbes automatically skip origin servers that are in the dead table.\nRetry status code:\nA CDN POP sends a retry request when it receives an HTTP 5xx status code from the origin server.\nOrigin fetch timeout: The CDN POP sends a retry request after it receives a retry status code from the origin server. If no retry status code is received from the origin server, the timeout processing logic is followed. After the timeout period is reached, the CDN POP is triggered to retry.\nBy default, the timeout period that is required to establish a TCP connection between POPs and an origin server is 10 seconds. To adjust the timeout period, submit a ticket\nThe origin write timeout is the amount of time allocated for data write after the TCP connection is established. By default, the origin write timeout is 30 seconds.\nThe origin read timeout is the amount of time that is required by the origin server to return all content requested by a CDN POP after the TCP connection is established. By default, the origin read timeout is 30 seconds.\nYou can adjust the values of the origin read timeout and origin write timeout by configuring a timeout period for HTTP origin requests.\nOrigin probing:\nAbnormal TCP connection: If the TCP connection between a CDN POP and an origin server fails or times out two times in a row, CDN removes the IP address of the origin server from the list of available origin IP addresses and adds the IP address to the dead table. In this case, subsequent origin requests are no longer sent to the IP address. Then the CDN POP connects to the origin server over TCP to probe the IP address every 5 minutes. If the TCP connection is established, Alibaba Cloud CDN restores the IP address to the list of available origin IP addresses.\nNormal TCP connection: If the TCP connection between a CDN POP and an origin server is normal, but the POP receives a retry status code such as the 5xx status code from the origin server, the IP address of the origin server is not removed from the list of available origin IP addresses. In this case, a retry is triggered and subsequent requests are still sent to the origin server based on the weight ratio. If HTTP request errors occur at Layer 7 when the TCP connection is normal, the IP address of the origin server is not automatically removed from the list of available origin IP addresses. If you want Alibaba Cloud CDN to automatically remove the IP address from the list of available origin IP addresses, submit a ticket\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Origin Fetch.\nIn the Timeout for HTTP Back-to-origin Requests section, click Modify.\nIn the Timeout for HTTP Back-to-origin Requests dialog box, configure the Timeout Value parameter.\n\nClick OK.\nBatchSetCdnDomainConfig\n"
    },
    "350": {
        "title": "CDN:Configure HTTP request headers",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-custom-request-headers",
        "content": "This Product\nCDN:Configure HTTP request headers\nBy default, Alibaba Cloud CDN supports request headers such as client IP addresses. You can also configure custom request headers. Alibaba Cloud CDN allows you to rewrite HTTP headers in origin requests. You can add, delete, change, or replace HTTP headers in origin requests based on your business requirements.\nHTTP request headers are a component of the header section in requests that are transmitted over HTTP. HTTP request headers include specific parameters that are sent to servers.\nWhen points of presence (POPs) retrieve the requested resources from an origin server, the origin server can obtain information that is included in request headers. Alibaba Cloud CDN allows you to rewrite HTTP headers in origin requests. The information that is included in request headers is passed to the origin server to meet specific business requirements. For example, you can configure the X-Forwarded-For (XFF) header to pass client IP addresses to your origin server.\nFor information about how the origin server obtains the IP address of a client from the XFF header in the origin request, see Retrieve the originating IP addresses of clients.\nAn origin request is an HTTP message that is transmitted by Alibaba Cloud CDN to the origin server of a specific accelerated domain name. A rewrite rule rewrites only the HTTP headers in requests that are transmitted between an origin server and POPs. A rewrite rule does not rewrite the HTTP headers in requests that are transmitted between POPs and clients.\nYou cannot specify custom HTTP request headers for wildcard domain names.\nBy default, Alibaba Cloud CDN supports the following HTTP request headers, which do not need to be configured.\nOrigin HTTP header\nDescription\nExample\nAli-Cdn-Real-Ip\nThe IP address that is used by the client to connect to a POP.\nAli-Cdn-Real-Ip:192.168.0.1\nX-Forwarded-For\nThe IP address of the client and IP address of a POP that is used to connect to the origin server.\nX-Forwarded-For:192.168.0.1, 172.16.0.1\nX-Client-Scheme\nThe protocol that is used by the client to send the request to a POP, such as HTTP or HTTPS.\nX-Client-Scheme:http\nHost\nThe domain name of the origin server to which the request is redirected.\nHost:example.com\nVia\nThe names of all POPs that the request passes through.\nVia:cn2546-10.l1, cache1.cn2546-10, l2cn2547-7.l2, cache1.l2cn2547-7\nIf the value of the HTTP request header is a variable, a specific value is assigned to the variable when the variable is used. The following table describes available variables.\nParameter\nOrigin HTTP header\nDescription\nExample\nAli-Cdn-Real-Port\n$http_Ali_Cdn_Real_Port\nAdds a header that passes the client port to the origin server.\nAli-Cdn-Real-Port:80\nAli_Cdn_Real_Ip\n$http_Ali_Cdn_Real_Ip\nAdds a header that passes the client IP address to the origin server.\nAli-Cdn-Real-Ip:192.168.0.1\nx_forwarded_for\n$proxy_add_x_forwarded_for\nAdds the XFF header to origin requests. The XFF header passes the client IP address and proxy IP address to the origin server.\nX-Forwarded-For:192.168.0.1, 172.16.0.1\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Origin Fetch.\nClick the Custom Request Header tab.\nClick Customize.\nConfigure the parameters in the dialog box that appears.\nWhen different operations are performed on the same request header at the same time, the operations have different priorities. The operations are prioritized in the following descending order: Replace > Add > Change or Delete. For example, if you perform the Add and Delete operations on the same request header at the same time, the request header is added and then deleted.\n\nParameter\nExample\nDescription\nOperation\nAdd\nAdds a request header to origin HTTP requests.\nRequest Header\nCustom Back-to-origin Request Headers\nYou can select a preset header, or select Custom Back-to-origin Request Headers from the Request Header drop-down list to specify a request header.\nHeader Name\nx-code\nThe name of the custom request header is x-code.\nHeader Value\nkey1, key2\nYou can specify multiple values for a request header. Separate the values with commas (,).\nAllow Duplicates\nYes\nYes: You can add duplicate request headers. Example: x-code:key1 and x-code:key2.\nNo: The latest header value overwrites the existing header value that uses the same header name. For example, if you add x-code:key1 and then add x-code:key2, x-code:key2 takes effect.\nRule Condition\nDo not use conditions\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\n\n\nParameter\nExample\nDescription\nOperation\nDelete\nThis operation deletes all request headers that match the values of the Request Header and Header Name parameters. Duplicate request headers are also deleted.\nRequest Header\nCustom Back-to-origin Request Headers\nYou can select a preset header, or select Custom Back-to-origin Request Headers from the Request Header drop-down list to specify a request header.\nHeader Name\nx-code\nThe name of the custom request header is x-code.\nRule Condition\nDo not use conditions\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\n\n\nParameter\nExample\nDescription\nOperation\nChange\nYou can perform the Change operation only if no duplicate request headers exist.\nRequest Header\nCustom Back-to-origin Request Headers\nYou can select a preset header, or select Custom Back-to-origin Request Headers from the Request Header drop-down list to specify a request header.\nHeader Name\nx-code\nThe name of the custom request header is x-code.\nChange Value To\nkey1, key3\nYou can specify multiple values for a request header. Separate the values with commas (,).\nRule Condition\nDo not use conditions\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\n\nParameter\nExample\nDescription\nOperation\nReplace\nYou can perform the Replace operation only if no duplicate request headers exist.\nRequest Header\nCustom Back-to-origin Request Headers\nYou can select a preset header, or select Custom Back-to-origin Request Headers from the Request Header drop-down list to specify a request header.\nHeader Name\nx-code\nThe name of the custom request header is x-code.\nFind\nkey\nYou can search for the value that you want to replace by using regular expressions.\nReplace With\nabc\nYou can replace matching values by using regular expressions.\nMatch\nMatch All\nMatch All: All matching values are replaced. For example, if you use a regular expression to replace all strings of \"key\" in x-code:key1,key2,key3 with abc, the key-value pair is changed to x-code:abc1,abc2,abc3.\nMatch the First Only: Only the first matching value is replaced. For example, if you use a regular expression to replace the first string of \"key\" in x-code:key1,key2,key3 with abc, the key-value pair is changed to x-code:abc1,key2,key3.\nRule Condition\nDo not use conditions\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\nClick OK.\nBatchSetCdnDomainConfig\n"
    },
    "351": {
        "title": "CDN:Rewrite origin URLs",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/rewrite-urls-in-back-to-origin-requests",
        "content": "This Product\nCDN:Rewrite origin URLs\nAlibaba Cloud CDN allows you to rewrite origin URLs. The URL rewrite feature functions on points of presence (POPs) without affecting the internal services of Alibaba Cloud CDN or the cache keys.\nPOPs match origin URLs against the URLs of the requested resources on the origin server based on URL rewrite rules. Then, the requests with specific parameters are redirected to the origin server.\nIn a rewrite rule, if you set the Flag parameter to None or Break, only the resource path in the URL is rewritten.\nIf you set the Flag parameter to enhance break, the resource path and query string are rewritten.\nYou can configure up to 50 Origin URL Rewrite rules for each domain name.\nThe system runs the rewrite rules that are listed on the Origin URL Rewrite tab in order from top to bottom. A change to this order may lead to a different rewrite result.\nOrigin URL Rewrite may conflict with the settings of the Ignore Parameters feature in Domain Names>Optimization. Make sure that the features do not conflict with each other.\nFeature\nDescription\nResult\nScenario\nRewrite access URLs\nThe URL that is accessed by clients is rewritten, and the origin URL also changes.\nThe URL seen by clients changes and is different from the actually accessed URL.\nThis feature is commonly used to map the URL of the old domain name to a new domain name or provide different URLs for mobile devices and PCs.\nExample: When a client accesses old.example.com/hello, rewrite the access URL to new.example.com/hello.\nRewrite origin URLs\nThe origin URL is rewritten, and the access URL remains unchanged.\nThe URL seen by clients remains unchanged and is the same as the actually accessed URL.\nThis feature is commonly used to hide the actual URLs of origin servers to protect information about origin servers. You can also use this feature to map URLs to allow POPs to retrieve content from different origin directories.\nExample: When a client accesses cdn.example.com/hello, rewrite the origin URL to origin.example.com/source/hello.\nA client initiates a request to a POP. The request URL is old.example.com/hello.\nAfter the POP receives the request, the POP adds the new URL to the HTTP Location header in the response that is returned together with an HTTP status code 302, and rewrites the request URL to new.example.com/hello based on access URL rewrite rules.\nAfter the client receives the response and the HTTP status code 302, the client initiates a request to the new URL.\nThe POP checks the cache. If the content that corresponds to the rewritten URL exists in the cache, the POP returns the content to the client. If not, the POP initiates a request to the origin server. The request URL is new.example.com/hello, which is rewritten.\nThe origin server receives the request and returns the requested content to the POP.\nThe POP caches the requested content and returns the requested content to the client.\nA client initiates a request to a POP. The request URL is cdn.example.com/files/hello.txt.\nAfter the POP receives the request, the POP checks the cache. If the content that corresponds to the request URL exists in the cache, the POP returns the content to the client. If not, the POP rewrites the origin URL to origin.example.com/secret/files/hello.txt based on origin URL rewrite rules and initiate a request to the origin server.\nThe origin server receives the request and returns the requested content to the POP.\nThe POP caches the requested content and returns the requested content to the client.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Origin Fetch.\nClick the Origin URL Rewrite tab.\nClick Add.\nConfigure the Path to Be Rewritten, Target Path, and Flag parameters. The following table describes the parameters.\n\nParameter\nExample\nDescription\nPath to Be Rewritten\n^/hello$\nEnter a URL that starts with a forward slash (/). The URL cannot contain http:// or domain names. You must use Perl Compatible Regular Expressions (PCRE).\nTarget Path\n/hello/test\nEnter a URL that starts with a forward slash (/). The URL cannot contain http:// or domain names. PCRE is supported.\nFlag\nNone\nIf you configure multiple URL rewrite rules, Alibaba Cloud CDN matches requests against the rules in order from top to bottom.\nbreak\nIf you configure multiple URL rewrite rules, and the current rule is matched, other rules are skipped.\nThis option rewrites only the resource path in the URL. The URL parameters remain unchanged. You can use the parameter rewrite feature to rewrite URL parameters.Origin URL Rewrite\nenhance break\nIf you configure multiple URL rewrite rules, and the current rule is matched, other rules are skipped.\nCompared with break, enhance break also rewrites URL parameters. However, the parameter rewrite settings may conflict with the settings of Parameter rewrite. If you want to enable both features, make sure that the settings do not conflict with each other.\nClick OK to apply the rule.\nThe new rewrite rule is displayed on the Origin URL Rewrite tab. You can click Modify or Delete in the Actions column of the rewrite rule to modify or delete the rewrite rule.\nPath to Be Rewritten\n^/hello$\nTarget Path\n/index.html\nFlag\nNone\nExpected result\nOriginal request: http://example.com/hello\nFinal request: http://example.com/index.html\nThe system continues to match the request against other URL rewrite rules that are listed on the Origin URL Rewrite tab.\nPath to Be Rewritten\n^/hello.jpg$\nTarget Path\n/image/hello.jpg\nFlag\nbreak\nExpected result\nOriginal request: http://example.com/hello.jpg\nFinal request: http://example.com/image/hello.jpg\nThe system stops matching the request against other URL rewrite rules that are listed on the Origin URL Rewrite tab.\nPath to Be Rewritten\n^/hello.jpg?code=123$\nTarget Path\n/image/hello.jpg?code=321\nFlag\nenhance break\nExpected result\nOriginal request: http://example.com/hello.jpg?code=123\nFinal request: http://example.com/image/hello.jpg?code=321\nThe system stops matching the request against other URL rewrite rules that are listed on the Origin URL Rewrite tab.\nAdd the /image path to the URLs of all files in the root directory. For example, rewrite /xxx in URLs to /image/xxx. In this example, xxx is a file name, such as hello.jpg or hello.html.\nPath to Be Rewritten\n^(.*)$\n^ matches a string from the beginning of the string. (.*) is a group, in which . matches any character except a line feed. * matches the preceding character or group zero or more times. You can use $1 in the target path to reference the variable content of the group. $ matches a string to the end of the string. ^(.*)$ matches a string from the beginning to the end of the string, which can contain any character except a line break, and then captures the matched content into a group. For example, for a string \"hello world\", ^(.*)$ matches the entire string and captures \"hello world\" into the first group.\nTarget Path\n/image$1\n/image matches the string \"/image\". $1 references the content of the first group, $2 references the content of the second group, and so forth. /image$1 matches the string \"/image\" followed by the content of the first group. For example, if the content of the first group is \"abc\", /image$1 matches the string \"/imageabc\". Note that the $1 references the content of the group instead of the literal \"$1\". If you want to match the literal \"$1\", use the escaped string \"\\$1\".\nFlag\nbreak\nExpected result\nOriginal request: http://example.com/hello.jpg\nFinal request: http://example.com/image/hello.jpg\nOriginal request: http://example.com/hello.html\nFinal request: http://example.com/image/hello.html\nThe system stops matching the request against other URL rewrite rules that are listed on the Origin URL Rewrite tab.\nAdd the /image path to the URLs of all files in the /live directory. For example, rewrite /live/xxx in URLs to /image/live/xxx. In this example, xxx is a file name, such as hello.jpg or hello.html.\nPath to Be Rewritten\n^/live/(.*)$\nTarget Path\n/image/live/$1\nFlag\nbreak\nExpected result\nOriginal request: http://example.com/live/hello.jpg\nFinal request: http://example.com/image/live/hello.jpg\nOriginal request: http://example.com/live/hello.html\nFinal request: http://example.com/image/live/hello.html\nThe system stops matching the request against other URL rewrite rules that are listed on the Origin URL Rewrite tab.\nCreate two URL rewrite rules, as shown in the following figure.\nExpected result:\nOriginal request: http://example.com/image_01.png\nFinal request: http://example.com/image/image_02.png\nThe request matches the first rule and the origin URL is rewritten to http://example.com/image_02.png. Then, the request matches the second rule and the origin URL is rewritten to http://example.com/image/image_02.png.\nCreate two URL rewrite rules, as shown in the following figure.\nExpected result:\nOriginal request: http://example.com/image_01.png\nFinal request: http://example.com/image_02.png\nThe request matches the first rule and the request URL is rewritten to http://example.com/image_02.png. Other rules are skipped.\n"
    },
    "352": {
        "title": "CDN:Refresh and prefetch resources",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/refresh-and-prefetch-resources",
        "content": "This Product\nCDN:Refresh and prefetch resources\nThe refresh feature allows you to remove cached resources from CDN nodes, compelling the CDN nodes to retrieve the most recent resources from the source server. This feature is useful in situations such as updating and releasing resources, removing non-compliant content, or making domain name configuration adjustments. The prefetch feature enables you to preload popular resources onto CDN nodes ahead of high-traffic periods, thereby reducing the burden on the source server and enhancing the user experience.\n\nRefresh: This feature marks the cached resources on all CDN nodes as invalid. When users request these resources again, CDN retrieves the updated content from the origin server and delivers it to the users, simultaneously recaching the resources on the CDN nodes. This process can lead to a reduced cache hit ratio.\nPrefetch: This feature allows the origin server to proactively cache resources on CDN nodes. When you first request these resources, you can directly retrieve the latest versions from the CDN nodes, bypassing the origin server. This process enhances the cache hit ratio.\nFunction\nApplicable scenarios\nRefresh\nResource Updates And Releases\nAfter the old resources on the origin server are updated or upgraded, you can submit the URLs or directories of the corresponding resources for refresh to prevent users from accessing outdated cached resources. Users can then directly access the latest resources, which are cached on CDN nodes.\nRemoval Of Non-compliant Resources\nIf your origin server contains non-compliant content as mentioned in the Limits, after you delete the resources from the origin server, the resources may still be accessible due to caching on CDN nodes. You can use the URL refresh feature to update the cached resources.\nPrefetch\nFirst-time integration with Alibaba Cloud CDN\nAfter you integrate with CDN for the first time, you can choose to prefetch your hot static resources in advance. When users access the resources, the CDN acceleration nodes can directly respond, improving access speed and avoiding slow initial access.\nOperational Activities\nWhen operating a large-scale event, prefetch the static resources involved in the event page to CDN nodes in advance. After the event starts, all static resources accessed by users are cached on CDN acceleration nodes and directly responded to by the acceleration nodes.\nInstallation Packages Or Other Large File Releases\nBefore releasing new version installation packages or upgrade packages, prefetch the resources to CDN acceleration nodes. After the product is officially published, the download requests from many users are directly responded to by CDN acceleration nodes, improving download speed, significantly reducing the load on the origin server, and enhancing user experience.\nSubmitting numerous refresh tasks can significantly clear the cache, leading to an increase in back-to-origin bandwidth and requests, which in turn increases the load on the origin server. It is advisable to perform this operation during periods of low website traffic.\nA refresh task typically takes effect within 5 to 6 minutes of submission. If the cache expiration time for files or directories is less than 5 minutes, there is no need to refresh as the cache will automatically update upon expiration.\nURL refresh, directory refresh, and regex refresh all support shared cache. When a domain name is configured with shared cache, you can submit a refresh task for the primary domain name or any associated domain names to clear the cache.\nAfter you submit and successfully execute a prefetch task, CDN nodes will immediately retrieve the necessary resources from the source server. Consequently, numerous prefetch tasks can lead to a substantial number of concurrent back-to-origin tasks, causing a sharp rise in back-to-origin bandwidth and requests. It is advisable to carry out this operation when your website experiences low traffic.\nEach account has a maximum prefetch queue capacity of 100,000 URLs. CDN processes prefetch requests in the order they were submitted. If the prefetch queue reaches its capacity of 100,000 URLs, CDN will not accept new prefetch tasks.\nThe time required to complete a prefetch task varies depending on the file sizes. It typically takes between 5 to 30 minutes, with smaller files being prefetched more quickly.\nOnce URL refresh or cache prefetch tasks are successfully issued, they cannot be stopped until completion.\nRAM users require authorization to perform refresh and prefetch operations. For more information, see Grant RAM Users Refresh and Prefetch Permissions.\nBoth refresh and prefetch have daily quotas. If your Alibaba Cloud account's daily bandwidth peak exceeds 200 Mbps, you can request an increase in the daily quota through Quota Management. Alibaba Cloud will evaluate and adjust based on your actual business needs.\nFor more information about refresh and prefetch precautions and issues, see FAQ about Refresh and Prefetch.\nIf you experience slow access after configuring CDN, it is recommended to troubleshoot the issue using the suggested document before updating resources with the refresh feature. For more information, see Troubleshoot Slow Website Access after Using Alibaba Cloud CDN Acceleration.\nFor website access issues, see Troubleshoot Inaccessible or Abnormal Access Issues.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Purge and Prefetch.\nOn the Purge/Prefetch tab, select  Refresh  as the operation type.\nSelect the appropriate operation method:  URL,  Directory, or  Regex.\nEnter or upload the data to be processed in the URL field.\nClick Submit.\nView the refresh progress.\nIf you have enabled auto CDN cache update in the OSS console, the auto CDN cache update tasks for OSS will not be visible in the CDN  console.\nOperation method\nRelated introduction\nPrecautions\nURL\nURL refresh refers to refreshing a single file. You need to enter the complete URL path of a single file. Include the protocol header, domain name, path, and file. For example: https://www.example.com/static/picture/earth.jpg\nWhen refreshing multiple URLs, enter one URL per line.\nAn account can submit up to 10,000 URL refreshes per day.\n\nDirectory\nRefresh all files in the folder through the URL path you enter. You need to enter the complete URL directory, which must end with a /. Include the protocol header, domain name, and path. For example: https://www.example.com/static/picture/\nWhen refreshing multiple URL directories, enter one URL per line.\nYou can submit up to 100 directory refreshes at a time, and up to 100 directory refreshes for a domain name per minute.\nDirectory refresh uses the \"refresh changed resources\" method by default. If the Last-Modified information of the resources requested by users has not changed, the old cache information is returned directly without retrieving from the origin server. If you need to force refresh the cache, refer to RefreshObjectCaches - Refresh cache.\nRegex\nRefreshes based on URLs with regular expressions. If the URL you entered matches the regular expression, it will be refreshed. For example: http://www.example.com/static/picture/[0-9][a-z].*.jpg\nAn account can submit up to 20 URLs containing regular expressions per day.\nFor more information about regex refresh, see Regex refresh description.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Purge and Prefetch.\nOn the Purge/Prefetch tab, select Prefetch as the operation type.\nSelect the appropriate  URL  for the operation method.\nEnter or upload the data to be processed in the URL field.\nClick Submit.\nView the prefetch progress.\nOperation method\nRelated introduction\nPrecautions\nURL\nURL prefetch refers to the prefetching of a single file. You need to enter the complete URL path of a single file. Include the protocol header, domain name, path, and file. For example: https://www.example.com/static/video/earth.mp4\nWhen prefetching multiple URLs, enter one URL per line.\nDirectories ending with / are not supported.\nAn account can submit up to 100 URL prefetch tasks at a time and up to 1,000 URL prefetch tasks per day.\n\n\nFor automating refresh or prefetch tasks, see Use Automated Scripts for Refresh and Prefetch.\nManual Query\nYou can view detailed records and monitor the progress of resource refresh or prefetch tasks on the Records tab. A progress indicator at 100% signifies that the task has been completed. Should the volume of prefetch or refresh tasks be excessive, it may slow down the overall completion rate. Your patience is appreciated.\n\nAPI Query\nUse the DescribeRefreshTaskById API to check the status of refresh or prefetch tasks. For more information, see DescribeRefreshTaskById - Query Refresh Prefetch Task by ID.\nExecute the following command to check the prefetch results of the file:\nThe system will display the following result:\n\nIf the X-Cache header is present:\nIf X-Cache shows HIT, this means the request successfully hit the cache and the prefetch was effective.\nIf X-Cache shows MISS, this means the request did not hit the cache, either because the prefetch task is incomplete or it failed. You can try prefetching again.\nIf the X-Cache header is absent:\nThe absence of the X-Cache header indicates that the resource is not using Alibaba Cloud CDN. Integrate the domain name of the URL with Alibaba Cloud CDN before prefetching the resource by referring to Quickly Integrate with Alibaba Cloud CDN.\nWhat to Do if Prefetch Fails?\nTroubleshoot Inaccessible or Abnormal Access Issues.\nWhy Aren't Resources Updated After Using the CDN Refresh Prefetch Feature?\nHow to Update Files with the Same Name After Configuring CDN?\nHow to Check if the Prefetch Task of CDN is Complete?\nYou can call API operations to refresh and prefetch resources. For more information, see Refresh and Prefetch API.\n"
    },
    "353": {
        "title": "CDN:Range origin fetch",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/object-chunking",
        "content": "This Product\nCDN:Range origin fetch\nIf a request that is redirected from a point of presence (POP) to the origin server includes the Range header, the origin server returns the content that is specified by the Range header to the POP. This process is called range origin fetch. Range origin fetch accelerates content delivery, increases cache hit ratios, reduces origin traffic and loads on origin servers, and speeds up site response.\nThe Range header is an HTTP header that specifies the part of content to be retrieved. For example, Range: bytes=0-100 specifies that the origin server is required to return the first 101 bytes in the requested file.\nAfter you enable the range origin fetch feature, requests for resources that have expired or are not cached on POPs are redirected to the origin server with the Range header retained. Then, Alibaba Cloud CDN retrieves the specified file chunk from the origin server and caches the file chunk on POPs.\nThe following figure shows how the range origin fetch feature works.\nWhen you enable the range origin fetch feature, take note of the following rules:\nMake sure that the origin server supports HTTP range requests, and the origin server can respond to requests with the HTTP 206 status code (partial content message). If the origin server does not support HTTP range requests, resources cannot be cached on POPs after range origin fetch is enabled.\nThe range origin fetch feature is optional and is disabled by default.\nThe Multipart Ranges feature is disabled by default and is not enabled after you enable the range origin fetch feature. To enable the Multipart Ranges feature, submit a ticket.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Video.\nIn the Range Origin Fetch section, click Modify.\nSet the Range Origin Fetch parameter to Do Not Enable Range Origin Fetch, Match Client, or Enable Range Origin Fetch (Recommended for Large File Delivery).\nParameter\nDescription\nExample\nRange Origin Fetch\nDo Not Enable Range Origin Fetch\nThis is the default option. POPs retrieve the entire file from the origin server regardless of whether the request carries the Range header. In this case, the file distribution efficiency is lower than expected in large file distribution scenarios.Do Not Enable Range Origin Fetch\nA client sends a request that contains range:0-100 to a POP. The POP redirects the request to the origin server without the Range header. The origin server returns the entire file to the POP. If the total size of the file is 10 MB, the origin server returns 10 MB of file data to the POP. The POP caches the received file and returns the chunk that is specified by range:0-100 to the client.\nMatch Client\nIf you choose Match Client, POPs redirect requests with the Range header retained to the origin server. For the first request for a resource that is redirected to the origin server, Alibaba Cloud CDN rounds up the value of the Range header to the nearest integer. For subsequent requests for the resource, Alibaba Cloud CDN sets the value of the Range header to 512 KB.\nFor example, a client requests content that is 600 KB in size. The POP retrieves content that is 1,024 KB in size from the origin server for the first request and retrieves content that is 512 KB in size for subsequent requests.\nA client sends a request that contains range:0-100 to a POP. The POP requests a file chunk that is 512 KB in size from the origin server. The origin server returns the file chunk. Then, the POP caches the file chunk and returns it to the client.\nEnable Range Origin Fetch (Recommended for Large File Delivery)\nIf you choose Enable Range Origin Fetch (Recommended for Large File Delivery), POPs redirect the requests of a client to the origin server with the Range header retained, regardless of whether the requests contain the Range header. Every range request pulls content that is 512 KB in size from the origin server.\nNone.\nRule Condition\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\n\nClick OK.\nBatchSetCdnDomainConfig"
    },
    "354": {
        "title": "CDN:Enable HTML optimization",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/enable-html-optimization",
        "content": "This Product\nCDN:Enable HTML optimization\nThe HTML optimization feature allows Alibaba Cloud CDN to automatically remove redundant content from web pages, such as comments and additional whitespace characters in HTML pages, CSS code, and JavaScript code. This reduces file sizes, accelerates content delivery, and improves website readability.\nIf MD5 verification is configured for files on the origin server, do not enable HTML optimization.\nThe HTML optimization feature changes the MD5 value of a file. After the file is optimized, the MD5 value of the file is no longer the same as that of the original file that is stored on the origin server.\nIf the origin server has Gzip or Brotli compression enabled, HTML optimization does not take effect. Alibaba Cloud CDN directly returns compressed files to clients.\nIf you want to use the HTML optimization feature in Alibaba Cloud CDN without disabling Gzip or Brotli compression on the origin server, you can delete the Accept-Encoding header from the origin HTTP headers. After you delete the Accept-Encoding header, the HTML optimization feature takes effect. For more information about how to delete the Accept-Encoding header, see Configure custom request headers.\nIf both HTML optimization and compression are enabled, HTML optimization does not take effect. Alibaba Cloud CDN only compresses files.\nIn some special cases, if you enable the HTML optimization feature to rewrite HTML files, CSS files, and JavaScript files on the webpages, the business logic of the website may be affected, and an error message similar to the following one may be returned when a client accesses the rewritten webpages: Hydration completed but contains mismatches. To fix the error, disable HTML optimization.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Optimization.\nIn the HTML Optimization section, turn on HTML Optimization, CSS Optimization, or JavaScript Optimization.\nThe HTML Optimization switch controls only HTML optimization. If you want to enable CSS or JavaScript optimization, you need to first turn on HTML Optimization, and then turn on CSS Optimization or JavaScript Optimization.\n\nTurn on HTML Optimization: Alibaba Cloud CDN optimizes HTML pages.\nTurn on CSS Optimization: Alibaba Cloud CDN optimizes CSS styling.\nTurn on JavaScript Optimization: Alibaba Cloud CDN optimizes JavaScript code.\nBatchSetCdnDomainConfig\n"
    },
    "355": {
        "title": "CDN:Configure Gzip compression",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/use-the-gzip-compression-feature",
        "content": "This Product\nCDN:Configure Gzip compression\nAfter you enable the Gzip compression feature, Alibaba Cloud CDN points of presence (POPs) use Gzip compression to compress resources before the resources are returned to clients. The Gzip compression feature reduces file sizes, accelerates file distribution, and reduces bandwidth consumption.\nCompression is divided into Gzip compression and Brotli compression. The Gzip compression feature uses the Gzip compression algorithm. For more information about Brotli compression, see Configure Brotli compression.\nYou can use the Gzip compression or Brotli compression feature to compress the files on the origin server whose size ranges from 1 KB to 10 KB. Files that are smaller than 1 KB or larger than 10 MB are not compressed.\nThe Gzip compression feature supports the following formats: text/xml, text/plain, text/css, application/javascript, application/x-javascript, application/rss+xml, text/javascript, image/tiff, image/svg+xml, application/json, and application/xml.\nIf a request carries the Accept-Encoding: gzip request header, the client wants to use Gzip compression to compress the requested resources.\nIf a response from the origin server carries the Content-Encoding: gzip response header, the resources returned to the client are Gzip-compressed.\nThe Gzip compression feature is compatible with all browsers. The Brotli compression feature is not compatible with outdated browsers. You can query whether a browser supports Brotli compression based on your business requirements.\nWhen Alibaba Cloud CDN compresses static files, the MD5 values of the files are changed. If MD5 verification is used in the service logic for your website, clients verify the MD5 values of files that are retrieved from POPs. If the MD5 value of a file is different from the MD5 value in the response header, the client considers the file download failed. In this case, you need to disable Gzip compression and Brotli compression.\nIf compression is enabled on the origin server and the response from the origin server contains Content_Encoding, compression on POPs does not take effect.\nIf both the Gzip compression and Brotli compression features are enabled, and the Accept-Encoding request header contains both br and gzip, only the Brotli compression feature takes effect.\nIf both HTML optimization and compression are enabled, HTML optimization does not take effect. Alibaba Cloud CDN only compresses files.\nImage files in common formats, including PNG, JPG, and JPEG, and video files in common formats, including MP4, AVI, and WMV, are already compressed. The Gzip compression and Brotli compression features do not take effect for these files. We recommend that you disable Gzip compression and Brotli compression for such files. If you want to reduce the size of image files, you can use the image editing feature. For more information, see Image editing overview. If you want to reduce the size of video files, you can use the video transcoding feature. For more information, see Audio and video transcoding.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Optimization.\nIn the Gzip Compression section, turn on Gzip Compression.\nYou can compare the format of a file before and after the Gzip compression feature is enabled. If the file name extension is .gzip, the file is compressed.\n\nWhy does Gzip compression fail to take effect for requests redirected to the origin server?\nBatchSetCdnDomainConfig\n"
    },
    "356": {
        "title": "CDN:Configure Brotli compression",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-brotli-compression",
        "content": "This Product\nCDN:Configure Brotli compression\nBrotli is a new open source compression algorithm, which has better performance than Gzip. After you enable Brotli compression, points of presence (POPs) compress resources before the resources are returned to clients. This reduces file sizes, accelerates file distribution, and reduces bandwidth consumption.\nCompression can be implemented by using Gzip or Brotli. Intelligent compression uses Gzip to compress files. For more information about intelligent compression, see Configure Gzip compression.\nYou can use the Gzip compression or Brotli compression feature to compress the files only if the size of files on the origin server ranges from 1 KB to 10 MB. Files that are smaller than 1 KB or larger than 10 MB are not compressed.\nBrotli compression supports the following formats: text/xml, text/plain, text/css, application/javascript, application/x-javascript, application/rss+xml, text/javascript, image/tiff, image/svg+xml, application/json, and application/xml.\nIf a response from the origin server includes the Content-Encoding: br response header, the resources that are returned to the client are Brotli-compressed.\nIf a request includes the Accept-Encoding: br request header, the client expects the requested resources to be Brotli-compressed.\nWhen Alibaba Cloud CDN compresses static files, the MD5 values of the files are changed. If files on the origin server have MD5 verification enabled, disable Gzip compression and Brotli compression.\nIf compression is enabled on the origin server and the response from the origin server carries content_encoding, compression on POPs does not take effect.\nIf both Brotli compression and Gzip compression are enabled, and the Accept-Encoding request header includes both br and gzip, only Brotli compression takes effect.\nIf both HTML optimization and compression are enabled, HTML optimization does not take effect. Alibaba Cloud CDN only compresses files.\nBrotli is not compatible with all browsers. You can query whether a browser is compatible with Brotli as needed.\nCommon types of image files such as PNG, JPG, and JPEG and video files such as MP4, AVI, and WMV are already compressed. Gzip compression and Brotli compression do not take effect for these files. We recommend that you disable compression. If you want to reduce the size of image files, you can use the image editing feature. For more information, see Image editing overview. If you want to reduce the size of video files, you can use the video transcoding feature. For more information, see Audio and video transcoding. Both image editing and video transcoding reduce image resolution.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Optimization.\nIn the Brotli Compression section, turn on Brotli Compression and configure the parameters based on your business requirements.\nAfter you enable Brotli compression, you can compare the format of a file before and after compression is performed. If the file name extension is .br, the file is compressed.\nBatchSetCdnDomainConfig\n"
    },
    "357": {
        "title": "CDN:Image editing",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/image-editing/",
        "content": "This Product\nCDN:Image editing"
    },
    "358": {
        "title": "CDN:Video seeking",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/video-seeking",
        "content": "This Product\nCDN:Video seeking\nThe video seeking feature helps users navigate through video or audio content by dragging the playback progress bar. This topic describes how to configure video seeking on the CDN console.\nAfter you enable video seeking, the time to first byte (TTFB) is increased by about 30 ms, which may have a minor effect on user experience.\nWhen video seeking is enabled, the client sends a URL request to the server to load the desired video segment whenever a user adjusts the playback position. At the same time, CDN identifies the nearest keyframe preceding the specified position if it is not a keyframe. Since a keyframe contains a complete image, this mechanism ensures a seamless keyframe-by-keyframe playback experience for users.\nThe origin server supports HTTP range requests.\nThe Ignore parameters feature is disabled.\nThe metadata of a MP4 file on the origin server must be included in the file header instead of the file tail.\nThe start parameter specifies the position in seconds, rounded to the third decimal point. For example, start=1.01 indicates that the playback starts at 1.01 seconds into the video.\nIf the start parameter specifies a position that is not a keyframe, CDN automatically locates the last keyframe before the position.\nIf the start parameter is a keyframe, CDN automatically locates the keyframe.\nFor example, the request URL http://domain/video.mp4?start=10 specifies that the video is played from the 10th second.\nFLV files on the origin server must contain metadata.\nThe start parameter specifies the position in bytes. Decimals are not supported, and the value is rounded down to the nearest positive integer. However, If you turn on Time-based FLV Seeking, the unit of the start and end parameters is second.\nSeeking by bytes is suitable for precise data handling or when working with raw video data, while seeking by seconds provides a user-friendly experience by moving to the exact second requested.\nIf the start parameter specifies a position that is not a keyframe, CDN automatically locates the last keyframe before the specified position.\nIf the start parameter is a keyframe, CDN automatically locates the keyframe.\nFor example, the request URL http://domain/video.flv?start=10 specifies that the video is played from the 10th byte.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Video.\nIn the Video Seeking section, turn on Video Seeking.\nOptional. Allow FLV files to be sought by time\nTurn on Time-based FLV Seeking.\nOptional. Customize parameters for video seeking.\nClick Modify to the right of Custom Parameters. In the Customize Parameters for Video Seeking dialog box, customize the start and end parameter names.\nThe default names of the start and end parameters are start and end. Parameter names can contain letters, digits, and underscores (_).\nClick OK.\nYou can call the BatchSetCdnDomainConfig operation to configure video seeking. For more information on related parameters, see Feature settings for domain names."
    },
    "359": {
        "title": "CDN:Configure a Referer whitelist or blacklist to enable hotlink protection",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-a-referer-whitelist-or-blacklist-to-enable-hotlink-protection",
        "content": "This Product\nCDN:Configure a Referer whitelist or blacklist to enable hotlink protection\nReferer-based hotlink protection refers to access control based on the Referer header. You can configure a Referer whitelist or blacklist to control access, protecting your resources from unauthorized access. After you configure a Referer whitelist or blacklist, Alibaba Cloud CDN allows or rejects requests based on the Referer header.\nBy default, Referer-based hotlink protection is not enabled in Alibaba Cloud CDN. This means that all websites can access your resources.\nReferer-based hotlink protection is a method to prevent data transmission abuse. For more information about protection methods, see Prevent data transmission abuse.\nAfter you add a domain name to the Referer whitelist or blacklist, the wildcard domain name that matches the domain name is automatically added to the whitelist or blacklist. For example, if you add aliyundoc.com to the Referer whitelist or blacklist, hotlink protection takes effect for all domain names that match *.aliyundoc.com.\nThe Referer header is a component of the header section in HTTP requests and contains information about the source address and is used to identify the source of a request. The Referer header consists of the scheme, domain, path, and parameters. The following figure describes the structure of the Referer header.\nThe protocol and domain name are required, and the path and query parameters are optional.\nAlibaba Cloud allows you to specify only domain names as Referers by selecting Ignore Scheme.\nA Referer whitelist or blacklist is suitable for the following scenarios:\nCopyright protection: To safeguard copyrighted content on your website, you can use a Referer whitelist or blacklist to allow only authorized websites to access the content.\nHotlink protection: Referer whitelists or blacklists can prevent your resources from being used by other websites.\nEnhanced website security: Only domain names that are included in the Referer whitelist are allowed to access your website resources. This prevents malicious hotlinking or theft of sensitive information.\nTraffic source management: You can manage the domains that are authorized to use your resources. This ensures the security and stability of your website.\nYou can use the hotlink protection feature in different scenarios to protect your website assets, manage traffic, and improve website security.\nThe server checks the Referer field of each request and rejects a request if the Referer field in the request does not match the pre-configured whitelist. This helps save bandwidth and server resources. Referer rules in Alibaba Cloud CDN:\nIf the Referer header in the request is included in the Referer blacklist or is not included in the Referer whitelist, Alibaba Cloud CDN rejects the request.\nIf the Referer header in the request is included in the Referer whitelist, Alibaba Cloud CDN allows the request.\nAfter you configure Referer-based hotlink protection, requests from clients in the Referer blacklist can still reach points of presence (POPs). However, POPs reject the requests and return HTTP 403 status code. The requests are recorded in Alibaba Cloud CDN logs.\nReferer-based hotlink protection refers to access control based on the Referer header. You are charged for data transfer that is generated when POPs block requests from clients in the blacklist and HTTPS requests if clients request resources over HTTPS.\nData transmission abuse is from Internet access. Therefore, Referer-based hotlink protection rules apply only to public domain names.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Access Control.\nOn the Hotlink Protection tab, click Modify.\nConfigure the parameters listed in the following table based on your business requirements.Referer-based hotlink protection parameters\nClick OK.\nParameter\nDescription\nType\nBlacklist\nRequests whose Referer field is in the Referer blacklist cannot access the resources.\nWhitelist\nOnly requests whose Referer field is in the Referer whitelist can access the resources.\nThe whitelist and blacklist are mutually exclusive. You can configure only one of the lists.\nRules\nYou can add multiple domain names to the Referer whitelist or blacklist. Separate domain names with carriage return characters.\nYou can use asterisks (*) as wildcards to match all domain names. For example, *.example.com matches all subdomains of example.com.\nYou can also omit the asterisk (*) to match the domain and its all subdomains. For example, example.com matches example.com and *.example.com.\nThe content that you enter in the Rules field cannot exceed 60 KB.\nYou do not need to specify the protocol when you configure rules.\nRedirect URL\nIf a request is blocked, HTTP status code 302 and the Location header are returned. This parameter is the value of the Location header. The value must start with http:// or https://, such as http://www.example.com.\nAdvanced Settings\nAllow resource URL access from browsers\nBy default, the check box is not selected. If you select the check box, requests that contain an empty Referer header are allowed to access CDN resources, regardless of whether you configure a Referer whitelist or blacklist.\nAn empty Referer header may suggest one of the following scenarios:\nThe Referer header is not included in the requests.\nThe Referer header is included, but the value is empty.\nExact Match\nBy default, the check box is not selected. After you select this check box, you cannot omit the asterisk (*) for matching. If the asterisk (*) is not used, example.com matches only example.com.\nIgnore Scheme\nIf you do not select Ignore Scheme, the value of the Referer header must start with http:// or https://.\nIf you select Ignore Scheme, the value of the Referer header does not need to start with http:// or https://.\nRule Condition\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\nThe curl command is used to verify the Referer header. -e is followed by the value of the Referer header, and -I is followed by the accelerated domain name. The header information is returned. In this example, the whitelist is used.\nIn this scenario, only a rule aliyun.com is configured. The Redirect URL, Advanced Settings, and Rule Condition parameters are not configured.\nRequests whose Referer header contains http(s)://aliyun.com or its subdomains are matched. Requests whose Referer header is not in the whitelist are rejected.\nRun the following command to verify a request whose Referer header contains the root domain: curl -e http://aliyun.com -I DomainName\n\nRun the following command to verify a request whose Referer header contains the subdomain: curl -e http://sub.aliyun.com -I DomainName\n\nRun the following command to verify a request whose Referer header contains another domain: curl -e http://aIiyun.com -I DomainName\n\nRun the following command to verify a request whose Referer header is empty: curl -e \" \" -I DomainName\n\nRun the following command to verify the Referer header that contains only the configured domain: curl -e aliyun.com -I DomainName\n\nIn this scenario, a rule aliyun.com is configured and Allow resource URL access from browsers is selected. Other options in Advanced Settings are not selected. The Redirect URL and Rule Condition parameters are not configured.\nCompared with the scenario 1, requests whose Referer header is empty are matched. This way, requests whose Referer header is empty and direct access requests are allowed.\nRun the following command to verify a request whose Referer header is empty: curl -I DomainName\n\nRun the following command to verify a request whose Referer header contains \" \": curl -e \" \" -I DomainName\n\nIn this scenario, a rule aliyun.com is configured and Ignore Scheme is selected. Other options in Advanced Settings are not selected. The Redirect URL and Rule Condition parameters are not configured.\nCompared with the scenario 1, requests whose Referer header does not contain the protocol, such as aliyun.com, are allowed.\nRun the following command to verify a request whose Referer header does not contain the protocol: curl -e aliyun.com -I DomainName\n\nIn most cases, the HTTP or HTTPS string is included in the Referer header in a request.\nHowever, in some cases, when a browser navigates a request from a website that does not use HTTPS to a website that uses HTTPS, the browser may present only the domain name in the Referer header. This is to protect sensitive user data based on security policies such as Referrer-Policy.\nIn addition, some browsers or proxy servers may automatically exclude the Referer string in specific scenarios, such as access in private browsing mode or by using an anonymous proxy.\nTherefore, in actual practice, take note of the scenarios in which HTTP or HTTPS is not included in the Referer header when you configure hotlink protection. If you want to allow requests whose Referer header does not include HTTP or HTTPS, select Ignore Scheme.\nIn most cases, the Referer header in a request contains the full URI, which includes the protocol, such as http or https, the hostname, and possibly the path and query string. The Referer header in a request may be empty due to the following reasons:\nDirect access: If a user enters a URL in the address bar of a browser, uses a bookmark, or opens a new blank browser tab, the Referer header is empty because a referring page does not exist.\nUser privacy settings: Users configure private browsing mode or use privacy-focused extensions to remove the Referer header out of privacy concerns.\nSecurity protocol: If a request is redirected from an HTTPS page to an HTTP page, the browser does not present the Referer header to prevent leakage of sensitive information.\nClient policy: For security purposes, some websites or applications may restrict the browser from sending the Referer header by specifying the <meta> tag or HTTP headers, such as Referrer-Policy.\nCross-origin requests: Specific cross-origin requests may not include the Referer header based on the security policy of the browser.\n\nThe handling measures vary with different scenarios and security requirements:\nDefault policy: If your service does not rely on the Referer header, you can allow requests that have an empty Referer header.\nAllow access: For specific URLs or sources, you can select Allow resource URL access from browsers to allow only requests from these URLs or sources. This way, POPs allow users to access your resources regardless of whether the Referer header is empty.\n"
    },
    "360": {
        "title": "CDN:URL signing",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/url-signing/",
        "content": "This Product\nCDN:URL signing"
    },
    "361": {
        "title": "CDN:Configure remote authentication",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-remote-authentication",
        "content": "This Product\nCDN:Configure remote authentication\nIf you have your own authentication server, you can configure remote authentication to forward user requests to the specified authentication server for verification.\nRemote authentication and URL signing both aim to protect resources by ensuring only authorized users have access. Unauthorized users will be denied access. The technical implementation of these two features differs as follows:\nURL signing: Authentication rules created for a domain name are applied to CDN edge nodes, which complete the authentication process.\nRemote authentication: CDN edge nodes receive client requests and redirect them to your specified authentication server for verification.\nThe data interaction process of the remote authentication feature is as follows:\nOrdinal number\nInteraction description\n\u2460\nA client sends a resource access request to a CDN edge node. The request carries parameters that are used for authentication. Example:\nOriginal request URL: https://example.com/123/test.txt?key=xxxxxxxxxx\nHeader carried in the original request: test=123\n\u2461\nThe CDN edge node receives the request and redirects it to the authentication server. You can specify whether the request is processed by the CDN edge node before it is redirected to the authentication server. Example:\nAuthentication server address: https://192.0.2.1/auth\nThe remote authentication feature in the CDN console is set to: Retain all request parameters and Retain all request headers\nThe request URL forwarded by the CDN to the authentication server is: https://192.0.2.1/auth?key=xxxxxxxxxx\nThe request forwarded by the CDN to the authentication server includes the header: test=123\n\u2462\nThe authentication server checks the parameters in the request and returns the authentication result to the CDN edge node.\n\u2463\nThe CDN edge node performs the specified action based on the authentication result and returns data to the client.\nExamples of authentication results are as follows:\nExample 1: The request passes the authentication. The CDN edge node returns the requested resources to the client.\nExample 2: The request fails the authentication. The CDN edge node returns the HTTP 403 status code to the client.\nExample 3: The request fails the authentication. The CDN edge node throttles requests sent from the client.\nExample 4: The authentication process times out. The CDN edge node performs the specified action, such as allow or reject.\nAfter you configure remote authentication, requests that fail the authentication can still reach the CDN edge nodes, but they will be rejected by the CDN edge nodes and the HTTP 403 status code will be returned. The CDN logs will still record the client request.\nBecause remote authentication routes user requests to the designated authentication server for verification, intercepting malicious requests at the CDN/ edge nodes incurs a small amount of traffic fees. Additionally, if the client employs the HTTPS protocol, fees for HTTPS requests will apply due to the resource consumption at the CDN/ edge nodes when intercepting these requests.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Access Control.\nClick the  Remote Authentication  tab.\nTurn on the  Remote Authentication  switch and follow the prompts to configure the remote authentication information.\nAfter enabling remote authentication, ensure your authentication server can handle traffic spikes without compromising performance.\nParameter\nDescription\nAuthentication Server Address\nThe address of the authentication server. The system checks the specified server address and the format of the address.\nFormat requirements\nThe authentication address supports HTTP and HTTPS protocols. Examples:\nhttp://example.com/auth\nhttps://example.com/auth\nhttp://192.0.2.1/auth\nhttps://192.0.2.1/auth\nValue requirements\nThe value cannot contain 127.0.0.1 or localhost because these local addresses are invalid.\nRequest Method\nThe request method that is supported by the authentication server. The supported request methods are GET, HEAD, and POST. The default request method is GET.\nAuthentication File Type\nAll File Types: All file types are authenticated.\nSpecified File Types: Only specified file types are authenticated.\nWhen you specify file types, separate multiple file types with vertical bars (|). Example: mp4|flv.\nFile types are case-sensitive. For example, .jpg and JPG are considered different file types.\nURL Authentication Parameters\nRetain Parameter Settings\nSpecify the URL parameters that you want the authentication server to check. You can select Retain All Parameters, Retain Specified Parameters, or Delete All URL Parameters.\nIf you specify multiple parameters, separate the parameters with vertical bars (|). Example: user|token.\nParameters are case-sensitive. For example, key and KEY are considered different parameters.\nAdd Custom Parameters\nSpecify the parameters that you want to add to the URLs of requests before they are redirected to the authentication server. You can specify key-value pairs or select variables provided by Alibaba Cloud CDN.\nWhen you specify key-value pairs, take note of the following rules:\nSeparate multiple parameters with vertical bars (|). Example: token=$arg_token|vendor=ali_cdn.\nValues are case-sensitive. For example, key and KEY are considered different values.\nIf you use preset variables, the values of the variables are added to requests that are sent to the POP before the requests are redirected to the authentication server.\nFor example, if you select the variable $http_host, the URL of the client request will include host=$http_host, where host indicates the value of the host header in the client request. For more information about variable names and meanings, see Variable names.\nRequest Header Authentication Parameters\nRetain Request Header Settings\nSpecify the request headers that you want the authentication server to check. You can select Retain All Parameters, Retain Specified Parameters, or Delete All Request Header Parameters.\nIf you specify multiple request headers, separate the request headers with vertical bars (|). Example: user_agent|referer|cookies.\nRequest headers are not case-sensitive. For example, http_remote_addr and HTTP_Remote_Addr are considered the same request header.\nIf you select Retain All Request Headers, CDN edge nodes delete the Host header from requests by default. If you want to retain the Host header in requests, you can select Retain Specified Request Header or configure the Custom Parameters parameter. CDN edge nodes delete the Host header from requests by default because the Host header in requests that are redirected to the authentication server specifies the accelerated domain name. The authentication server may fail to identify these requests and cause errors such as the HTTP 404 status code, which indicates authentication failures.\nAdd Custom Parameters\nSpecify the parameters that you want to add to request headers before the requests are redirected to the authentication server. You can specify key-value pairs or select variables provided by Alibaba Cloud CDN.\nWhen you specify key-value pairs, take note of the following rules:\nSeparate multiple request headers with vertical bars (|). Example: User-Agent=$http_user_agent|vendor=ali_cdn.\nRequest headers are not case-sensitive. For example, http_remote_addr and HTTP_Remote_Addr are considered the same request header.\nIf you use preset variables, the values of the variables are added to requests that are sent to the POP before the requests are redirected to the authentication server.\nFor example, if you select the variable $http_host, the URL of the client request will include host=$http_host, where host indicates the value of the host header in the client request. For more information about variable names and meanings, see Variable names.\nStatus Codes For Authentication Results\nStatus Codes For Successful Authentication\nDescription\nWhen the authentication server successfully authenticates a request, it returns specific HTTP status codes to the CDN. You can configure multiple status codes. Separate multiple status codes with commas.\nExample\nIf you set the status codes for successful authentication to 200,206, the authentication is considered successful when the authentication server returns 200 or 206.\nException handling mechanism\nTo prevent all user requests from being blocked due to exceptions, if the status code returned by the authentication server is neither a success status code nor a failure status code, the CDN edge node will allow the request by default.\nStatus Codes For Failed Authentication\nDescription\nWhen the authentication server fails to authenticate a request, it returns specific HTTP status codes to the CDN. You can configure multiple status codes. Separate multiple status codes with commas.\nExample\nIf you set the status codes for failed authentication to 400,403, the authentication is considered failed when the authentication server returns 400 or 403.\nException handling mechanism\nTo prevent all user requests from being blocked due to exceptions, if the status code returned by the authentication server is neither a success status code nor a failure status code, the CDN edge node will allow the request by default.\nAllow Other Status Codes\nYes: To prevent all user requests from being blocked due to exceptions, if the status code returned by the authentication server is neither a success status code nor a failure status code, the CDN edge node will allow the request by default.\nExample:\nIf the status code for successful authentication is set to 200 and the authentication server returns 201, the request is allowed.\nIf the status code for failed authentication is set to 403 and the authentication server returns 404, the request is allowed.\nNo: If the status code returned by the authentication server is neither a success status code nor a failure status code, the CDN edge node will reject the request.\nActions Performed By The CDN After Failed Authentication\nCustom Status Code For Response\nThe HTTP status code that is returned from CDN edge nodes to clients after the edge nodes receive an HTTP status code indicating that the request fails the authentication from the authentication server.\nFor example, if you set the custom status code for response to 403, the CDN edge node returns the HTTP 403 status code to the client for requests that fail the authentication.\nAuthentication Timeout Configuration\nAuthentication Timeout Period\nThe timeout period starts when a CDN edge node redirects a request to the authentication server. The timeout period ends when the CDN edge node receives the authentication result from the authentication server. The timeout period is measured in milliseconds. You can set the timeout period to up to 3,000 milliseconds.\nActions Performed After Authentication Timeout\nSpecify the action that you want the CDN edge nodes to perform on a request if the authentication on the request times out. The supported actions are Allow and Reject. The differences are as follows:\nAllow: The authentication process times out. The CDN edge node allows the request.\nReject: Authentication timeout. The CDN rejects the user's request and returns the configured Custom Response Status Code to the user.\nClick OK to finalize the configuration.\nOnce you have successfully configured the remote authentication feature, you can alter the existing configuration or deactivate the remote authentication on the  Remote Authentication  tab.\nWhen adding custom parameters, select from the variables provided by Alibaba Cloud CDN. The following table describes these variables.\nVariable name\nVariable meaning\n$http_host\nThe value of the Host header.\n$http_user_agent\nThe value of the User-Agent header.\n$http_referer\nThe value of the Referer header.\n$http_content_type\nThe value of the Content-Type header.\n$http_x_forward_for\nThe value of the X-Forwarded-For header.\n$remote_addr\nThe client IP address.\n$scheme\nThe protocol of the request.\n$server_protocol\nThe protocol version of the request.\n$uri\nThe original URI of the request.\n$args\nThe query string of the request URL. The query string does not include the question mark (?).\n$request_method\nThe request method.\n$request_uri\nThe content of uri+'?'+args.\nCan Alibaba Cloud CDN URL signing and remote authentication be enabled simultaneously?\nCan you configure the authentication server for remote authentication with an internal network address?\nWhy does the CDN process requests when the authentication server returns a status code that is neither indicative of success nor failure?\nIf the remote authentication server fails, will the CDN allow all requests?\nBatchSetCdnDomainConfig\n"
    },
    "362": {
        "title": "CDN:Configure a User-Agent blacklist or whitelist",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-a-user-agent-blacklist-or-whitelist",
        "content": "This Product\nCDN:Configure a User-Agent blacklist or whitelist\nUser-Agent is an HTTP header. It contains the information about the client that makes the request, including the operating system (OS), OS version, browser, and browser version. You can configure a User-Agent blacklist or whitelist to restrict access to Alibaba Cloud CDN resources and improve service security.\nThe blacklist and whitelist are mutually exclusive and cannot be configured at the same time.\nIf the value of the User-Agent header in a request matches a value in the User-Agent blacklist, the request can reach the point of presence (POP) but is rejected by the POP. Then, the HTTP 403 status code is returned to the client, and the request is recorded in Alibaba Cloud CDN logs.\nYou are charged for data transfer that is generated when POPs block malicious requests. If clients request resources over HTTPS, you are also charged for HTTPS requests.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Access Control.\nOn the page that appears, click the User-Agent Blacklist/Whitelist tab.\nOn the User-Agent Blacklist/Whitelist tab, click Modify.\nConfigure a Blacklist or Whitelist as prompted.\nParameter\nDescription\nType\nThe following types of lists are supported:\nBlacklist\nRequests whose User-Agent header matches a value in the blacklist are rejected, and an HTTP 403 status code is returned.\nWhitelist\nOnly requests whose User-Agent header matches a value in the whitelist are allowed to access resources on POPs.\nRules\nWhen you specify User-Agent fields, separate fields with vertical bars (|). The wildcard character (*) is supported. Example: *curl*|*IE*|*chrome*|*firefox*.\nIf you want to enable access control for requests whose User-Agent header is empty, you can use the this-is-empty-ua parameter to specify that the User-Agent header is empty.\nIf you specify the this-is-empty-ua parameter in the rules of the whitelist, requests that contain an empty User-Agent header are allowed.\nIf you specify the this-is-empty-ua parameter in the rules of the blacklist, requests that contain an empty User-Agent header are rejected.\nThe User-Agent blacklist and whitelist do not support access control for requests that do not contain the User-Agent header. You can use EdgeScript or submit a ticket to enable the feature. For more information, see EdgeScript overview.\nRule Condition\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\nClick OK.\nExample 1: Configure a whitelist\nRules of the whitelist: *IE*|*firefox*\nExpected result: Only requests that are sent from IE or Firefox are allowed to access resources on POPs.\nExample 2: Configure a blacklist\nRules of the blacklist: *IE*|this-is-empty-ua\nExpected result: Requests that are sent from IE or contain an empty User-Agent header are rejected.\n"
    },
    "363": {
        "title": "CDN:Configure an IP address blacklist or whitelist",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-an-ip-blacklist-or-whitelist",
        "content": "This Product\nCDN:Configure an IP address blacklist or whitelist\nAn IP address blacklist or whitelist filters user requests, and blocks or allows requests from specific IP addresses. The IP list feature can restrict access sources and protect points of presence (POPs) from IP theft and attacks.\nBy default, the IP list feature is disabled. The IP address blacklist and whitelist are mutually exclusive. You can configure only one of the lists.\nIf an IP address is added to the blacklist, requests from the IP address can reach POPs but are rejected by the POPs, the HTTP 403 status code is returned, and requests from the IP address are recorded in the logs of Alibaba Cloud CDN.\nThe IP address blacklist and whitelist identify IP addresses based on Layer 7 HTTP IP recognition techniques. You are charged for network traffic that is generated when POPs block malicious requests. If clients access POPs over HTTPS, you are also charged for HTTPS requests.\nSome Internet service providers (ISPs) may assign private IP addresses to clients in specific regions. Therefore, POPs may receive requests from private IP addresses.\nPrivate IP addresses are of the following types:\nType-A private IP addresses: 10.0.0.0 to 10.255.255.255. Subnet mask: 10.0.0.0/8.\nType-B private IP addresses: 172.16.0.0 to 172.31.255.255. Subnet mask: 172.16.0.0/12.\nType-C private IP addresses: 192.168.0.0 to 192.168.255.255. Subnet mask: 192.168.0.0/16.\nWhen a client connects to a POP, the client IP address and the IP address that is used by the client to connect to the POP are determined based on whether a proxy is used. For example, the client IP address is 10.10.10.10, and the proxy IP address is 192.168.0.1.\nIf no proxy is used when a client connects to a POP, the following rules apply:\nThe value of the X-Forwarded-For (XFF) header in the user request is 10.10.10.10.\nThe client IP address 10.10.10.10 is the IP address that is used by the client to connect to the POP.\nIf a proxy is used when a client connects to a POP, the following rules apply:\nThe value of the XFF header in the user request is 10.10.10.10,192.168.0.1.\nThe client IP address 10.10.10.10 is the first IP address in the XFF header.\nThe IP address that is used by the client to connect to a POP is the IP address of the proxy, which is 192.168.0.1.\nThe client IP address is not the IP address that is used by the client to connect to the POP.\nThe IP list feature of Alibaba Cloud CDN supports three IP address verification modes. The following table describes the verification modes.\nIP address verification mode\nDescription\nDetermine based on the XFF header\nThis is the default mode. This mode verifies only the client IP address. The client IP address is the first IP address in the XFF header in a client request.\nIf a proxy is used when a client connects to a POP, the client uses the IP address of the proxy to connect to the POP. In this case, access control in this verification mode may not be accurate.\nDetermine based on the IP address that is used to connect to the POP\nThis mode verifies only the IP address that is used by a client to connect to a POP.\nDetermine based on the XFF header and the IP address that is used to connect to the POP\nThis mode verifies the following IP addresses:\nThe first IP address in the XFF header, which is the client IP address.\nThe IP address that is used by a client to connect to a POP.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click Access Control.\nClick the IP Blacklist or Whitelist tab.\nIn the IP Blacklist or Whitelist section, click Modify.\nSelect Blacklist or Whitelist based on your business requirements.\nParameter\nDescription\nType\nThe following types of IP lists are supported:\n\nBlacklist\nRequests from IP addresses in the blacklist are blocked.\nWhitelist\nOnly requests from IP addresses in the whitelist can access resources on the POPs.\nRules\nRule format requirements\nYou can enter IP addresses or CIDR blocks.\nSeparate multiple IP addresses or CIDR blocks with line feeds.\nYou can enter IPv4 addresses or CIDR blocks:\nIPv4 address example: 192.168.0.1.\nIPv4 CIDR block example: 192.168.0.0/24.\nYou cannot use 0.0.0.0/0 to specify all IPv4 addresses. To specify all IPv4 addresses, use the following subnets:\n0.0.0.0/1\n128.0.0.0/1\nYou can enter IPv6 addresses or CIDR blocks:\nIPv6 address example: FC00:AA3:0:23:3:300:300A:1234.\nIPv6 CIDR block example: FC00:0AA3:0000:0000:0000:0000:0000:0000/48.\nThe letters in IPv6 addresses are not case-sensitive. Examples: FC00:AA3:0:23:3:300:300A:1234 and fc00:0aa3:0000:0023:0003:0300:300a:1234.\n: : is not supported. For example, FC00:0AA3::0023:0003:0300:300A:1234 is invalid.\nYou cannot use 0000:0000:0000:0000:0000:0000:0000:0000/0 to specify all IPv6 addresses. To specify all IPv6 addresses, use the following subnets:\n0000:0000:0000:0000:0000:0000:0000:0000/1\n8000:0000:0000:0000:0000:0000:0000:0000/1\nRule length limit\nThe value of Rules can be up to 30 KB in size. You can enter up to about 700 IPv6 addresses/CIDR blocks or 2,000 IPv4 addresses/CIDR blocks in this field based on the average size of IP addresses and CIDR blocks. If you want to block more IP addresses, activate Dynamic Content Delivery Network (DCDN) and configure a region blacklist.\nIP Rules\nYou can select one of the following rules:\nDetermine based on the XFF header\nDetermine based on the IP address that is used to connect to the POP\nDetermine based on the XFF header and the IP address that is used to connect to the POP.\nIf the XFF header does not include an IP address, determine based on the IP address that is used to connect to the POP.\nRule Condition\nRule conditions can identify parameters in a request to determine whether a configuration applies to the request.\nDo not use conditions\nSelect the configured rule conditions in Rules Engine. For more information, see Rules engine.\nClick OK.\nWhitelist\nRules: 192.168.2.0/24\nExpected result: Only IP addresses that range from 192.168.2.1 to 192.168.2.254 can access the resources of the specified domain name.\nBlacklist\nRules: 192.168.0.1\nExpected result: The IP address 192.168.0.1 is not allowed to access the resources of the specified domain name.\nWhen I configure an IP address blacklist or whitelist, the number of IP addresses is limited. Is a CIDR block considered one IP address or multiple IP addresses?\nCan I obtain the IP addresses of POPs that I want to add to the origin whitelist?\nWhy can I still use an IP address in the IP address blacklist to request resources?\nHow do I retrieve the originating IP addresses of clients?\nBatchSetCdnDomainConfig: configures an IP address blacklist or whitelist for multiple domain names at a time. The ip_black_list_set parameter specifies an IP address blacklist and the ip_allow_list_set parameter specifies an IP address whitelist.\n"
    },
    "364": {
        "title": "CDN:Configure an SSL certificate",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-an-ssl-certificate",
        "content": "This Product\nCDN:Configure an SSL certificate\nAlibaba Cloud CDN supports HTTPS secure acceleration. You can deploy an SSL certificate in the Alibaba Cloud CDN console and enable HTTPS secure acceleration to encrypt requests between clients and points of presence (POPs).\nAn SSL certificate is prepared for the accelerated domain name.\nIf you want to purchase an SSL certificate, log on to the Certificate Management Service console to purchase one.\nCertificates that are issued by third-party certificate authorities (CAs) must meet the certificate format requirements. For more information, see Certificate formats.\nOnly certificates in the PEM format are supported. You can convert certificates in other formats to the PEM format. For more information, see Convert certificate formats.\nWhen you upload a certificate that is issued by a third-party CA, use a private key that does not have password protection.\nYou can deploy an SSL certificate that is purchased from Certificate Management Service for multiple domain names in the Alibaba Cloud CDN console. For more information, see Configure an SSL certificate for multiple domain names.\nYou can view SSL certificates. You cannot view private keys because the keys are considered sensitive information. Keep certificate-related information confidential.\nIf you do not want to expose your private key to environments other than Alibaba Cloud CDN, you can use the Certificate Signing Request (CSR) tool that is provided by Alibaba Cloud Certificate Management Service to generate a CSR and a private key based on algorithms such as Rivest-Shamir-Adleman (RSA) and Elliptic-curve cryptography (ECC). You can also upload an existing CSR. For more information, see Manage CSRs.\nIf you want to enable end-to-end data transfer over HTTPS, you need to configure origin fetch over HTTPS. Make sure that the origin servers support HTTPS.\nAfter you enable HTTPS in Alibaba Cloud CDN, you are charged for HTTPS requests for static content based on the pay-as-you-go billing method.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, find the domain name that you want to manage and click Manage in the Actions column.\nIn the left-side navigation tree of the domain name, click HTTPS.\nIn the HTTPS Certificate section, click Modify.\nIn the Modify HTTPS Settings dialog box, turn on HTTPS Secure Acceleration, and configure the parameters.\nIf you have purchased a certificate from Alibaba Cloud Certificate Management Service, set the Certificate Source parameter to SSL Certificates Service and select the purchased certificate from the Certificate Name drop-down list.\nIf the certificate that you purchased is unavailable, check whether the domain name that is associated with the purchased certificate is the accelerated domain name.\nIf you use a certificate that is issued by a third-party CA, set the Certificate Source parameter to Custom Certificate (Certificate+Private Key). After you configure the Certificate Name parameter, configure the Certificate (Public Key) and Private Key parameters. Then the certificate is saved in Alibaba Cloud Certificate Management Service. You can view the certificate on the SSL Certificate Management page.\nParameter\nDescription\nCertificate Name\nEnter a name for the certificate that you want to upload.\nThe name can contain letters, digits, periods (.), underscores (_), and hyphens (-).\nA certificate name must be unique. You can view existing certificates on the SSL Certificates page.\nIf the system prompts that the certificate already exists, change the certificate name and re-upload the certificate.\nCertificate (Public Key)\nEnter the content of the PEM-encoded certificate file.\nYou can use a text editor to open the certificate file in the PEM format. Then, copy the content to the Certificate (Public Key) field.\nFor more information, click PEM Encoding Reference below the Certificate (Public Key) field.\nPrivate Key\nEnter the content of the PEM-encoded private key file.\nYou can use a text editor to open the private key file in the KEY format. Then, copy the content to the Private Key field.\nFor more information, click PEM Encoding Reference below the Private Key field.\nIf you obtain a private key that starts with \"----- BEGIN PRIVATE KEY -----\" and ends with \"----- END PRIVATE KEY -----\", use the OpenSSL tool to run the following command to convert the private key format. Then, copy the content of the new_server_key.pem file to the Private Key field.\nClick OK.\nAfter you upload an SSL certificate, the certificate takes effect within 1 minute. To check whether the SSL certificate takes effect, you can send HTTPS requests to access resources. If the URL is displayed with a lock icon in the address bar of the browser, HTTPS secure acceleration is working as expected.\nAfter you configure an SSL certificate, take note of the expiration time of the certificate. You need to configure a new certificate before the certificate expires.\nIf you no longer require HTTPS secure acceleration, you can disable the feature in the Alibaba Cloud CDN console. Disabling HTTPS secure acceleration immediately takes effect. After you disable HTTPS secure acceleration, you can no longer access resources over HTTPS, and the SSL certificate and the private key are no longer retained.\nIf you want to re-enable HTTPS secure acceleration, select another SSL certificate.\nTopic\nDescription\nConfigure URL redirection\nYou can configure the URL redirection feature to forcibly redirect requests from clients to POPs to HTTPS.\nConfigure HSTS\nAfter you configure HTTP Strict Transport Security (HSTS), clients such as browsers can establish only HTTPS connections to POPs to improve security.\nConfigure OCSP stapling\nPOPs cache certificate verification results and then send the results to clients without the need for the clients to verify certificates with the CAs. This reduces the verification time.\nDo I need to configure HTTPS secure acceleration for POPs if HTTPS is configured on the origin server?\nDo I need to renew the SSL certificate in Alibaba Cloud CDN after an origin server renews its SSL certificate?\nAPI operation\nDescription\nCreateCdnCertificateSigningRequest\nCreates a certificate signing request (CSR).\nDescribeDomainCertificateInfo\nQueries the certificate information about an accelerated domain name.\nSetCdnDomainSSLCertificate\nEnables or disables the certificate of a domain name, and modifies the certificate information.\nSetCdnDomainCSRCertificate\nConfigures an SSL certificate for a specified domain name.\nDescribeCdnDomainByCertificate\nQueries accelerated domain names by SSL certificate.\nDescribeCdnCertificateDetail\nQueries the detailed information about an SSL certificate.\nDescribeCdnCertificateList\nQueries information about certificates.\nDescribeCertificateInfoByID\nQueries the information about a specified SSL certificate.\nDescribeCdnHttpsDomainList\nQueries the information about the SSL certificates within your Alibaba Cloud account.\nDescribeUserCertificateExpireCount\nQueries the number of domain names whose SSL certificates are about to expire or have already expired.\nSetCdnDomainSMCertificate\nEnables or disables a ShangMi (SM) certificate for a domain name.\nDescribeCdnSMCertificateList\nQueries the SM certificates of an accelerated domain name.\nDescribeCdnSMCertificateDetail\nQueries the details about an SM certificate.\n"
    },
    "365": {
        "title": "CDN:Configure an SSL certificate for multiple domain names",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/configure-an-ssl-certificate-for-multiple-domain-names",
        "content": "This Product\nCDN:Configure an SSL certificate for multiple domain names\nAlibaba Cloud CDN supports HTTPS secure acceleration to encrypt requests between clients and points of presence (POPs). If your SSL certificate is purchased from Certificate Management Service, you can deploy the certificate for multiple domain names in Alibaba Cloud CDN to enable HTTPS secure acceleration.\nYou can deploy a certificate purchased from Alibaba Cloud Certificate Management Service for multiple domain names in the Alibaba Cloud CDN console.\nYou can configure a certificate that is issued by a third-party certificate authority (CA) for only one domain name at a time. For more information, see Configure an SSL certificate.\nHTTPS secure acceleration is a value-added service. After you enable HTTPS, you are charged based on the number of HTTPS requests. You cannot use data transfer plans to offset the fees. For more information about the pricing of HTTPS secure acceleration, see Billing of HTTPS requests for static content.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click HTTPS Center.\nOn the Certificate Center page, click Add Certificate.\nSelect a certificate.\nOn the Add Certificate page, configure the parameters. The following table describes the parameters.\nParameter\nDescription\nCertificate Source\nOnly SSL Certificates Service is supported. You can select only certificates purchased from Certificate Management Service.\nCertificate Name\nSelect a purchased certificate.\nCertificate (Public Key)\nThe PEM-encoded public key. For certificates purchased from Certificate Management Service, the PEM-encoded public key is automatically obtained by the system.\nPrivate Key\nThe PEM-encoded private key. For certificates purchased from Certificate Management Service, the PEM-encoded private key is automatically obtained by the system.\nClick Next.\nAssociate one or more domain names with the certificate.\nIf a selected domain name is already associated with a certificate, the existing certificate will be replaced by the selected certificate in this step.\nIf you set Certificate Source to SSL Certificates Service, you can renew or deploy the specified certificate for multiple domain names at a time.\n\nClick OK to deploy or update the certificate.\nOptional. Configure POPs to redirect requests to origin servers over HTTPS if you want to enable end-to-end HTTPS encryption. Make sure that the origin servers support HTTPS. For more information, see Configure the origin protocol policy.\nAfter you upload an SSL certificate, the certificate takes effect within 1 minute. To check whether the SSL certificate takes effect, you can send HTTPS requests to access resources. If the URL is displayed with a lock icon in the address bar of the browser, HTTPS secure acceleration is working as expected.\nLog on to the Alibaba Cloud CDN console. In the left-side navigation pane, choose HTTPS Center. On the Certificate Center page, click the certificate that you configured for the domain name.\nYou can view the information about the SSL certificate configured for the domain name. However, you cannot view the private key. Keep the certificate information confidential.\nDo I need to configure HTTPS secure acceleration for POPs if HTTPS is configured on the origin server?\nDo I need to renew the SSL certificate in Alibaba Cloud CDN after an origin server renews its SSL certificate?\nAPI operation\nDescription\nCreateCdnCertificateSigningRequest\nCreates a certificate signing request (CSR).\nDescribeDomainCertificateInfo\nQueries the certificate information about an accelerated domain name.\nSetCdnDomainSSLCertificate\nEnables or disables the certificate of a domain name, and modifies the certificate information.\nSetCdnDomainCSRCertificate\nConfigures an SSL certificate for a specified domain name.\nDescribeCdnDomainByCertificate\nQueries accelerated domain names by SSL certificate.\nDescribeCdnCertificateDetail\nQueries the detailed information about an SSL certificate.\nDescribeCdnCertificateList\nQueries information about certificates.\nDescribeCertificateInfoByID\nQueries the information about a specified SSL certificate.\nDescribeCdnHttpsDomainList\nQueries the information about the SSL certificates within your Alibaba Cloud account.\nDescribeUserCertificateExpireCount\nQueries the number of domain names whose SSL certificates are about to expire or have already expired.\nSetCdnDomainSMCertificate\nEnables or disables a ShangMi (SM) certificate for a domain name.\nDescribeCdnSMCertificateList\nQueries the SM certificates of an accelerated domain name.\nDescribeCdnSMCertificateDetail\nQueries the details about an SM certificate.\n"
    },
    "366": {
        "title": "CDN:Introduction to sandboxes",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/introduction-to-sandboxes",
        "content": "This Product\nCDN:Introduction to sandboxes\nThis topic introduces sandboxes and the features of sandboxes. This topic also describes the impacts on domain names that are in a sandbox.\nA sandbox is a set of special points of presence (POPs) for Alibaba Cloud CDN. The POPs are isolated from regular POPs and are used to isolate high-risk acceleration services.\nAlibaba Cloud CDN provides content delivery for thousands of accelerated domain names. If an accelerated domain name is under attack, such as DDoS attacks or HTTP flood attacks, or experiences significant increases in bandwidth or QPS due to traffic spikes that are not reported to Alibaba Cloud, Alibaba Cloud CDN can add the attacked domain name to a sandbox based on factors such as the service status of the domain name and the impact of the attack. This ensures that the acceleration services of other users can work as expected. If the attack is severe, other accelerated domain names that belong to the same account are also added to the sandbox, and new domain names cannot be added to the account.\nAfter an accelerated domain name is added to a sandbox, Alibaba Cloud CDN cannot ensure service quality, and the domain name may be unavailable for a period of time.\nIf the acceleration region of a domain name is outside the Chinese mainland and the domain name does not have an Internet Content Provider (ICP) number, the domain name becomes inaccessible after it is added to a sandbox.\nIf your domain name that violates the Alibaba Cloud CDN or DCDN limits is under attack, Alibaba Cloud CDN or DCDN does not bear any responsibility and all fees that are generated are borne by you.\nAfter an accelerated domain name is added to a sandbox, visits to the accelerated domain name continue to generate data transfer fees.\nTo ensure that other users can use their services as expected, you cannot remove domain names from sandboxes.\nFor users whose services are frequently attacked or are attacked due to violations of the product limits, Alibaba Cloud CDN can terminate acceleration services based on factors such as the service status of the domain names and the impact of the attacks.\nAfter an accelerated domain name is added to a sandbox, you will be notified by a text message. You can also log on to the CDN console to check the domain status.\nBy default, Alibaba Cloud CDN provides acceleration services, but does not provide protection against attacks. You can choose to use DDoS mitigation or Alibaba Cloud Security Services based on your requirements. For more information, see DDoS mitigation or visit the Alibaba Cloud Security Services page.\n"
    },
    "367": {
        "title": "CDN:Resource monitoring",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/resource-monitoring",
        "content": "This Product\nCDN:Resource monitoring\nThe resource monitoring feature collects data including network traffic, bandwidth, the number of requests, cache hit ratio, and HTTP status codes based on the region and Internet service provider (ISP) of client IP addresses. You can make informed business decisions and optimize Alibaba Cloud CDN resource management based on the collected monitoring data.\nCompared with real-time monitoring, resource monitoring supports a longer maximum time range per query and a longer time period within which historical data is available.\nYou can query resource monitoring data by using the Alibaba Cloud CDN console or API. However, the maximum time range per query and the time period within which historical data is available are different. The following table describes the maximum time range to query, the period within which historical data is available, and the data delay.\nUse the console\nTime granularity\nMaximum time range per query\nHistorical data available\nData delay\n5 minutes\n3 days\n90 days\n15 minutes\n1 hour\n31 days\n90 days\n4 hours\n1 day\n90 days\n90 days\n04:00 on the next day\nUse the API\nTime granularity\nMaximum time range per query\nHistorical data available\nData delay\n5 minutes\n3 days\n93 days\n15 minutes\n1 hour\n31 days\n186 days\n4 hours\n1 day\n366 days\n366 days\n04:00 on the next day\nThe following table describes the resource monitoring items. You can specify filter conditions, such as accelerated domain names, regions, and ISPs. You can also export monitoring data for further analysis.\nIn terms of resource monitoring, data is collected based on the region and ISP of client IP addresses. In terms of metering, fees are calculated based on the network traffic, bandwidth, and number of requests on Alibaba Cloud CDN points of presence (POPs) in each billable region. The resource monitoring data and the billing data may be slightly different due to different collection methods. The line chart of resource monitoring displays the change of bandwidth usage. For more information about the metering data in bills, see Resource usage overview.\nData is collected and calculated by calling API operations. For more information, see the API references in the following table.\nMonitoring item\nDescription\nAPI operation\nData Transfer/Bandwidth of Requests\nMonitors the bandwidth and network traffic of accelerated domain names. You can query monitoring data by region, ISP, and protocol. The following protocols are supported: HTTP, HTTPS, QUIC, IPv4, and IPv6.\nDescribeDomainBpsDataByLayer\nDescribeDomainsUsageByDay\nBack-to-origin Data Transfer/Bandwidth\nMonitors the origin bandwidth and traffic of accelerated domain names.\nBack-to-origin bandwidth: The network bandwidth consumed by a CDN POP when requesting resources from the origin server after a cache miss.\nBack-to-origin data transfer: The traffic generated when a CDN POP requests content from the origin server because it is not available in the local cache.\nDescribeDomainSrcBpsData\nDescribeDomainSrcTrafficData\nNumber of Requests\nMonitors the number of requests and queries per second (QPS) of accelerated domain names. You can query monitoring data by region, ISP, and protocol. The following protocols are supported: HTTP, HTTPS, QUIC, IPv4, and IPv6.\nThe number of requests refers to the total number of requests during a data collection interval. For example, if data is collected every 5 minutes, the number of requests refers to the total number of requests within 5 minutes.\nQPS refers to the number of queries per second.\nDescribeDomainQpsDataByLayer\nHit Rate\nMonitors the byte hit ratios and request hit ratios of accelerated domain names.\nHit rate: The percentage of total requests to CDN POPs that are directly served by the CDN. Calculation: (Total requests to CDN POPs - CDN origin requests) \u00f7 Total requests to CDN POPs.\nHTTPS hit rate: The ratio of HTTPS requests successfully served from the cache to the total HTTPS requests. Calculation: Cached requests \u00f7 Total HTTPS requests.\nDescribeDomainHitRateData\nDescribeDomainReqHitRateData\nHTTPCODE\nMonitors the HTTP status codes returned from POPs. The HTTP status codes include 2xx, 3xx, 4xx, and 5xx.\nDescribeDomainHttpCodeDataByLayer\nHTTP Status Codes to Back-to-origin Requests\nMonitors the HTTP status codes, including 2xx, 3xx, 4xx, and 5xx, returned from origin servers.\nDescribeDomainSrcHttpCodeData\nThe traffic usage of accelerated domain names queried using the monitoring or resource usage feature available in the CDN or DCDN console or by calling API operations differs from that collected in logs. In most cases, the former is about 1.1 times that of the latter. For more information, see Why is the traffic amount found by using the monitoring and usage analytics feature or the usage statistics feature different from the traffic amount that is logged?\nResource usage query: Usage data is collected by POP. You can query resource usage data based on the billable region where the POP belongs to, such as the Chinese mainland, Asia Pacific 1, and North America. For more information, see Query resource usage.\nResource monitoring and real-time monitoring: Monitoring data is collected based on client IP addresses. Each client IP address belongs to a region or an ISP. You can query monitoring data by region, ISP, or both. For more information, see Resource monitoring and Real-time monitoring.\nMinimum data delay: Real-time monitoring has a lower data delay. The data delay for real-time monitoring is about 5 minutes with the query granularity of 1 minute, while the data delay for resource monitoring is about 15 minutes with the query granularity of 5 minutes.\nMinimum data granularity: Real-time monitoring supports smaller granularity. The minimum data query granularity for real-time monitoring is 1 minute, while the minimum data query granularity for resource monitoring is 5 minutes.\nQuery by protocol: Resource monitoring supports more protocols. Resource monitoring supports data query by HTTP, HTTPS, QUIC, IPv4, and IPv6, while real-time monitoring does not.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, choose Monitoring & Usage Analytics > Resource Monitoring.\nOn the Resource Monitoring page, select the monitoring item that you want to query and filter conditions, and click Search.\nThe system displays monitoring data based on the specified item and filter conditions. Then, you can analyze data online or export the data to your local PC for analysis."
    },
    "368": {
        "title": "CDN:Real-time monitoring",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/real-time-monitoring",
        "content": "This Product\nCDN:Real-time monitoring\nThe real-time monitoring feature in Alibaba Cloud CDN collects data at an interval of 1 minute. You can query data transfer, bandwidth usage, and origin fetch statistics in the last 1 minute and earlier. You can query data in the last 7 days. The maximum time range per query is 24 hours. Real-time monitoring allows you to detect anomalies in network traffic and locate errors at the earliest opportunity.\nCompared with resource monitoring, real-time monitoring supports a shorter maximum time range per query and a shorter maximum period of time within which historical data is available.\nYou can query monitoring data by using the Alibaba Cloud CDN console or API. However, the time granularity, the maximum time range that you can query, and the maximum period of time within which historical data is available are different. The following table describes the maximum time range to query, the time period within which historical data is available, and data delay.\nUse the console\nTime granularity\nMaximum time range per query\nHistorical data available\nData delay\n1 minute\n1 hour\n7 days\n5 minutes\n5 minutes\n3 days\n7 days\n15 minutes\nUse the API\nTime granularity\nMaximum time range per query\nHistorical data available\nData delay\n1 minute\n1 hour\n7 days\n5 minutes\n5 minutes\n3 days\n93 days\n15 minutes\n1 hour\n31 days\n186 days\n4 hours\nThe following table describes the monitoring items. You can query metrics such as bandwidth and network traffic by specifying filter conditions, such as domain name, region, Internet service provider (ISP), and time range.\nIn terms of real-time monitoring, data is collected based on the region or ISP of client IP addresses. In terms of metering, fees are calculated based on the network traffic, bandwidth, and number of requests on Alibaba Cloud CDN points of presence (POPs) in each billable region. The resource monitoring data and the billing data may be slightly different due to different collection methods. The line chart of real-time monitoring displays the change of bandwidth usage. For more information about the metering data in bills, see Resource usage overview.\nData is collected and calculated by calling API operations. For more information, see the API references in the following table.\nMonitoring item\nDescription\nAPI operation\nRequests\nMonitors the bandwidth, network traffic, number of requests, and QPS of accelerated domain names.\nDescribeDomainRealTimeBpsData\nDescribeDomainRealTimeQpsData\nDescribeDomainRealTimeTrafficData\nBack-to-origin Routing\nMonitors the origin bandwidth and traffic of accelerated domain names.\nDescribeDomainRealTimeSrcBpsData\nDescribeDomainRealTimeSrcTrafficData\nCache Hit Ratio/HTTP Status Code\nMonitors the cache hit ratio, byte hit ratio, HTTP status codes 2xx, 3xx, 4xx, and 5xx for accelerated domain names.\nDescribeDomainRealTimeReqHitRateData\nDescribeDomainRealTimeByteHitRateData\nDescribeDomainRealTimeHttpCodeData\nThe traffic usage of accelerated domain names that is queried by using the monitoring or resource usage feature available in the Alibaba Cloud CDN or DCDN console or by calling API operations differs from that collected in logs. Typically, the traffic usage of accelerated domain names that is queried by using the monitoring or resource usage feature is 1.1 times that collected in logs. For more information, see Why is the traffic amount found by using the monitoring and usage analytics feature or the usage statistics feature different from the traffic amount that is logged?\nResource usage query: Usage data is collected by POP. You can query resource usage data based on the billable region where the POP belongs to, such as the Chinese mainland, Asia Pacific 1, and North America. For more information, see Query resource usage.\nResource monitoring and real-time monitoring: Monitoring data is collected based on client IP addresses. Each client IP address belongs to a region or an ISP. You can query monitoring data by region, ISP, or both. For more information, see Resource monitoring and Real-time monitoring.\nMinimum data delay: Real-time monitoring has a lower data delay. The data delay for real-time monitoring is about 5 minutes with the query granularity of 1 minute, while the data delay for resource monitoring is about 15 minutes with the query granularity of 5 minutes.\nMinimum data granularity: Real-time monitoring supports smaller granularity. The minimum data query granularity for real-time monitoring is 1 minute, while the minimum data query granularity for resource monitoring is 5 minutes.\nQuery by protocol: Resource monitoring supports more protocols. Resource monitoring supports data query by HTTP, HTTPS, QUIC, IPv4, and IPv6, while real-time monitoring does not.\nIn the left-side navigation pane, choose Monitoring & Usage Analytics > Real-time Monitoring.\nOn the Real-time Monitoring page, select the monitoring item that you want to query and filter conditions, and click Search.\nThe system displays the monitoring data based on the specified item and filter conditions for further analysis."
    },
    "369": {
        "title": "CDN:Query resource usage",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/query-resource-usage-1",
        "content": "This Product\nCDN:Query resource usage\nYou can query resource usage of specified domain names. You can set different filter conditions to query specific usage information, including bandwidth values, network traffic, and the number of HTTPS or QUIC requests. You can query information by accelerated domain name, time range, and billable region.\nThe traffic usage of accelerated domain names that is queried by using the monitoring or resource usage feature available in the Alibaba Cloud CDN or DCDN console or by calling API operations differs from that collected in logs. Typically, the traffic usage of accelerated domain names that is queried by using the monitoring or resource usage feature is 1.1 times that collected in logs. For more information, see Why is the traffic amount found by using the monitoring and usage analytics feature or the usage statistics feature different from the traffic amount that is logged?\nResource usage query: Usage data is collected by POP. You can query resource usage data based on the billable region where the POP belongs to, such as the Chinese mainland, Asia Pacific 1, and North America. For more information, see Query resource usage.\nResource monitoring and real-time monitoring: Monitoring data is collected based on client IP addresses. Each client IP address belongs to a region or an ISP. You can query monitoring data by region, ISP, or both. For more information, see Resource monitoring and Real-time monitoring.\nYou can query resource usage in the Alibaba Cloud CDN console or by calling API operations. However, the maximum time range that you can query and the maximum period of time within which historical data is available are different. The following table describes the maximum time range to query, the period within which historical data is available, and data delay.\nIn the Alibaba Cloud CDN console:\nTime granularity\nMaximum time range per query\nHistorical data available\nData delay\n5 minutes\n3 days\nThe last 6 months\n15 minutes\n1 hour\n31 days\nThe last 6 months\n4 hours\n1 day\n31 days\nThe last 6 months\n04:00 on the next day\nCall API operations:\nTime granularity\nMaximum time range per query\nHistorical data available\nData delay\n5 minutes\n3 days\n93 days\n15 minutes\n1 hour\n31 days\n186 days\n4 hours\n1 day\n366 days\n366 days\n04:00 on the next day\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Usage.\nOn the Usage page, select an item that you want to query and set the filter conditions.\nThe following figure shows the resource usage data of the last 30 days of all domain names. The table below the chart lists the resource usage data collected every day.\n\nDescribeDomainUsageData: queries the usage data of domain names in a specified billable region."
    },
    "370": {
        "title": "CDN:Logs and reports",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/logs-and-reports/",
        "content": "This Product\nCDN:Logs and reports"
    },
    "371": {
        "title": "CDN:Quota management",
        "url": "https://www.alibabacloud.com/help/en/cdn/user-guide/quota-management",
        "content": "This Product\nCDN:Quota management\nThe quota management feature of Alibaba Cloud CDN is integrated with Quota Center. You can query and manage quotas of Alibaba Cloud CDN and create quota alert rules in the Quota Center console. This topic describes how to manage quotas of Alibaba Cloud CDN.\nDue to business growth, you may want to adjust the number of times that URLs or directories can be refreshed, the number of URLs that can be prefetched, and the number of domain names that can be accelerated. If you want to adjust these quotas, you can log on to the Quota Center console and adjust the quotas based on your business requirements.\nQuota Center provides the following features:\nQuota query: allows you to query the quotas of services, query whether you can apply for quota increases, and query the upper limit on quota increases.\nQuota applications: allows you to submit applications and query the progress of each application.\nQuota alerts: allows you to configure quota alert rules based on percentage values or absolute values. Quota alerts notify you of quota status at the earliest opportunity. This way, you can adjust quotas based on your business requirements.\nAPI operations: facilitate and automate O&M and help improve O&M efficiency.\nAll-in-one: Quota Center provides a suite of quota management features.\nTransparent: Quota Center displays the default quotas on services and quotas after increases.\nAutomated: Quota Center supports quota alerts, which can notify you of quota status at the earliest opportunity.\nEfficient: Quota Center allows you to submit applications, which are more efficient than tickets.\nIf the quota that you want to apply for exceeds the Limits, you must submit an application. Alibaba Cloud reviews your application based on your business requirements. For more information, see Submit an application to increase a quota.\nThe system allocates quotas on the number of URLs or directories that can be refreshed and the number of URLs that can be prefetched on a daily basis. After the quota for the current day is exhausted, the quota for the next day is automatically allocated at 00:00:00 (UTC+8) on the next day.\nThe number of domain names that can be accelerated is a one-off allocation. If you want to increase the quota, you must submit an application in Quota Center.\nYou must use your Alibaba Cloud account if you want to manage quotas. If you want to manage quotas as a RAM user, the RAM user must be granted the required permissions by the Alibaba Cloud account. For more information, see Authorize a RAM user.\nLog on to the Quota Center console.\nIn the left-side navigation pane, choose Products > General Quota.\nOn the Products with General Quotas page, select Media Service & CDN from the Category drop-down list.\nClick Alibaba Cloud CDN to go to the quota management page. Then, you can perform the following operations:\nClick Apply in the Actions column to apply for a quota increase. For more information, see Submit an application to increase a quota.\nClick Application Records in the Actions column to query application records. For more information, see Query applications and view application details.\nClick Create Alert in the Actions column to configure quota alert rules. For more information, see Create an alert rule for a quota item.\nClick the More icon and select View Alerts in the Actions column to view quota alerts. For more information, see View alert rules created for quota items and rule details."
    },
    "372": {
        "title": "CDN:EdgeScript overview",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgescript-overview",
        "content": "This Product\nCDN:EdgeScript overview\nEdgeScript (ES) allows you to customize CDN configurations by running scripts if the standard configurations in the CDN console cannot meet your business requirements.\nES supports easy-to-learn syntax and provides a large library of functions. You can use the syntax and functions to customize CDN features.\nES provides encapsulated functions, simple decision-making statements, and built-in variables that can be recognized by CDN points of presence (POPs).CDN You can combine simple variables and existing functions in ES to meet most of your requirements for custom configurations. For example, you can use ES to customize authentication, caching, and throttling, and add fields to or remove fields from request headers. This helps you customize your configurations and provides agile and fast service updates.\nES is free of charge."
    },
    "373": {
        "title": "CDN:How EdgeScript works",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/how-edgescript-works",
        "content": "This Product\nCDN:How EdgeScript works\nThis topic describes how EdgeScript (ES) works, the model of scripts in ES, positions where the scripts are executed, script priorities, and execution and termination of scripts.\nScripts created by using ES are the same as the standard configurations specified in the CDN console. They process requests that are sent to CDN points of presence (POPs). The following figure shows the positions where scripts are executed. After a CDN POP receives a request, the POP processes the request based on the configurations in the Alibaba Cloud CDN console and scripts in ES. In a request processing pipeline, you can specify the position where a script is executed. A script can be executed before the configurations in the CDN console are applied (head) or after they are applied (foot).\nIf you want to execute more than one script at the head or foot of a request processing pipeline, you can assign priorities to these scripts to determine the execution order.\nFor scripts that are executed in the same position, you can choose to skip the subsequent scripts when a script is executed."
    },
    "374": {
        "title": "CDN:Use EdgeScript to create a script",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/use-edgescript-to-create-a-script/",
        "content": "This Product\nCDN:Use EdgeScript to create a script"
    },
    "375": {
        "title": "CDN:EdgeScript syntax",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgescript-syntax",
        "content": "This Product\nCDN:EdgeScript syntax\nThis topic describes the conventions of annotations, identifiers, data types, variables, operators, clauses, and functions in the EdgeScript syntax.\nYou cannot use double quotation marks (\") in EdgeScript.\nThe following table describes the details about the EdgeScript syntax.\nSyntax\nRule\nAnnotations\nAll annotations must start with a number sign (#). Example: # this is annotation.\nIdentifiers\nIdentifiers are case-sensitive. An identifier can contain letters, digits, and underscores (_). It cannot start with a digit.\nAll names of built-in variables, custom variables, built-in functions, and custom functions must comply with the identifier conventions.\nData types\nString\nLiteral constants: use a pair of single quotation marks (') to quote a literal constant, such as 'hello, EdgeScript'.\nNumber\nLiteral constants: decimal numbers, such as 10, -99, or 1.1.\nBoolean\nLiteral constants: true or false.\nDictionary\nLiteral constants:\n[]: an empty string.\n['key1', 'key2', 100]:\n1 -> 'key1'\n2 -> 'key2'\n3 -> '100'\n['key1' = 'value1', 'key2' = '1000']\n'key1' -> 'value1'\n'key2' -> 1000\nVariables\nDefinition\nA variable is a symbolic name associated with a value that may change.\nHow to use\nBoth built-in and custom variables are referenced by using their names.\nReference a built-in variable: host.\nReference a custom variable: seckey.\nTo emphasize the built-in properties of a variable, you can use $ to reference it.\nReference a built-in variable: $host.\nA custom variable and a built-in variable cannot use the same name.\nFor more information about built-in variables, see EdgeScript built-in variables.\nOperators\n=: the assignment operator.\nExample: seckey = 'ASDLFJ234dxvf34sDF'\nExample: seckeys = ['key1', 'key2']\n-: the minus operator.\nExample: inum = -10\nBuilt-in functions are used to process different types of data. No additional operators are provided. For more information about built-in functions, see Logical functions.\nThe built-in functions support the following data types:\nString\nNumber\nDictionary\nExamples\nsval = concat(sval, 'trail')\nlen(arrvar)\nClauses\nCondition clause\nClause description\nA condition clause contains the following elements:\nLiteral constant\nVariable\nFunction call\nBody\nThe body can be empty.\nMultiple statements are allowed. Enter only one statement on each line.\nStatement nesting is allowed.\nCodingStyle\nThe opening brace ({) must follow if condition on the same line.\nfor loop\nTake note of the following limits:\nfor loops are used only to traverse data of the dictionary or array type.\nKeywords such as break are not supported. We recommend that you use custom functions and use the return keyword to break loops.\nStatement nesting is allowed.\nCodingStyle\nThe opening brace ({) must follow for... on the same line.\nFunctions\nSyntax\nDescription\nParameter list\nThe parameter list can be empty.\nMultiple parameters are allowed. Separate parameters with commas (,).\nBody\nThe body can be empty.\nMultiple statements are allowed. Enter only one statement on each line.\nThe return values support the return clause.\nCodingStyle\nThe opening brace ({) must follow def Function name(Parameter list) on the same line.\nFunction call\nYou must use Function name() to call both built-in and custom functions.\nOthers\nYou must not use double quotation marks (\") in EdgeScript."
    },
    "376": {
        "title": "CDN:EdgeScript built-in variables",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgescript-built-in-variables",
        "content": "This Product\nCDN:EdgeScript built-in variables\nThis topic describes EdgeScript built-in variables and the corresponding NGINX variables.\nThe dollar sign ($) before a variable is used to specify that the variable is a built-in variable. You can remove the dollar sign based on your business requirements.\nDo not assign values to built-in variables in the same way as parameters.\nYou can specify at most 200 global variables and an unlimited number of local variables in a script. To specify more than 200 global variables in a script, create a custom function and use the global variables as local variables in the function.\nThe following table describes the EdgeScript built-in variables.\nBuilt-in variable\nDescription\nNGINX variable\n$arg_{name}\nThe value of the name parameter in the query string. The query string represents request parameters in an HTTP request.\n$arg_\nIf the {name} field contains a hyphen (-), req_uri_arg instead of $arg_ is used to extract the header value. If the request is http://example.com/1.jpg?example-demo=123, the header value is extracted based on req_uri_arg('example-demo').\n$http_{name}\nThe value of the name field in the request header.\n$http_\nHyphens (-) in the {name} field must be replaced by underscores (_). For example, X-USER-ID must be changed to $http_x_user_id.\n$cookie_{name}\nThe value of the name field in the request cookie header.\n$cookie_\nIf the {name} field contains a hyphen (-), req_cookie instead of $cookie_ is used to extract the header value. If the request is cookie:example-demo=123, the header value is extracted based on req_cookie('example-demo'.\n$scheme\nThe protocol type.\n$scheme\n$server_protocol\nThe protocol version.\n$server_protocol\n$host\nThe original host.\n$host\n$uri\nThe original URI.\nNone\n$args\n$args represents all request parameters in an HTTP request, excluding question marks (?). In the request http://example.aliyundoc.com/1k.file?k1=v1&k2=v2:\n$arg_k1 returns the value of the k1 parameter: v1.\n$args is used to return the entire query string: k1=v1&k2=v2. Question marks (?) are excluded.\n$args\n$request_method\nThe request method.\n$request_method\n$request_uri\nThe content of uri+'?'+args.\n$request_uri\n$remote_addr\nThe IP address used by the client to connect to points of presence (POPs).\n$remote_addr"
    },
    "377": {
        "title": "CDN:EdgeScript built-in functions",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgescript-built-in-functions/",
        "content": "This Product\nCDN:EdgeScript built-in functions"
    },
    "378": {
        "title": "CDN:EdgeScript common scenarios",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/edgescript-common-scenarios",
        "content": "This Product\nCDN:EdgeScript common scenarios\nThis topic describes the use scenarios of EdgeScript, including authentication logic customization, request header and response header customization, rewrite and redirect customization, cache control customization, and throttling customization.\nThe following example shows how to customize authentication rules:\nUse scenario\nRequest URL format: /path/digest/?.ts?key=&t=.\nFor .ts requests, the requirements for customizing hotlink protection are:\nRule 1: If the request does not contain the t or key parameter, the point of presence (POP) returns the HTTP 403 status code and adds the X-AUTH-MSG response header to indicate the cause of failure.\nRule 2: The t parameter specifies the expiration time. If the specified t parameter is earlier than the current time, the POP returns the HTTP 403 status code and adds the X-AUTH-MSG response header to indicate the cause of failure. For this authentication, note that there may be a gap between the timestamps obtained on the client and the CDN POP, which may cause authentication failure.\nRule 3: md5 (private key + path + file name.file name extension) == digest. If md5 does not match digest, the POP returns the HTTP 403 status code.\nScript\nThe following example shows automatic file renaming:\nExample:\nYou can add the response header Content-Disposition:attachment to HTTP responses to have the message body automatically downloaded. In addition, if the response carries the filename parameter, it is automatically renamed filename. If the response does not carry the filename parameter, the default name is used.\nThe value for the filename parameter is enclosed in a pair of double quotation marks (\"\"). The string \"34\" is the ASCII string for double quotation marks. It can be converted back to the quotation mark string (\"\") by using the tochar function.\nOutput:\nScript:\nThe following examples show how to customize rewrites and redirects:\nRewrite a URI.\nUse scenario\nEnable CDN to rewrite /hello to /index.html. As a result, the URI of the back-to-origin request is changed to /index.html and the parameters remain unchanged.\nScript\nRewrite a file extension.\nUse scenario\nEnable Alibaba Cloud CDN to rewrite the URI /1.txt to /1.<URL parameter type> on CDN POPs. As a result, the file name extension in the URI is replaced by the value of the type parameter in the request URL. For example, /1.txt?type=mp4 is changed to /1.mp4?type=mp4 before the request is redirected to the origin server. Then, the retrieved content is cached on CDN POPs.\nScript\nConvert a file extension to lowercase letters.\nUse scenario\nConvert URI strings to lowercase letters.\nScript\nAdd a URI prefix.\nUse scenario\nEnable Alibaba Cloud CDN to rewrite ^/nn_live/(.*) to /3rd/nn_live/$1 on CDN POPs.\nScript\nPerform a 302 redirect\nUse scenario\nPerform a 302 redirect from the / root directory to /app/movie/pages/index/index.html.\nScript\nPerform a 302 redirect to HTTPS URIs\nUse scenario\nRedirect the following URIs that match the ^/$ root directory to https://rtmp.cdnpe.com/index.html. You can specify the final URI as needed.\nhttp://demo.aliyundoc.com\nhttps://demo.aliyundoc.com\nScript\nThe following example shows how to customize the time-to-live (TTL) value of cached resources:\nUse scenario\nCustomize the TTL value of cached resources based on various conditions.\nScript\nFor URLs that start with /image, set a TTL value of 10 seconds for the HTTP 301 status code and a TTL value of 5 seconds for the HTTP 302 status code.\nThe following example shows how to customize a throttling policy:\nUse scenario\nIf the sp and unit parameters are set, throttling is implemented. The sp parameter specifies the maximum threshold value before throttling is triggered. The unit parameter specifies the unit. The unit can be KB or MB.\nScript\nThe following examples show region- and ISP-based access control:\nUse scenarios\nAccess control is implemented by identifying the region and Internet service provider (ISP) of the IP address included in the client request.\nThe following functions are used to identify the region and ISP of the client IP address. For more information, see Request logic functions.\nclient_region: returns the code of the region of the client IP address.\nclient_isp: returns the code of the Internet service provider (ISP) of the client IP address.\nScript"
    },
    "379": {
        "title": "CDN:Increase the cache hit ratios of Alibaba Cloud CDN",
        "url": "https://www.alibabacloud.com/help/en/cdn/use-cases/increase-the-cache-hit-ratios-of-alibaba-cloud-cdn",
        "content": "This Product\nCDN:Increase the cache hit ratios of Alibaba Cloud CDN\nIf the cache hit ratio of Alibaba Cloud CDN is low, the loads on origin servers increase and the retrieval of static resources slows down. You can select a solution to improve the cache hit ratios of Alibaba Cloud CDN based on the causes.\nAlibaba Cloud CDN caches static resources on points of presence (POPs) to accelerate content delivery. When a client requests a resource that is cached on a POP, the POP returns the requested resource to the client. This simplifies the delivery process, accelerates content delivery, and reduces loads on the origin server. A low cache hit ratio increases loads on the origin server and degrades user experience.\nProvide support for major events\nIf you want to hold a major event, you can prefetch the static resources of the event page to POPs. After the event starts, visitors can access the static resources that are already cached on POPs. This accelerates content delivery.\nRelease installation packages\nBefore you release an installation or upgrade package of a product, you can prefetch the package to POPs. After the product is launched, visitors can download the package from POPs. This accelerates content delivery and reduces loads on the origin server when a large number of visitors want to access your resources.\nScenarios: Static resources are deployed on the origin server but are not cached on POPs. The resources that are cached on POPs frequently expire.\nScenarios: Redirect URLs that contain different query strings to the same resource.\nScenarios: Downloads of installation packages or video streaming.\nAlibaba Cloud CDN records the cache hit status of all requests. For more information about log formats, see Download logs.\nYou can also call the DescribeCdnDomainLogs operation to query the log data of accelerated domain names."
    },
    "380": {
        "title": "CDN:Accelerate the retrieval of resources from an OSS bucket",
        "url": "https://www.alibabacloud.com/help/en/cdn/use-cases/accelerate-the-retrieval-of-resources-from-an-oss-bucket-in-the-alibaba-cloud-cdn-console",
        "content": "This Product\nCDN:Accelerate the retrieval of resources from an OSS bucket\nYou can use Alibaba Cloud CDN to accelerate the retrieval of static resources, such as images and videos, from an Object Storage Service (OSS) bucket. This topic describes how to accelerate the retrieval of resources from an OSS bucket by using the Alibaba Cloud CDN console and the use scenarios of Alibaba Cloud CDN.\nOSS is a cost-effective storage service. Alibaba Cloud CDN can accelerate the delivery of static resources. OSS buckets as origin servers provide the following benefits:\nAll requests that are destined for the origin server are redirected to points of presence (POPs). This reduces loads on the origin server.\nYou are charged for outbound data transfer from Alibaba Cloud CDN instead of outbound data transfer over the Internet from OSS. Outbound data transfer from Alibaba Cloud CDN is billed at a lower price.\nClients retrieve static resources from the nearest POPs. This minimizes the network transmission distance and ensures the quality of data transmission.\nIf an origin server is an OSS bucket, Alibaba Cloud CDN caches the static resources, including scripts, images, audio files, and video files, from the bucket to POPs. When users request the resources, the POPs return the requested resources to the users. This accelerates content delivery.\nThe following figure shows the architecture.\nYou can use content delivery network (CDN) services in the following scenarios: static content delivery acceleration, dynamic content delivery acceleration, and secure acceleration. Alibaba Cloud CDN serves to accelerate only the delivery of static content. If you want to accelerate the delivery of dynamic content or accelerate content delivery while ensuring high security, you can use Dynamic Content Delivery Network (DCDN).\nThe website image.example.com requires acceleration for image retrieval from an OSS bucket. The following table describes the business requirements and related information.\nItem\nDescription\nExample\nWebsite domain name\nThe domain name that is accelerated by Alibaba Cloud CDN.\nimage.example.com\nBusiness type\nDetermine the business type based on the website content.\nIf the website distributes images, set the business type to Image and Small File.\nImage and Small File\nAcceleration region\nThe region where the website visitors are located.\nChinese Mainland Only\nOrigin domain name\nSelect an OSS bucket that belongs to the current Alibaba Cloud account, or enter the public domain name of an OSS bucket.\n***.oss-cn-hangzhou.aliyuncs.com\nOther features\nEnable other features based on your business requirements.\nIncrease cache hit ratios by adding cache rules.\nSpecify domain names for origin fetch by configuring origin hosts.\nProtect OSS buckets from unauthorized access by enabling access control for private OSS buckets.\nAccelerate delivery for specific resources by enabling range origin fetch.\nIncrease the cache hit ratio and accelerate file distribution by enabling parameter filtering.\nProtect POPs from hotlinking by configuring Referer whitelists or Referer blacklists.\nProtect websites from hotlinking issues and IP theft by enabling URL signing.\n\nThe following figure shows how to use Alibaba Cloud CDN to accelerate content delivery for a website. The preceding scenario is used as an example.\nIf the origin server is an OSS bucket, you are charged for outbound data transfer from Alibaba Cloud CDN (charged by Alibaba Cloud CDN) and data transfer from OSS to Alibaba Cloud CDN (charged by OSS). For more information, see Billing of OSS content acceleration.\nAn Alibaba Cloud account is created, and real-name verification is completed for the account. For more information, visit the Sign up to Alibaba Cloud and Real-name Registration pages.\nOSS is activated, an OSS bucket is created, and related resources are uploaded to the OSS bucket. For more information, see Activate OSS.\nA domain name to be accelerated is prepared.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names. On the Domain Names page, click Add Domain Name and configure the following parameters:\nDomain Name to Accelerate: the domain name that is used to access your website by users. In this example, enter image.example.com.\nRegion: the region in which you want to accelerate the delivery of images in OSS, such as Chinese Mainland Only.\nIf you set the Region parameter to Chinese Mainland Only, you need to apply for an ICP filing for the domain name. For more information, see Prepare and check a domain name.\nThe first time you add a domain name to Alibaba Cloud CDN, the system verifies the ownership of the domain name before you can add the domain name. Follow the on-screen instructions to complete the verification. For more information, see Verify the ownership of a domain name.\nClick Add Origin Server and configure the parameters. Set Origin Info to OSS Domain and select the OSS bucket that you want to accelerate from the Domain Name drop-down list. Use the default values for other parameters and click OK.\nAfter you add an origin server, read and select the compliance commitment, click Next, and then wait for manual review.\nIf your accelerated domain name does not require manual review, you can proceed to the next step. You can configure the cache expiration, bandwidth cap, and HTML optimization features in the Recommended Features step based on your business requirements. The features improve the cache hit ratio, security, and access performance of the Alibaba Cloud CDN.\nWhen the Status of the domain name is Enabled, view the CNAME of the accelerated domain name. In this example, the CNAME is image.example.com.w.kunlunsl.com.\nAfter you add a domain name to Alibaba Cloud CDN, the system assigns a CNAME to the domain name. You must add a CNAME record in the system of your DNS service provider to map the domain name to the CNAME before requests can be redirected to POPs.\nIn the following example, Alibaba Cloud DNS is used to show how to add a CNAME record. For more information, see Add a CNAME record for a domain name.\nLog on to the Alibaba Cloud DNS console with the Alibaba Cloud account to which the accelerated domain name belongs.\nIn the left-side navigation pane, click Domain Name Resolution. Find the domain name for which you want to add a CNAME and click DNS Settings in the Actions column.\nClick Add DNS Record and add a CNAME record.\nRecord Type: Select CNAME.\nHostname: Enter image.\nRecord Value: Enter the CNAME assigned by Alibaba Cloud CDN to your accelerated domain name, such as image.example.com.w.kunlunsl.com.\nKeep the default values for other parameters.\nClick OK.\nTo improve acceleration performance, secure data transmission, and accelerate content delivery, you can enable the corresponding features based on your business requirements.\nIn the Alibaba Cloud CDN console, go to the Domain Names page, find the domain name that you want to manage, and then click Manage in the Actions column.\nConfigure the following features based on your business requirements.\nScenario\nDescription\nReferences\nIncrease the cache hit ratio\nSpecify a time-to-live (TTL) value for cached resources based on the following rules to increase the cache hit ratio:\nSpecify a TTL of one month or longer for static files that are infrequently updated, such as images and application packages.\nSpecify a TTL based on your business requirements for static files that are frequently updated, such as JavaScript and CSS files.\nSpecify a TTL of 0 seconds to disable caching for dynamic files, such as PHP, JSP, and ASP files.\nCreate a cache rule for resources\nSpecify a site to which POPs redirect requests\nBy default, the address of the host is the domain name of the OSS bucket. In this example, the domain name of the OSS bucket is ***.oss-cn-hangzhou.aliyuncs.com.\nIf a custom domain name such as origin.developer.aliyundoc.com is mapped to the OSS bucket, you need to set Domain Type to Custom Domain, and set the origin host to origin.developer.aliyundoc.com.\nFor more information, see Configure the default origin host.\nProtect OSS buckets from unauthorized access\nBy default, OSS buckets are accessible over the Internet. If you want to protect OSS buckets from unauthorized access, you can set the ACL of OSS buckets to private and enable the private bucket access feature. This way, Alibaba Cloud CDN has permissions to redirect requests only to OSS buckets that belong to the same account as Alibaba Cloud CDN.\nConfigure access to private OSS buckets\nBefore you perform this operation, set the ACL of OSS buckets to private to allow only authorized access. For more information, see Bucket ACLs.\nAccelerate file distribution on POPs\nAfter you enable range origin fetch, the OSS bucket that serves as the origin server returns the chunk of file that is specified by the Range header to POPs. This reduces origin traffic and accelerates content delivery.\nRange origin fetch is suitable for large file distribution scenarios such as audio and video streaming. Range origin fetch is not suitable for small file distribution scenarios. You do not need to enable range origin fetch when you use Alibaba Cloud CDN to accelerate the delivery of images.\nRange origin fetch\nIncrease the cache hit ratio\nIncrease file distribution efficiency\nAfter you enable the parameter filtering feature, POPs remove parameters that follow the question mark (?) from request URLs. This way, requests that carry different query strings but are destined for the same resource can hit the cache. This increases the cache hit ratio and reduces origin traffic.\nIgnore parameters\nProtect websites from hotlinking\nAfter you configure a Referer whitelist or blacklist, Alibaba Cloud CDN allows or blocks requests based on user identities. If a request is allowed, Alibaba Cloud CDN returns the URL of the requested resource. If a request is blocked, Alibaba Cloud CDN returns the HTTP 403 status code.\nConfigure a Referer whitelist or blacklist to enable hotlink protection\nProtect websites from hotlinking and IP theft\nURL signing cannot be performed without the origin server. The origin server generates signed URLs based on the URL signing settings on the POPs. After you enable URL signing, only requests that pass authentication can access resources on POPs.\nConfigure URL signing\n\nAfter the CNAME record takes effect and you set the ACL of the resources to be accessed to public-read, you can access resources in the OSS bucket by using one of the following methods:\nConcatenate the accelerated domain name and file path, and then enter the concatenated URL into a web browser. For example, if the accelerated domain name is aliyundoc.com and you want to access the file image_01.jpg in the root directory, you can send a request to http://aliyundoc.com/image_01.jpg.\nSet the domain name of the OSS bucket to the accelerated domain name in your client. This way, you can access resources in the OSS bucket by using the accelerated domain name from your client.\n"
    },
    "381": {
        "title": "CDN:Use Alibaba Cloud CDN to accelerate the retrieval of resources from an ECS instance",
        "url": "https://www.alibabacloud.com/help/en/cdn/use-cases/use-alibaba-cloud-cdn-to-accelerate-the-retrieval-of-resources-from-an-ecs-instance",
        "content": "This Product\nCDN:Use Alibaba Cloud CDN to accelerate the retrieval of resources from an ECS instance\nYou can use Alibaba Cloud CDN to accelerate the retrieval of resources from an Elastic Compute Service (ECS) instance. This topic describes how Alibaba Cloud CDN accelerates content delivery and how to use Alibaba Cloud CDN to accelerate the retrieval of resources from an ECS instance.\nECS is an infrastructure as a service (IaaS) that provides stable, reliable, and elastic cloud computing services with excellent performance. Alibaba Cloud CDN can accelerate static content delivery. ECS instances that are used as origin servers provide the following benefits:\nAll requests that are destined for the origin server are redirected to points of presence (POPs). This reduces loads on the origin server.\nYou are charged for outbound data transfer from Alibaba Cloud CDN instead of outbound data transfer over the Internet. Outbound data transfer from Alibaba Cloud CDN is billed at a lower price.\nClients retrieve static resources from the nearest POPs. This minimizes the network transmission distance and ensures the quality of data transmission.\nIf the origin server is an ECS instance, Alibaba Cloud CDN caches static resources, including scripts, images, audio files, and video files, on POPs. Clients can retrieve the cached resources from the nearest POPs. Dynamic resources, such as data from web programs and databases, are returned from the ECS instance to clients.\nIf you want to accelerate the retrieval of dynamic resources from an ECS instance, use Dynamic Content Delivery Network (DCDN). For more information, see What is DCDN?\nThe following figure shows how Alibaba Cloud CDN accelerates the retrieval of resources from an ECS instance.\nThe website image.example.com requires acceleration for image retrieval from an ECS instance. The following table describes the business information and requirements.\nItem\nDescription\nExample\nDomain name\nThe domain name that is accelerated by Alibaba Cloud CDN.\nimage.example.com\nBusiness type\nDetermine the business type based on the website content.\nIf the website distributes images, set the business type to Image and Small File.\nImage and Small File\nAcceleration region\nThe region where the website visitors are located.\nChinese Mainland Only\nOrigin server domain name\nYou can select Site Domain or IP.\nSite Domain: Enter the domain name of the origin server. The domain name is resolved to the IP address of the ECS instance.\nIP: Enter the public IP address of the ECS instance.\necs.example.com\nThe domain name of the origin server is used in this example.\nOther services\nEnable other features based on your business requirements.\nIncrease cache hit ratios by adding cache rules.\nSpecify domain names for origin fetch by configuring origin hosts.\nAccelerate delivery for specific resources by enabling the range origin fetch feature.\nIncrease the cache hit ratio and accelerate file distribution by enabling parameter filtering.\nProtect POPs from hotlinking by configuring Referer whitelists or Referer blacklists.\nProtect websites from hotlinking issues and IP theft by enabling URL signing.\nThe following procedure shows how to use Alibaba Cloud CDN to accelerate the retrieval of resources from an ECS instance. The preceding scenario is used as an example.\n\nAn Alibaba Cloud account is created and real-name verification is completed for the account. For more information, visit the Sign up to Alibaba Cloud and Real-name Registration pages.\nAlibaba Cloud CDN is activated. For more information, see Activate Alibaba Cloud CDN.\nAn ECS instance is created. For more information, see Create an instance.\nThe domain name that you want to accelerate is prepared.\nLog on to the Alibaba Cloud CDN console.\nIn the left-side navigation pane, click Domain Names. On this page, click Add Domain Name and configure the following parameters. The scenario that is described in Sample scenario is used an as example.\nThe first time a domain name is added to Alibaba Cloud CDN, Alibaba Cloud CDN verifies the ownership of only the root domain name. For more information, see Verify the ownership of a domain name. If the root domain name has already passed ownership verification, ignore the message.\nFor information about the parameters and usage notes, see Step 1: Configure business information.\nDomain Name to Accelerate: Enter image.example.com.\nBusiness Type: Select Image and Small File.\nRegion: Select Chinese Mainland Only.\nClick Add Origin Server to add an origin server.\nSet the Origin Info parameter to Site Domain or IP, and then enter the domain name of the origin server or the public IP address of the ECS instance that is used as the origin server. The domain name ecs.example.com of the origin server is used in this example. Use the default values for other parameters.\nFor information about the parameters and usage notes, see Step 2: Set up origin servers.\n\nAfter you add the origin server, click Next.\nWait for manual verification to complete.\nAfter the domain name passes the verification, the status of the domain name changes to Enabled. In this case, the domain name is added to Alibaba Cloud CDN.\n\nView the CNAME that is assigned to the domain name when the value in the Status column changes to Enabled. The CNAME for the domain name that is used in this example is image.example.com.w.kunlunsl.com.\nTo improve acceleration performance, secure data transmission, and accelerate content delivery, you can enable the corresponding features based on your business requirements.\nIn the Alibaba Cloud CDN console, go to the Domain Names page, find the domain name that you want to manage, and then click Manage.\nConfigure the features based on your business requirements. The following table describes the features.\nFeature\nDescription\nReferences\nIncrease the cache hit ratio\nSpecify a time-to-live (TTL) value for cached resources based on the following rules to increase the cache hit ratio:\nSpecify a TTL of one month or longer for static files that are infrequently updated, such as images and application packages.\nSpecify a TTL based on your business requirements for static files that are frequently updated, such as JavaScript and CSS files.\nSpecify a TTL of 0 seconds to disable caching for dynamic files, such as PHP, JSP, and ASP files.\nCreate a cache rule for resources\nSpecify the site to which POPs redirect requests\nIf multiple sites are hosted on your origin server, and the site on which the requested content resides is different from the site to which the accelerated domain name points, you need to configure an origin host. The origin host specifies the site to which Alibaba Cloud CDN redirects requests.\nConfigure the default origin host\nAccelerate file distribution on POPs\nAfter you enable the range origin fetch feature, the ECS instance that functions as the origin server returns the file chunk that is specified by the Range header to POPs. This reduces origin traffic and accelerates content delivery.\nThe range origin fetch feature is suitable for scenarios that involve large file distribution, such as audio and video streaming. The range origin fetch feature is not suitable for small file distribution scenarios. You do not need to enable the range origin fetch feature when you use Alibaba Cloud CDN to accelerate the delivery of images.\nConfigure the range origin fetch feature\nIncrease the cache hit ratio\nIncrease file distribution efficiency\nAfter you enable parameter filtering, POPs remove parameters that follow the question mark (?) from request URLs. This way, requests that carry different query strings but are destined for the same resource can hit the cache. This increases the cache hit ratio and reduces origin traffic.\nIgnore parameters\nProtect websites from hotlinking\nAfter you configure a Referer whitelist or blacklist, Alibaba Cloud CDN allows or blocks requests based on user identities. If a request is allowed, Alibaba Cloud CDN returns the URL of the requested resource. If a request is blocked, Alibaba Cloud CDN returns the HTTP 403 status code.\nConfigure a Referer whitelist or blacklist to enable hotlink protection\nProtect websites from hotlinking and IP theft\nURL signing cannot be performed without the origin server. The origin server generates signed URLs based on the URL signing settings on the POPs. After you enable URL signing, only requests that pass authentication can access resources on POPs.\nConfigure URL signing\nYou need to add a CNAME record to the system of your DNS service provider to map the domain name to the CNAME before requests can be redirected to POPs. Otherwise, CDN acceleration cannot take effect.\nIn the following example, Alibaba Cloud DNS is used to show how to add a CNAME record.\nFor more information, see Add a CNAME record for a domain name.\nLog on to the Alibaba Cloud DNS console with the Alibaba Cloud account to which the accelerated domain name belongs.\nGo to the Domain Name Resolution page, find the root domain name of the accelerated domain name example.com, and then click DNS Settings in the Actions column.\nClick Add DNS Record to add a CNAME record.\nRecord Type: Select CNAME.\nHostname: Enter image.\nRecord Value: Enter the CNAME that is assigned to the accelerated domain name. In this example, image.example.com.w.kunlunsl.com is used.\nUse the default values for other parameters.\nCheck whether the CNAME record takes effect.\nMethod 1: Use the Alibaba Cloud CDN console\nLog on to the Alibaba Cloud CDN console and navigate to the Domain Names page.\nFind the domain name and move the pointer over the CNAME Status column. If the CNAME status is Configured, the CNAME has taken effect.\nIf you add a CNAME record, it takes effect immediately. If you modify a CNAME record, it takes 10 minutes for the update to take effect because the default TTL value of a CNAME record is 10 minutes. During this period, the status of the domain name may be displayed as Pending Configuration in the Alibaba Cloud CDN console until the update takes effect. The actual time period varies based on the TTL value that you specify for the CNAME record.\nMethod 2: Run the nslookup command\nStart Command Prompt in Windows or Terminal in macOS or Linux.\nRun the nslookup -type=CNAME domainName command. If the CNAME in the output is the same as the CNAME that is assigned to the domain name in the Alibaba Cloud CDN console, Alibaba Cloud CDN acceleration takes effect for the domain name."
    },
    "382": {
        "title": "CDN:Accelerate web portal through CDN",
        "url": "https://www.alibabacloud.com/help/en/cdn/use-cases/accelerate-content-delivery-for-infographic-and-video-websites",
        "content": "This Product\nCDN:Accelerate web portal through CDN\nThis topic walks you through how to use Alibaba Cloud Content Delivery Network (CDN) to accelerate the storage of Image and Small File in OSS.\nCommon web portals mainly display static resources such as images, text, and videos. If your website resources are small images and files, set Business Type to Image and Small File. If your website has a large number of audio and video resources, select VOD. In this example, we use testcdn.top.\nUse the Alibaba Cloud ARMS monitoring tool to test the OSS resource URL and CDN accelerated domain name. The result is as follows:\nThe result of each test may be different due to network.\n\nBased on the above data, it can be accelerated by about 35% by connecting to CDN.\nCDN is activated. For information about how to activate CDN, see Activate CDN.\nAn origin server that provides stable performance is deployed. If you do not have an origin server, follow the instructions in Create and manage an ECS instance in the console (express version) or Create a bucket to create one.\nLog on to the CDN console.\nIn the left-side navigation pane, click Domain Names.\nOn the Domain Names page, click Add Domain Name.\nIn the Add Domain Name dialog box, set the following items:\nRegion: Global (Excluding the Chinese Mainland)\nDomain Name: images.testcdn.top\nBusiness Type: Image and Small File\nResource Group: Default Resource Group\nThe first time you add a domain name to CDN, you must verify the its ownership. For more information, see Verify the ownership of a domain name.\nClick Add Origin Sever. Set the following items:\nOrigin Info: OSS Domain\nDomain Name: select your bucket domain name\nPriority: Primary\nWeight: 10\nPort: 80\nRead the Compliance Warranty Regarding Cross-border Data Transfers notice, select I have read and agree to the preceding compliance commitment. Click Next, and then click Back to Domain Management.\nOn the Domain Names page, find the domain name that you added and copy the value in the CNAME field.\nMove the pointer over the left-side navigation pane of Alibaba Cloud to search for Products and Services. Enter DNS in the search box.\nIn the Enterprise Services & Cloud Communication section of the search results, click Alibaba Cloud DNS.\nOn the Authoritative DNS Resolution page, find the domain name that you want to manage and click DNS Settings in the Actions column.\nOn the DNS Settings tab, click Add DNS Record. Set Type to CNAME, Host Record to images, Request Source to Default, Value to the CNAME that you copied in Step 1, and TTL 10 Minutes (recommend).\nIssue\nAfter you add an accelerated domain name and configure a CNAME record, you can directly access the acceleration resource 403.\n\nSolution\nThis issue occurs because public read is not enabled for private OSS resources. For safety, the following operations are recommended.\nOn the CDN console, go to Domain Names page, find images.testcdn.top and click Manage.\nOn the CDN Domain Names page, click Origin Fetch. Turn on Status for Alibaba Cloud OSS Private Bucket Access. Select Bucket in the Same Account.\nVerify the access.\n\n"
    },
    "383": {
        "title": "CDN:Deliver Alibaba Cloud CDN real-time logs to Simple Log Service for analysis",
        "url": "https://www.alibabacloud.com/help/en/cdn/use-cases/ship-and-analyze-alibaba-cloud-cdn-real-time-logs-in-log-service",
        "content": "This Product\nCDN:Deliver Alibaba Cloud CDN real-time logs to Simple Log Service for analysis\nThis topic describes how to use the real-time log delivery feature to deliver logs from Alibaba Cloud CDN to Simple Log Service, and analyze the logs in Simple Log Service.\nThe real-time log delivery feature is a log data processing service that is jointly developed by Alibaba Cloud CDN and Simple Log Service. Featuring low-latency (typically within 3 minutes) shipping, you can use this feature to push access logs from points of presence (POPs) all over the world to Simple Log Service. You can then use Simple Log Service to store and analyze user access data. Requests that flow through Alibaba Cloud CDN are logged, and a trove of data is provided for analysis. You can analyze these logs to gain insights into user composition and access speed, as well as to locate and troubleshoot content delivery issues.\nAlibaba Cloud CDN is activated and a domain name is added for acceleration. For more information, see Activate Alibaba Cloud CDN.\nSimple Log Service is activated. For more information, see Getting Started.\nReal-time log delivery is configured for the accelerated domain name for which you want to analyze user access data. For more information, see Real-time log delivery.\nLog latency\nThe real-time log delivery feature collects log data in real time, and logs are generated within 3 minutes after an event occurs. Offline log data is generated within 24 hours.\nLog analysis\nThe real-time log delivery feature integrates the log storage and log analysis capabilities of Simple Log Service. The feature provides four preset analysis report templates, including templates for basic data, error analysis, frequently requested resources, and user analysis. The feature also supports custom log analysis policies. In comparison, the offline log feature only allows you to ship logs to Object Storage Service (OSS), and does not integrate log analysis capabilities.\nLow latency\nLog data is generated in 3 minutes after an event occurs. This allows you to analyze access logs, identify issues, and resolve them in a timely manner.\nEnd-to-end\nTraditional offline log analysis solutions typically require you to first download logs, upload them to a data warehouse, and subsequently clean the data and provide a definition for the data model. Only then will you be able to perform data analysis. This results in high labor costs and extends the time that is required for analysis. The real-time log delivery feature integrates log storage and log analysis capabilities of Simple Log Service to eliminate the tedious process of the traditional offline log analysis.\nYou can use real-time log delivery to troubleshoot issues that may occur when you use Alibaba Cloud CDN to accelerate domain names. You can also analyze user access statistics based on collected logs. The real-time log delivery feature of Alibaba Cloud CDN provides preset log analysis reports and supports custom log analysis policies to meet diverse requirements.\nLog analysis report\nDescription\nBasic data\nThis report provides information about the overall performance of Alibaba Cloud CDN and the user access efficiency, such as hit ratio, access latency, and download speed. You can quickly identify and handle service quality issues based on the report.\nAccess errors\nThis report helps you quickly locate issues when application access exceptions occur, such as URI issues, origin server failures, unavailable POPs, regional network issues, and Internet service provider (ISP) network issues.\nFrequently requested resources\nThis report provides information about frequently requested resources and helps you gain insight into popular domain names and URIs, as well as the provinces where most of your customers are located, and the ISPs of the customers. The data is also useful in helping you gain a better understanding of your business, such as whether operational activities attract the expected traffic volume, and whether the traffic during peak hours is higher or lower than expected. The information can help you make adjustments to the overall operations of your business.\nUser composition\nThis report provides information about the user composition of your website, including the client types, general locations, and ISPs of the users. You can analyze top users with most visits or most downloads.\nOn the Real-time Logs page, find the project for which you want to analyze logs, and click View Report.\n\nOn the data query template page, the data of all domain names is queried by default. You can also query the data of a specified domain name or URI.\n\nFor more information, see the following sections:\nPreset report: Basic data\nPreset report: Access errors\nPreset report: Frequently requested resources\nPreset report: User composition\nSubscribe to report template data\nIf the preset log analysis reports are unable to satisfy your requirements, you can use the log analysis feature of Simple Log Service to implement custom log analysis.\nFor example, you can view the ranking of domain names in requests whose HTTP status code is 499 or 502.\nOn the Real-time Logs page, find the project for which you want to analyze logs, and click Log analysis.\n\nOn the custom log analysis page, you can enter a query statement in the search box to query log data by using complex query conditions, or click log fields on the Raw Logs tab to filter logs by using simple filter conditions.\n\nFor more information, see Custom reports.\nYou can create a Log Service project to store real-time logs of an accelerated domain name, such as aliyun.example.com. For more information, see Real-time log delivery.\nThe following figure shows a created project, where the project name is project-example, the Logstore name is project-example, and the log storage region is China (Hangzhou) whose ID is cn-hangzhou.\n\nThis report provides information about the overall performance of Alibaba Cloud CDN and the user access efficiency, such as hit ratio, access latency, and download speed. It also allows you to quickly identify and handle service quality issues.\nThis report includes the following data. You can view all data, or filter data by domain name or URI.\nHealth: the proportion of requests with a normal HTTP status code\nCache hit ratio: the average cache hit ratio by the number of bytes\nDownload speed: the average download speed of resources\nAccess status: the percentages of HTTP status codes, including abnormal HTTP status codes\nAccess latency distribution: the proportion of each latency segment\nBandwidth: bandwidth data that is collected every minute\nPV/UV: page views and unique visitors\nRequest hit ratio: the hit ratio by the number of requests\nAccess latency: the average latency for resource download\n\nThis report helps you quickly locate issues when application access exceptions occur, such as URI issues, origin server failures, unavailable POPs, regional network issues, and ISP network issues.\nThis report includes the following data. You can view all data, or filter data by domain name or URI.\nTop 10 error domain names: the top 10 domain names with most access errors\nTop 10 error URIs: the top 10 URIs with most access errors\nRequest error percentage: the percentage of HTTP 4xx or 5xx status code by time\nError request distribution: the number and proportion of each HTTP status code\nErrors by ISP: the number of HTTP 4xx and 5xx status codes by ISP\nErrors by province: the number of HTTP 4xx and 5xx status codes by province\nError details (4xx): the number and proportion of HTTP 4xx status codes by province and ISP\nError details (5xx): the number and proportion of HTTP 5xx status codes by province and ISP\nError distribution by client: the number and proportion of HTTP 4xx or 5xx status codes corresponding to User-Agent information about each client\n\nThis report provides information about frequently requested resources and helps you gain insight into popular domain names and URIs, as well as the provinces where most of your customers are located, and the ISPs of the customers. The data is also useful in helping you gain a better understanding of your business, such as whether operational activities attract the expected traffic volume, and whether the traffic during peak hours is higher or lower than expected. The information can help you make adjustments to the overall operations of your business.\nThis report includes the following data. You can view all data, or filter data by domain name or URI.\nTop domain names by visit: the top domain names by the proportion of total visits\nTop domain names by download traffic: the top domain names by the percentage of total download traffic\nFrequently requested URIs: the numbers of visits, unique visitors, and downloads for each URI\nPopular access sources: popular Referer source domain names, the numbers of visits and unique visitors, and percentage\nVisits across the Chinese mainland: the average number of visits by province\nDownload speed across the Chinese mainland: the average download speed by province\nStatistics by province: the total number of visits, total download traffic, and average download speed by province\nTraffic and download speed by ISP: the total download traffic and average download speed by ISP\nStatistics by ISP: the total number of visits, total download traffic, and average download speed for each ISP\n\nThis report provides information about the user composition of your website, including the client types, general locations, and ISPs of the users. You can analyze top users with most visits or most downloads.\nThis report includes the following data. You can view all data, or filter data by domain name or URI.\nPV: page views\nUV: unique visitors\nSource region distribution: the number and proportion of visits for each province\nVisits by client: the number and proportion of visits by client type\nVisits by ISP: the number and proportion of visits by ISP\nTop users: the total number of visits, error visits, and downloads by IP address\nTop users with most valid visits: the total number of visits, number of error visits, and downloads by IP address, excluding invalid visits with HTTP status codes such as 4xx and 5xx\n\nIf you want Simple Log Service to periodically send data from a report template to you, you can use the subscription feature.\nBasic data is used as an example. Click Subscribe in the upper-right corner of the page, and then click Create.\nIn the dialog box that appears, configure Subscription Name, Frequency, and Global Time, and then click Next.\nSelect a notification method from the Notifications drop-down list, specify relevant information, and then click Submit.\nThe notification methods include Email, WebHook-DingTalk Bot, WebHook-Feishu Chat Bot, Webhook-WeCom Bot, and WeChat.\n\nExample 1: View the ranking of domain names with most HTTP status codes 499 in the last 30 days.\nLog analysis statement: return_code = 499| select domain , count(*) as c group by domain order by c desc limit 10\n\nExample 2: View the ranking of domain names with most HTTP status codes 502 in the last 30 days.\nLog analysis statement: return_code = 502| select domain , count(*) as c group by domain order by c desc limit 10\n\nExample 3: View the log data where URI is /cpu in the last 30 days.\nYou can directly click the uri field on the Raw Logs tab on the left and click /cpu to filter the required logs.\n"
    },
    "384": {
        "title": "CDN:List of operations by function",
        "url": "https://www.alibabacloud.com/help/en/cdn/developer-reference/api-cdn-2018-05-10-overview",
        "content": "This Product\nCDN:List of operations by function"
    },
    "385": {
        "title": "Enterprise Distributed Application Service:Trends and Announcements",
        "url": "https://www.alibabacloud.com/help/en/edas/product-overview/trends-and-announcements/",
        "content": "This Product\nEnterprise Distributed Application Service:Trends and Announcements"
    },
    "386": {
        "title": "Enterprise Distributed Application Service:Product Introduction",
        "url": "https://www.alibabacloud.com/help/en/edas/product-overview/product-introduction/",
        "content": "This Product\nEnterprise Distributed Application Service:Product Introduction"
    },
    "387": {
        "title": "Enterprise Distributed Application Service:Pricing",
        "url": "https://www.alibabacloud.com/help/en/edas/product-overview/pricing/",
        "content": "This Product\nEnterprise Distributed Application Service:Pricing"
    },
    "388": {
        "title": "Enterprise Distributed Application Service:Use EDAS to create applications",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/use-edas-to-create-applications",
        "content": "This Product\nEnterprise Distributed Application Service:Use EDAS to create applications\nThis topic describes how to use Enterprise Distributed Application Service (EDAS) to create applications in a Kubernetes cluster and an Elastic Compute Service (ECS) cluster.\nThe following figure shows the process of creating an application in a Kubernetes cluster.\nThe preceding process consists of the following steps:\nCreate a Container Service for Kubernetes (ACK) cluster. For more information, see Create an ACK managed cluster.\nImport the ACK cluster to EDAS. For more information, see Import the ACK cluster to the EDAS console.\nCreate an application. For more information, see Deploy an application in the ACK cluster.\nEnable access to the application over the Internet. For more information, see Bind CLB instances.\nView change records. For more information, see View application changes.\nView application logs. For more information, see View file logs.\nView service monitoring data. For more information, see View the overall information about an application.\nThe following figure shows the process of creating an application in an ECS cluster.\n\nThe preceding process consists of the following steps:\nCreate an ECS cluster. For more information, see Create an ECS cluster in the EDAS console.\nImport ECS instances to the ECS cluster. For more information, see Scale out an ECS cluster in the EDAS console.\nCreate an application. For more information, see Create and deploy an application in an ECS cluster.\nBind a Server Load Balancer (SLB) instance. For more information, see Overview.\nView change records. For more information, see View application changes.\nView application logs. For more information, see View instance logs.\nView service monitoring data. For more information, see Overview."
    },
    "389": {
        "title": "Enterprise Distributed Application Service:Get started with EDAS",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/get-started-with-edas",
        "content": "This Product\nEnterprise Distributed Application Service:Get started with EDAS\nTo help you use Enterprise Distributed Application Service (EDAS), this topic describes how to deploy the microservices application demos of Spring Cloud and Apache Dubbo to different EDAS environments. A demo can be deployed to an EDAS environment within 30 minutes.\nEDAS provides one to five pay-as-you-go application instances for free. If you have activated pay-as-you-go Standard Edition for EDAS and deployed no more than five application instances, you are not charged for using EDAS. However, you must pay for the Alibaba Cloud resources that you use to create Elastic Compute Service (ECS) and Server Load Balancer (SLB) instances until you release these resources.\nNacos is used as the registry for the application demo that is provided by EDAS. You can also create a registry or use Microservices Engine (MSE) to host another type of registry, such as Eureka or ZooKeeper, based on your business requirements. Make sure that the registry and the environment in which applications are to be deployed are connected over a network. If this condition is met, you can deploy your applications to EDAS without modifying code and use the application management, microservices, and cloud-native Platform as a Service (PaaS) platform capabilities of EDAS. For more information, see What is EDAS?\n\nDefault environment: the default ECS cluster in the default virtual private cloud (VPC) and default microservices namespace that are provided by EDAS. EDAS provides a default environment only for ECS clusters but not for Kubernetes clusters.\nCustom environment: the ECS cluster or Kubernetes cluster that you create."
    },
    "390": {
        "title": "Enterprise Distributed Application Service:Activate EDAS",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/activate-edas",
        "content": "This Product\nEnterprise Distributed Application Service:Activate EDAS\nYou must activate Enterprise Distributed Application Service (EDAS) before you use it. This topic describes how to activate EDAS.\nAn Alibaba Cloud account is created, and real-name verification is complete for the Alibaba Cloud account.\nVisit the EDAS  product page from a browser.\nOn the product page, click Buy Now.\nOn the EDAS buy page, select the billing method, edition, and number of application instances that you want to use.\nYou can select Subscription as the billing method. For more information about pricing, see Billing overview.\nCurrent Environment: By default, this parameter is set to Public Cloud. The setting cannot be modified.\nEdition: The valid values are Standard, Professional, and Platinum. For more information about the functional differences among different editions, see Editions.\nPayment type: By default, this parameter is set to Prepaid. The setting cannot be modified.\nInstances: Select the number of application instances as required.\nWe recommend that you select one to five application instances if you use EDAS for the first time and are not clear about how many application instances are required. Later, you can increase the number of application instances based on your business requirements.\nIf you have clear requirements, follow the instructions in the Product ranges available for sale section to avoid a mismatch between the selected configuration and specifications.\nRenewal duration: Select a renewal duration for the EDAS service.\nLog on with your Alibaba Cloud account and purchase the EDAS service as prompted.\nAfter you activate EDAS, click Console and log on to the EDAS console.\nIf you use EDAS for the first time, the Security Authorization Tip dialog box appears after you log on to the console. Click Authorize Now. On the Cloud Resource Access Authorization page, click Confirm Authorization Policy.\n"
    },
    "391": {
        "title": "Enterprise Distributed Application Service:Select an environment to deploy applications",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/select-an-environment-to-deploy-applications",
        "content": "This Product\nEnterprise Distributed Application Service:Select an environment to deploy applications\nEnterprise Distributed Application Service (EDAS) supports the Elastic Compute Service (ECS) environment and Kubernetes environment. Both environments allow you to host applications in them. However, ECS and Kubernetes provide different features. When you make business decisions or decide on the environment to which you want to migrate workloads, questions may arise. This topic describes and compares the ECS and Kubernetes environments. You can choose an environment based on your business requirements.\nEDAS supports the ECS environment and Kubernetes environment. You can deploy applications in ECS or Kubernetes clusters. Both ECS and Kubernetes support the Spring Cloud, Apache Dubbo, High-Speed Service Framework (HSF) microservice frameworks. EDAS allows you to host, govern, and monitor Java applications that use the preceding frameworks. ECS and Kubernetes have different requirements for applications and technology stacks. EDAS also provides different application management features to ECS and Kubernetes.\nKubernetes is applicable to most scenarios. EDAS is integrated with Container Service for Kubernetes (ACK), which provides a wide array of application management features to help you increase resource utilization.\nWe recommend that you choose an environment based on the actual business requirements.\nECS is a better alternative to hosting non-containerized applications because it provides an easier way to reuse existing application O&M systems.\nNo. ECS does not allow you to deploy multiple applications on the same instance. If you want to deploy multiple applications on the same instance, choose the Kubernetes environment.\nNo. ECS does not support applications written in different programming languages. If you want to deploy applications written in different programming languages, choose the Kubernetes environment.\nThe Kubernetes environment automatically scales in and scales out pods. In most cases, a Kubernetes cluster does not create new nodes (ECS instances) or release existing nodes.\nYou can use features provided by ACK to automatically scale in and scale out nodes.\nIn the ECS environment, scripts that are mounted to applications are used to run specified commands when the change order enters the specified stage. ECS allows you to mount scripts to the following lifecycle stages of an application: create an instance, start the application, stop the application, and release the instance.\nIn a Kubernetes pod, creating an instance and starting the application are considered the same process.\nIn a Kubernetes pod, stopping and releasing an instance are considered the same process."
    },
    "392": {
        "title": "Enterprise Distributed Application Service:Deploy Spring Cloud and Dubbo applications in a Kubernetes cluster",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/use-images-to-deploy-microservices-applications-in-kubernetes-clusters",
        "content": "This Product\nEnterprise Distributed Application Service:Deploy Spring Cloud and Dubbo applications in a Kubernetes cluster\nEnterprise Distributed Application Service (EDAS) allows you to deploy microservices applications. EDAS provides microservices application demos that use the following frameworks: Spring Cloud, Dubbo, and High-speed Service Framework (HSF). You can deploy application demos in the specified Kubernetes clusters. This topic describes how to deploy microservices applications in a Kubernetes cluster.\nEDAS is activated. For more information, see Activate EDAS.\nA Container Service for Kubernetes (ACK) cluster is created and added to EDAS. This operation is required because you cannot create a Kubernetes cluster in EDAS. For more information, see Use the EDAS console to manage Kubernetes clusters.\nTo experience fast application deployment, we recommend that you add your ACK cluster to the default microservices namespace of the region that you use. If you want to isolate resources and services in EDAS, you can add the ACK cluster that you created to a specified microservices namespace based on your business requirements.\nAn application image is created. For more information, see Create an application image.\nIf you use an image from a repository of Container Registry Enterprise Edition to deploy applications as a Resource Access Management (RAM) user, the RAM user must be authorized by the relevant Alibaba Cloud account. For more information, see RAM authentication rules.\nKubernetes environment: A Kubernetes environment is a Kubernetes cluster that resides in a specified microservices namespace and region.\nApplication demo: You can use application demo images in the EDAS console to call simple services. A demo image contains a server-side application (service provider) and a client-side application (service consumer). EDAS also provides WAR and JAR packages of microservices application demos that use the Spring Cloud, Dubbo, and HSF frameworks. For more information about how to deploy applications by using JAR or WAR packages, see Use a JAR or WAR package to deploy an application in an ACK cluster and Use a JAR package or WAR package to deploy an application in an ACK Serverless cluster.\nIn this example, a demo image is used to describe how to deploy microservices applications. For more information about application demos, visit alibabacloud-microservice-demo.\nFor more information about how to implement the features of microservices applications, see Overview of application development.\nA demo image contains a server-side application (service provider) and a client-side application (service consumer). This topic describes how to deploy a server-side application. The procedures for deploying a server-side application and a client-side application are similar.\nLog on to the EDAS console.\nIn the left-side navigation pane, choose Application Management > Applications.\nOn the Applications page, select a region in the top navigation bar, select a microservices namespace, and then click Create Application.\nIn the Basic Information step of the Create Application wizard, configure the basic information of the application and click Next. The following table describes the configurations used in this example.\nParameter\nOperation\nCluster Type\nSelect Kubernetes Clusters.\nApplication Runtime Environment\nHosted Applications: Select Java.\nSelect Application: Select Custom.\nIn the Configurations step of the Create Application wizard, configure the application environment, select a demo image, and then click Next. The following table describes the configurations used in this example.\nIf you want to use an image from a repository of Container Registry Enterprise Edition to deploy the server-side application as a RAM user, the RAM user must be authorized by the relevant Alibaba Cloud account. For more information, see RAM authentication rules.\n\nParameter\nDescription\nMicroservices Namespace\nSelect Default.\nThis topic aims to show you how to deploy a microservices application demo in a Kubernetes cluster. We recommend that you use the default microservices namespace and do not create a microservices namespace. If you want to isolate resources and services in EDAS to meet your business requirements, you can create a microservices namespace. For more information, see Manage microservices namespaces.\nCluster\nSelect the desired Kubernetes cluster from the drop-down list.\nK8s Namespace\nSelect default from the drop-down list.\nIf you want to create a custom Kubernetes namespace, click Create Kubernetes Namespace. In the dialog box that appears, enter a name for the Kubernetes namespace in the K8s Namespace field. The name can contain digits, lowercase letters, and hyphens (-), and can be 1 to 63 characters in length. It must start and end with a letter or a digit.\nApplication Name\nEnter an application name in the text box.\nApplication Description\nEnter a description for the application in the text box.\nImage Type\nSelect Demo Image.\nImage Repository Namespace\nSelect edas-demo-project from the drop-down list. Then, select 1.0 from the rightmost drop-down list of edas-demo-project/provider.\nThe demo image edas-demo-project/provider in the image repository edas-demo-project and the image version 1.0 are provided by EDAS. You are not allowed to change the settings.\nTotal Pods\nSet the value to 1.\nSingle-pod Resource Quota\nSet CPU Reserved CPU (Core) to 1 and Mem Reserved CPU (MB) to 2048.\nIn the Advanced Settings step of the Create Application wizard, click Create Application.\nIn the Advanced Settings step, you can configure the advanced settings based on your requirements. For more information, see Configure scheduling rules.\nIn the Creation Completed step of the Create Application wizard, confirm the information in the Basic Information, Configurations, and Advanced Settings steps. Then, click Create Application.\nAfter EDAS starts to deploy the application, the message Application change in progress... is displayed in the upper part of the Basic Information tab. The deployment takes about 2 minutes.\nYou can also click View Details next to the message to go to the Change List page of the application. On this page, you can check the deployment progress and log data.\nThe service consumer can be a web service consumer. After a server-side application and a client-side application are deployed, you can access the web page of the client-side application to verify the result.\n"
    },
    "393": {
        "title": "Enterprise Distributed Application Service:Deploy a microservices application in the default ECS cluster",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/deploy-a-microservices-application-in-the-default-ecs-cluster",
        "content": "This Product\nEnterprise Distributed Application Service:Deploy a microservices application in the default ECS cluster\nEnterprise Distributed Application Service (EDAS) provides microservices application demos that use the following frameworks: Spring Cloud, Dubbo, and High-speed Service Framework (HSF). These demos show you how to deploy microservices applications in EDAS. In addition, EDAS provides a default Elastic Compute Service (ECS) cluster in which you can deploy applications. This topic describes how to deploy a microservices application in the default ECS cluster.\nEDAS is activated. For more information, see Activate EDAS.\nAuto Scaling is activated and granted permissions on related Alibaba Cloud resources.\nDefault ECS cluster: A default microservices namespace is created in each region. EDAS automatically creates a default ECS cluster in the default microservices namespace. The default ECS cluster is deployed in the default virtual private cloud (VPC) of the region.\nApplication demos: You can use the microservices application demos in the EDAS console to deploy and call simple services. The microservices application demos use the Spring Cloud, Dubbo, and HSF frameworks. Each demo contains two applications. The procedure for deploying an application demo is the same for different frameworks. In this example, an application demo that uses the Spring Cloud framework is deployed. For more information about the microservices application demos, see alibabacloud-microservice-demo.\nFor more information about how to implement the features of a microservices application, see Overview of application development.\n\nEach microservices application demo contains a server-side application (service provider) and a client-side application (service consumer). The following example shows how to deploy the server-side application. After you deploy the server-side application, repeat the steps in this section to deploy the client-side application.\nDue to the way how services are called, you must deploy the server-side application before you deploy the client-side application. If you deploy the client-side application first, the service cannot be called, and an error is returned.\nLog on to the EDAS console.\nIn the left-side navigation pane, choose Application Management > Applications.\nIn the Basic Information step of the Create Application wizard, configure the basic information of the application and click Next.\n\nIn the Cluster Type section, click ECS Cluster.\nIn the Application Runtime Environment section, click Java. In the Java Environment drop-down list, select Open JDK 8.\nThe Spring Cloud application demo to be deployed in the ECS cluster is a Java Archive (JAR) package. Therefore, Java is selected as the application runtime environment in this example. If you want to deploy Spring Cloud, Dubbo, or HSF applications in the ECS cluster by using WAR packages, follow the instructions on this page to select an appropriate application runtime environment and version.\nEnter an application name in the Application Name field.\n(Optional) Enter a description for the application in the Application Description field.\nIn the Configurations step, configure the deployment package and environment for the application, and click Next.\n\nParameter\nDescription\nSource of Deployment Package\nThe source of the deployment package. In this example, Official Demo is used.\nDemo Type\nThe demon type. In this example, Spring Cloud Server Application is selected.\nInstance Source\nThe source of the instance. In this example, Purchase Instance is selected.\nEnvironment\nThe environment of the application. In this example, Default Environment is selected.\nPurchase Method\nThe method to purchase ECS instances. In this example, Purchase Based on Recommended Specifications is selected.\nSelect Specifications\nThe specifications of the ECS instances that you want to purchase. In this example, Ultra-low-spec Instance is selected.\nQuantity\nThe number of ECS instances that you want to purchase. In this example, 1 is used.\nLogon Password\nThe logon password of the ECS instance that you want to purchase.\nTerms of Service\nSelect Elastic Compute Service Terms of Service | Terms of Service for Images.\nIn the Advanced Settings step, configure the Version and Application Health Check parameters and click Create Application.\nBy default, the current timestamp is specified as the version number. The format of the version number is yyyymmdd:hhmmss.\nAfter EDAS starts to deploy the application, the message Application change in progress... is displayed in the upper part of the Basic Information tab. The deployment takes about 2 minutes.\nYou can also click View Details next to the message to go to the Change Details page of the application. On this page, you can check the deployment progress and log data.\nRepeat the steps in the \"Create a provider application\" section to create a consumer application. For more information, see Create a provider application.\nAn application is usually created and deployed in a VPC. Therefore, the application does not have a public IP address unless otherwise specified. If you want to allow access to your application over the Internet, we recommend that you configure an Internet-facing SLB instance for the application.\nIn this case, EDAS enables the session persistence feature for HTTP listeners. The feature cannot be disabled.\nLog on to the EDAS console.\nIn the left-side navigation pane, choose Application Management > Applications.\nOn the Applications page, select a region in the top navigation bar, select a microservices namespace from the Microservices Namespace drop-down list, and then select ECS Clusters from the Cluster Type drop-down list. Then, click the name of the consumer application that you created.\nOn the Basic Information page, click the Basic Information tab. In the Application Settings section, click Add on the right side of SLB (Internet).\nIn the Add Load Balancing (Public) dialog box, configure the SLB parameters as prompted. For more information, see Configure a dedicated SLB instance for an application.\nThe client-side application contains web services. After both the server-side and client-side applications are deployed, check whether you can log on to the web interface of the client-side application."
    },
    "394": {
        "title": "Enterprise Distributed Application Service:Deploy Spring Cloud and Dubbo applications in a custom ECS environment",
        "url": "https://www.alibabacloud.com/help/en/edas/getting-started/deploy-java-microservices-applications-in-custom-ecs-environments",
        "content": "This Product\nEnterprise Distributed Application Service:Deploy Spring Cloud and Dubbo applications in a custom ECS environment\nEnterprise Distributed Application Service (EDAS) provides microservices application demos that use the following frameworks: Spring Cloud, Dubbo, and High-speed Service Framework (HSF). These demos show you how to quickly deploy microservices applications in specified Elastic Compute Service (ECS) environments in EDAS. This topic describes how to deploy microservices applications in a custom ECS environment.\nEDAS is activated. For more information, see Activate EDAS.\nAuto Scaling is activated and granted permissions on related Alibaba Cloud resources.\nA virtual private cloud (VPC) and ECS instances are created.\nCustom environments are environments where applications run in the microservices namespaces, VPCs, ECS instances, and ECS clusters that you create. You can create microservice namespaces and ECS clusters when you deploy applications. You must create VPCs and ECS instances before you deploy applications in custom environments.\nFor information about how to create VPCs that use IPv4 CIDR blocks, see VPC console (manual creation). When you deploy a microservices application in a custom ECS environment, VPCs that use IPv6 CIDR blocks are not supported. Make sure that the region of the selected VPC is the same as the region where you want to deploy your microservices applications.\nFor information about how to create ECS instances, see Create an instance. When you create ECS instances, you must use the VPC that you created in Step a. To reduce costs, we recommend that you create two pay-as-you-go ECS instances, each of which is configured with one vCPU and two GB of memory. If you no longer require the ECS instances, we recommend that you release the instances at the earliest opportunity.\n\nThe port that is configured in the application demo is port 8080. When you create the ECS instances, you must enable port 8080 in the security group settings. Otherwise, you cannot access the web page of the client-side application. If you want to enable specific ports after you deploy your microservices application, you must perform the following operations: On the application details page, click the Basic Information tab. In the Application Settings section, view the value of the Application Port parameter and specify the Port Range parameter in the security group rule based on the application port.\n\nCustom ECS environment: A custom ECS environment refers to an ECS cluster that resides in a specified microservices namespace and in a specified VPC in a region.\nApplication demo: You can use application demos in the EDAS console to call simple services. An application demo uses the Spring Cloud, Dubbo, or HSF framework. Each demo contains two microservices applications. The procedure for deploying an application demo is the same for different frameworks. In this example, a Spring Cloud application demo is deployed. For more information about application demos, visit alibabacloud-microservice-demo.\nFor more information about how to implement the features of microservices applications, see Overview of application development.\nPython microservices applications cannot be deployed in ECS environments. You can deploy Python microservices applications in Kubernetes environments by using images. For more information, see Deploy Spring Cloud and Dubbo applications in a Kubernetes cluster.\nEach microservices application demo contains a server-side application (service provider) and a client-side application (service consumer). The following example shows how to deploy the server-side application. After you deploy the server-side application, repeat the steps in this section to deploy the client-side application.\nLog on to the EDAS console.\nIn the left-side navigation pane, choose Application Management > Applications.\nIn the Basic Information step of the Create Application wizard, configure the basic information of the application and click Next.\n\nIn the Cluster Type section, click ECS Cluster.\nIn the Application Runtime Environment section, click Java. In the Java Environment drop-down list, select Open JDK 8.\nThe Spring Cloud application demo to be deployed in the ECS cluster is a Java Archive (JAR) package. Therefore, Java is selected as the application runtime environment in this example. If you want to deploy Spring Cloud, Dubbo, or HSF applications in the ECS cluster by using WAR packages, follow the instructions on this page to select an appropriate application runtime environment and version.\nEnter an application name in the Application Name field.\n(Optional) Enter a description for the application in the Application Description field.\nIn the Configurations step, configure the deployment package and environment parameters for the application, and click Next. The following table describes the configurations used in this example.\n\nParameter\nOperation\nSource of Deployment Package\nSelect Official Demo.\nDemo Type\nSelect Spring Cloud Server Application from the drop-down list.\nInstance Source\nSelect Use Existing Instance.\nEnvironment\nSelect Custom Environment.\nMicroservices Namespace\nSelect the microservices namespace where your cluster resides from the drop-down list.\nIf the cluster resides in the default microservices namespace, select Default.\nCluster\nIf you want to use an existing cluster, select your cluster from the drop-down list. If you want to create a cluster, perform the following operations:\nClick Create Cluster. In the Create Cluster dialog box, select VPC from the Network Type drop-down list and select the VPC that you created in Step a from the VPC Network drop-down list.\n\nInstance Source Type\nIf you want to use an instance that is not imported to a cluster, select Instance not Imported to Any Cluster.\nIf you want to use an instance that is imported to the selected cluster, select Instances in Current Cluster. To import an instance to the cluster, perform the following operations:\nIn the left-side navigation pane of the EDAS console, choose Resource Management > ECS Clusters. Find the cluster to which you want to import the instance and click the cluster name to go to the Cluster Details page. In the ECS Instance section, click the  icon and click Add Existing ECS.\nIn the Select Cluster and Existing ECS Instances step of the Add ECS Instance wizard, select Import ECS, select the created ECS instance, and then click Next.\nIn the Ready to Import step, confirm the information about the instance and click Confirm and Import.\nIn the Import step, check whether Directly imported. appears in the Status column. If Directly imported. appears, click Back to Cluster Details. You can view the imported instance in the ECS Instance section.\nSelect Instance\nSelect the created ECS instance.\nIn the Advanced Settings step, configure the Version, Application Health Check, Batch, Batch Mode, and Wait Time Before Next Batch parameters, and click Create Application.\nThe Wait Time Before Next Batch parameter is required only when you select more than one ECS instance. In this example, the application demo is deployed only on one ECS instance. Therefore, you do not need to specify this parameter.\nBy default, the current timestamp is specified as the version number. The format of the version number is yyyymmdd:hhmmss.\nBatch: Select 1 Batches.\nBatch Mode: Select Automatic.\nAfter EDAS starts to deploy the application, the message Application change in progress... is displayed in the upper part of the Basic Information tab. The deployment takes about 2 minutes.\nYou can also click View Details next to the message to go to the Change Details page of the application. On this page, you can check the deployment progress and log data.\nYou can refer to the procedure for creating a server-side application to create a client-side application. For more information, see Create a server-side application. When you create a client-side application, you must select Spring Cloud Client Application from the Demo Type drop-down list.\nThe client-side application contains web services. After both the server-side and client-side applications are deployed, check whether you can log on to the web interface of the client-side application.\n"
    },
    "395": {
        "title": "Enterprise Distributed Application Service:User Guide for Alibaba Finance Cloud",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/user-guide-for-alibaba-finance-cloud",
        "content": "This Product\nEnterprise Distributed Application Service:User Guide for Alibaba Finance Cloud\nEnterprise Distributed Application Service (EDAS) is supported on Alibaba Finance Cloud. You can use EDAS to host and perform governance operations on microservices applications on Alibaba Finance Cloud.\nAlibaba Finance Cloud is an industrial cloud that serves financial institutions, such as banks, security agencies, insurance companies, and funds. Alibaba Finance Cloud relies on a cluster of independent data centers to provide cloud services that meet the regulatory requirements of the People's Bank of China, China Banking and Insurance Regulatory Commission (CBIRC), and China Securities Regulatory Commission (CSRC). Compared to Alibaba Cloud, Alibaba Finance Cloud provides more professional and comprehensive services for financial customers. Based on the compliance requirements of the People's Bank of China and CBIRC, Alibaba Finance Cloud is significantly improved in terms of security, service availability, and data reliability.\nEDAS is supported on Alibaba Finance Cloud in the China East 1 Finance, China East 2 Finance, and China South 1 Finance regions.\nThe features EDAS provides on Alibaba Finance Cloud are different from those on Alibaba Cloud. We apologize for the inconvenience brought by the differences. Take note of the following limits when you use EDAS on Alibaba Finance Cloud:\nKubernetes clusters that are created in the China (Hangzhou) region are not supported.\nKubernetes clusters of V1.22 or later are not supported.\nElastic Compute Service (ECS) clusters purchased by EDAS cannot be used to manage applications. For example, you cannot use such an ECS cluster to create applications, scale out applications, or configure auto scaling for applications.\nServerless Kubernetes clusters are not supported.\nMulti-language applications are not supported.\nThe throttling and degradation features are not supported for ECS applications and Kubernetes applications.\nThe overview page of the component center module, the batch operations feature, and the distributed job scheduling feature are not supported.\nSome features of the microservices governance module are not supported. The features include Dubbo Admin, tag-based routing, service testing, automated regression, service degradation, service mesh, and end-to-end throttling. For more information, see Supported features.\nAlibaba Finance Cloud also imposes specific limits on the cloud sources based on which you can use EDAS.\nEDAS provides a series of application management features that you can use on Alibaba Finance Cloud.\nModule\nFeature description\nReferences\nResource management\nMicroservices namespace\nEDAS uses microservices namespaces to provide isolated runtime environments, such as development, staging, and production environments. You can use microservices namespaces to isolate resources and services. This way, you can realize centralized management by using a single account.\nManage microservices namespaces in the EDAS console\nECS cluster management\nEDAS allows you to create clusters, scale out clusters, and perform other management operations on clusters. You cannot manage ECS clusters that are purchased by EDAS.\nManage ECS clusters\nScale out an ECS cluster in the EDAS console\nKubernetes cluster management\nEDAS allows you to import all types of Kubernetes clusters created in Container Service for Kubernetes (ACK), except ACK Serverless clusters.\nOverview\nOverview of application upgrades and rollbacks (applicable to Kubernetes clusters)\nHybrid cloud\nEDAS allows you to deploy applications in hybrid cloud ECS clusters and provides complete solutions for the scale-out, networking, and centralized management of these clusters. You can connect Alibaba Finance Cloud ECS instances, servers from data centers, and servers from other cloud service providers by using Express Connect circuits, and add the instances and servers to hybrid cloud ECS clusters in EDAS. This way, you can deploy applications in these clusters and use application hosting capabilities that are provided by EDAS.\nCreate a hybrid cloud ECS cluster\nResource group\nIf you use your Alibaba Finance Cloud account to purchase resources and manage applications as a RAM user, you can manage account permissions by using resource groups. EDAS allows you to grant RAM users the permissions on a resource group. This way, each authorized RAM user can manage all the resources in the resource group.\nManage resource groups\nApplication deployment\nAfter you develop and test an application, you can create and deploy the application in an ECS cluster.\nAfter you create and deploy an application in EDAS, you may need to update the application. If an error occurs on the new application version after an update, you can roll back your application to an earlier version.\nOverview\nOverview\nOverview of application upgrades and rollbacks (applicable to Kubernetes clusters)\nOverview\nApplication O&M\nEDAS provides the following O&M features for applications:\nApplication lifecycle management\nServer load balancing\nChange history\nLogs\nManage lifecycle for applications deployed in ECS clusters\nView application changes\nOverview\nEDAS provides a series of service governance features that you can use on Alibaba Finance Cloud.\nFeature\nDescription\nReferences\nService authentication\nEDAS supports access control on Spring Cloud and Dubbo applications by using service authentication. If a microservices application requires high security and you want to restrict access to it from other applications, you can authenticate the applications that call the microservices application. This ensures that only the applications that match the authentication rules can call the microservices application.\nImplement access control on Spring Cloud applications by using service authentication\nImplement access control of Dubbo applications through service authentication\nOutlier ejection\nIn a microservices framework, service calls are affected if consumers cannot detect the exceptions on the application instances of a provider. This further affects the performance and even availability of the services provided by the consumers. The outlier ejection feature monitors the availability of application instances and dynamically adjusts the instances. This ensures successful service calls and improves the service stability and quality of service (QoS).\nEnsure the availability of Spring Cloud applications by using outlier ejection\nEnsure the availability of Dubbo applications by using outlier ejection\nThe following table describes the EDAS features that are supported on Alibaba Finance Cloud and compares the supported features among different regions. Y indicates that a feature is supported, whereas N indicates that a feature is not supported.\nFeature\nChina East 1 Finance\nChina East 2 Finance\nChina South 1 Finance\nBilling method\nOnly the subscription billing method is supported. The pay-as-you-go method is not supported.\nResource management\nECS instance\nY\nY\nY\nVirtual private cloud (VPC)\nN\nN\nN\nECS cluster\nY\nY\nY\nACK cluster\nN: Kubernetes clusters that are created in the China (Hangzhou) region are not supported.\nY\nY\nServerless Kubernetes cluster\nN\nN\nN\nPermission management on resources\nRAM authentication\nY\nY\nY\nRAM resource group\nN\nN\nN\nResource tagging\nN\nN\nN\nQuota\nN\nN\nN\nApplication management\nMicroservices namespace\nY\nY\nY\nApplication list\nY\nY\nY\nECS application\nBasic information\nY\nY\nY\nCanary release\nY\nY\nY\nChange history\nY\nY\nY\nLog management\nY\nY\nY\nOnline log view\nY\nY\nY\nLog Service-based distributed log search\nY\nY\nY\nApplication Real-Time Monitoring Service (ARMS)-based application monitoring\nY\nY\nY\nARMS-based alerting\nY\nY\nY\nApplication High Availability Service (AHAS)-based throttling and degradation\nN\nN\nN\nThrottling and degradation (old version)\nN\nN\nN\nConfiguration push\nY\nY\nY\nService list\nY\nY\nY\nAuto scaling\nY\nY\nY\nEvent center\nY\nY\nY\nContainer version\nY\nY\nY\nKubernetes application\nBasic information\nN\nY\nY\nChange history\nN\nY\nY\nApplication event\nN\nY\nY\nReal-time log\nN\nY\nY\nLog directory\nN\nY\nY\nFile logs in Log Service\nN\nY\nY\nARMS-based application monitoring\nN\nY\nY\nAHAS-based throttling and degradation\nN\nN\nN\nThrottling and degradation (old version)\nN\nN\nN\nARMS-based notification and alerting\nN\nY\nY\nEvent center\nN\nY\nY\nService list\nN\nY\nY\nKubernetes Service management\nN\nY\nY\nAuto scaling\nN\nY\nY\nMulti-language application\nKubernetes multi-language application\nN\nN\nN\nApplication routing\nKubernetes Ingress\nY\nY\nY\nConfiguration management\nConfiguration list, historical version, listening query, and push track\nY\nY\nY\nKubernetes configuration\nY\nY\nY\nMicroservices governance\nTrace query\nY\nY\nY\nService query\nY\nY\nY\nOutlier ejection\nY\nY\nY\nService authentication\nY\nY\nY\nDubbo Admin\nN\nN\nN\nTag-based routing\nN\nN\nN\nService testing\nN\nN\nN\nService stress testing\nN\nN\nN\nAutomated regression\nN\nN\nN\nService inspection\nN\nN\nN\nService degradation\nN\nN\nN\nService mesh\nN\nN\nN\nEnd-to-End throttling\nN\nN\nN\nComponent center\nOverview\nN\nN\nN\nBatch operations\nN\nN\nN\nSchedulerX V2.0\nN\nN\nN\nSystem management\nAlibaba Finance Cloud account\nY\nY\nY\nRAM user\nY\nY\nY\nRole\nY\nY\nY\nAll permissions\nY\nY\nY\nPermission assistant\nY\nY\nY\nPersonal information\nY\nY\nY\nAccount switching\nY\nY\nY\nService usage\nY\nY\nY\nOperation log\nY\nY\nY"
    },
    "396": {
        "title": "Enterprise Distributed Application Service:Application Hosting (K8s)",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/application-hosting-1/",
        "content": "This Product\nEnterprise Distributed Application Service:Application Hosting (K8s)"
    },
    "397": {
        "title": "Enterprise Distributed Application Service:Application Hosting (ECS)",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/application-hosting/",
        "content": "This Product\nEnterprise Distributed Application Service:Application Hosting (ECS)"
    },
    "398": {
        "title": "Enterprise Distributed Application Service:Select an O&M method for your service registry",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/select-an-o-and-m-method-for-your-service-registry",
        "content": "This Product\nEnterprise Distributed Application Service:Select an O&M method for your service registry\nEureka, ZooKeeper, and Nacos are popular service registries in Java microservices frameworks. Service registries are used to implement service registration and discovery. They can decouple services and free you from dependency management. This way, you can dynamically manage microservices. This topic describes the service registries supported by Enterprise Distributed Application Service (EDAS) and how to perform O&M for these service registries.\nEDAS supports the following service registries: Eureka, ZooKeeper, and Nacos. For more information about each service registry, visit the corresponding official website or GitHub repository. You can choose a service registry based on your actual needs.\nEDAS provides hosting and microservices governance services for your applications, regardless of the type of service registry that your applications use.\n\nEDAS provides various O&M methods to cater to different types of service registries that your applications use.\nIf you use Nacos as the service registry, the following two options are available:\nUse the shared service registry of EDAS\nEDAS integrates the general availability (GA) version of Nacos. EDAS provides the service registration and discovery capabilities of Nacos in the form of a shared service registry that does not require O&M.\nBenefits\nThe shared service registry of EDAS provides the following benefits:\nThe shared service registry saves the costs for the deployment and O&M of a service registry.\nLinks are encrypted for calls during service registration and discovery. This protects your services from being discovered by unauthorized applications.\nThe shared service registry of EDAS is fully integrated with other EDAS components to provide you with a comprehensive microservices solution.\nOperations\nWhen you create or deploy a Kubernetes application, clear Use the service registry configured for the application. This way, the URL of the Nacos service registry specified in the application configurations will be overwritten by the URL of the shared service registry of EDAS.\nUse an MSE-managed or a self-managed Nacos service registry\nOperations\nWhen you create or deploy a Kubernetes application, select Use the service registry configured for the application. To prevent the URL of the configured Nacos service registry from being overwritten by the URL of the shared service registry of EDAS during application deployment, EDAS adds the following settings to the application configurations. This ensures that your application uses the service registry that is specified in the application configurations.\nMake sure that the service registry that is specified in the application configurations can connect to the application deployed in EDAS. For example, the service registry resides in the same virtual private cloud (VPC) as the application.\nNacos 2.X does not support access from all regions. Therefore, your client cannot connect to port 9848.\nFor more information about how to specify Use the service registry configured for the application, see Configure microservices governance.\nYou can use an MSE-managed or a self-managed Eureka or ZooKeeper service registry. For more information about Microservice Engine (MSE) and the benefits of MSE-managed service registries, see What is MSE?.\nMake sure that the service registry that is specified in the application configurations can connect to the application deployed in EDAS. For example, the service registry resides in the same VPC as the application.\nOperations\nWhen you create or deploy a Kubernetes application in the EDAS console by using a Eureka or ZooKeeper service registry, select Use the service registry configured for the application. For more information about how to perform the operations, see Configure microservices governance.\nYou can also change Eureka or ZooKeeper to Nacos in the application configurations to use the shared service registry of EDAS.\nIf you want to use a service registry of other types, such as Consul, the service registry must be self-managed.\nMake sure that the service registry that is specified in the application configurations can connect to the application deployed in EDAS. For example, the service registry resides in the same VPC as the application.\nOperations\nWhen you create or deploy a Kubernetes application in the EDAS console by using a service registry of another type, select Use the service registry configured for the application. For more information about how to perform the operations, see Configure microservices governance.\nYou can also change this type of service registry to Nacos in the application configurations to use the shared service registry of EDAS.\nThe authentication information of an EDAS tenant will be injected into EDAS. Authentication by using the username and password method has a higher priority than authentication by using the tenant information. Therefore, you must remove the username and password configured for the service registry in the application configurations.\nTo connect to the MSE Nacos service registry, perform the following operations: Associate the MSE service registry with an MSE Nacos instance when you create a microservice namespace. Then, select this microservice namespace when you create an application. For more information about how to create a microservice namespace, see Create a microservice namespace.\nApplication Configuration Management (ACM) that is integrated with EDAS is not affected after ACM is discontinued. For more information about how to write code, see Create and dynamically adjust configuration values."
    },
    "399": {
        "title": "Enterprise Distributed Application Service:Search for a resource",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/search-for-a-resource",
        "content": "This Product\nEnterprise Distributed Application Service:Search for a resource\nEnterprise Distributed Application Service (EDAS) provides the resource search feature to help you find and access resources. You can use information such as resource IDs and names to search for resources. This topic describes how to use the resource search feature to quickly access resources.\nEDAS resources include microservices namespaces, clusters, and applications. Each type of resource has multiple attributes or subresources. You may want to find microservices namespaces, clusters, or applications based on their attributes or subresources. For example, you may want to find the application on which a pod runs based on the IP address of the pod, or find the Elastic Compute Service (ECS) cluster in which an ECS instance resides based on the instance. These search operations are frequently required in day-to-day management, but rarely completed. EDAS provides the resource search feature that helps you quickly access resources.\nYou can search for the following resources:\nMicroservices namespace\nCluster: ECS clusters, Container Service for Kubernetes (ACK) clusters, and serverless Kubernetes (ASK) clusters\nApplication: applications deployed in ECS clusters, ACK clusters, and ASK clusters\nYou must have the permissions to search for a resource. For more information, see Grant the search permissions on resources.\nThe resource search feature allows you to search for microservices namespaces, clusters, and applications in EDAS. When you use a Resource Access Management (RAM) user to search for resources, you must grant the search permissions on the resources to the RAM user. This ensures data security.\nIf you use your Alibaba Cloud account, you are granted the search permissions on resources by default.\nLog on to the EDAS console with your Alibaba Cloud account and switch the account to a RAM user. For more information, see Step 4: Replace the EDAS-defined permissions with the RAM policy for the RAM user in the EDAS console.\nIn the left-side navigation pane, choose System Management > Permission Assistant.\nOn the Permission Assistant page, click Create Policy.\nIn the Create Custom Policy step of the Create Policy wizard, configure Policy Name and Remarks.\nAdd statements and click Next Step.\nYou can create multiple statements for a policy. If a permission is specified in statements that have different effects, the Deny statement prevails. For example, if a permission is specified in an Allow statement and a Deny statement, the Deny statement prevails.\nWhen you add a statement, you can select only one statement type. Available statement types are Allow and Deny.\nIn the Create Custom Policy step, click Add Statement. In the Add Statement panel, add statements.\nEDAS uses separate permissions to control whether the RAM user can search for resources and view the details of search results. For example, if a RAM user wants to view the application resources in a search result, the RAM user must have the permission to view the application. You can grant the search permissions on microservices namespaces, clusters, and applications to RAM users based on your business requirements.\nThe following section provides examples on how to add statements. In this example, statements that allow the RAM user to view a microservices namespace named test, view clusters in the microservices namespace, and manage applications in the microservices namespace are added.\nSelect Allow as Effect.\nIn the left-side directory tree of the Operation and Resource Permissions section, choose Resource Search > Resource Search.\nIn the left-side directory tree of the Operation and Resource Permissions section, choose Namespace > View Namespace. From the drop-down lists on the right side, select China (Beijing) and test.\nThis permission allows the RAM user to view the test microservices namespace. You can determine whether to grant the permission to a RAM user based on your business requirements.\nIn the left-side directory tree of the Operation and Resource Permissions section, choose Clusters > View Cluster. From the drop-down lists on the right side, select China (Beijing), test, and All Clusters.\nThis permission allows the RAM user to view all clusters in the test microservices namespace. You can determine whether to grant the permission on specific clusters to a RAM user based on your business requirements.\nIn the left-side directory tree of the Operation and Resource Permissions section, select Applications to select all permissions on applications. From the drop-down lists on the right side, select China (Beijing) and test.\nThis permission allows the RAM user to view all applications in the test microservices namespace. You can determine whether to grant the permission on specific applications to a RAM user based on your business requirements.\nFollow the on-screen instructions in the Preview Policy step to create a custom policy in the RAM console and attach the policy to the RAM user. After you create the custom policy, preview the permissions and click Complete. For more information, see Step 3: Create a RAM user and attach the policy to the RAM user.\nThe New policy authorization succeeded message appears. Click Back to Policy List to return to the Permission Assistant page. On this page, view the created policy.\nLog on to the EDAS console.\nIn the left-side navigation pane, click Resource Search (CTRL+F). In the search box that appears, enter the keyword of the resource that you want to query.\nYou can also perform fine-grained searches by selecting the attribute prefix of the keyword. The following attribute prefixes are supported:\nid: the unique identifier of the resource.\nname: the name of the resource.\nip: the IP address of the resource.\ntag: the tag of the resource.\nYou can enter the following commands in the search box to obtain the help information:\nhelp: provides the help information.\ninfo: provides information about the current account.\nIn the EDAS console, you can press Ctrl+F on your keyboard to open the resource search box for real-time queries.\nThe resource is displayed on the right side of the search box. Click the resource ID to go to the resource details page."
    },
    "400": {
        "title": "Enterprise Distributed Application Service:Microservice Governance",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/microservice-governance/",
        "content": "This Product\nEnterprise Distributed Application Service:Microservice Governance"
    },
    "401": {
        "title": "Enterprise Distributed Application Service:Application Routing",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/application-routing/",
        "content": "This Product\nEnterprise Distributed Application Service:Application Routing"
    },
    "402": {
        "title": "Enterprise Distributed Application Service:Application Acceptance",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/application-acceptance/",
        "content": "This Product\nEnterprise Distributed Application Service:Application Acceptance"
    },
    "403": {
        "title": "Enterprise Distributed Application Service:Application Platform Management",
        "url": "https://www.alibabacloud.com/help/en/edas/user-guide/application-platform-management/",
        "content": "This Product\nEnterprise Distributed Application Service:Application Platform Management"
    },
    "404": {
        "title": "Enterprise Distributed Application Service:K8s",
        "url": "https://www.alibabacloud.com/help/en/edas/use-cases/k8s/",
        "content": "This Product\nEnterprise Distributed Application Service:K8s"
    },
    "405": {
        "title": "Enterprise Distributed Application Service:ECS",
        "url": "https://www.alibabacloud.com/help/en/edas/use-cases/ecs-1/",
        "content": "This Product\nEnterprise Distributed Application Service:ECS"
    },
    "406": {
        "title": "Enterprise Distributed Application Service:Application development",
        "url": "https://www.alibabacloud.com/help/en/edas/use-cases/application-development-3/",
        "content": "This Product\nEnterprise Distributed Application Service:Application development"
    },
    "407": {
        "title": "Enterprise Distributed Application Service:Devops",
        "url": "https://www.alibabacloud.com/help/en/edas/use-cases/devops/",
        "content": "This Product\nEnterprise Distributed Application Service:Devops"
    },
    "408": {
        "title": "Enterprise Distributed Application Service:Application Development",
        "url": "https://www.alibabacloud.com/help/en/edas/developer-reference/application-development-2/",
        "content": "This Product\nEnterprise Distributed Application Service:Application Development"
    },
    "409": {
        "title": "Enterprise Distributed Application Service:API Reference",
        "url": "https://www.alibabacloud.com/help/en/edas/developer-reference/api-reference/",
        "content": "This Product\nEnterprise Distributed Application Service:API Reference"
    },
    "410": {
        "title": "Enterprise Distributed Application Service:SDK Reference",
        "url": "https://www.alibabacloud.com/help/en/edas/developer-reference/sdk-reference/",
        "content": "This Product\nEnterprise Distributed Application Service:SDK Reference"
    },
    "411": {
        "title": "Enterprise Distributed Application Service:FAQ",
        "url": "https://www.alibabacloud.com/help/en/edas/support/faq-7/",
        "content": "This Product\nEnterprise Distributed Application Service:FAQ"
    },
    "412": {
        "title": "Container Service for Kubernetes:Product Introduction",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/product-introduction",
        "content": "This Product\nContainer Service for Kubernetes:Product Introduction\nContainer Service for Kubernetes (ACK) (ACK ) is one of the first services to participate in the Certified Kubernetes Conformance Program in the world. ACK provides high-performance containerized application management services to allow enterprises to manage the lifecycle of containerized applications and efficiently deploy containerized applications in the cloud. This topic introduces ACK and describes different types of ACK clusters.\nACK provides multiple types of clusters, including ACK managed clusters, ACK Serverless clusters, and ACK Edge clusters.\nCluster type\nDescription\nReferences\nContainer Service for Kubernetes\nACK Pro clusters are developed based on ACK Basic clusters. ACK Pro clusters provide all benefits of ACK Basic clusters, such as fully-managed control planes and control plane high availability. ACK Pro clusters also provide enhanced reliability, security, and schedulability and are covered by SLAs that contain compensation clauses. ACK Pro clusters are ideal for large-scale businesses in production environments and enterprises that require high stability and security.\nWhat is ACK?\nACK Serverless\nA serverless container service. In ACK Serverless clusters, you can deploy containerized applications without the need to purchase nodes, maintain nodes, or plan the node capacity. Pay-as-you-go fees are charged based on the CPU and memory resources requested by the applications that you deploy. ACK Serverless clusters are compatible with Kubernetes and can help you easily get started with Kubernetes. You can focus on application development instead of worrying about the infrastructure.\nWhat is ACK Serverless?\nACK Edge\nACK Edge is a cloud-edge coordination solution intended for edge computing. ACK Edge clusters are standard, secure, and highly-available Kubernetes clusters and are integrated with cloud virtualization, storage, network, and security capabilities. ACK Edge clusters can simplify your cluster O&M work and allow you to focus on containerized application development and management.\nWhat is ACK Edge?\nACK Lingjun\nACK Lingjun clusters are Kubernetes clusters developed based on Intelligent Computing LINGJUN with fully-managed and highly-available control planes. In ACK Lingjun clusters, Lingjun nodes serve as worker nodes.\nWhat is ACK Lingjun?\nCloud-native AI suite\nA cloud-native AI technology and product solution that uses ACK as the base.\nThe cloud-native AI suite can be used to centrally manage heterogeneous resources and is compatible with standard Kubernetes environments and APIs. You can run key components in the cloud-native AI suite to manage and maintain resources, schedule AI jobs, scale applications, accelerate data access, orchestrate workflows, integrate big data services, manage the lifecycle of AI jobs, and manage AI artifacts.\nThe cloud-native AI suite also targets key steps in AI development pipelines, including AI dataset management, AI model development, training, and evaluation, and inference services.\nCloud-native AI suite overview\nDistributed Cloud Container Platform for Kubernetes (ACK One)\nACK One is an enterprise-class cloud-native platform intended for hybrid cloud, multi-cluster, distributed computing, and disaster recovery scenarios. ACK One can connect and manage Kubernetes clusters deployed in any region or on top of any infrastructure, including cloud, edge, and data centers. ACK One provides a consistent management experience and Kubernetes-compatible APIs to allow you to centrally manage and maintain computing, storage, networks, security, monitoring, logs, jobs, applications, and traffic.\nACK One overview\nCompared with self-managed Kubernetes clusters, ACK clusters are not only compatible with Kubernetes but also have enhanced Kubernetes capabilities in terms of applications, networks, storage, and security to help you greatly reduce cluster O&M costs. The following table compares self-managed Kubernetes clusters with ACK clusters.\nComparison item\nSelf-managed Kubernetes cluster\nACK cluster\nCluster management\nYou need to manually deploy and develop clusters. You also need to develop a management system.\n\nYou can easily create clusters in the console based on GPU-accelerated instances and Elastic Compute Service (ECS) Bare Metal instances. You can also deploy your cluster across zones to ensure high availability.\nProvide OS images that are optimized for containerized applications and support Kubernetes versions and Docker versions with high stability and enhanced security.\nSupport multi-cluster management and cluster federation management. You can also deploy your cluster across zones to ensure high availability.\nApplication management\nYou need to develop a management system.\nSupport canary releases and blue-green deployment.\nSupport application monitoring and scaling.\nProvide a built-in application marketplace that allows you to deploy applications with a few clicks by using Helm, and provide service catalogs to simplify cloud service integration.\nNetwork management\nYou need to use network plug-ins from the community for adaptation.\nYou need to develop a management system.\nProvide high-performance network plug-ins that are optimized by Alibaba Cloud for virtual private clouds (VPCs) and elastic network interfaces (ENIs), boasting 20% increased performance compared with common network solutions.\nSupport access control and traffic throttling for containers.\nStorage management\nYou need to develop a management system.\nSupport Alibaba Cloud disks, local disks, File Storage NAS (NAS), CPFS, and Object Storage Service, and provide standard CSI drivers.\nSupport automatic volume creation and migration.\nO&M management\nYou need to manually manage and maintain control planes.\nSupport quick update to the latest Kubernetes version, cluster component lifecycle management, and manual scaling and auto scaling.\nProvide a high-performance log collection agent and a variety of log dashboards.\nSupport fully-managed Prometheus monitoring systems with built-in dashboards.\nThe control planes of ACK Pro clusters are fully-managed, highly-scalable, and deployed across zones to improve high availability. Control plane observability is also provided to allow you to monitor control planes.\nSecurity management\nYou need to develop a security system.\nSupport image scanning and image signing.\nSupport container runtime security check.\nSupport Secret encryption.\nSupport Multi-Level Protection Scheme (MLPS) security hardening for operating systems and OS Security Hardening.\nService guarantee\nYou need to build a dedicated team.\nNo service-level agreement (SLA) guarantee is provided.\nThe ACK team provides technical support to ensure the stability and security of your ACK clusters.\nACK is one of the largest public cloud container services in China. It has been tested within Alibaba Group on a large scale.\nAlibaba Cloud has passed the Kubernetes certification tests and becomes a platinum member of the Cloud Native Computing Foundation (CNCF).\nAlibaba Cloud was recognized as the top performer among Chinese Internet enterprises in Forrester Research Reports 2019. Alibaba Cloud is the only Asian cloud service provider that was recognized as a leader in the 2023 Gartner\u00ae Magic Quadrant\u2122 for Container Management.\nACK Pro clusters are covered by SLAs that contain compensation clauses.\nBilling\nSupported regions\nUsage notes and instructions on high-risk operations\nQuotas and limits\n"
    },
    "413": {
        "title": "Container Service for Kubernetes:Billing",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/billing-overview",
        "content": "This Product\nContainer Service for Kubernetes:Billing\nContainer Service for Kubernetes (ACK) allows you to create a variety of ACK clusters. In most cases, you are charged the cluster management fee, node management fee, and fees for other Alibaba Cloud resources. Fees vary based on cluster types and cloud service usage.\nContainer Service for Kubernetes integrates virtualization, storage, networking, and security capabilities of Alibaba Cloud to allow you to efficiently manage and scale containerized applications. ACK also simplifies operations such as cluster creation and scaling, allowing you to focus on the development and management of containerized applications. The cluster management fee charged by ACK varies based on the type of cluster.\nACK Edge supports various heterogeneous edge node resources, including on-premises resources, Edge Node Service, IoT devices, and nodes that use the x86 and ARM architectures. ACK Edge also supports hybrid scheduling of heterogeneous resources.\nYou are charged the cloud service fee by the cloud services used by your ACK cluster based on the billing rules of these services. No cloud service fee is charged if no cloud service is used by your ACK cluster. The cloud service fee varies based on the cloud services used by your ACK cluster. For more information, see Alibaba Cloud services related to ACK.\n: Relevant resources are used and fees are charged.\n: Relevant resources are used but no fee is charged.\nN/A: No relevant resources are used and no fee is charged.\nCluster type\nCluster management fee\nNode management fee\nCloud service fee\nReferences\nACK Pro cluster\n\nN/A\n\nBilling\nBilling description\nView your bills\nBilling of cloud services\nACK Basic cluster\n\nN/A\n\nACK dedicated cluster\n\nN/A\n\nACK Serverless Pro cluster\n\nN/A\n\nBilling of ACK Serverless cluster\nACK Serverless Basic cluster\n\nN/A\n\nACK Edge Pro cluster\n\n\n\nBilling of ACK edge clusters\nACK Edge Basic cluster\n\n\n\nRegistered cluster\n\nN/A\n\nACK One billing\nACK Lingjun cluster\n\n\n\nBilling of ACK Lingjun clusters\nCloud-native AI suite service fees = Cloud-native AI suite fee + ACK fee + Other cloud service fees. For more information, see Billing of the cloud-native AI suite."
    },
    "414": {
        "title": "Container Service for Kubernetes:Announcements and Updates",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/announcements-and-updates/",
        "content": "This Product\nContainer Service for Kubernetes:Announcements and Updates"
    },
    "415": {
        "title": "Container Service for Kubernetes:Release Notes",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/release-notes-1/",
        "content": "This Product\nContainer Service for Kubernetes:Release Notes"
    },
    "416": {
        "title": "Container Service for Kubernetes:Regions supported by ACK",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/supported-regions",
        "content": "This Product\nContainer Service for Kubernetes:Regions supported by ACK\nRegions are physical locations distributed around the world in which Alibaba Cloud hosts our data centers. When you create a resource, you are required to choose a region in which the resource resides. You cannot change the region after the resource is created. This topic describes the regions supported by Container Service for Kubernetes (ACK).\nThe following table describes the regions supported by ACK, the cities of the regions, and the region IDs.  indicates that ACK is available in the region.  indicates that ACK is unavailable in the region.\nIf you want to use ACK in the SAU (Riyadh - Partner Region) region, submit a ticket.\nThe supported regions displayed in the console may vary based on the account that you use. If you have any questions, submit a ticket for technical support.\nCloud environment\nRegion\nCity\nRegion ID\nACK Pro cluster\nACK dedicated cluster\nACK Serverless Pro cluster\nACK Edge Pro cluster\nACK registered cluster\n\nChina (Qingdao)\nQingdao\ncn-qingdao\n\n\n\n\n\n\nAlibaba Cloud public cloud\nChina (Beijing)\nBeijing\ncn-beijing\n\n\n\n\n\nChina (Zhangjiakou)\nZhangjiakou\ncn-zhangjiakou\n\n\n\n\n\nChina (Hohhot)\nHohhot\ncn-huhehaote\n\n\n\n\n\nChina (Ulanqab)\nUlanqab\ncn-wulanchabu\n\n\n\n\n\nChina (Hangzhou)\nHangzhou\ncn-hangzhou\n\n\n\n\n\nChina (Shanghai)\nShanghai\ncn-shanghai\n\n\n\n\n\nChina (Nanjing - Local Region)\nNanjing\ncn-nanjing\n\n\n\n\n\n\n\n\n\nChina (Fuzhou - Local Region)\nFuzhou\ncn-fuzhou\n\n\n\n\n\n\n\n\n\nChina (Shenzhen)\nShenzhen\ncn-shenzhen\n\n\n\n\n\nChina (Heyuan)\nHeyuan\ncn-heyuan\n\n\n\n\n\nChina (Guangzhou)\nGuangzhou\ncn-guangzhou\n\n\n\n\n\nChina (Chengdu)\nChengdu\ncn-chengdu\n\n\n\n\n\nChina (Wuhan - Local Region)\nWuhan\ncn-wuhan-lr\n\n\n\n\n\nChina (Hong Kong)\nHong Kong\ncn-hongkong\n\n\n\n\n\nJapan (Tokyo)\nTokyo\nap-northeast-1\n\n\n\n\n\nSouth Korea (Seoul)\nSeoul\nap-northeast-2\n\n\n\n\n\nSingapore\nSingapore\nap-southeast-1\n\n\n\n\n\nMalaysia (Kuala Lumpur)\nKuala Lumpur\nap-southeast-3\n\n\n\n\n\nIndonesia (Jakarta)\nJakarta\nap-southeast-5\n\n\n\n\n\nPhilippines (Manila)\nManila\nap-southeast-6\n\n\n\n\n\nThailand (Bangkok)\nBangkok\nap-southeast-7\n\n\n\n\n\nUAE (Dubai)\nDubai\nme-east-1\n\n\n\n\n\n\n\nSAU (Riyadh - Partner Region)\nRiyadh\nme-central-1\n\n\n\n\n\n\n\n\n\nUS (Silicon Valley)\nSilicon Valley\nus-west-1\n\n\n\n\n\nUS (Virginia)\nVirginia\nus-east-1\n\n\n\n\n\nGermany (Frankfurt)\nFrankfurt\neu-central-1\n\n\n\n\n\nUK (London)\nLondon\neu-west-1\n\n\n\n\n\n"
    },
    "417": {
        "title": "Container Service for Kubernetes:Supported time zones",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/supported-time-zones",
        "content": "This Product\nContainer Service for Kubernetes:Supported time zones\nThis topic describes the time zones that are supported by Container Service for Kubernetes\n                  (ACK)."
    },
    "418": {
        "title": "Container Service for Kubernetes:Usage notes and instructions on high-risk operations",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/before-you-start",
        "content": "This Product\nContainer Service for Kubernetes:Usage notes and instructions on high-risk operations\nContainer Service for Kubernetes (ACK) is a managed service that you can use to run Kubernetes without the need to manage the technical architectures and key components of Kubernetes. This means that you no longer have to worry about misconfigured control plane components that cause service downtime or interruptions. We recommend that you read this topic to fully understand the risks that may arise when you use ACK.\nItem\nReferences\nUsage notes\nData plane components\nCluster update\nKubernetes configurations\nACK Serverless clusters\nCluster registration\nApp catalogs\nHigh-risk operations\nHigh-risk operations on clusters\nHigh-risk operations on node pools\nHigh-risk operations on networks and load balancing\nHigh-risk operations on storage\nHigh-risk operations on logs\nData plane components are system components that run on your Elastic Compute Service (ECS) instances. Data plane components include CoreDNS, Ingress, kube-proxy, Terway, and kubelet. This means that both you and ACK share responsibility for ensuring the stability of data plane components.\nACK provides the following features for data plane components:\nManagement and maintenance capabilities including custom component configurations, periodic component optimization, bug fixes, Common Vulnerabilities and Exposures (CVE) patches, and the relevant documentation.\nObservability into components by providing monitoring and alerting capabilities and generating log files for key components, which are obtainable through Simple Log Service (SLS).\nBest practices and suggestions for component configurations based on the size of the cluster in which the components are deployed.\nPeriodic component inspection and alerting. The inspection items include but are not limited to component versions, component configurations, component loads, component topology, and the number of component pods.\nWe recommend that you follow these suggestions when you use data plane components:\nUse the latest component version. New releases may contain bug fixes and new features. When a new component version is released, choose an appropriate time to update your components based on the instructions provided in the user guide. This helps prevent issues that may be caused by outdated components. For more information, see Component overview.\nSpecify the email addresses and mobile phone numbers of alert contacts in the alert center of ACK. Then, specify the notification methods. Alibaba Cloud can then use the specified notification methods to send alerts and notifications. For more information, see Alert management.\nWhen you receive alerts that notify you of component stability risks, follow the instructions to mitigate the risks at the earliest opportunity.\nIf you want to configure custom component parameters, we recommend that you call the ACK API or go to the Operations > Add-ons page of your cluster in the ACK console. Custom component parameters that are modified by using other methods may cause the component to malfunction. For more information, see Manage components.\nDo not use the APIs of Infrastructure as a Service (IaaS) services to modify the environment of data plane components. For example, do not use the ECS API to change the status of the ECS instances on which data plane components run, or modify the security groups or network settings of the worker nodes. Do not use the Server Load Balancer (SLB) API to modify the configurations of the SLB instances that are used by your cluster. Improper changes to IaaS resources may cause the components to malfunction.\nSome data plane components may inherit bugs or vulnerabilities from their open source versions. We recommend that you update your components when ACK provides updated versions to ensure the stability of your business.\nUse the cluster update feature of ACK to update the Kubernetes versions of your ACK clusters. Other methods may cause stability or compatibility issues. For more information, see Manually upgrade ACK clusters.\nACK provides the following features to support cluster updates:\nVersion updates for ACK clusters.\nPre-update checks to ensure that an ACK cluster meets the conditions for version updates.\nRelease notes that describe new Kubernetes versions and compare new versions with earlier versions.\nPre-update notifications that inform you of the risks that may arise due to resource changes caused by version updates.\nWe recommend that you follow these suggestions when you use the cluster update feature:\nBefore you perform an update, we recommend that you perform a precheck and fix the identified issues.\nRead and understand the release notes of new Kubernetes versions. Check the status of your cluster and workloads based on the update risks that are reported by ACK. Then, evaluate the impacts of updating the cluster. For more information, see Overview of Kubernetes versions supported by ACK.\nYou cannot roll back cluster updates. Before you update a cluster, prepare for the update and make sure that you have a backup plan.\nUpdate your cluster to the latest Kubernetes version before the Kubernetes version that is used by your cluster is deprecated by ACK. For more information, see Support for Kubernetes versions.\nDo not change key Kubernetes configurations. For example, do not change the following directories or modify the paths, links, and content of the files in the directories:\n/var/lib/kubelet\n/var/lib/docker\n/etc/kubernetes\n/etc/kubeadm\n/var/lib/containerd\nDo not use the annotations that are reserved by Kubernetes in YAML templates. Otherwise, your application may fail to locate resources or send requests, and may behave abnormally. Labels prefixed with kubernetes.io/ or k8s.io/ are reserved for key components. Example: pv.kubernetes.io/bind-completed: \"yes\".\nIn the following scenarios, ACK Serverless clusters are not eligible for compensation clauses:\nTo simplify cluster O&M, ACK Serverless clusters provide fully-managed system components, which are deployed and maintained by ACK after you enable these components. ACK Serverless is not liable for any business loss caused by user errors such as accidental deletion of Kubernetes resources used by the fully-managed system components and therefore no compensation is provided.\nWhen you register an external Kubernetes cluster with ACK in the ACK console, make sure that the network connectivity between the cluster and Alibaba Cloud is stable.\nACK allows you to register external Kubernetes clusters but does not ensure the stability of the external clusters and cannot prevent accidental operations on these clusters. Proceed with caution when you configure labels, annotations, and tags for the nodes in an external cluster by using the cluster registration proxy. Improper configurations may cause applications to malfunction.\nThe application marketplace of ACK provides the app catalog feature to help you install applications that are developed based on open source versions. ACK cannot prevent the defects in open source applications. Proceed with caution when you install these applications. For more information, see App Marketplace.\nThe following operations are considered high-risk operations in ACK. Improper usage may cause stability issues, and in severe circumstances may cause your cluster to fail. Read and understand the impacts of the following high-risk operations before you perform these operations:\nCategory\nHigh-risk operation\nImpact\nHow to recover\nAPI Server\nDelete the SLB instance that is used to expose the API server.\nYou cannot manage the cluster.\nUnrecoverable. You must create a new cluster. For more information about how to create a cluster, see Create an ACK managed cluster.\nWorker nodes\nModify the security group of nodes.\nThe nodes may become unavailable.\nAdd the nodes to the original security group again. The security group is created when you create the cluster. For more information, see Manage ECS instances in security groups.\nThe subscriptions of nodes expire or nodes are removed.\nThe nodes become unavailable.\nUnrecoverable.\nReinstall the node OS.\nComponents are uninstalled from nodes.\nRemove the nodes and then add the nodes to the cluster again. For more information, see Remove nodes and Add existing ECS instances to an ACK cluster.\nUpdate component versions.\nThe nodes may become unavailable.\nRoll back to the original component versions.\nChange the IP addresses of nodes.\nThe nodes become unavailable.\nChange the IP addresses of the nodes to the original IP addresses.\nModify the parameters of key components, such as kubelet, docker, and containerd.\nThe nodes may become unavailable.\nRefer to the ACK official documentation and configure the component parameters.\nModify node OS configurations.\nThe nodes may become unavailable.\nRestore the configurations, or remove the worker nodes and then purchase new nodes.\nModify the system time of nodes.\nThe components on the nodes do not work as expected.\nReset the system time of the nodes.\nMaster nodes in ACK dedicated clusters\nModify the security group of master nodes.\nThe master nodes may become unavailable.\nAdd the master nodes to the original security group again. The security group is created when you create the cluster. For more information, see Manage ECS instances in security groups.\nThe subscriptions of master nodes expire or master nodes are removed.\nThe master nodes become unavailable.\nUnrecoverable.\nReinstall the node OS.\nComponents are uninstalled from master nodes.\nUnrecoverable.\nUpdate master nodes or the etcd component.\nThe cluster may become unavailable.\nRoll back to the original component versions.\nDelete or format the directories that store business-critical data on nodes, for example, /etc/kubernetes.\nThe master nodes become unavailable.\nUnrecoverable.\nChange the IP addresses of master nodes.\nThe master nodes become unavailable.\nChange the IP addresses of the master nodes to the original IP addresses.\nModify the parameters of key components, such as etcd, kube-apiser, and docker.\nThe master nodes may become unavailable.\nRefer to the ACK official documentation and configure the component parameters.\nReplace the certificates of master nodes or the etcd component.\nThe cluster may become unavailable.\nUnrecoverable.\nIncrease or decrease the number of master nodes.\nThe cluster may become unavailable.\nUnrecoverable.\nModify the system time of nodes.\nThe components on the nodes do not work as expected.\nReset the system time of the nodes.\nOther services\nUse Resource Access Management (RAM) to modify permissions.\nResources such as SLB instances may fail to be created.\nRestore the permissions.\nHigh-risk operation\nImpact\nHow to recover\nDelete scaling groups.\nNode pool exceptions occur.\nUnrecoverable. You must create new node pools. For more information about how to create a node pool, see Procedure.\nUse kubectl to remove nodes from a node pool.\nThe number of nodes in the node pool that is displayed in the ACK console is different from the actual number.\nRemove nodes in the ACK console, by calling the ACK API, or by configuring the Expected Nodes parameter of the node pool. For more information, see Remove nodes and Create a node pool.\nManually release ECS instances.\nIncorrect information may be displayed on the node pool details page. A node pool is configured with the Expected Nodes parameter when the node pool is created. After you release the ECS instances, ACK automatically scales out the node pool to the value of the Expected Nodes parameter.\nUnrecoverable. To release ECS instances in a node pool, configure the Expected Nodes parameter of the node pool in the ACK console or by calling the ACK API. You can also remove the nodes that are deployed on the ECS instances. For more information, see Create a node pool and Remove nodes.\nManually scale in or scale out a node pool that has auto scaling enabled.\nThe auto scaling component automatically adjusts the number of nodes in the node pool after you manually scale in or scale out the node pool.\nUnrecoverable. You do not need to manually scale a node pool that has auto scaling enabled.\nChange the upper or lower limit of instances that a scaling group can contain.\nScaling errors may occur.\nFor a node pool that has auto scaling disabled, the default upper limit of instances for the scaling group is 2,000, and the default lower limit of instances is 0.\nFor a node pool that has auto scaling enabled, make sure that the upper and lower limits of instances for the scaling group are the same as the upper and lower limits of instances for the node pool.\nAdd existing nodes to a cluster without backing up the data on the nodes.\nThe data on the nodes is lost after the nodes are added to the cluster.\nUnrecoverable.\nIf you want to add existing nodes in Manual mode, you must first back up the data on the nodes.\nIf you want to add existing nodes in Auto mode, you must first back up the data on the system disks because the system disks will be replaced when the nodes are added to the cluster.\nStore business-critical data on the system disk.\nIf you enable auto repair for a node pool, the system may handle node exceptions by resetting node configurations. As a result, data on the system disk is lost.\nUnrecoverable. Store business-critical data to data disks, cloud disks, File Storage NAS (NAS) file systems, or Object Storage Service (OSS) buckets.\nHigh-risk operation\nImpact\nHow to recover\nSpecify the following kernel parameter setting: net.ipv4.ip_forward=0.\nNetwork connectivity issues occur.\nReplace the setting with the following content: net.ipv4.ip_forward=1.\nSpecify the following kernel parameter settings:\nnet.ipv4.conf.all.rp_filter = 1|2\nnet.ipv4.conf.[ethX].rp_filter = 1|2\nethX specifies the network interface controllers whose names start with eth.\nNetwork connectivity issues occur.\nReplace the settings with the following content:\nnet.ipv4.conf.all.rp_filter = 0\nnet.ipv4.conf.[ethX].rp_filter = 0\nSpecify the following kernel parameter setting: net.ipv4.tcp_tw_reuse = 1.\nPods fail to pass health checks.\nReplace the setting with the following content: net.ipv4.tcp_tw_reuse = 0.\nSpecify the following kernel parameter setting: net.ipv4.tcp_tw_recycle = 1.\nNetwork address translation errors occur.\nReplace the setting with the following content: net.ipv4.tcp_tw_recycle = 0.\nSpecify the following kernel parameter setting: net.ipv4.ip_local_port_range.\nNetwork connectivity issues occasionally occur.\nReplace the setting with the following content: net.ipv4.ip_local_port_range=\"32768 60999\".\nInstall firewall software, such as Firewalld or ufw.\nThe container network becomes inaccessible.\nUninstall the firewall software and restart the nodes.\nThe security group of a node does not open UDP port 53 for the pod CIDR block.\nDNS cannot work as expected in the cluster.\nRefer to the ECS official documentation and modify the security group configuration to open UDP port 53 for the pod CIDR block.\nModify or delete the tags that ACK added to SLB instances.\nThe SLB instances do not work as normal.\nRestore the tags.\nModify the configurations of the SLB instances that are managed by ACK, including the configurations of the instances, listeners, and vServer groups.\nThe SLB instances do not work as normal.\nRestore the SLB configurations.\nRemove the service.beta.kubernetes.io/alibaba-cloud-loadbalancer-id: ${YOUR_LB_ID} annotation that is used to specify an existing SLB instance from the Service configuration.\nThe SLB instances do not work as normal.\nAdd the annotation to the Service configuration.\nIf a Service is configured to use an existing SLB instance, you cannot modify the configuration to create a new SLB instance for the Service. To use a new SLB instance, you must create a new Service.\nDelete the SLB instances that are created by ACK in the SLB console.\nErrors may occur in the cluster network.\nDelete SLB instances by deleting the Services that are associated with the SLB instances. For more information about how to delete a Service, see Delete a Service.\nManually delete the nginx-ingress-lb Service in the kube-system namespace of a cluster that has the NGINX Ingress controller installed.\nThe NGINX Ingress controller does not run as normal or may stop running.\nUse the following YAML template to create a Service that has the same name:\nConfigure the nameserver parameter in the DNS configuration file of an ECS node. The DNS configuration file is named /etc/resolv.conf.\nIf the DNS server is not configured properly, DNS resolution may fail. As a result, the cluster cannot run as expected.\nIf you want to use a self-managed DNS server, we recommend that you configure the DNS server in CoreDNS. For more information, see Configure CoreDNS.\nHigh-risk operation\nImpact\nHow to recover\nUnmount cloud disks that are mounted to pods in the ECS console.\nI/O errors occur when you write data to the pods.\nRestart the pods and clear residual data on the nodes.\nUnmount disks from their mount paths on nodes.\nPod data is written to local disks.\nRestart the pods.\nManage cloud disks on the nodes.\nPod data is written to local disks.\nUnrecoverable.\nMount a cloud disk to multiple pods.\nPod data is written to local disks or I/O errors occur when you write data to the pods.\nMount the cloud disk only to one pod.\nAlibaba Cloud disks cannot be shared. Each disk can be mounted only to one pod.\nManually delete the NAS directories that are mounted to pods.\nI/O errors occur when you write data to the pods.\nRestart the pods.\nDelete the NAS file systems that are mounted to pods or delete the mount targets that are used to mount NAS file systems.\nI/O hangs occur when you write data to the pods.\nRestart the ECS instances. For more information about how to restart an ECS instance, see Restart an instance.\nHigh-risk operation\nImpact\nHow to recover\nDelete the /tmp/ccs-log-collector/pos directory on a node.\nDuplicate logs are collected.\nUnrecoverable. The /tmp/ccs-log-collector/pos directory contains information about the path from which logs are collected.\nDelete the /tmp/ccs-log-collector/buffer directory on a node.\nLogs are lost.\nUnrecoverable. The /tmp/ccs-log-collector/buffer directory stores cached log files that need to be consumed.\nDelete the aliyunlogconfig CustomResourceDefinition (CRD) objects.\nLogs cannot be collected.\nRecreate the aliyunlogconfig CRD objects that are deleted and the related resources. Logs that are generated within the period of time during which the aliyunlogconfig CRD objects do not exist cannot be collected.\nIf you delete the aliyunlogconfig CRD objects, the related log collection tasks are also deleted. After you recreate the aliyunlogconfig CRD objects, you must also relaunch the log collection tasks.\nUninstall logging components.\nLogs cannot be collected.\nReinstall the logging component and manually create the aliyunlogconfig CRD objects. Logs that are generated within the period of time during which the logging component and the aliyunlogconfig CRD objects do not exist cannot be collected.\nIf you delete the logging component, the aliyunlogconfig CRD objects and Logtail are also deleted. Logs that are generated within the period of time during which the logging component does not exist cannot be collected.\nUsage notes of the NGINX Ingress controller\nBest practices for DNS services\n"
    },
    "419": {
        "title": "Container Service for Kubernetes:Quotas and limits on ACK",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/limits",
        "content": "This Product\nContainer Service for Kubernetes:Quotas and limits on ACK\nThis topic describes the quotas and limits on using Container Service for Kubernetes (ACK), including cloud service and cluster configuration limits, individual cluster capacity limits, cluster quotas, and dependent cloud service quotas.\nBefore you activate ACK and when you use ACK clusters, take note of the following limits.Container Service for Kubernetes\nLimit\nDescription\nAccount authentication\nYou need to complete real-name verification and activate ACK before you can create ACK clusters. For more information, see Quick start for first-time users.\nCluster configurations\nAfter you create an ACK cluster, you cannot modify the following cluster configurations.\nYou cannot change the virtual private cloud (VPC) of the cluster.\nYou cannot change the cluster type. For example, you cannot directly change the cluster type from ACK dedicated cluster to ACK managed cluster.\nHot migration from ACK basic clusters to ACK Pro clusters is supported.\nYou cannot change the cluster edition. For example, you cannot change the cluster edition from ACK Pro cluster to ACK Basic cluster.\nHot migration from ACK basic clusters to ACK Pro clusters is supported.\nYou cannot switch between the Terway and Flannel network plug-ins.\nECS instance (node instance) configurations\nThree billing methods are supported: pay-as-you-go, subscription, and preemptible instances. You can change the billing method from pay-as-you-go to subscription in the Elastic Compute Service (ECS) console. For more information, see Change the billing method.\nDue to the quota and stock limits of the dependent cloud services such as ECS, ACK may succeed to create only partial nodes when creating or scaling out a cluster.\nThe node specifications must be 4 vCPUs and 8 GB of memory or higher. For more information, see Suggestions on choosing ECS specifications for ACK clusters.\nAccess to control plane components\nWhen you use the API or CLI to access a control plane component, such as the API server or etcd, to query large numbers of cluster events, traffic throttling may be triggered due to the bandwidth limit. As a result, the query operation may fail. We recommend that you query cluster events by using the event center. You can also add pagination parameters, such as --chunk-size=500, to the API request or command lines to reduce the number of events to be returned per request. For more information, see Scenario 1: Use node-problem-detector with the Kubernetes event center of Log Service to sink cluster events.\nIf traffic throttling is frequently triggered in an ACK Basic cluster, we recommend that you migrate your applications to an ACK Pro cluster. For more information, see Hot migration from ACK basic clusters to ACK Pro clusters.\nACK Pro clusters and ACK Basic clusters are applicable to different scenarios. Therefore, the cluster capacities are also different.\nACK Pro clusters: We recommend that you use this type of cluster in enterprise production environments.\nIf an ACK Pro cluster uses Terway and has IPVLAN enabled, you can add less than 5,000 nodes to the cluster and create at most 50,000 pods. You can create at most 64,000 mappings between Services and pods.\nACK Basic clusters: This type of cluster is only for individual testing or learning.\nThe following table describes the capacities of different resources in an ACK cluster.\nResource\nACK Pro cluster\nACK Basic cluster\netcd storage\n8 GB\n2 GB\nMaximum etcd storage for each type of objects\n800 MB\n200 MB\nNodes\nThe default is 5,000 and the maximum is 15,000\n10\nPods\n150,000\n300\nNamespaces\n10,000\n100\nConfigMaps\n30,000\n300\nSecrets\n100,000\n1,000\nPVCs\n100,000\n1,000\nPVs\n100,000\n1,000\nServices\n10,000\n100\nRoles\n50,000\n500\nRoleBindings\n50,000\n500\nCRDs\n100,000\n1,000\nThe following table describes the default values of different cluster quotas. You can view the adjustable quotas and their maximum values in the Quota Center console and apply for quota increases.\nCluster type\nMaximum number of clusters within an Alibaba Cloud account\nMaximum number of node pools in a cluster\u2460\nMaximum number of nodes in a cluster\nMaximum number of pods on a node\u2461\nHow to apply for a quota increase\nACK managed cluster\nBasic\n2\n10\n10\nIf the network plug-in is Flannel: 256.\nIf the network plug-in is Terway: It depends on the node specifications.\nNot adjustable\nPro\n100\n100\nIf the network plug-in is Flannel: The default is 200 and the maximum is 1000.\nIf the network plug-in is Terway: The default is 5,000 and the maximum is 15,000.\nlog on to the Quota Center console and submit an application\nACK dedicated cluster\n0\n100\nlog on to the Quota Center console and submit an application\nACK Serverless cluster\nBasic\n2\nN/A\nN/A\n1,000\u2462\nlog on to the Quota Center console and submit an application\nPro\n100\nN/A\nN/A\nThe maximum is 50,000.\nWe recommend that you keep the number of pods under 20,000 if a large number of pods are associated with the Service.\nlog on to the Quota Center console and submit an application\nACK Edge cluster\nBasic\n2\n10\n10\n256\nNot adjustable\nPro\n100\n100\n1,000\n256\nlog on to the Quota Center console and submit an application\nRegistered cluster\n5\n100\nN/A\n256\nlog on to the Quota Center console and submit an application\n\u2460: For the new quota on the maximum number of node pools per cluster to take effect, you must also increase the quota on scaling groups. To do this, log on to the Quota Center console and apply for a quota increase.\n\u2461: The maximum number of pods on a node\nThe maximum number of pods on a node depends on the cluster network plug-in.\nFlannel: The maximum number of pods on a node depends on the cluster CIDR block that you specified when you create the cluster. Refer to the preceding table for the quota limit. However, the quota is not adjustable in this scenario.\nTerway: The maximum number of pods on a node depends on the number of elastic network interfaces (ENIs) supported by the corresponding ECS instance type. We recommend that you choose the latest ECS instance types and ECS instance types with high specifications.\nThe quota on the maximum number of pods per node is subject to a worker node. The quota on the maximum number of pods per cluster is subject to an ACK cluster. You can add nodes to an ACK cluster to increase the pod quota. However, when the cluster size grows, the availability and performance of the cluster may be compromised. We recommend that you decide the cluster size properly. For more information, see Suggestions on using large-scale clusters.\n\u2462: ACK Serverless clusters does not have physical nodes. This quota specifies the maximum number of pods that can run in an ACK Serverless cluster.\nCloud service\nQuota\nDefault value\nHow to apply for a quota increase\nECS\nMaximum number of Resource Orchestration Service (ROS) templates\n100\nsubmit a ticket\nMaximum number of vCPUs of all pay-as-you-go instances\n500\nsubmit a ticket\nHigh-specification pay-as-you-go instances (equipped with more than 16 vCPUs)\nOnly pay-as-you-go instances with less than 16 vCPUs can be purchased\nsubmit a ticket\nMaximum number vCPUs of all preemptible instances\n800\nsubmit a ticket\nChange the billing method from pay-as-you-go to subscription\nThe following instance types (or families) are not supported: t1, s1, s2, s3, c1, c2, m1, m2, n1, n2, and e3\nsubmit a ticket\nMaximum number of ECS instances in a scaling group\n2,000\nlog on to the Quota Center console and submit an application\nOS\nNodes that run the following operating systems can be added to an ACK cluster:\nAlibaba Cloud Linux\nCentOS 7.x\nCentOS 8.x and later are not supported.\nWindows Server 2019 and Windows Server version 1809 and later.\nN/A\nNetworking\nMaximum number of custom routes that can be created in each route table (excluding dynamic routes)\n200\nUse one of the following methods:\nGo to the Quota Management page to request an increase. For more information, see Manage VPC quotas.\nGo to the Quota Center page to submit a quota increase request. For more information, see Request a quota increase.\nMaximum number of vSwitches that can be created in each VPC\n150\nMaximum number of VPCs that can be created in each region\n10\nMaximum number of private IP addresses that can be contained in a security group of the VPC type\nBasic security group: 6,000\nAdvanced security group: 65,535\nTo apply for the basic security group, go to the Quota Center.\nMaximum number of security groups in an account\nView and change the quota in the Quota Center console.\nMaximum number of secondary ENIs that can be created in an account\nView the quota in the Quota Center console.\nGo to the Quota Center console.\nMaximum number of elastic IP addresses (EIPs) that each Alibaba Cloud account can apply for\n20\nUse one of the following methods:\nGo to the Quota Management page and request a quota increase. For more information, see Manage service quotas.\nGo to the Quota Center and request a quota increase. For more information, see Request a quota increase.\nLoad balancing\nMaximum number of CLB instances that can be created by each Alibaba Cloud account\n30\nUse one of the following methods:\nGo to the Quota Management page in the CLB console, find the quota slb_quota_instances_num, and then click Apply in the Actions column. For more information, see Manage quotas.\nLog on to the Quota Center console and request a quota increase. For more information, see Manage CLB quotas.\nMaximum number of backend servers that can be added to a CLB instance\n200\nUse one of the following methods:\nGo to the Quota Management page in the CLB console, find the quota slb_quota_backendservers_num, and then click Apply in the Actions column. For more information, see Manage quotas.\nLog on to the Quota Center console and request a quota increase. For more information, see Manage CLB quotas.\nMaximum number of listeners that can be added to a CLB instance\n50\nUse one of the following methods:\nGo to the Quota Management page in the CLB console, find the quota slb_quota_listeners_num, and then click Apply in the Actions column. For more information, see Manage quotas.\nLog on to the Quota Center console and request a quota increase. For more information, see Manage CLB quotas.\nMaximum number of times that a server can be added as a CLB backend server\n50\nN/A\nElastic Block Storage (EBS)\nMaximum number of pay-as-you-go disks in all regions within an Alibaba Cloud account\nThis quota is five times the number of ECS instances across all regions within an Alibaba Cloud account. However, Alibaba Cloud allows you to create at least 10 pay-as-you-go disks in all regions within an Alibaba Cloud account.\nsubmit a ticket\nTotal capacity of all pay-as-you-go disks that are used as data disks within an Alibaba Cloud account\nThis quota is subject to the number of ECS instances within the account, regions in which the ECS instances reside, and disk types that the ECS instances use. You can go to the Privileges page in the ECS console to view details. For more information, see View and increase instance quotas.\nsubmit a ticket\nWhen you use different types of ACK clusters, you need to pay close attention to the usage notes and instructions on high-risk operations for different modules. Otherwise, your businesses may be interrupted.Container Service for Kubernetes For more information, see Usage notes and instructions on high-risk operations.\nWhen you use ACK managed clusters and ACK dedicated clusters, you must configure the clusters, workloads, and components properly to ensure the stability and reliability of applications in the clusters. For more information, see Recommended configurations for high reliability.\n"
    },
    "420": {
        "title": "Container Service for Kubernetes:Open source projects",
        "url": "https://www.alibabacloud.com/help/en/ack/product-overview/open-source-projects",
        "content": "This Product\nContainer Service for Kubernetes:Open source projects\nOpen source projects are useful for extending the features of Kubernetes clusters.\n                  This topic provides a list of open source projects that are commonly used together\n                  with Container Service for Kubernetes (ACK)."
    },
    "421": {
        "title": "Container Service for Kubernetes:Troubleshooting and FAQ",
        "url": "https://www.alibabacloud.com/help/en/ack/support/troubleshooting-and-faq",
        "content": "This Product\nContainer Service for Kubernetes:Troubleshooting and FAQ\nThis topic provides links to the troubleshooting and FAQ about different types of Container Service for Kubernetes (ACK) clusters and components.\nCluster/component\nReferences\nACK managed cluster and ACK dedicated cluster\nService troubleshooting\nNGINX Ingress controller troubleshooting\nDNS troubleshooting\nUse ACK CoreDNS DNSTAP Analyser to diagnose DNS resolution errors\nPod troubleshooting\nNode troubleshooting\nStorage troubleshooting\nACK console troubleshooting (cluster access exceptions)\nComponent troubleshooting\nServerless Kubernetes (ASK) cluster\nTroubleshooting\nCluster/component\nReferences\nACK managed cluster and ACK dedicated cluster\nFAQ\nACK Serverless cluster\nFAQ\nDistributed Cloud Container Platform for Kubernetes (ACK One)\nFAQ\nACK Distro\nFAQ\n"
    },
    "422": {
        "title": "Container Service for Kubernetes:Contact Us",
        "url": "https://www.alibabacloud.com/help/en/ack/support/contact-us",
        "content": "This Product\nContainer Service for Kubernetes:Contact Us\nIf you have any questions about Container Service for Kubernetes (ACK), contact us by using the following methods.\nCluster type\nContact method\nACK managed cluster and ACK dedicated cluster\nJoin the DingTalk group 74560018672.\nACK Serverless cluster\nJoin the DingTalk group 31544226.\nACK Edge cluster\nJoin the DingTalk group 21976595.\nCloud-native AI suite\nJoin the DingTalk group 33214567.\nACK One\nJoin the DingTalk group 35688562.\n"
    },
    "423": {
        "title": "Container Service for Kubernetes:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/product-overview/",
        "content": "This Product\nContainer Service for Kubernetes:Product Overview"
    },
    "424": {
        "title": "Container Service for Kubernetes:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/getting-started/",
        "content": "This Product\nContainer Service for Kubernetes:Getting Started"
    },
    "425": {
        "title": "Container Service for Kubernetes:User Guide",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/user-guide/",
        "content": "This Product\nContainer Service for Kubernetes:User Guide"
    },
    "426": {
        "title": "Container Service for Kubernetes:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/use-cases/",
        "content": "This Product\nContainer Service for Kubernetes:Use Cases"
    },
    "427": {
        "title": "Container Service for Kubernetes:Security and Compliance",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/security-and-compliance/",
        "content": "This Product\nContainer Service for Kubernetes:Security and Compliance"
    },
    "428": {
        "title": "Container Service for Kubernetes:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/developer-reference/",
        "content": "This Product\nContainer Service for Kubernetes:Developer Reference"
    },
    "429": {
        "title": "Container Service for Kubernetes:Support",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-managed-and-ack-dedicated/support/",
        "content": "This Product\nContainer Service for Kubernetes:Support"
    },
    "430": {
        "title": "Container Service for Kubernetes:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/product-overview/",
        "content": "This Product\nContainer Service for Kubernetes:Product Overview"
    },
    "431": {
        "title": "Container Service for Kubernetes:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/getting-started/",
        "content": "This Product\nContainer Service for Kubernetes:Getting Started"
    },
    "432": {
        "title": "Container Service for Kubernetes:User Guide",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/user-guide/",
        "content": "This Product\nContainer Service for Kubernetes:User Guide"
    },
    "433": {
        "title": "Container Service for Kubernetes:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/use-cases/",
        "content": "This Product\nContainer Service for Kubernetes:Use Cases"
    },
    "434": {
        "title": "Container Service for Kubernetes:Security and Compliance",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/security-and-compliance/",
        "content": "This Product\nContainer Service for Kubernetes:Security and Compliance"
    },
    "435": {
        "title": "Container Service for Kubernetes:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/developer-reference/",
        "content": "This Product\nContainer Service for Kubernetes:Developer Reference"
    },
    "436": {
        "title": "Container Service for Kubernetes:Support",
        "url": "https://www.alibabacloud.com/help/en/ack/serverless-kubernetes/support/",
        "content": "This Product\nContainer Service for Kubernetes:Support"
    },
    "437": {
        "title": "Container Service for Kubernetes:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-edge/product-overview/",
        "content": "This Product\nContainer Service for Kubernetes:Product Overview"
    },
    "438": {
        "title": "Container Service for Kubernetes:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-edge/quick-start",
        "content": "This Product\nContainer Service for Kubernetes:Getting Started\nACK Edge is a cloud-edge integrated collaboration and managed solution provided by Alibaba Cloud Container Service for Kubernetes (ACK). This solution allows you to manage resources and applications at the edge in the cloud. This topic describes the prerequisites, quick start process, and quick usage methods of ACK Edge clusters to help you get started.\nBefore you use an ACK Edge cluster, you must understand the following information: announcements and updates, release notes, usage notes, instructions on high-risk operations, and supported regions.\nItem\nDescription\nReferences\nAnnouncements and updates\nProduct updates and announcements of ACK Edge clusters.\nProduct changes\nProduct maintenance\nRelease notes for Kubernetes versions supported by ACK\nComponent changes\nSystem restoration\nCVE vulnerability fixes\nRelease notes\nThe release notes for ACK Edge clusters, Kubernetes versions, OS images, runtimes, and components.\nRelease notes\nRelease notes for supported Kubernetes versions\nRelease notes for OS images\nRelease notes for components\nRegions\nThe regions supported by ACK Edge clusters.\nSupported regions\nSupported time zones\nThe time zones supported by ACK Edge clusters.\nTime zones\nUsage notes and instructions on high-risk operations\nBefore you use ACK Edge clusters, we recommend that you read the usage notes and learn the risks that may arise when you use ACK Edge clusters.\nUsage notes and instructions on high-risk operations\nLimits\nThe limits when you use ACK Edge clusters, such as capacity limits and quotas.\nQuotas and limits\nACK Edge clusters allow you to manage edge computing resources in the same Kubernetes cluster. You can also migrate existing cloud services to edge Kubernetes clusters. This improves the O&M efficiency of edge resources and services and ensures stable business operations. You can use the following methods to quickly get started with ACK Edge clusters.\nThe following figure shows the quick usage process of an ACK Edge cluster:\nStep\nDescription\nReferences\nPrepare the network environment\nBefore you create an ACK Edge cluster, you must confirm the network environment on which the cluster and nodes depend, and the selected network plug-in.\nHow to choose a network plug-in\nConfiguration of domain name and IP routing network segment for edge node access\nActivate and authorize ACK\nYou must activate ACK Edge before you can create an ACK Edge cluster. If ACK is not activated, you cannot create clusters.\nQuickly create an ACK managed cluster\nCreate a cluster\nYou can create an ACK edge cluster in the ACK console, by calling API operations, or by using Terraform.\nCreate an ACK Edge cluster\nCreate a cluster by calling an API operation\nUse Terraform to create an ACK Edge cluster\nAdd an edge node\nACK Edge clusters allow you to manage multiple types of resources, including nodes in data centers, Elastic Compute Service (ECS) nodes in different regions and cloud vendors, and Edge Node Service (ENS) nodes. Before you can use the related features, you must add edge nodes to ACK Edge clusters.\nAdd an edge node\nAdd a GPU-accelerated node\nType\nFeature\nDescription\nReferences\nEdge scalability\nNetwork autonomy of edge nodes\nYou can configure edge node autonomy to ensure that applications on an edge node can still run as expected when the edge node is disconnected from the cloud and no application pod is evicted or migrated to other edge nodes.\nConfigure edge node autonomy\nApplication management\nIn edge scenarios such as multi-region nodes and on-premises data centers, you can use YurtAppSets and DaemonSet update models to improve application management capabilities.\nYurtAppSets management: You can use YurtAppSet to manage multiple workloads, such as Deployments.\nDaemonSet update models: When the edge network disconnects from the cloud, DaemonSet updates may become stuck and issues may occur in over-the-air (OTA) updates. To address the preceding issues, ACK Edge provides the AdvancedRollingUpdate and OTA update model extensions.\nManage YurtAppSets\nDaemonSet update models\nCross-region communication\nIf cloud-edge resources are not in the same network domain, you can use the cross-region communication component Raven to implement efficient cloud-edge O&M in multiple regions.\nUse the cross-region O&M communication component Raven\nOffline O&M\nIf you configured edge node autonomy, the cloud control plane cannot make O&M changes to the edge business. In an emergency, you can use offline O&M tools to perform O&M operations on the business on the offline node. The operations that you can perform include business rollback, resource configuration change, and business configuration modification.\nOffline O&M for edge nodes\nElastic Cloud Resource\nElastic capabilities of ECS nodes and elastic container instances and ACS instances\nWhen on-premises resources are insufficient, ACK Edge clusters can quickly scale out nodes in the cloud. ACK Edge clusters support the elasticity of ECS-based node pools in the cloud and elastic instances and ACS-based instances.\nECS node elasticity\nEnable node auto scaling\nServerless elasticity in virtual nodes\nCloud Capability Sinking\nObservability\nACK Edge clusters are seamlessly integrated with monitoring, logging, and Node Problem Detector (NPD) capabilities to ensure the stability of edge services.\nUse Managed Service for Prometheus to monitor ACK edge clusters\nUse Simple Log Service to collect container logs from ACK Edge clusters\nCollect the logs of control plane components in ACK Edge clusters\nCloud-native AI suite\nIn AI scenarios, ACK Edge clusters and the cloud-native AI suite provide the AI suite console, GPU sharing and scheduling, KServe, and Fluid acceleration.\nUse Fluid to accelerate access to OSS files from edge nodes\nUse GPU sharing\nWork with ack-kserve\nUse Fluid to accelerate access to OSS files from edge nodes\nImage Acceleration\nYou can use image acceleration to accelerate image pulling and reduce the application deployment time. ACK Edge clusters support on-demand image loading and P2P image loading.\nLoad resources of a container image on demand\nUse the P2P acceleration feature\nSecurity management\nYou can use cloud security capabilities to improve the security governance efficiency of cloud resources and business applications. ACK Edge clusters support cluster auditing, custom Subject Alternative Names (SANs) of the API server certificate, Secret encryption, and RAM Roles for Service Accounts (RRSA).\nWork with cluster auditing\nCustomize the SANs of the API server certificate when you create an ACK cluster\nUse KMS to encrypt secrets in an ACK Edge cluster\nUse RRSA to authorize different pods to access different cloud services\n"
    },
    "439": {
        "title": "Container Service for Kubernetes:User Guide",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-edge/user-guide/",
        "content": "This Product\nContainer Service for Kubernetes:User Guide"
    },
    "440": {
        "title": "Container Service for Kubernetes:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-edge/developer-reference/",
        "content": "This Product\nContainer Service for Kubernetes:Developer Reference"
    },
    "441": {
        "title": "Container Service for Kubernetes:Support",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-edge/support/",
        "content": "This Product\nContainer Service for Kubernetes:Support"
    },
    "442": {
        "title": "Container Service for Kubernetes:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-lingjun-managed-clusters/product-overview/",
        "content": "This Product\nContainer Service for Kubernetes:Product Overview"
    },
    "443": {
        "title": "Container Service for Kubernetes:User Guide",
        "url": "https://www.alibabacloud.com/help/en/ack/ack-lingjun-managed-clusters/user-guide/",
        "content": "This Product\nContainer Service for Kubernetes:User Guide"
    },
    "444": {
        "title": "Container Service for Kubernetes:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/ack/cloud-native-ai-suite/product-overview/",
        "content": "This Product\nContainer Service for Kubernetes:Product Overview"
    },
    "445": {
        "title": "Container Service for Kubernetes:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/ack/cloud-native-ai-suite/getting-started/",
        "content": "This Product\nContainer Service for Kubernetes:Getting Started"
    },
    "446": {
        "title": "Container Service for Kubernetes:User Guide",
        "url": "https://www.alibabacloud.com/help/en/ack/cloud-native-ai-suite/user-guide/",
        "content": "This Product\nContainer Service for Kubernetes:User Guide"
    },
    "447": {
        "title": "Container Service for Kubernetes:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/ack/cloud-native-ai-suite/use-cases/",
        "content": "This Product\nContainer Service for Kubernetes:Use Cases"
    },
    "448": {
        "title": "Container Service for Kubernetes:Support",
        "url": "https://www.alibabacloud.com/help/en/ack/cloud-native-ai-suite/support/",
        "content": "This Product\nContainer Service for Kubernetes:Support"
    },
    "449": {
        "title": "Container Service for Kubernetes:Product Overview",
        "url": "https://www.alibabacloud.com/help/en/ack/distributed-cloud-container-platform-for-kubernetes/product-overview/",
        "content": "This Product\nContainer Service for Kubernetes:Product Overview"
    },
    "450": {
        "title": "Container Service for Kubernetes:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/ack/distributed-cloud-container-platform-for-kubernetes/getting-started",
        "content": "This Product\nContainer Service for Kubernetes:Getting Started\nThis topic describes how to quickly get started with Distributed Cloud Container Platform for Kubernetes (ACK One) and provides links to the references for ACK One.\nDistributed Cloud Container Platform for Kubernetes is activated. The default Resource Access Management (RAM) role is assigned to ACK One and the Alibaba Cloud services used by ACK One are activated.ACK One For more information, see Permissions of Service-linked roles for ACK One.\nThe following figure shows how to quickly get started with ACK One.\nACK One provides the following features: registered clusters, Fleet management, Kubernetes clusters for distributed Argo workflows, and backup center. You can use these features separately or use them in a combination.\nYou can register Kubernetes clusters that are deployed in data centers or Kubernetes clusters that are deployed on a third-party platform to ACK One. This way, you can manage clusters in a hybrid cloud environment.\nFeature\nDescription\nReferences\nCreate a registered cluster and connect a Kubernetes cluster that is deployed in a data center to the registered cluster\nThis feature allows you to create a registered cluster and connect a Kubernetes cluster that is deployed in a data center or on a third-party platform to the registered cluster. This way, you can manage your clusters in ACK One in a centralized manner.\nOverview of registered clusters\nCreate a registered cluster\nElasticity\nThis feature allows you to scale self-managed Kubernetes clusters that are deployed in data centers by adding computing resources deployed in the cloud to the clusters. For example, you can manually or automatically adjust the number of Elastic Compute Service (ECS) instances or ECS bare metal instances in self-managed Kubernetes clusters deployed in data centers.\nCreate a script to add cluster nodes\nCreate and scale out a node pool\nConfigure auto scaling\nSchedule pods to elastic container instances that are deployed as virtual nodes\nDeploy alibaba-cloud-metrics-adapter in a registered cluster\nObservability\nThis feature supports the following observability capabilities: Event Center, Ingress dashboards, log collection, application monitoring based on Application Real-Time Monitoring Service (ARMS), ARMS-Prometheus, Node Problem Detector (NPD), and Metrics Adapter.\nEnable Simple Log Service for a registered cluster\nCreate a Kubernetes event center for a registered cluster\nSet up alerting for a registered cluster\nEnable ARMS for a registered Kubernetes cluster\nEnable Managed Service for Prometheus for a registered cluster\nCluster cost insights\nSecurity management\nThis feature provides authentication based on RAM, authorization based on role-based access control (RBAC), cluster auditing based on Simple Log Service, and cluster inspection.\nEnable cluster auditing\nUse the inspection feature to check for security risks in the workloads of a registered Kubernetes cluster\nCoordinated scheduling\nThis feature requires you to install ack-co-scheduler in the registered cluster and allows you to use the scheduling features of ACK in various types of applications, such as big data applications and AI applications, in a convenient manner and improve resource utilization.\nUse ack-co-scheduler to coordinate resource scheduling\nUse ack-co-scheduler to achieve multilevel resource scheduling\nFleet instances are fully-managed resources in ACK. You can use Fleet instances to manage Kubernetes clusters in any environments, which provides a consistent cloud-native application management experience.\nFeature\nDescription\nReferences\nEnable Fleet management\nAfter you enable Fleet management, you can use Fleet instances provided by ACK One to schedule and distribute workloads, applications, and configurations among multiple clusters.\nFleet management overview\nEnable Fleet management\nAssociated cluster management\nAfter you enable Fleet management, you can associate clusters with a Fleet instance and then distribute applications or workloads to the associated clusters from the Fleet instance.\nManage associated clusters\nGitOps\nAfter you enable GitOps on a Fleet instance of ACK One, you can manage versions of application manifests and Helm charts in Git repositories. GitOps also supports multi-cluster continuous delivery.\nGetting started with GitOps\nLog on to the GitOps system\nRepository management\nUse GitOps to manage ACK clusters\nApplication management\nUse an ApplicationSet to create multiple applications\nMulti-cluster gateways\nThe multi-cluster gateway of ACK One is a solution provided by Alibaba Cloud for application disaster recovery and north-south traffic management in hybrid cloud or multi-cluster environments. This solution helps you quickly implement zone-disaster recovery or geo-disaster recovery for hybrid cloud and multi-cluster applications, and facilitates traffic management and governance.\nOverview of multi-cluster gateways\nOverview of ALB multi-cluster gateways\nManage gateways\nManage north-south traffic\nMCS\nThe multi-cluster Services (MCS) feature allows you to access Services across Kubernetes clusters without the need to create load balancers.\nMCS overview\nUse the CLI to configure MCS\nJob distribution\nACK One job distribution is a solution provided by Alibaba Cloud for AI workload orchestration and distribution across multi-cluster and hybrid cloud environments. You can schedule tasks to optimal clusters based on factors such as real-time resource availability and scaling demands.\nJob distribution\nMulti-cluster scheduling and distribution of Spark jobs\nHow to use Kube Queue on a Fleet instance and schedule PyTorchJob by using gang scheduling\nMonitoring management\nThe global monitoring feature collects the metrics of different clusters, aggregates these metrics, and then displays global monitoring information about these clusters on a dashboard of Managed Service for Prometheus. This way, you can view the metrics of different clusters on one dashboard.\nGlobal monitoring\nMulti-cluster alert management\nOverride alerting configurations for multi-cluster management\nFeature\nDescription\nReferences\nCreating workflow clusters and obtaining kubeconfig files\nWorkflow clusters use a serverless architecture. This type of cluster runs Argo workflows on elastic container instances, optimizes cluster parameters to schedule large-scale workflows with efficiency and elasticity, and uses preemptible elastic container instances to reduce costs.\nCreate a workflow cluster\nWorkflows\nWorkflow clusters are developed based on open source Argo Workflows. You can refer to the documentation of Argo Workflows to customize workflows.\nCreate a workflow\nRun workflows on a specified type of ECS instances\nArgo Server\nYou can enable Argo Server to access workflow clusters, use the Argo Server API to automate workflow submission, and use the open source Argo UI to manage workflows.\nEnable Argo Server for a workflow cluster\nEnable Internet access for Argo Server\nEventing\nWorkflow clusters support eventing. This allows you to build an automated system that automatically triggers workflows based on events.\nEnable eventing\nUse Simple Message Queue (formerly MNS) to trigger event-driven workflows\nUpload objects to OSS to trigger workflows\nObservability\nWorkflow clusters are integrated with Managed Service for Prometheus and Simple Log Service. You can view the status of clusters and their metrics in dashboards of Managed Service for Prometheus, and deliver the pod logs of workflows to Simple Log Service and analyze these logs anytime.\nEnable Managed Service for Prometheus\nConfigure Simple Log Service\n\nThe backup center is a one-stop solution that helps you back up, restore, and migrate stateful or stateless applications. The backup center also provides disaster recovery and application migration capabilities for stateful applications in hybrid cloud and multi-cluster environments.\nFeature\nDescription\nReferences\nEnabling the backup center\nThe backup center is a one-stop solution that helps you back up, restore, and migrate stateful or stateless applications. The backup center also provides disaster recovery and application migration capabilities for stateful applications in hybrid cloud and multi-cluster environments.\nBackup center\nInstall migrate-controller and grant permissions\nBackup and restoration of applications and data\nThis feature allows you to back up and restore stateful applications that are deployed in a cluster. This feature provides an all-in-one solution to achieve crash consistency, application consistency, and cross-region disaster recovery for stateful applications that are deployed in Kubernetes clusters.\nBack up and restore applications in an ACK cluster\nCross-cluster application migration\nThis feature allows you to back up and restore stateful applications that are deployed in a cluster. This feature provides an all-in-one solution to implement crash consistency, application consistency, and cross-region disaster recovery for stateful applications that are deployed in Kubernetes clusters.\nMigrate applications across clusters in the same region\nMigrate applications across clusters in different regions\nMigrate applications from external Kubernetes clusters to ACK clusters\nMigrate applications from a Kubernetes cluster on a third-party cloud platform to an ACK cluster\n"
    },
    "451": {
        "title": "Container Service for Kubernetes:User Guide",
        "url": "https://www.alibabacloud.com/help/en/ack/distributed-cloud-container-platform-for-kubernetes/user-guide/",
        "content": "This Product\nContainer Service for Kubernetes:User Guide"
    },
    "452": {
        "title": "Container Service for Kubernetes:Use Cases",
        "url": "https://www.alibabacloud.com/help/en/ack/distributed-cloud-container-platform-for-kubernetes/use-cases/",
        "content": "This Product\nContainer Service for Kubernetes:Use Cases"
    },
    "453": {
        "title": "Container Service for Kubernetes:Developer Reference",
        "url": "https://www.alibabacloud.com/help/en/ack/distributed-cloud-container-platform-for-kubernetes/developer-reference/",
        "content": "This Product\nContainer Service for Kubernetes:Developer Reference"
    },
    "454": {
        "title": "Container Service for Kubernetes:Support",
        "url": "https://www.alibabacloud.com/help/en/ack/distributed-cloud-container-platform-for-kubernetes/support/",
        "content": "This Product\nContainer Service for Kubernetes:Support"
    },
    "455": {
        "title": "Container Service for Kubernetes:Billing",
        "url": "https://www.alibabacloud.com/help/en/container-service-for-kubernetes/latest/product-billing",
        "content": "This Product\nContainer Service for Kubernetes:Billing"
    },
    "456": {
        "title": "Platform For AI:What is PAI?",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/what-is-machine-learning-platform-for-ai",
        "content": "This Product\nPlatform For AI:What is PAI?\nAlibaba Cloud Platform for AI (PAI) is a one-stop machine learning platform that provides data labeling, model development, model training, and model deployment services. This topic describes what PAI is.\nPAI is a one-stop machine learning platform for developers. With its core modules, such as Machine Learning Designer, Data Science Workshop (DSW), Deep Learning Containers (DLC), and Elastic Algorithm Service (EAS), PAI provides an all-in-one solution for machine learning, covering data labeling, model development, model training, and model deployment. PAI supports multiple open-source frameworks and AI optimization capabilities. PAI is flexible and easy to use.\nFeatures\nBenefits\nBilling\nScenarios\nAI development phase\nRelated module\nDescription\nData preparation\nPAI-iTAG\nIn the data preparation phase, iTAG provides intelligent data labeling services. You can create data labeling tasks for the following data types: image, text, video, and audio. You can also create multimodal data labeling tasks. iTAG provides various content and question components for data labeling. You can use the preset templates provided by iTAG or custom data labeling templates based on your business requirements. iTAG also provides fully managed data labeling services that are outsourced.\n\nModel development\nPAI-Designer\nMachine Learning Designer provides more than 140 mature algorithms and allows you to develop AI models by performing visualized drag-and-drop operations in a low-code environment.\nPAI-DSW\nDSW allows you to develop models through interactive programming. DSW is a cloud integrated development environment (IDE) embedded with Notebook, VS Code, and Terminal. DSW also grants you sudo permissions for flexible management.\nModel training\nPAI-DLC\nYou can use general computing resources and Lingjun resources for model training based on scenarios and computing power types.\nGeneral computing resources: Alibaba Cloud general computing resources, such as Elastic Compute Service (ECS), Elastic Container Instance, and Elastic GPU Service (EGS). DLC supports multiple training frameworks such as Tensorflow, PyTorch, and MPI and provides flexible, stable, and easy-to-use model training services.\nLingjun intelligent computing resources: Based on the integrated optimization technology of software and hardware, DLC allows you to run ultra-large distributed deep learning jobs and provides benefits such as high performance, high efficiency, and high utilization. Both Lingjun AI Computing Service Serverless Edition on the Alibaba Cloud public cloud and Lingjun AI Computing Service Dedicated Edition for a single tenant are supported. An AI engineering end-to-end platform with software-hardware heterogeneously integrated computing power is provided.\n\nModel deployment\nPAI-EAS\nEAS allows you to deploy models as online inference services or AI-powered web applications. EAS is suitable for multiple scenarios, such as real-time inference, asynchronous inference, and offline inference.\nView more features\nEnd-to-end AI-powered R&D\nSupports data labeling, model development, model training, model optimization, model deployment, and AI O&M as a one-stop AI platform.\nProvides over 140 types of optimized built-in algorithm components.\nProvides core capabilities such as multiple modes, deep integration with big data engines, multi-framework compatibility, and custom images.\nProvides  cloud-native AI development, training, and deployment services.\nMultiple open-source frameworks\nSupports Flink, a stream computing framework.\nSupports TensorFlow, PyTorch, Megatron and DeepSpeed, which are optimized deep learning frameworks based on the related open-source frameworks.\nSupports Parameter Server, a computing framework that can process hundreds of billions of samples in parallel.\nSupports Spark, PySpark, MapReduce, and other mainstream open-source computing frameworks.\nIndustry-leading AI optimization\nSupports high-performance training framework, sparse training scenarios, billions to tens of billions of sparse features, tens to hundreds of billions of samples, and distributed incremental training of thousands of workers.\nSupports acceleration of mainstream framework models such as RestNet50 and Transformer language model (LM) by using PAI Blade.\nDiverse service modes\nSupports fully managed and semi-managed services for public cloud.\nProvides high-performance AI computing clusters and lightweight service modes.\nSupports periodical scheduling by using DataWorks. You can run scheduled tasks in the production or development environment. This enables data isolation.\n\nBilling method\nDescription\nInvolved module\nPay-as-you-go\nIf you use the pay-as-you-go billing method, you are charged based on the actual usage of each module.\nThe pay-as-you-go billing method is suitable for short-term or uncertain workloads. It allows you to pay for resources based on the actual amount of resources that you use. The pay-as-you-go billing method is suitable for test environments, development environments, unexpected requirements, or projects in the early phases.\nMachine Learning Designer, DSW, DLC, and EAS\nSubscription\nThe subscription billing method\nis suitable for long-term and stable workloads. You must pay in advance to use resources for a specific period of time, such as a month or a year. The subscription billing method is more cost-effective than the pay-as-you-go billing method for long-term use.\nDSW, DLC, and EAS\nResource plan\nResource plans refer to quota plans of specific resources that you can purchase in advance.\nResource plans are suitable for scenarios in which you want to use a large number of specific resources. You can purchase quota plans for specific resources at more favorable prices.\nDSW\nSavings plan\nYou can purchase savings plans in advance, which offer specific discounts or benefits.\nSavings plans provide discounted pay-as-you-go rates in exchange for committing to a specific spending amount within a specific period of time.\nDSW and EAS\nPay-by-inference-duration\nYou are charged based on the actual inference duration. The resource specifications support automatic scaling based on the number of service requests.\nThis billing method is suitable for inference tasks that require indefinite quantities and is appropriate for high-concurrent requests and dynamic loads.\nEAS\nView more information about billing\nScenario\nUse case\nLarge language model (LLM)\nQuickly deploy LLMs in EAS\nRetrieval-Augmented Generation (RAG)-based LLM chatbot\nRAG-based LLM chatbot\nAI painting\nUse Stable Diffusion web UI to deploy an AI painting service\nGenerate a video\nSubmit a standalone training job that uses PyTorch\nView more scenarios\nIf you use PAI for the first time, you must activate PAI and create a default workspace. For more information, see Activate PAI and create a default workspace."
    },
    "457": {
        "title": "Platform For AI:Features",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/product-function-node-learn",
        "content": "This Product\nPlatform For AI:Features\n\n\nModule\nFeature\nDescription\nReference\nAI computing resource management\nLingjun resources\nPAI provides Lingjun resources for large-scale and high-density computing. Lingjun resources provide heterogeneous computing power, which is required for high-performance AI training and computing. You can use Lingjun resources for trainings in PAI.\nLingjun resource quotas\nGeneral training resources\nGeneral training resources are deep learning training resources based on Container Service for Kubernetes (ACK). The resources provides scalable, stable, easy-to-use, and high-performance runtimes for training deep learning models.\nGeneral computing resource quotas\nOther big data computing resources\nBig data computing resources, such as MaxCompute and Realtime Compute for Apache Flink.\nOverview of AI computing resources\nWorkspaces\nResource management\nThe workspace administrator can associate the AI computing resources in the current Alibaba Cloud account with the workspace to allow workspace members to use the resources for development and training.\nManage workspaces\nWorkspace notification\nPAI provides a notification mechanism for workspaces. You can create a notification rule to track and monitor Deep Learning Containers (DLC) jobs or Machine Learning Designer pipelines. You can also use notification rules to trigger events when the status of the model version changes.\nCreate a notification rule\nWorkspace storage and SLS configuration\nThe workspace administrator can specify the default storage path for development training in the current workspace and the storage lifecycle of temporary tables.\nManage workspaces\nMember and permission management\nPAI uses role-based access control that provides multiple roles, such as labeling administrators, algorithm developers, and algorithm O&M, to facilitate efficient collaboration. You can manage the visibility scope of AI assets in a workspace and manage access permissions for different roles.\nManage members of a workspace\nQuickStart\nModel Hub\nPAI provides various pre-trained models from open-source communities, such as ModelScope and Hugging Face.\nDeploy and train models\nPre-trained model training\nYou can use the pre-trained models for training in PAI.\nDeploy and train models\nPre-trained model deployment\nYou can use the pre-trained models for deployment in PAI.\nDeploy and train models\nMachine Learning Designer\nPipeline building\nMachine Learning Designer allows you to build and debug models by using pipelines. You can drag components to the canvas to build a pipeline based on your business requirements.\nPipeline overview\nPipeline import and export\nYou can export a pipeline as a JSON file. You can also import a JSON file to a workspace to build a pipeline.\nExport and import pipelines\nPipeline scheduling\nYou can use DataWorks to periodically schedule pipelines in Machine Learning Designer.\nUse DataWorks tasks to schedule pipelines in Machine Learning Designer\nPreset pipeline templates\nPAI provides pipeline templates that for various industries, such as product recommendation, news classification, financial risk control, haze weather prediction, heart disease prediction, agricultural loan issuance, and population census. The templates are preset with complete datasets and documentation to facilitate usage.\nGeneral solutions that use Machine Learning Designer\nCustom pipeline templates\nYou can create a pipeline template based on algorithm workflows that you develop and share the template with your team. Your team member can directly perform modeling, deployment, and online verification based on the custom template.\nCreate a pipeline from a custom template\nDashboards\nMachine Learning Designer provides dashboards to help you visualize data analysis, model analysis, and model results.\nUse dashboards to view analytical reports\nPreset algorithm component library\nPAI provides hundreds of built-in algorithm components for various industries, such as data source, data preprocessing, feature engineering, statistical analysis, machine learning, time series, recommendation algorithms, anomaly detection, natural language processing, network analysis, finance, visual algorithms, speech algorithms, and custom algorithms.\nComponent reference: Overview of all components\nCustom algorithms\nYou can implement nodes by using multiple methods, such as SQL, Python, and PyAlink scripts.\nCustom algorithm components\nData Science Workshop (DSW)\nCloud-native development environment\nDSW provides a flexible, stable, easy-to-use, and high-performance environment for AI development and various CPU-accelerated and GPU-accelerated resources to facilitate training.\nWhat is DSW?\nDSW Gallery\nDSW Gallery provides easy-to-use cases from various industries and technical verticals to help improve development efficiency.\nNotebook Gallery\nJupyterLab\nDSW integrates open source JupyterLab and provides plug-ins for custom development. You can directly start Notebook to write, debug, and run Python code without O&M configurations.\nAccess a DSW instance\nWebIDE\nDSW provides WebIDE in which you can install open source plug-ins for modeling.\nAccess a DSW instance\nTerminal\nDSW supports character terminals to debug models.\nAccess a DSW instance\nPersistent instance environment\nYou can manage the lifecycle of the development environment, save the instance environment, mount and share data, and persist the environment image.\nMount datasets or OSS paths\nResource usage monitoring\nYou can view real-time resource usage in a visualized manner.\nAccess a DSW instance\nImage creation\nYou can create an image and save the image to Container Registry for subsequent distributed training or inference.\nManage DSW instances\nSSH remote connection\nDSW provides the following SSH connection methods: direct connection and proxy client connection. You can select a connection method based on the resource dependencies, usage methods, and limits of the connection methods to meet your business requirements.\nConnect to a DSW instance over SSH\nDeep Learning Containers (DLC)\nCloud-native distributed training environment\nDLC is a deep learning platform developed based on Container Service for Kubernetes (ACK) that provides stable, easy-to-use, scalable, and high-performance runtimes for training deep learning models.\nBefore you begin\nDataset mounting\nYou can mount multiple datasets, such as File Storage NAS or Object Storage Service (OSS) datasets, in DLC at the same time.\nBefore you begin\nPublic and dedicated resource groups\nDLC provides public and dedicated resource groups.\nBefore you begin\nOfficial and custom images\nDLC allows you to use official images or custom images to submit training jobs.\nBefore you begin\nDistributed trainings\nDLC provides a distributed deployment solution for implementing data parallelism, model parallelism, and hybrid parallelism.\nCreate a training job\nTraining job management\nDLC allows you to manage jobs during the entire lifecycle.\nManage training jobs\nElastic Algorithm Service (EAS)\nResource group management\nEAS provides resources in resource groups for isolation. When you create a model service, you can deploy the model service in the public resource group provided by the system or a dedicated resource group that you created.\nOverview of EAS resource groups\nService and application deployment\nYou can deploy models that you downloaded from the open source community or models that you trained as inference services or AI-powered web applications in EAS. EAS provides multiple methods that you can use to deploy models. You can use the PAI console to deploy models as API services.\nDeploy a model service in the PAI console\nService debugging and stress testing\nAfter you deploy the service, you can use the online debugging and stress testing feature to test whether the service runs as expected.\nService debugging and stress testing\nAuto scaling\nYou can configure automatic scaling, scheduled scaling, and elastic resource pools for EAS services.\nService Auto Scaling\nService calls\nEAS provides the following service call methods based on the network environment of the client: Internet access, VPC access, and VPC direct connection.\nService calls\nAsynchronous inference\nEAS provides the asynchronous inference feature, which allows you to obtain inference results by subscribing to requests or polling.\nAsynchronous inference services\nIntegrated resource group and service management capabilities\nEAS provides standard OpenAPI and SDKs that support integration.\nList of operations by function\nAI computing asset management\nDatasets\nPAI provides public datasets and supports dataset management during labeling and modeling. PAI also support OSS and NAS datasets and SDK calls.\nCreate and manage datasets\nModels\nPAI allows you to manage versions, lineages, evaluation metrics, and associated services of models in a centralized manner.\nRegister and manage models\nTasks\nPAI supports management of distributed training tasks and PAIFlow pipeline runs.\nJob management\nImages\nPAI provides official images and supports image management.\nView and add images\nCode builds\nYou can register code repositories to PAI to facilitate code version management in PAI modules.\nCode builds\nCustom components\nYou can create custom algorithm components based on your business requirements. You can use custom components together with preset components in Machine Learning Designer to manage pipelines in a flexible manner.\n-\nAutoML\nAutomatic hyperparameter optimization (HPO)\nHPO is used to automatically fine-tune model-related parameters and training parameters.\nHow AutoML works\nScenario-based solutions\nMultimedia analysis\nPAI provides ready-to-use image-related services such as image labeling, classification, and quality evaluation.\nOverview of multimedia analysis\nAI acceleration\nDataset Accelerator\nDatasetAcc is a PaaS service developed by Alibaba Cloud to accelerate AI and datasets in the cloud. DatasetAcc provides dataset acceleration solutions for various cloud-native training engines by pre-analyzing and preprocessing training datasets used in machine learning training. This helps improve the overall training efficiency.\n-\nEasy Parallel Library (EPL)\nEPL is an efficient and easy-to-use framework for distributed model training. EPL uses multiple training optimization technologies and provides easy-to-use API operations that allow you to use parallelism strategies. You can use EPL to reduce costs and improve the efficiency of distributed model training.\nUse EPL to accelerate AI model training\nPAI-Rapidformer\nPAI-Rapidformer applies various technologies to optimize the training of PyTorch transformers and provide optimal training performance.\nPai-Megatron-Patch overview\nBlade\nBlade integrates various optimization technologies. You can use PAI-Blade to optimize the inference performance of a trained model.\nOverview of Blade\nPAI-SDK\nDistributed model training\nPAI SDK for Python provides an easy-to-use HighLevel API that allows you to submit training jobs to PAI and run the jobs in the cloud.\nSubmit a training job\nService deployment\nPAI SDK for Python provides an easy-to-use HighLevel API that allows you to deploy models to PAI and create inference services.\nDeploy an inference service"
    },
    "458": {
        "title": "Platform For AI:Service architecture",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/service-architecture",
        "content": "This Product\nPlatform For AI:Service architecture\nThis topic describes the architecture of Platform for AI (PAI).\n\nThe architecture of PAI consists of the following layers, as shown in the preceding figure:\nBasic resources layer (computing resources and infrastructure):\nInfrastructure: includes CPU, GPU, high-speed Remote Direct Memory Access (RDMA) network, and Container Service for Kubernetes (ACK) resources.\nComputing resources: include cloud-native resources (intelligent computing LINGJUN resources and general-purpose computing resources) and big data computing resources (MaxCompute and Flink resources).\nPlatform and framework layer (PAI-Lingjun AI Computing Service and AI frameworks):\nAI frameworks: include frameworks that can be used to run distributed computing tasks, such as Alink, TensorFlow, PyTorch, Megatron, DeepSpeed, and Reinforcement Learning from Human Feedback (RLHF).\nOptimization and acceleration frameworks: include DatasetAcc for dataset acceleration, TorchAcc for training acceleration, Easy Parallel Library (EPL) for parallel training acceleration, Blade for inference acceleration, AIMaster for automatic fault tolerance trainings, and EasyCkpt for second-level asynchronous training snapshots.\nPAI provides services for full-link machine learning development, including data preparation, model development and training, and model deployment.\nData preparation: iTAG allows you to label data and manage datasets in multiple scenarios.\nModel development and training: PAI provides various services to meet different modeling requirements. These services are Machine Learning Designer, Data Science Workshop (DSW), Deep Learning Containers (DLC), and FeatureStore. Machine Learning Designer is a visualized modeling service. DSW allows you to create models by using interactive programming. DLC is a cloud-native platform for training deep learning models. FeatureStore allows you to manage model features.\nModel deployment: You can use Elastic Algorithm Service (EAS) to deploy models as services.\nApplication layer (model services): model services, such as ModelScope community, PAI-DashScope, third-party MaaS platforms, and Alibaba Cloud Model Studio.\nBusiness layer (Scenario-based solutions): PAI is widely used in business scenarios, such as autonomous driving, scientific research, financial risk management, and AI recommendations. The search systems, recommendation systems, and financial service systems of Alibaba Group use PAI to mine data and make informed business decisions."
    },
    "459": {
        "title": "Platform For AI:Terms",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/terms",
        "content": "This Product\nPlatform For AI:Terms\nThis topic describes the terms related to management, AI development, and modules in Machine Learning Platform for AI (PAI).\nTerm\nDescription\nworkspace\nWorkspace is a key concept in PAI. Workspaces allow your organization or team to manage computing resources and user permissions in a centralized manner and provide tools and features for collaboration at every stage of AI development. PAI runs on top of DataWorks. Therefore, workspaces in PAI are mapped to workspaces in DataWorks. A workspace created in PAI also appears in the workspace list of DataWorks.\nDefault Workspace: The default workspace contains commonly used pay-as-you-go resources. You need to activate the default workspace before you can use these resources. The default workspace can help first-time users quickly get started with model development and training without the need to understand concepts such as resource groups.\nDeep Learning Containers (DLC)\nDLC is a cloud-native platform for basic AI computing jobs. DLC provides an elastic, stable, easy-to-use, and high-performance environment for model training. DLC provides multiple algorithm frameworks, allows you to run a large number of deep learning jobs in a distributed manner, and supports custom algorithm frameworks. DLC supports the following types of clusters:\nFully managed clusters: Fully managed clusters are public resource groups or dedicated resource groups. The administrators of a workspace can associate fully managed clusters with the workspace to use these clusters.\nSemi-managed clusters: Semi-managed clusters are self-managed resource groups. Semi-managed clusters provide separate dashboards and can be used more flexibly than fully managed clusters.\nresource group\nYou can create resource groups to classify computing resources by different dimensions, such as purposes, permissions, and ownership. Resource groups can be used to isolate computing resources that belong to different users or workspaces.\nResource groups refer to all underlying resources that are used by different modules in PAI, such as MaxCompute quota groups, DLC clusters, Kubernetes clusters, E-MapReduce (EMR) clusters, Flink clusters, and Elastic Compute Service (ECS) clusters.\nYou can purchase and create resource groups on the MaxCompute, EMR, or other consoles by using an Alibaba Cloud account or the resource administrator role. The purchased resource groups can be consumed in workspaces.\nmember\nMembers are Alibaba Cloud accounts or Resource Access Management (RAM) users that join workspaces. Members in the same workspace can assume different roles to collaborate throughout the AI development pipeline. Only the owner and administrators of a workspace can modify the members in the workspace.\nrole\nRoles are mappings between members and permissions. You can use the system roles or create custom roles. The system roles include:\nResource administrator: This role has the permissions to purchase and manage compute resources. In most cases, Alibaba Cloud enterprise accounts assume this role. To manage the permissions provided by this role and assign the role, you need to log on to the RAM console.\nWorkspace owner: This role has the permissions to modify the members in the workspace and reference resource groups. This role is automatically assigned to the user who created the workspace.\nWorkspace administrator: This role has the permissions to modify the members and manage all assets in the workspace, including resource groups.\nAlgorithm Developer: This role has the permissions to develop and train models in the workspace.\nAlgorithm O&M Engineer: This role has the permissions to manage job priorities, publish models, and monitor online services.\nLabel Administrator: This role has the permissions to use intelligent labeling.\nVisitor: This role has the read-only permissions on all assets in the workspace.\ndependency\nPAI relies on other Alibaba Cloud services. To use the features provided by PAI, you must first activate these Alibaba Cloud services and complete RAM authorization by using an Alibaba Cloud account or the resource administrator role. The Alibaba Cloud services that you need to activate include Object Storage Service (OSS), File Storage NAS (NAS), Log Service, Container Registry, and API Gateway.\nTerm\nDescription\ndataset\nDatasets are used in labeling, model training, and model evaluation. You can create datasets to use structured data or unstructured data or mount directories in datastores such as OSS, NAS, and MaxCompute. In addition, you can centrally manage the storage, versions, and schemas of datasets in PAI.\npipeline\nPipelines are directed acyclic graphs (DAGs) that consist of upstream components and downstream components connected based on logical scheduling. You can submit multiple runs for a pipeline to generate PipelineRuns.\nPipelineDraft\nPipelineDrafts are configurable pipeline objects on the canvas of Designer. You can edit a PipelineDraft to generate multiple pipelines. You can submit runs for PipelineDrafts to generate PipelineRuns.\ncomponent\nComponents are the smallest configurable units in pipelines and PipelineDrafts, and the smallest executable units in PipelineRuns. Components consist of the following types:\nBuilt-in components: PAI provides built-in components that can be used throughout the model development pipeline. These components are developed based on the best practices of Alibaba Cloud and can be used to preprocess data, train models, and make predictions.\nCustom components: You can create custom components based on code or images, and add these custom components to your pipelines.\nnode\nNodes represent components that are dragged and dropped to the canvas to form a pipeline.\nsnapshot\nEach time the system runs a single node in a PipelineDraft, multiple nodes in the PipelineDraft, or the entire PipelineDraft, the system creates a snapshot for the configurations of the PipelineDraft. The snapshot includes the node configurations, runtime parameters, and execution mode. Snapshots can be used in PipelineDraft versioning and configuration rollbacks.\nPipelineRun\nA PipelineRun represents a single run of a pipeline. After you use Designer to submit a run for a PipelineDraft or use the SDK to submit a run for a pipeline, a PipelineRun is generated.\njob\nJobs, such as DLC jobs, use computing resources. The resource environment in which jobs run belongs to the user.\nrun\nA run represents a single execution of a pipeline. Run is equivalent to the same concept in MLflow. All runs must belong to an experiment. You can use runs to track the training jobs that you submitted in Machine Learning Platform for AI. You can also use the MLflow client to submit runs from an on-premises machine. A run can contain multiple jobs.\nmodel\nModels are generated by training jobs based on datasets, algorithms, and code. You can use models to make predictions.\nProcessor\nA processor is a package of online prediction logic, including the logic for loading models and handling requests. In most cases, processors are deployed together with model files to provision services. Processors consist of the following types:\nBuilt-in processors: EAS provides built-in processors for commonly used models, such as Predictive Model Markup Language (PMML) models and TensorFlow models.\nCustom processors: If the built-in processors cannot meet your business requirements, you can create custom processors that conform to the processor development standards.\nservice\nYou can deploy model files together with the online prediction logic as services. EAS allows you to create, update, start, stop, scale out, and scale in services.\nimage\nPAI allows you to manage the following Docker images as AI assets:\nPublic images that are provided by PAI.\nCustom images that are saved in Data Science Workshop (DSW).\nCustom images that are saved in Container Registry.\nYou can use images in pipelines to create custom components to complete specific jobs. Images can also provide runtime environments for DSW instances and training jobs.\ninstance\nInstances are the smallest units for provisioning compute resources. Instances consist of the following types:\nDSW instances: DSW instances are notebook instances. Each DSW instance provides a certain amount of compute resources for you to modify code, perform debugging, or train models. The resource environment of instances belongs to the user.\nEAS instances: EAS instances are service processes. You can deploy one or more EAS instance for each service to increase the number of concurrent requests that can be handled by the service. The resource environment of instances belongs to the user.\nTerm\nDescription\niTAG\niTAG is a dataset labeling tool that is developed with black box models to help improve the quality and efficiency of dataset labeling.\nDesigner\nDesigner is intended for pipeline design in the AI sector. Designer provides a variety of built-in machine learning algorithm components. You can drag and drop these components to train models without coding.\nData Science Workshop (DSW)\nDSW is an integrated development environment (IDE) intended for interactive AI development in the cloud. DSW consists of Notebook, VS Code, and Terminal. You can use images to deploy DSW instances that use NAS as the storage.\nDeep Learning Containers (DLC)\nYou can submit training jobs to computing resource groups, such as DLC clusters, in the current workspace. After you submit training jobs, you can view the details about the jobs in the Jobs module of the PAI console.\nElastic Algorithm Service (EAS)\nEAS allows you to deploy complex models as services on a large scale with a few clicks. EAS supports real-time scaling and provides a sophisticated monitoring and maintenance system.\nAI Asset Management\nThis module allows you to manage key AI assets, including datasets, models, and source code repositories.\nScenario-based Solution\nA collection of solutions provided by PAI to help you resolve issues in vertical markets."
    },
    "460": {
        "title": "Platform For AI:Regions and zones",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/regions-and-zones",
        "content": "This Product\nPlatform For AI:Regions and zones\nThis topic describes the regions and zones supported by Platform for AI (PAI).\nResource type\nArea\nRegion\nLingjun resources\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Ulanqab)\nChina (Shenzhen)\nSingapore\nGeneral computing resources\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Ulanqab)\nChina (Shenzhen)\nChina (Guangzhou)\nJapan (Tokyo)\nSingapore\nChina (Hong Kong)\nMalaysia (Kuala Lumpur)\nIndonesia (Jakarta)\nEurope & America\nUS (Virginia)\nGermany (Frankfurt)\nElastic Algorithm Service (EAS) computing resources\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Zhangjiakou)\nChina (Ulanqab)\nChina (Shenzhen)\nChina (Heyuan)\nChina (Chengdu)\nChina (Hong Kong)\nJapan (Tokyo)\nSingapore\nIndonesia (Jakarta)\nEurope & America\nGermany (Frankfurt)\nUS (Silicon Valley)\nUS (Virginia)\n\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Zhangjiakou)\nChina (Ulanqab)\nChina (Shenzhen)\nChina (Heyuan)\nChina (Chengdu)\nChina (Hong Kong)\nJapan (Tokyo)\nSingapore\nMalaysia (Kuala Lumpur)\nIndonesia (Jakarta)\nEurope & America\nGermany (Frankfurt)\nUS (Silicon Valley)\nUS (Virginia)\nMiddle East\nUAE (Dubai)\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Ulanqab)\nChina (Shenzhen)\nSingapore\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Hong Kong)\nSingapore\n\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Ulanqab)\nChina (Hong Kong)\nJapan (Tokyo)\nSingapore\nIndonesia (Jakarta)\nEurope & America\nGermany (Frankfurt)\nUS (Silicon Valley)\nUS (Virginia)\nArea\nRegion\nBilling method\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Guangzhou)\nChina (Hong Kong)\nChina (Ulanqab)\nJapan (Tokyo)\nSingapore\nIndonesia (Jakarta)\nMalaysia (Kuala Lumpur)\nPay-as-you-go\nEurope & America\nGermany (Frankfurt)\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Guangzhou)\nChina (Ulanqab)\nJapan (Tokyo)\nSingapore\nChina (Hong Kong)\nIndonesia (Jakarta)\nSubscription\nArea\nRegion\nBilling method\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Guangzhou)\nChina (Hong Kong)\nChina (Ulanqab)\nJapan (Tokyo)\nSingapore\nMalaysia (Kuala Lumpur)\nIndonesia (Jakarta)\nPay-as-you-go\n\nEurope & America\nGermany (Frankfurt)\nUS (Virginia)\nAsia Pacific\nChina (Shanghai)\nChina (Beijing)\nChina (Hangzhou)\nChina (Shenzhen)\nChina (Guangzhou)\nChina (Ulanqab)\nJapan (Tokyo)\nSingapore\nChina (Hong Kong)\nMalaysia (Kuala Lumpur)\nIndonesia (Jakarta)\nSubscription\nEurope & America\nUS (Virginia)\nGermany (Frankfurt)\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Zhangjiakou)\nChina (Ulanqab)\nChina (Shenzhen)\nChina (Heyuan)\nChina (Guangzhou)\nChina (Chengdu)\nChina (Hong Kong)\nJapan (Tokyo)\nSingapore\nIndonesia (Jakarta)\nEurope & America\nGermany (Frankfurt)\nUS (Virginia)\nUS (Silicon Valley)\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Zhangjiakou)\nChina (Ulanqab)\nChina (Shenzhen)\nChina (Heyuan)\nChina (Hong Kong)\nSingapore\nMalaysia (Kuala Lumpur)\nIndonesia (Jakarta)\nEurope & America\nGermany (Frankfurt)\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Hong Kong)\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Hong Kong)\nSingapore\nEurope & America\nUS (Virginia)\nUS (Silicon Valley)\nFeature module\nArea\nRegion\nUser growth\nAll regions\nPersonalized recommendation (PAI-Rec)\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Shenzhen)\nChina (Hong Kong)\nSingapore\nEurope & America\nUS (Virginia)\nUS (Silicon Valley)\nSmart retail\nAll regions\nMultimedia analysis\nAll regions\nAI portrait\nAll regions\nArea\nRegion\nAsia Pacific\nChina (Hangzhou)\nChina (Shanghai)\nChina (Beijing)\nChina (Ulanqab)\nChina (Shenzhen)\nSingapore"
    },
    "461": {
        "title": "Platform For AI:Announcements and Updates",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/announcements-and-updates/",
        "content": "This Product\nPlatform For AI:Announcements and Updates"
    },
    "462": {
        "title": "Platform For AI:Billing of AI computing resources",
        "url": "https://www.alibabacloud.com/help/en/pai/ai-computing-resource-billing-description",
        "content": "This Product\nPlatform For AI:Billing of AI computing resources\nThis topic describes the billing rules of AI computing resources.\nAI computing resources include general computing resources and Lingjun resources.\n\n\n\nThe following table describes how you are billed for AI computing resources.\nBilling method\nBillable resource\nBillable item\nBilling rule\nHow to stop billing\nSubscription\nGeneral computing resources\nThe number of nodes and the subscription duration based on the node type.\nYou are charged for dedicated resources based on the number of nodes and the subscription duration.\nN/A\nLingjun resources\nBilling formula\nUnit price\nDuration\nScaling\nUsage notes\nBill amount = Unit price of the node type \u00d7 Number of nodes \u00d7 Subscription duration\nTo view the pricing details of general computing resources, go to the AI Computing Resource Group (International Site) page and click General Computing Resources under Resource Type.\nStart time: 00:00:00 the next day after the purchase.\nEnd time: the time when the subscription expires.\nN/A\nNone\nTo purchase general computing resources, go to the Platform for AI (PAI) console and choose AI Computing Resources > Resource Pool in the left-side navigation pane. For more information, see Create a resource group and purchase general computing resources.\nLingjun resources are available only in the China (Ulanqab) and Singapore regions. Only whitelisted users can use Lingjun resources. If you want to use Lingjun resources, contact your account manager to apply for the whitelist.\nBilling formula\nUnit price\nDuration\nScaling\nUsage notes\nBill amount = Unit price of the node type \u00d7 Number of nodes \u00d7 Subscription duration\nFor information about the pricing of Lingjun resources, see the \"Pricing of Lingjun resources\" section in this topic. You can also go to the AI Computing Resource Group (International Site) page and click Lingjun Resources under Resource Type to view the pricing details.\nStart time: 00:00:00 the next day after the purchase.\nEnd time: the time when the subscription expires.\nN/A\nNone\nThe following table describes the supported node types.\nThe supported node types in the table are only for reference. You can view the actual node types on the buy page.\nNode type\nGPU\nCPU (core)\nMemory (GB)\nRegion\nml.gu7xf.c96m1600.8-gu108\n8 GPUs (gu7xf)\n96\n1600\nChina (Ulanqab)\nml.gu8ef.8xlarge-gu100\n8 GPUs (gu8ef)\n160\n1800\nSingapore\nThe following table describes the prices of different node types.\nThe prices in the table are only for reference. You can view the actual prices on the buy page.\nNode type\nPrice (USD per month)\nml.gu7xf.c96m1600.8-gu108\n23,932.70\nml.gu8ef.8xlarge-gu100\n111,425.60\nTo purchase Lingjun resources, go to the PAI console and choose AI Computing Resources > Resource Pool in the left-side navigation pane. For more information, see Create a resource group and purchase Lingjun resources.\nThe following examples are only for reference. You can view the actual prices in the console or on the buy page.\nScenario\nYou deploy two subscription instances of the ecs.g6.13xlarge-52c192g instance type in the China (Shanghai) region. The subscription duration is two months and the unit price is USD 980.57 per month.\nFee calculation\nScenario\nYou deploy two subscription instances of the ml.gu7xf.c96m1600.8-gu108 instance type in the China (Ulanqab) region. The subscription duration is one month and the unit price is USD 23,932.70 per month.\nFee calculation"
    },
    "463": {
        "title": "Platform For AI:Billing of QuickStart",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-quick-start",
        "content": "This Product\nPlatform For AI:Billing of QuickStart\nThis topic describes how QuickStart of Platform for AI (PAI) is billed.\nQuickStart is provided free of charge. You are charged for the resources that you use to train or deploy models.\nWhen you train models by using QuickStart, the system creates training jobs in Deep Learning Containers (DLC) and schedules resources to run the jobs. You are charged for computing resources that are used in DLC jobs. For more information, see Billing of DLC.\nWhen you deploy models by using QuickStart, the system creates deployment services in Elastic Algorithm Service (EAS) and schedules resources to complete the tasks. You are charged for the resources that are used for EAS services. For more information, see Billing of EAS."
    },
    "464": {
        "title": "Platform For AI:Billing of iTAG",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-itag",
        "content": "This Product\nPlatform For AI:Billing of iTAG\niTAG is an intelligent data labeling platform that supports the following labeling tasks:\nData labeling for traditional machine learning: image, text, video, and audio.\nData labeling for multimodal large language models (LLMs): text Q&A, Visual Question Answering (VQA) dialogues, and image-text descriptions.\nPure manual labeling.\nAutomated labeling assisted by intelligent labeling service.\nThe billing details of iTag:\nIf you need to perform pure manual labeling, you can use iTAG for free.\nIf you need outsourced manual labeling services, submit a ticket to contact the PAI team and apply for paid labeling services.\nBy default, iTAG provides the intelligent labeling service for some LLM templates, such as Image-to-text Generation and Image Caption. Intelligent labeling services are temporarily free of charge until further notice.\n"
    },
    "465": {
        "title": "Platform For AI:Billing of Machine Learning Designer",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-machine-learning-designer-2",
        "content": "This Product\nPlatform For AI:Billing of Machine Learning Designer\nThis topic describes the billing rules of Machine Learning Designer of Platform for AI (PAI).\nThe pricing information in this topic is only for reference. The actual prices in the billing statement shall prevail.\n\nBillable resource\nBillable item\nBilling method\nStop billing\nBilling rule\nGeneral algorithm components\nRuntime of the component\nPay-as-you-go\nStop the component.\nThe resources consumption of the components is calculated based on billable hours on a pay-as-you-go basis.\nWhen you use the algorithm components in Machine Learning Designer, the unit price of the component varies based on the type of the algorithm. The following section describes the billing method.\nBilling formula: Bill amount = Number of billable hours \u00d7 Unit price\nNumber of billable hours = Max (Number of vCPUs \u00d7 Billing duration (h), Memory size (GB) \u00d7 Billing duration/4).\nBilling duration: The billing starts when the component starts to run and ends when the component stops running.\nBilling example: The following formula shows how to calculate the number of billable hours if you use 2 vCPUs and 5 GB of memory of a data analysis component for 1 hour and 30 minutes: Number of billable hours: Max (2 \u00d7 (1 + 30/60), 5 \u00d7 (1 + 30/60)/4) = 3. The bill amount is calculated by using the following formula: Bill amount = 3 \u00d7 0.21 = USD 0.63. The following table describes the unit price of each type of algorithm components:\nAlgorithm\nUnit price (USD per billable hour)\nAlgorithm description\nData preprocessing (data_manipulation)\n0.16\nIncludes the following types of components: data preprocessing and feature engineering.\nData analysis (data_analysis)\n0.21\nIncludes the following types of components: statistical analysis, machine learning, time series, network analysis, and financial.\nText analysis (text_analysis)\n0.27\nIncludes components that use text analysis algorithms.\nDeep learning (deep_learning)\n0.16\nDeep learning tasks that consume only CPU, including EasyRec-based components and the CPU version of Tensorflow-based framework components.\nIf you activate MaxCompute when you activate PAI, you are charged for MaxCompute resources when you use the SQL Script, JOIN, UNION, and Filtering and Mapping components. For more information, see Billing of MaxCompute.\nIf you activate Realtime Compute for Apache Flink when you activate PAI, you are charged when you use the Alink components. For more information, see Billing of Flink.\nA pipeline in Machine Learning Designer consists of multiple algorithm components. An algorithm component is composed of multiple subtasks. To calculate the fees for a pipeline, you need to calculate the fees of the subtasks in each algorithm component and then add the fees of all components that are used in the pipeline.\nDetermine the category of an algorithm component.\nLog on to the PAI console.\nIn the upper-left corner, select a region based on your business requirements.\nIn the left-side navigation pane, click Workspaces. On the Workspaces page, click the name of the workspace that you want to use.\nIn the left-side navigation pane, choose Model Training > Visual Modeling (Designer).\nOn the Pipelines page, select a pipeline and click Open to go to the canvas.\nIn the component list, the PLDA component is in the Natural Language Processing folder. The price of the PLDA component is USD 0.27 per billable hour.\n\nView the resources consumed for the job.\nOn the canvas, right-click the PLDA component.\nIn the menu that appears, click View Log.\nOn the Log-PLDA tab, click a hyperlink. Each hyperlink corresponds to a subtask.\n\nOn the LogView page, click the SourceXML tab.\nIn the TaskPlan section, you can view the value of the CPU and Memory fields.\nThe number of used vCPUs is calculated by using the following formula: CPU field value/100. In this example, 1 vCPU is used for running the job.\nThe unit of the Memory field is MB. In this example, 1,024 MB of memory is used to run the job.\nOn the LogView page, click the Job Details tab.\nClick the task object on the AlgoTask_0_0 tab. In the section that appears, click the Terminated tab. The Latency field specifies the running duration of each job.\nIn this example, the subtask has 49 jobs, and each job runs for approximately 26 seconds.\nCalculate the fee of the subtask.\nNumber of billable hours used in the subtask = Max (Number of vCPUs \u00d7 Usage duration, Memory size \u00d7 Usage duration/4) = Max [49 \u00d7 1 \u00d7 (26/3,600), 49 \u00d7 1 \u00d7 26/3,600/4] \u2248 0.35 billable hours\nSubtask fee = Number of billable hours \u00d7 Unit price = 0.35 \u00d7 0.27 \u2248 USD 0.095\nCalculate and add the total fee of all running subtasks in the PLDA component.\nRepeat the preceding steps to calculate and add the fees of all components used in the pipeline.\n"
    },
    "466": {
        "title": "Platform For AI:Billing of DSW",
        "url": "https://www.alibabacloud.com/help/en/pai/dsw-billing-description",
        "content": "This Product\nPlatform For AI:Billing of DSW\nThis topic describes the billing rules of Data Science Workshop (DSW) of Platform for AI (PAI).\nThe following figure shows the billable resources of DSW.\n\n\nThe following table describes the billing methods of DSW.\nBilling method\nBillable resource\nBillable item\nBilling rule\nStop billing\nPay-as-you-go\nPublic resources\nThe running duration of a DSW instance , which is the duration for which the public resource group is occupied.\nThe public resource group is billed based on the amount of time during which public resources are occupied by the DSW instance.\nStop the instance.\nDelete the instance.\nPay-as-you-go\nSystem disk\nThe capacity and running duration of the system disk.\nYou can expand the system disk capacity. The expanded capacity is billed based on the capacity and running duration.\nDelete the DSW instance.\nSubscription\nAI computing resources (general computing resources and Lingjun resources)\nFor more information, see Billing of AI computing resources.\nFor more information, see Billing of AI computing resources.\nN/A\nIf you want to use the pay-as-you-go billing method, you must use public resources to create a DSW instance.\nBillable resource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nPublic resources\n\nBill amount = (Price/60) \u00d7 Running duration. The running duration is measured in minutes.\nThe price of a DSW instance may vary based on the region. To view the actual price of an instance, go to the Create Instance page in the PAI console and set the Resource Quota parameter to Public Resource Group (Pay-as-you-go). For information about how to go to the Create Instance page, see Create a DSW instance.\nRunning duration of a DSW instance\nN/A\nN/A\nSystem disk\nBill amount = System disk capacity (GiB) \u00d7 Unit price \u00d7 Running duration (hours).\nFor information about pricing, visit the ECS pricing page. Choose Pricing > Storage and view the System Cloud Disk Fee.\nAfter you expand the system disk capacity, you are charged based on the capacity that exceeds the free quota and running duration.\nThe billing starts when the capacity is expanded.\nN/A\nAI computing resources include general computing resources and Lingjun resources. If you want to use the subscription billing method, you must purchase AI computing resource quotas and use the resource quotas to create DSW instances. For more information, see Billing of AI computing resources.\n\nThe following billing examples are only for reference. For the actual fees, go to the console or buy page of the service that you want to purchase.\nScenario\nFor example, you use public resources to create a DSW instance of the ecs.g6.13xlarge instance type that is deployed in the China (Shanghai) region. The instance runs for 1 minute and 15 seconds.\nFee calculation\nScenario\nFor example, you use dedicated resources to create two DSW instances of the ecs.g6.13xlarge-52c192g instance type that are deployed in the China (Shanghai) region. The subscription period is two months and the unit price is USD 980.57 per month.\nFee calculation"
    },
    "467": {
        "title": "Platform For AI:Billing of DLC",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-dlc",
        "content": "This Product\nPlatform For AI:Billing of DLC\nThis topic describes how you are billed for Deep Learning Containers (DLC) of Platform for AI (PAI).\nThe pricing information in this topic is only for reference. You can view the actual prices in your billing statements.\nThe following figure shows the billable resources of DLC.\n\nThe following table describes the billing methods of DLC.\nBilling method\nBillable resource\nBillable item\nBilling rule\nHow to stop billing\nPay-as-you-go\nPublic resources\nThe amount of time for which DLC jobs run by using public resources.\nIf you run DLC jobs by using public resources, you are charged based on the usage duration.\nBilling stops when DLC jobs are complete.\nBilling stops when you stop DLC jobs.\nSubscription\nAI computing resources (general computing resources and Lingjun resources)\nFor more information, see Billing of AI computing resources.\nFor more information, see Billing of AI computing resources.\nN/A\nTo use the pay-as-you-go billing method, you must use public resources to create DLC jobs.\nResource\nBilling formula\nUnit price\nBilling duration\nScaling\nUsage notes\nPublic resources\n\nBill amount = Number of nodes \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nThe unit prices may vary based on the instance type and region. To view the unit prices, go to the Create Job page in the PAI console. For more information, see Submit a job in the console. In the Resource Information section, set the Source parameter to Public Resources and select an instance type. You can view the unit price of the instance in the Current Price/Original Price ($/Hour) column.\nRunning duration of DLC jobs.\nN/A\nNone\nAI computing resources include general computing resources and Lingjun resources. AI computing resources support only the subscription billing method. You can add resource quotas for purchased AI computing resources and use the quotas to create DLC jobs. For more information, see Billing of AI computing resources.\nThe following example is only for reference. You can view the actual prices in the console or on the buy page.\nScenario\nYou purchase a pay-as-you-go ecs.g6.2xlarge instance in the China (Shanghai) region to create a training job. The job runs for 1 minute and 15 seconds.\nFee calculation\nFor billing examples of AI computing resources, see Billing of AI computing resources.\nThe following table describes some of the instance types that can be used to create DLC jobs in the public resource group. For a complete list of the supported instance types, go to the DLC page in the PAI console and click Create Job. You can view the supported instance types in the Resource Information section. For more information, see Submit a job in the console. The supported instance types may vary based on the region.\nInstance type\nSpecification\nGPU\necs.g6.xlarge\n4 vCPUs + 16 GB memory\nNone\necs.c6.large\n2 vCPUs + 4 GB memory\nNone\necs.g6.large\n2 vCPUs + 8 GB memory\nNone\necs.g6.2xlarge\n8 vCPUs + 32 GB memory\nNone\necs.g6.4xlarge\n16 vCPUs + 64 GB memory\nNone\necs.g6.8xlarge\n32 vCPUs + 128 GB memory\nNone\necs.r7.large\n2 vCPUs + 16 GB of memory\nNone\necs.r7.xlarge\n4 vCPUs + 32 GB memory\nNone\necs.r7.2xlarge\n8 vCPUs + 64 GB memory\nNone\necs.r7.4xlarge\n16 vCPUs + 128 GB memory\nNone\necs.r7.6xlarge\n24 vCPUs + 192 GB memory\nNone\necs.r7.8xlarge\n32 vCPUs + 256 GB memory\nNone\necs.r7.16xlarge\n64 vCPUs + 512 GB memory\nNone\necs.g5.xlarge\n4 vCPUs + 16 GB memory\nNone\necs.g7.xlarge\n4 vCPUs + 16 GB memory\nNone\necs.g7.2xlarge\n8 vCPUs + 32 GB memory\nNone\necs.g5.2xlarge\n8 vCPUs + 32 GB memory\nNone\necs.g6.3xlarge\n12 vCPUs + 48 GB memory\nNone\necs.g7.3xlarge\n12 vCPUs + 48 GB memory\nNone\necs.g7.4xlarge\n16 vCPUs + 64 GB memory\nNone\necs.r7.3xlarge\n12 vCPUs + 96 GB memory\nNone\necs.c6e.8xlarge\n32 vCPUs + 64 GB memory\nNone\necs.g6.6xlarge\n24 vCPUs + 96 GB memory\nNone\necs.g7.6xlarge\n24 vCPUs + 96 GB memory\nNone\necs.g5.4xlarge\n16 vCPUs + 64 GB memory\nNone\necs.hfc6.8xlarge\n32 vCPUs + 64 GB memory\nNone\necs.g7.8xlarge\n32 vCPUs + 128 GB memory\nNone\necs.hfc6.10xlarge\n40 vCPUs + 96 GB memory\nNone\necs.g6.13xlarge\n52 vCPUs + 192 GB memory\nNone\necs.g5.8xlarge\n32 vCPUs + 128 GB memory\nNone\necs.hfc6.16xlarge\n64 vCPUs + 128 GB memory\nNone\necs.g7.16xlarge\n64 vCPUs + 256 GB memory\nNone\necs.hfc6.20xlarge\n80 vCPUs + 192 GB memory\nNone\necs.g6.26xlarge\n104 vCPUs + 384 GB memory\nNone\necs.g5.16xlarge\n64 vCPUs + 256 GB memory\nNone\necs.r5.8xlarge\n32 vCPUs + 256 GB memory\nNone\necs.re6.13xlarge\n52 vCPUs + 768 GB memory\nNone\necs.re6.26xlarge\n104 vCPU + 1,536 GB memory\nNone\necs.re6.52xlarge\n208 vCPU + 3,072 GB memory\nNone\necs.g7.32xlarge\n128 vCPU + 512 GB memory\nNone\necs.gn7i-c8g1.2xlarge\n8 vCPUs + 30 GB memory\n1 \u00d7 NVIDIA A10\necs.gn6v-c8g1.2xlarge\n8 vCPUs + 32 GB memory\n1 \u00d7 NVIDIA V100\necs.gn6e-c12g1.24xlarge\n96 vCPUs + 736 GB memory\n8 \u00d7 NVIDIA V100\necs.gn6v-c8g1.16xlarge\n64 vCPUs + 256 GB memory\n8 \u00d7 NVIDIA V100\necs.gn6v-c10g1.20xlarge\n82 vCPUs + 336 GB memory\n8 \u00d7 NVIDIA V100\necs.gn6e-c12g1.12xlarge\n48 vCPUs + 338 GB memory\n4 \u00d7 NVIDIA V100\necs.gn6v-c8g1.8xlarge\n32 vCPUs + 128 GB memory\n4 \u00d7 NVIDIA V100\necs.gn6i-c24g1.24xlarge\n96 vCPUs + 372 GB memory\n4 \u00d7 NVIDIA T4\necs.gn5-c8g1.4xlarge\n16 vCPUs + 120 GB memory\n2 \u00d7 NVIDIA P100\necs.gn7i-c32g1.16xlarge\n64 vCPUs + 376 GB memory\n2 \u00d7 NVIDIA A10\necs.gn6i-c24g1.12xlarge\n48 vCPUs + 186 GB memory\n2 \u00d7 NVIDIA T4\necs.gn6e-c12g1.3xlarge\n12 vCPUs + 92 GB memory\n1 \u00d7 NVIDIA V100\necs.gn5-c4g1.xlarge\n4 vCPUs + 30 GB memory\n1 \u00d7 NVIDIA P100\necs.gn5-c8g1.2xlarge\n8 vCPUs + 60 GB memory\n1 \u00d7 NVIDIA P100\necs.gn5-c28g1.7xlarge\n28 vCPUs + 112 GB memory\n1 \u00d7 NVIDIA P100\necs.gn6i-c4g1.xlarge\n4 vCPUs + 15 GB memory\n1 \u00d7 NVIDIA T4\necs.gn6i-c8g1.2xlarge\n8 vCPUs + 31 GB memory\n1 \u00d7 NVIDIA T4\necs.gn6i-c16g1.4xlarge\n16 vCPUs + 62 GB memory\n1 \u00d7 NVIDIA T4\necs.gn6i-c24g1.6xlarge\n24 vCPUs + 93 GB memory\n1 \u00d7 NVIDIA T4\necs.gn7i-c32g1.8xlarge\n32 vCPUs + 188 GB memory\n1 \u00d7 NVIDIA A10\necs.gn7e-c16g1.4xlarge\n16 vCPUs + 125 GB memory\n1 \u00d7 GU50\necs.gn7-c12g1.3xlarge\n12 vCPUs + 95 GB memory\n1 \u00d7 GU50\necs.gn7i-c16g1.4xlarge\n16 vCPUs + 60 GB memory\n1 \u00d7 NVIDIA A10\necs.gn7-c13g1.26xlarge\n104 vCPUs + 760 GB memory\n8 \u00d7 GU50\necs.ebmgn7e.32xlarge\n128 vCPUs + 1,024 GB memory\n8 \u00d7 GU50\necs.gn7i-c32g1.32xlarge\n128 vCPUs + 752 GB memory\n4 \u00d7 NVIDIA A10\necs.gn7-c13g1.13xlarge\n52 vCPUs + 380 GB memory\n4 \u00d7 GU50\necs.gn7s-c32g1.32xlarge\n128 vCPUs + 1,000 GB memory\n4 \u00d7 NVIDIA A30\necs.gn7s-c56g1.14xlarge\n56 vCPUs + 440 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c48g1.12xlarge\n48 vCPUs + 380 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c16g1.4xlarge\n16 vCPUs + 120 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c8g1.2xlarge\n8 vCPUs + 60 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c32g1.8xlarge\n32 vCPUs + 250 GB memory\n1 \u00d7 NVIDIA A30"
    },
    "468": {
        "title": "Platform For AI:Billing of LangStudio",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-langstudio",
        "content": "This Product\nPlatform For AI:Billing of LangStudio\nThis topic describes the billing rules of Application Development (LangStudio) of Platform for AI (PAI).\nWhen you use LangStudio to develop LLM applications, the following cloud services may incur fees, including Object Storage Service (OSS), Managed Service for OpenTelemetry, Simple Log Service (SLS), and PAI-EAS:\nWhen developing application flow, you need to select an OSS bucket as the working path to store code, configuration files, development and debugging logs, and service deployment snapshots. For more information, see Billing of OSS.\nLangStudio requires Managed Service for OpenTelemetry for debugging individual runs and for API calls post-deployment. For more information, see Billing of Managed Service for OpenTelemetry.\nManaged Service for OpenTelemetry uses Simple Log Service (SLS) to store trace log data. For more information, see Billing of SLS.\nRuntime dependencies for application flow development and debugging use pay-as-you-go PAI-EAS instances. For more information, see Billing of EAS.\nYou can deploy your developed and debugged application flow in EAS to provide external API services. For more information, see Billing of EAS."
    },
    "469": {
        "title": "Platform For AI:Billing of EAS",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-eas",
        "content": "This Product\nPlatform For AI:Billing of EAS\nThis topic describes the billable items and billing methods of Elastic Algorithm Service (EAS) of Platform for AI (PAI).\nThe pricing information in this topic is only for reference. The actual prices in the billing statement shall prevail.\nThe following figure shows the billable resources of EAS.\n\n\nThe following table describes the billing methods of EAS.\nBilling method\nBillable resource\nBillable item\nBilling rule\nStop billing\nPay-as-you-go\nPublic resource group\nThe amount of time for which a model service runs by using public resources.\nIf you use public resources to deploy a model service, you are charged based on the usage duration. Billing starts immediately after model services are deployed.\nStop model services.\nPay-as-you-go\nEAS resources (dedicated resource group)\nThe number of nodes and the usage duration.\nIf you use dedicated resources to deploy a model service, you are charged only for nodes in the dedicated resource group. Billing starts immediately after pay-as-you-go nodes are created in dedicated resource groups.\nDelete pay-as-you-go nodes from dedicated resource groups.\nSubscription\nThe number of nodes and the subscription duration.\nN/A\nPay-as-you-go\nSystem disk\nThe system disk capacity and the usage duration.\nBilling starts immediately after the system disk is created.\nDelete nodes from dedicated resource groups.\nDelete model services deployed in the public resource group.\nSubscription\nThe system disk capacity and the subscription duration.\nBilling starts immediately after the system disk is created.\nN/A\nSubscription\nAI computing resources (Lingjun resources)\nFor more information, see Billing of AI computing resources.\nFor more information, see Billing of AI computing resources.\nN/A\nPay-by-inference-duration\nService calls\nThe inference duration of the Serverless Edition service.\nYou are billed based on the inference duration of the Serverless Edition service.\nIf you do not use the service to perform inference, you are not charged.\nPay-as-you-go\nDedicated gateway\nThe number and usage duration of gateway nodes.\nYou are billed based on the number of gateway nodes you purchase and the usage duration of the nodes.\nDelete dedicated gateways.\nSubscription\nThe number and purchase duration of gateway nodes\nYou are billed based on the number of gateway nodes you purchase and the usage duration of the nodes.\nN/A\nThe public resource group supports only the pay-as-you-go billing method. When you deploy a model service in the public resource group, you can select an instance type that has predefined resources or specify resources based on your business requirements.Dedicated resource group (pay-as-you-go)\nResource type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nSpecified resources\nBill amount for each model service = Number of nodes \u00d7 [Number of vCPUs \u00d7 (Unit price of vCPUs/60) + Memory size \u00d7 (Unit price of memory/60)] \u00d7 Usage duration (minutes)\nFor the unit prices per hour of vCPUs and memory, see Table 1. Pricing for specified resources in this topic. Fees are billed per minute. You can calculate the unit prices per minute by dividing the prices listed in Table 1 by 60.\nBilling starts when a model service starts to run and consume resources.\nBilling ends when a model service stops running and releases resources.\nIf you scale out a model service, you are charged for new resources after the scale-out activity is complete.\nIf you scale in a model service, the released resources are no longer billed. You are charged only for the remaining resources.\nThe usage duration is measured in minutes.\nTo prevent unnecessary costs, we recommend that you stop model services that you no longer use.\nSpecified instance type\nBill amount for each model service = Number of nodes \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nUnit prices may vary based on the instance type and the region. To view the unit prices of nodes, go to the EAS page in the PAI console, click Deploy Service, and then click Custom Deployment. In the Resource Deployment Information section, set the Resource Group Type parameter to Public Resource Group and select the instance type that you want to use. The unit price of the instance is displayed. For more information, see Model service deployment by using the PAI console.\nFor information about the instance types supported by the public resource group, see Appendix: Public resource group instance types.\nBilling starts when a model service starts to run and consume resources.\nBilling ends when a model service stops running and releases resources.\nN/A\nThe usage duration is measured in minutes.\nTo prevent unnecessary costs, we recommend that you stop model services that you no longer use.\nSpecific resources may be unavailable in specific regions for a short period of time.\nTable 1. Resource-based configuration\nThe unit prices listed in the following table are only for reference. You can view the actual prices in the console or on the buy page of the service resource that you want to purchase.\nResource\nUnit price\nvCPU\nUSD 0.03 per vCPU-hour\nMemory\nUSD 0.004 per GB-hour\nEAS resources support the pay-as-you-go billing method.\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated resource group\nBill amount for each resource group = Number of nodes \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nFor information about the unit prices of pay-as-you-go nodes, go to the EAS post-payment for dedicated machine buy page.\nBilling starts immediately after a node is created in a dedicated resource group and enters the Running state.\nBilling ends when all resources in a dedicated resource group are released.\nIf you scale out a model service, you are charged for new resources after the scale-out activity is complete.\nIf you scale in a model service, the released resources are no longer billed. You are charged only for the remaining resources.\nThe usage duration is measured in minutes.\nSpecific instance types may become unavailable for short periods of time in specific regions. In this case, you can purchase instances in different regions.\nEAS resources also support the subscription billing method.\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated resource group\nBill amount for each resource group = Number of nodes \u00d7 Unit price \u00d7 Subscription duration (months)\nFor information about the unit prices of subscription nodes, go to the EAS pre-payment for dedicated machine buy page.\nBilling starts at 00:00:00 the next day after the purchase.\nBilling ends when the subscription expires.\nN/A\nSpecific instance types may become unavailable for short periods of time in specific regions. In this case, you can purchase instances in different regions.\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nSystem disk\nBill amount = Number of nodes \u00d7 System disk capacity (GiB) \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nTo view the unit prices of system disks, go to the product overview page of Elastic Compute Service (ECS), click the Pricing tab, and then click Storage. The pricing information of Enhanced SSD PL1 is displayed in the System Cloud Disk Fee section.\nBilling starts immediately after a system disk is created.\nBilling ends when nodes are deleted from dedicated resource groups or when model services deployed in the public resource group are deleted.\nN/A\nN/A\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nSystem disk\nBill amount = Number of nodes \u00d7 System disk capacity (GiB) \u00d7 Unit price \u00d7 Subscription duration (months)\nTo view the unit prices of system disks, go to the product overview page of ECS, click the Pricing tab, and then click Storage. The pricing information of Enhanced SSD PL1 is displayed in the System Cloud Disk Fee section.\nBilling starts immediately after a system disk is created.\nBilling ends when the subscription expires.\nN/A\nNone\nLingjun resources support the subscription billing method. You can deploy model services in EAS by using Lingjun resource quotas. For more information, see Billing of AI computing resources.\nThe deployment of Serverless Edition services is free of charge. You are charged only if you call the services based on the inference duration. For example, if you click Generate on the web UI page to generate an image and the process requires 10 seconds, the billing duration is 10 seconds.\nTo view the pricing details, go to the Deploy Service page in the PAI console, click AI Painting - SD Web UI Deployment in the Scenario-based Deployment section, and then select Serverless Edition. The pricing information is displayed in the Total Configuration Fee section. For more information, see Use SD web UI to deploy an AI painting service.\nResource type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated gateway\nBill amount = (Unit price/60) \u00d7 Number of gateway nodes \u00d7 Usage duration (minutes)\nTo view the unit prices of dedicated gateways, go to the EAS Dedicated Gateway Postpay buy page.\nBilling starts immediately after a dedicated gateway is purchased.\nBilling ends when the dedicated gateway is deleted.\nN/A\nN/A\nResource type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated gateway\nBill amount = Unit price \u00d7 Number of gateway nodes \u00d7 Usage duration (months)\nTo view the unit prices of dedicated gateways, go to the EAS Dedicated Gateway Prepay buy page.\nBilling starts immediately after a dedicated gateway is purchased.\nBilling ends when the dedicated gateway expires.\nN/A\nN/A\n\nThe following examples are for reference only. The actual prices listed on the EAS buy page of the PAI console shall prevail.\nScenario\nYou used the public resource group to deploy a model service in the China (Hangzhou) region. You specified the public resources used for model deployment based on your business requirements.\nThe model service occupied 2 vCPUs and 8 GB of memory and started to run at 09:00:00 (UTC+8) on June 3, 2019.\nYou scaled in the model service and reduced the occupied resources to 1 vCPU and 4 GB of memory at 10:00:00 (UTC+8) on June 3, 2019.\nYou scaled out the model service and increased the occupied resources to 4 vCPUs and 16 GB of memory at 11:00:00 (UTC+8) on June 3, 2019.\nThe model service stopped running at 12:00:00 (UTC+8) on June 3, 2019.\nFee calculation\nScenario\nYou subscribed to two NVIDIA T4 GPUs in the China (Hangzhou) region for three months. Each GPU provides 4 vCPUs and 15 GB of memory. The unit price of the GPU is USD 570 per month.\nFee calculation\nScenario\nYou purchased two pay-as-you-go ecs.g6.6xlarge instances in the China (Hangzhou) region and used the instances for 45 minutes. Each instance provides 24 vCPUs and 96 GB of memory. The unit price of the instance is USD 1.02 per hour.\nFee calculation\nScenario\nYou purchased two subscription instances in the China (Hangzhou) region for a dedicated resource group. Each instance provides a system disk capacity of 300 GiB (free storage: 200 GiB). The subscription duration is three months.\nFee calculation\nDedicated resource group\nScenario\nYou purchased two pay-as-you-go instances in the China (Hangzhou) region for a dedicated resource group and used them for 5 hours. Each instance provides a system disk capacity of 300 GiB (free storage: 200 GiB).\nFee calculation\nPublic resource group\nScenario\nYou purchased two pay-as-you-go instances in the public resource group and deployed them in the China (Hangzhou) region. You used the instances for 5 hours. Each instance provides a system disk capacity of 300 GiB (free storage: 30 GiB).\nFee calculation\nThe following table lists some of the instance types that can be used to deploy EAS services in the public resource group. For a complete list of supported instance types, go to the EAS page in the PAI console, click Deploy Service, and then click Custom Deployment. In the Resource Deployment Information section, you can view the supported instance types. For more information, see Model service deployment by using the PAI console. The supported instance types may vary based on the region.\nInstance type\nvCPU\nMemory (GiB)\necs.c7.large\n2\n4\necs.c7.xlarge\n4\n8\necs.c7.2xlarge\n8\n16\necs.c7.4xlarge\n16\n32\necs.c7.6xlarge\n24\n48\necs.c7.8xlarge\n32\n64\necs.c7.16xlarge\n64\n128\necs.r7.4xlarge\n16\n128\necs.r7.large\n2\n16\necs.r7.xlarge\n4\n32\necs.r7.2xlarge\n8\n64\necs.r7.6xlarge\n24\n192\necs.r7.8xlarge\n32\n256\necs.r7.16xlarge\n64\n512\necs.g7.large\n2\n8\necs.g7.xlarge\n4\n16\necs.g7.2xlarge\n8\n32\necs.g7.4xlarge\n16\n64\necs.g7.6xlarge\n24\n96\necs.g7.8xlarge\n32\n128\necs.g7.16xlarge\n64\n256\necs.g6.large\n2\n8\necs.g6.xlarge\n4\n16\necs.g6.2xlarge\n8\n32\necs.g6.4xlarge\n16\n64\necs.g6.6xlarge\n24\n96\necs.g6.8xlarge\n32\n128\necs.c6.large\n2\n4\necs.c6.xlarge\n4\n8\necs.c6.2xlarge\n8\n16\necs.c6.4xlarge\n16\n32\necs.c6.6xlarge\n24\n48\necs.c6.8xlarge\n32\n64\necs.r6.large\n2\n16\necs.r6.xlarge\n4\n32\necs.r6.2xlarge\n8\n64\necs.r6.4xlarge\n16\n128\necs.r6.6xlarge\n24\n192\necs.r6.8xlarge\n32\n256\necs.g5.6xlarge\n24\n96\necs.c5.6xlarge\n24\n48\necs.g8y.large\n2\n8\necs.g8y.xlarge\n4\n16\necs.g8y.2xlarge\n8\n32\necs.g8y.4xlarge\n16\n64\necs.g8y.8xlarge\n32\n128\necs.g8y.16xlarge\n64\n256\necs.c7a.large\n2\n4\necs.c7a.xlarge\n4\n8\necs.c7a.2xlarge\n8\n16\necs.c7a.4xlarge\n16\n32\necs.c7a.8xlarge\n32\n64\necs.c7a.16xlarge\n64\n128\necs.g7a.large\n2\n8\necs.g7a.xlarge\n4\n16\necs.g7a.2xlarge\n8\n32\necs.g7a.4xlarge\n16\n64\necs.g7a.8xlarge\n32\n128\necs.g7a.16xlarge\n64\n256\nInstance type\nvCPU\nMemory (GiB)\nGPU memory\nml.gu7i.c8m30.1-gu30\n8\n30\n1 * 24 GB\nml.gu7i.c16m60.1-gu30\n16\n60\n1 * 24 GB\nml.gu7i.c32m188.1-gu30\n32\n188\n1 * 24 GB\nml.gu7i.c64m376.2-gu30\n64\n376\n2 * 24 GB\nml.gu7i.c128m752.4-gu30\n80\n256\n4 * 24 GB\necs.gn5i-c4g1.xlarge\n4\n16\n1 * 8 GB\necs.gn5i-c8g1.2xlarge\n8\n32\n1 * 8 GB\necs.gn5-c4g1.xlarge\n4\n30\n1 * 16 GB\necs.gn5-c8g1.2xlarge\n8\n60\n1 * 16 GB\necs.gn5-c8g1.4xlarge\n16\n120\n2 * 16 GB\necs.gn5-c28g1.7xlarge\n28\n112\n1 * 16 GB\necs.vgn6i-m4-vws.xlarge\n4\n23\n1 * 4 GB\necs.vgn6i-m8-vws.2xlarge\n10\n46\n1 * 8 GB\necs.gn6i-c4g1.xlarge\n4\n15\n1 * 16 GB\necs.gn6i-c8g1.2xlarge\n8\n31\n1 * 16 GB\necs.gn6i-c16g1.4xlarge\n16\n62\n1 * 16 GB\necs.gn6i-c24g1.6xlarge\n24\n93\n1 * 16 GB\necs.gn6i-c24g1.12xlarge\n48\n186\n2 * 16 GB\necs.gn6i-c24g1.24xlarge\n96\n372\n4 * 16 GB\necs.gn7i-c8g1.2xlarge\n8\n30\n1 * 24 GB\necs.gn7i-c16g1.4xlarge\n16\n60\n1 * 24 GB\necs.gn7i-c32g1.8xlarge\n32\n188\n1 * 24 GB\necs.gn7i-c32g1.16xlarge\n64\n376\n2 * 24 GB\necs.gn7i-c32g1.32xlarge\n128\n752\n4 * 24 GB\necs.gn6v-c8g1.2xlarge\n8\n32\n1 * 16 GB\necs.gn6v-c8g1.4xlarge\n16\n64\n2 * 16 GB\necs.gn6v-c8g1.8xlarge\n32\n128\n4 * 16 GB\necs.gn6e-c12g1.3xlarge\n12\n92\n1 * 32 GB\necs.gn6e-c12g1.12xlarge\n48\n368\n4 * 32 GB\necs.gn6e-c12g1.24xlarge\n96\n736\n8 * 32 GB\necs.gn7-c12g1.3xlarge\n12\n94\n1 * 40 GB\necs.gn7-c13g1.13xlarge\n52\n378\n4 * 40 GB\necs.gn7-c13g1.26xlarge\n104\n756\n8 * 40 GB\necs.gn7-c13g1.6xlarge\n26\n189\n2 * 40 GB\necs.gn7e-c16g1.4xlarge\n16\n125\n1 * 80 GB\necs.gn7e-c16g1.8xlarge\n32\n250\n2 * 80 GB\necs.gn7e-c16g1.16xlarge\n64\n500\n4 * 80 GB\necs.gn7e-c16g1.32xlarge\n128\n1000\n8 * 80 GB"
    },
    "470": {
        "title": "Platform For AI:Billing of Dataset Accelerator",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-dataset-accelerator",
        "content": "This Product\nPlatform For AI:Billing of Dataset Accelerator\nThis topic describes the billing rules of Dataset Accelerator of Platform for AI (PAI).\nThe following figure shows how Dataset Accelerator is billed.\nThe following table describes the billing methods of Dataset Accelerator.\nBilling method\nBillable resource\nBillable item\nBilling rule\nStop billing\nSubscription\nAccelerator capacity\nPurchased capacity and duration\nYou are charged based on the purchased capacity and duration of the accelerator.\nN/A\nDataset Accelerator supports only the subscription billing method. The following table describes the billing details.\nInstance type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nCapacity\nBill amount = Unit price of capacity \u00d7 Capacity (GB) \u00d7 Duration (months)\nFor more information about the capacity pricing, visit the AI Dataset Accelerator (Subscription) page.\nBilling start time: 00:00:00 the next day after the purchase.\nBilling end time: the time when the model releases its resources.\nCapacity scale-out: You can upgrade the existing accelerators. The expanded capacity takes effect upon purchase. The expanded capacity expires at the same time that the subscription accelerator expires.\nCapacity scale-in: N/A.\nN/A\nThe following billing examples are only for reference. Refer to the console or buy page of the service that you want to purchase for the actual fees.\nScenario\nYou purchase accelerators whose capacity is 500 GB for 2 months in the Singapore region.\nFee calculation"
    },
    "471": {
        "title": "Platform For AI:Scenario-based solution billing description",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-of-scenario-based-solutions/",
        "content": "This Product\nPlatform For AI:Scenario-based solution billing description"
    },
    "472": {
        "title": "Platform For AI:View billing details",
        "url": "https://www.alibabacloud.com/help/en/pai/view-bills-and-usage-details",
        "content": "This Product\nPlatform For AI:View billing details\nTo view the billing details of Platform for AI (PAI), go to the Expenses and Costs page.\n\n\nIf you use a Resource Access Management (RAM) user to access the Expenses and Costs page, you must grant the AliyunBSSFullAccess permissions to the RAM user by using your Alibaba Cloud account. For more information about how to grant permissions to a RAM user, see Authorize a RAM user.\nThe billing details are updated the next day after they are generated.\nTo export usage details, on the Usage Records tab, set the product parameter to learn. Valid values of the Billable Item parameter:\nMachine Learning Designer: PAI_ALGO\nData Science Workshop (DSW): PAI_DSW_PAY_FULLY_MANAGED\nElastic Algorithm Service (EAS): PAI_EAS\nThe pay-as-you-go bills generated by Deep Learning Containers (DLC) are categorized by instance tags into spot jobs and regular pay-as-you-go jobs.\nSpot: The instance tag is key:acs:pai:dlc:payType value:spot.\nPay-as-you-go: The instance tag is key:acs:pai:dlc:payType value:postpaid.\nYou can use the tags to query the bills. Take spot jobs as an example:\nActivate the acs:pai:dlc:payType tag.\nLog on to the Expenses and Costs console.\nIn the left-side navigation pane, choose .\nEnter acs:pai:dlc:payType in the Tag Key text box and click Search.\nClick Enable in the Operations column of  acs:pai:dlc:payType.\nIn the left-side navigation pane, choose Bills > Bill Details.\nOn the Billing Details tab, examine the spot job bills.\nView a single spot job:\nClick Instance Name and switch to Instance ID. Enter the job ID and click Search.\nView spot jobs in batch:\nSelect DLC (Pay-As-You-Go) International Site for Product Details.\nClick Customize Column Options. In the dialog box that appears, select Instance Tag and click OK.\nClick Export Billing Overview (CSV).\nIn the Export Billing Overview CSV dialog box, select an Export Content and click OK.\nIn the exported CSV, find spot job bills using the tag key:acs:pai:dlc:payType value:spot."
    },
    "473": {
        "title": "Platform For AI:Overdue payments",
        "url": "https://www.alibabacloud.com/help/en/pai/overdue-payments",
        "content": "This Product\nPlatform For AI:Overdue payments\nThis topic describes the consequences of overdue payments for PAI-AI computing resource groups, EAS, Designer, Dataset Accelerator, and scenario-based solutions modules.\nAn overdue payment occurs if your Alibaba Cloud account lacks sufficient funds, including the account balance and vouchers, to cover a payment.\nIf computing power nodes in an AI computing resource group expire or are not renewed, the associated features become unavailable.\nRenewing the nodes within one calendar day (24 hours) after the expiration date will automatically restore the related features.\nFailing to renew the nodes within one calendar day (24 hours) after the expiration date results in the release of resources. After 24 hours, related tasks are stopped, and operations cannot be continued.\nVisit the Billing and Cost home page to check the amount due.\n\n\nYour account balance is insufficient.\nSubscription nodes: The account balance is inadequate for subscription fees.\nPay-as-you-go nodes, including public resource groups and pay-as-you-go nodes in dedicated resource groups: The account balance is below the bill amount of the previous billing cycle. An overdue payment occurs if the payment fails.\nSubscription nodes\nExpired or unrenewed nodes are released, ceasing service provision and causing EAS services using those nodes to enter a waiting state.\nNodes are automatically recovered if renewed within 15 calendar days (360 hours) after expiration. If not renewed within this period, they are permanently deleted.\nIf the node is not renewed within 15 calendar days (360 hours) following its expiration date, it will be permanently deleted.\nPay-as-you-go resource groups (including public resource groups and pay-as-you-go nodes in resource groups)\nResource groups stay available if overdue payments are settled within 24 hours. Otherwise, public resource groups stop, and pay-as-you-go nodes are released, entering a stopped state along with the EAS services using them.\nSettling overdue payments within 15 calendar days (360 hours) results in the recovery of resource groups and retention of data. If not settled within this period, stopped nodes are permanently deleted.\nVisit the Billing and Cost home page to check the amount due.\n\n\nYour account balance is insufficient:\nSubscription: The account balance is inadequate for renewal orders.\nPay-as-you-go: The account balance falls short of the previous billing cycle's bill. An overdue payment occurs if fee deduction fails.\nThe Dataset Accelerator only supports the subscription billing method.\nIn PAI, bills are generated within 4 hours after the billing cycle ends, using the T + 1 settlement method. Overdue payment notifications are sent via text messages.\nPAI resources remain accessible for 24 hours post-notification. After this period, services are suspended, and related features become inaccessible.\nVisit the Billing and Cost home page to check the amount due.\n\n\nYour account balance is insufficient:\nSubscription: The account balance is inadequate for subscription fees.\nPay-as-you-go: The account balance is below the bill amount of the previous billing cycle. An overdue payment occurs if the payment fails.\nDSW bills are generated hourly and are typically received 2 to 3 hours after usage.\nAn immediate stop of the DSW instance occurs if an overdue payment is detected, accompanied by a text message notification.\nDSW instances are automatically released after 7 days of overdue payment. To prevent business disruption, timely renewal is advised. For more information, see renewal.\nVisit the Billing and Cost home page to check the amount due.\n\n\nYour account balance is insufficient:\nSubscription: The account balance is inadequate for renewal orders.\nPay-as-you-go: The account balance falls short of the previous billing cycle's bill. An overdue payment occurs if fee deduction fails.\nIn PAI, bills are generated within 4 hours after the billing cycle ends, using the T + 1 settlement method. Overdue payment notifications are sent via text messages.\nPAI resources remain accessible for 24 hours post-notification. After this period, services are suspended, and algorithm detection services become inaccessible.\nVisit the Billing and Cost home page to check the amount due.\n\n\nAn overdue payment occurs if your Alibaba Cloud account lacks sufficient funds, including the account balance and vouchers, to cover a payment:\nSubscription: The account balance is inadequate for renewal orders.\nPay-as-you-go: The account balance is below the bill amount of the previous billing cycle, which is one month long.\nIn PAI, bills are generated within 4 hours after the billing cycle ends, using the T + 1 settlement method. Overdue payment notifications are sent via text messages.\nServices related to PAI become inaccessible if your account is overdue.\nVisit the Billing and Cost home page to check the amount due.\n\n"
    },
    "474": {
        "title": "Platform For AI:Renewal policy",
        "url": "https://www.alibabacloud.com/help/en/pai/renewal-description",
        "content": "This Product\nPlatform For AI:Renewal policy\nThis topic describes how to renew Data Science Workshop (DSW), Deep Learning Containers (DLC), Elastic Algorithm Service (EAS), Dataset Accelerator, and scenario-based solutions in Platform for AI (PAI).\nAuto-renewal\nTo enable auto-renewal, select Auto-renewal when you purchase subscription computing resources. For more information, see Overview.\nManual renewal\nIn the resource list of a dedicated resource group, find the resource that you want to renew and click Renew in the Actions column to renew the resource. For more information, see Manage resources.\nSubscription nodes in dedicated resource groups can be automatically renewed upon expiration or manually renewed.\nAuto-renewal\nTo enable auto-renewal, select Auto-renewal when you purchase subscription nodes. For more information, see Work with dedicated resource groups.\nManual renewal\nTo manually renew a subscription node, go to the details page of the dedicated resource group to which the node belongs, find the node, and then click  > Renew in the Actions column. For more information, see Work with dedicated resource groups.\nAuto-renewal\nTo enable auto-renewal, select Auto-renewal when you purchase AI dataset accelerators (subscription).\nManual renewal\nTo manually renew an AI dataset accelerator, go to the Dataset Accelerators page, find the AI dataset accelerator that you want to renew, and then click Renew in the Actions column.\nMultimedia analytics: To use resource plans, click Purchase Resource Plan on the Multimedia Analytics page. For more information, see Overview.\nAI portrait: To use resource plans, click Purchase Resource Plan on the AI Portrait page. For more information, see Overview.\n"
    },
    "475": {
        "title": "Platform For AI:Billing FAQ",
        "url": "https://www.alibabacloud.com/help/en/pai/billing-faq",
        "content": "This Product\nPlatform For AI:Billing FAQ\nThis topic provides answers to some frequently asked questions about billing.\nWhich projects incur fees in PAI?\nHow do I stop a project that is being billed?\nHow do I query deductions and details?\nAre fees still incurred after stopping DSW instances/EAS services?\nAre additional fees incurred when using EAS trial resources?\nWhy are fees deducted after I stop a billable project?\nAre additional fees incurred when using DSW resource deduction packages?\nDesigner/Studio workflows currently in execution will incur charges for the use of algorithm widgets.\nDSW instances in use consume computing resources and generate charges. To avoid incurring unnecessary expenses, we recommend stopping any instances that are no longer needed.\nIf you expanded your system disk after you stop the instance, the expanded capacity continues to generate storage fees. If you want to stop all billing related to the DSW instance, delete the instance. Before you delete the instance, make sure that you back up all required data.\nDLC tasks running in public resource groups are subject to charges, whereas tasks in dedicated resource groups are not, as these groups are prepaid at the time of purchase.\nEAS services in public resource groups are billed regardless of invocation. Pay-as-you-go dedicated resource groups incur charges, while subscription dedicated resource groups do not, as they are prepaid.\nThe billing rules are straightforward. For more information, see EAS billing description.\nWhen a pay-as-you-go dedicated resource group is in Running state, billing occurs.\nScaling in or out a dedicated resource group in the Running state triggers an intermediate state, either Scaling out or Scaling in. Fees are also incurred for resources used during this intermediate state.\nWhen a service in a public resource group is in the Running state, billing occurs.\nScaling out a deployed service leads to a Pending intermediate state. Resources used during this state are billed as well.\nSystem disk fees.\nIf you add a system disk when you deploy an EAS service by using a public resource group, charges for the system disk will continue even after you stop the service. To stop these charges, you must delete the service. Make sure you no longer require the service before you delete it.\nIf you add a system disk when you purchase a dedicated resource group instance, the system disk is not billed only after you delete the pay-as-you-go resource group instance or the subscription resource group instance expires. Before you delete the resource group instance, make sure that you no longer use it.\nCease billing for Designer/Studio visual modeling projects.\nLog on to the PAI console. At the top of the page, choose the desired destination region. On the right, select your target workspace. Then click  Enter Designer.\nOn the Visual Modeling (designer) page, you can double-click the workflow name to access the workflow page.\nOn the canvas, click the  button to stop the running workflow.\nStop DSW instances.\nIf a DSW instance is created by using a dedicated resource group and no datasets are mounted to the instance, the system disk of the DSW instance is used for temporary storage. If you stop or delete the DSW instance, data cannot be restored. Proceed with caution.\nIf a DSW instance is created by using a public resource group, the environment is saved on the free disk mounted to the instance after you stop the instance. If you do not restart the instance within 15 days after the instance is suspended, the disk is released.\nIf you resize a system disk when you create a DSW instance, you are still charged for the system disk even if the instance is stopped. If you want to stop all billing related to the DSW instance, delete the DSW instance. Make sure that the required data is backed up before you delete the instance.\nWe recommend that you create DSW instances in workspaces. This helps prevent unnecessary costs that are incurred when you cannot stop your DSW instances due to misconfiguration.\nLog on to the PAI console. At the top of the page, choose the destination region. On the right, select your desired workspace. Then click  Enter DSW.\nOn the Interactive Modeling (DSW) page, click  Stop in the  Actions column for the desired instance.\nAfter stopping the instance, its Status will show as Stopped. At this point, billing ceases for pay-as-you-go instances. To prevent incurring unnecessary charges, ensure that your instance is in the Stopped state before exiting DSW.\nStop billing for online model services (EAS):\nMake sure that the projects you stop are no longer needed to avoid unnecessary business losses.\nStop services that run in pay-as-you-go dedicated resource groups.\nTo stop billing, reduce the number of servers in the dedicated resource group to 0. Use the following methods:\nLog on to the PAI console. Select a region on the top of the page. Then, select the desired workspace and click Enter Elastic Algorithm Service (EAS).\nOn the Online Model Services (EAS) page, click the name of the desired resource group under the Resource Groups tab to access the details page for that resource group.\nOn the Machine List tab, you can click Delete in the Actions column next to the pay-as-you-go machine to remove it and cease billing.\nStop services that run in public resource groups:\nOn the Online Model Services (EAS) page, you can click  Stop in the  Actions column next to the service you want to stop on the  Inference Services tab. This action will halt the model service and its associated billing.\nIf you added a system disk when you deployed the EAS service, you are still charged for the system disk even if the service is stopped. If you want to stop all billing related to the EAS service, delete the EAS service.  Before you delete the service, make sure that it is no longer used to avoid unnecessary business losses.\nStop pay-as-you-go billing for EAS dedicated gateways\nOn the Online Model Services (EAS) page, you can click  Delete in the  Actions column for the pay-as-you-go dedicated gateway listed under the  Dedicated Gateways tab.\nUnsubscribe from AI computing resource groups (subscription), EAS dedicated gateway subscription, and EAS dedicated machine subscription\nMake sure that the resources you unsubscribe from are no longer needed to avoid unnecessary business losses.\nLog on to the Billing and Cost Management console.\nIn the left-side navigation pane, select  > Unsubscription Management.\nChoose the appropriate unsubscription type for your needs. For Product Name, select either  International Site_ai Computing Resource Group_subscription,  EAS Dedicated Gateway Subscription, or  EAS Dedicated Machine Subscription. Then, follow the on-screen instructions to finalize the unsubscription.\nOn the  Billing Details  page, you can use filters to view detailed billing information for machine learning services. For more information, see View Billing Details. The  Product Details  column shows the specific sub-product module that generated the charges. The values in this column have the following meanings:\nEAS Dedicated Machine Pay-as-you-go: This refers to the fees incurred by the dedicated resource group on a pay-as-you-go basis within EAS.\nMachine Learning (PAI): Charges for this service encompass the use of MaxCompute computing resources for training within Designer/Studio. To understand the specific fees, refer to the Billable Items. The details of these charges are outlined below.\nProduct Details\nBillable items\nInstance ID\nExpense source\nMachine Learning (PAI)\nUsage\ntext_analysis\ndata_analysis\ndata_manipulation\ndeep_learning\ndefault\nFees generated by Designer/Studio experiment training.\nEAS Dedicated Machine Subscription: This refers to the fees incurred by the dedicated resource group under the EAS subscription.\n\nDSW instances: If you expanded your system disk when you created the DSW instance, you are still charged for the system disk regardless of whether the instance is running. If you want to stop all billing related to the DSW instance, delete the DSW instance.  Before you delete the instance, make sure that you back up all required data.\nEAS services: Not using EAS services in the conventional sense does not mean that the service is not running in the background (which still consumes resources and incurs fees). Therefore, if you are sure that you do not need EAS services, we recommend that you manually stop or delete the EAS service.  When you delete the service, make sure that you back up all required data.\nBilling reason: When deploying stable-diffusion-webui or comfyui in EAS, if the selected image version includes -api or -cluster, these two versions occupy resources in an asynchronous queue during deployment. These resources are chargeable and cannot be offset by EAS trial resources.\nSolution: When deploying stable-diffusion-webui or comfyui, select the standard version, which is the image version with -standard or no suffix.\nFees are not immediately deducted after you stop a project. Instead, fees are deducted after a bill is generated for the project. A delay exists between the time when the bill is generated and the time when you stop the project. For example, fees incurred by resource usage between 10:00 and 11:00 may be billed and deducted several hours later. Therefore, even if you perform the stop operation at 11:00, you may still receive a deduction notification several hours later, creating the illusion of overcharging. Only the actual fees generated by the project are deducted.\nBilling reason: If you purchase and use DSW resource deduction packages but still incur additional fees, it may be because the resource package expired while the DSW instance was still running. Additionally, fees are not immediately deducted after you stop a project. Instead, fees are deducted after a bill is generated for the project, which may take several hours. Therefore, pay-as-you-go fees are incurred.\nSolution:\nYou can visit the Billing and Cost Management console on the Resource Instance Management page to verify the expiration date of your purchased DSW resource deduction package and ensure you purchase a new package as needed.\nWe recommend that you reserve a certain amount of money for your Alibaba Cloud account to avoid overdue payments caused by the expiration of the resource package when the bill is generated, which may affect service usage."
    },
    "476": {
        "title": "Platform For AI:Get started with PAI",
        "url": "https://www.alibabacloud.com/help/en/pai/getting-started/getting-started",
        "content": "This Product\nPlatform For AI:Get started with PAI\nThis topic aims to help you quickly get familiar with and use Platform for AI (PAI). You can understand the key modules and common use scenarios of PAI and the billing methods of the modules. You can also get familiar with the common use cases of PAI and gain valuable operational experience.\nPAI is a machine learning and deep learning engineering platform for developers and enterprises. PAI offers end-to-end Artificial Intelligence (AI) development services, including data labeling, model development, model training, model deployment, and inference optimization. In addition, PAI provides more than 140 built-in optimization algorithms and a variety of plug-ins for AI-empowered industries to implement easy-to-use and high-performance cloud-native AI engineering capabilities.\nWhat is PAI?\nTerms\nFeatures\nBilling\nThe terms related to the following basic modules help you understand the core features and use scenarios of PAI.\niTAG\nElastic Algorithm Service (EAS)\nMachine Learning Designer\nData Science Workshop (DSW)\nDeep Learning Containers (DLC)\nMore terms\nScenario description:\nArtistic creation: Use AI to generate high-quality digital artworks, which is suitable for scenarios such as illustration and concept art.\nAdvertising design: Quickly generate creative advertising images to improve design efficiency.\nGame development: Provide rich visual materials for games to improve the diversity of game graphics.\nEducation and training: Use AI painting as a visual aid in teaching and training to enhance the learning experience.\nRelated model: Stable Diffusion\nInvolved modules in PAI: DSW and EAS\nReferences:\nUse Stable Diffusion web UI to deploy an AI painting service\nScenario description:\nContent generation: Automatically generate high-quality articles, reports, and marketing copies to improve content creation efficiency.\nData analytics: Intelligently analyze and interpret complex data to generate easy-to-understand analysis reports.\nCustomer service chat: Provide intelligent customer service conversations to improve the response speed and customer satisfaction.\nEducational tutoring: Help online education platforms to generate teaching content and answer questions.\nRelated models: Qwen, Llama, Baichuan series, and other models\nInvolved modules in PAI: DSW and EAS\nReferences:\nQuickly deploy open source LLMs in EAS\nFine-tune a Llama3-8B model\nScenario description:\nCustomer service system: Improve the intelligence and response speed of customer service conversations to improve customer satisfaction.\nIntelligent assistant: Provide users with accurate question answering services to enhance user experience.\nEducational tutoring: Help online education platforms to provide students with instant question answering support.\nMedical consultation: Provide initial medical consultation services for patients to reduce the workloads of doctors.\nRelated models: Qwen, Llama, Baichuan series, and other models\nInvolved module in PAI: EAS\nReferences:\nUse EAS and Elasticsearch to deploy an RAG-based LLM chatbot\nRAG-based LLM chatbot\nScenario description:\nMarketing video: Automatically generate creative marketing videos to improve brand promotion effectiveness.\nEducational videos: Quickly generate educational videos to improve the production efficiency of educational resources.\nEntertainment content: Generate short videos, animations, and other entertainment content to enrich social media platforms.\nEnterprise training: Produce internal training videos to reduce production costs and improve training effectiveness.\nRelated model: Stable Video Diffusion\nInvolved module in PAI: EAS\nReferences:\nAI Video Generation: ComfyUI-based Deployment\nScenario description:\nData cleansing: Ensure data uniqueness by using the LLM-MD5 Deduplicator, LLM-Document Deduplicator, and LLM-N-Gram Repetition Filter components.\nContent standardization: Improve data consistency by using the LLM-Text Normalizer, LLM-Special Characters Ratio Filter, and LLM-Length Filter components.\nSensitive information processing: Protect privacy and copyright by using the LLM-Sensitive Keywords Filter, LLM-Sensitive Content Mask, and LLM-Clean Copyright Information components.\nLanguage processing: Ensure that data meets specific language requirements by using the LLM-Language Recognition and Filter component.\nLaTeX processing: Simplify LaTeX documentations by using the LLM-LaTeX Expand Macro, LLM-LaTeX Remove Bibliography, LLM-LaTeX Remove Comments, and LLM-LaTeX Remove Header components.\nRelated algorithms: LLM data processing algorithms\nInvolved module in PAI: Machine Learning Designer\nReferences:\nData processing for LLM (web text data from Wikipedia)\nLLM data processing (MaxCompute)\nE2E Development and Usage of LLM: Data Processing + Model Training + Model Inference\nScenario description:\nContent moderation: Ensure that uploaded images comply with platform specifications by using the LVM-Image-NSFW Filter (DLC) and LVM-Image-Watermark Filter (DLC) components.\nImage optimization: Improve image quality by using the LVM-Image-Aesthetic Filter (DLC), LVM-Image-Aspect-Ratio Filter (DLC), and LVM-Image-Shape Filter (DLC) components.\nAutomatic description: Automatically generate a description for an image by using the LVM-Image-Caption Mapper (DLC) component. This helps you understand and search for an image.\nContent recommendation: Optimize recommendation systems and improve user experience by using the LVM-Image-Text-Matching Filter (DLC) and LVM-Image-Text-Similarity Filter (DLC) components.\nAdvertisement filtering: Filter images that are suitable for advertising by using the LVM-Image-Face-Ratio Filter (DLC) and LVM-Image-Size Filter (DLC) components.\nRelated algorithms: LVM image preprocessing algorithms\nInvolved module in PAI: Machine Learning Designer\nReferences:\nImage preprocessing operators\nScenario description:\nText classification: Automatically classify large volumes of text data, which is suitable for news classification and spam email detection.\nSentiment analysis: Identify emotional tendencies in user comments and social media content to help enterprises collect user feedback.\nEntity recognition: Extract entity information, such as the name of a person, name of a place, and name of an organization, from text for information extraction and knowledge graph construction.\nImage labeling: Add labels to images for image classification, object detection, and image searching.\nSpeech recognition: Add labels to, separate, or recognize audio content. This is suitable for voice assistants and customer service systems.\nVideo analytics: Add labels to video content for content sharing and moderation.\nInvolved module in PAI: iTAG\nReferences:\niTAG\nScenario description:\nImage recognition and processing: In computer vision scenarios, a large number of high-resolution images need to be processed when you train deep convolutional neural network (CNN) models. Distributed training can accelerate model training.\nNatural language processing (NLP): Large-scale text data and complex model structures need to be processed for NLP tasks, such as language translation, text generation, and sentiment analytics. Distributed training can effectively handle the preceding tasks and improve the training speed and accuracy of models.\nRecommendation system: Large amounts of user behavior data and diversified commodity information need to be processed for recommendation systems. Distributed training can accelerate the iteration and optimization of models, which improves the accuracy and timeliness of recommendations.\nInvolved module in PAI: DLC\nReferences:\nSubmit a standalone training job that uses PyTorch\nMore use scenarios\nQuickStart integrates various high-quality pre-trained models in open source AI communities. You can quickly get started with model-related operations, such as fine-tuning, deploying, and evaluating models.\nDeploy and train models\nModel evaluation\niTAG allows you to label different types of data, such as images, text, videos, and audios, or multimodal data. iTAG provides a wide range of labeling content and topic components. You can use common labeling templates that are provided by iTAG or create custom labeling templates based on your business scenarios.\nProcedure\nMachine Learning Designer provides various built-in and proven machine learning algorithms to meet your business requirements in different scenarios, such as product recommendation, financial risk management, and advertising prediction. In addition, Machine Learning Designer provides an end-to-end visualized environment for modeling development.\nDemo for a custom pipeline\nDemo for creating a pipeline by using a template\nComponent reference: Overview of all components\nDSW integrates multiple cloud development environments, such as JupyterLab, WebIDE, and Terminal, for coding, debugging, and job running. DSW provides various heterogeneous computing resources and open source framework images and allows you to mount datasets of the Object Storage Service (OSS), File Storage NAS (NAS), and Cloud Parallel File Storage (CPFS) types. You can manage the lifecycles of DSW instances and use DSW for development in an efficient manner.\nProcedure\nDSW use cases\nDLC provides a flexible, stable, easy-to-use, and high-performance machine learning and training environment. DLC supports multiple algorithm frameworks, including custom algorithm frameworks, and can implement large-scale distributed deep learning jobs. DLC allows you to enjoy an optimal training environment and can improve the training efficiency and reduce costs.\nSubmit training jobs\nDLC use cases\nEAS allows you to deploy models as online inference services or AI-powered web applications. EAS is suitable for multiple AI inference scenarios, such as real-time inference and near-real-time asynchronous inference. EAS supports automatic scaling and has a complete monitoring and maintenance system.\nScenario-based deployment\nMethods for calling services\nEAS use cases\nThe PAI console provides various scenario-based solutions.\nMultimedia analysis\nJudge model\nAI portrait\nArtLab\nMore information about PAI modules\nBilling method\nDescription\nInvolved module\nPay-as-you-go\nIf you use the pay-as-you-go billing method, you are charged based on the actual usage of each module.\nThe pay-as-you-go billing method is suitable for short-term or uncertain workloads. It allows you to pay for resources based on the actual amount of resources that you use. The pay-as-you-go billing method is suitable for test environments, development environments, unexpected requirements, or projects in the early phases.\nMachine Learning Designer, DSW, DLC, and EAS\nSubscription\nThe subscription billing method\nis suitable for long-term and stable workloads. You must pay in advance to use resources for a specific period of time, such as a month or a year. The subscription billing method is more cost-effective than the pay-as-you-go billing method for long-term use.\nDSW, DLC, and EAS\nResource plan\nResource plans refer to quota plans of specific resources that you can purchase in advance.\nResource plans are suitable for scenarios in which you want to use a large number of specific resources. You can purchase quota plans for specific resources at more favorable prices.\nDSW\nSavings plan\nYou can purchase savings plans in advance, which offer specific discounts or benefits.\nSavings plans provide discounted pay-as-you-go rates in exchange for committing to a specific spending amount within a specific period of time.\nDSW and EAS\nPay-by-inference-duration\nYou are charged based on the actual inference duration. The resource specifications support automatic scaling based on the number of service requests.\nThis billing method is suitable for inference tasks that require indefinite quantities and is appropriate for high-concurrent requests and dynamic loads.\nEAS\nMore information about billing\nDeploy and fine-tune a Stable Diffusion 1.5 model\nFine-tune a Llama3-8B model\nDevelop Qwen models in PAI-Lingjun AI Computing Service\nResponsible AI: fairness analysis\nResponsible AI: error analysis\nUse Stable Diffusion web UI to deploy an AI painting service\nUse ComfyUI to deploy an AI video generation model service\nRAG-based LLM chatbot\nQuickly deploy LLMs in EAS\nQuickly deploy Stable Diffusion for text-to-image generation in EAS\nQuickly deploy Tongyi Qianwen in EAS\nData processing for LLM (web text data from Wikipedia)\nData processing for LLM (thesis data from arXiv)\nData processing for LLM (SFT data from Alpaca-CoT)\nVideo data filtering and labeling\nClassify news based on text analysis\nPredict the repayment ability of agricultural loan applicants\nMore use cases\nTo obtain more information and technical support for PAI, scan the following QR code by using DingTalk to join the PAI group.\n\n"
    },
    "477": {
        "title": "Platform For AI:Preparations",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/preparations/",
        "content": "This Product\nPlatform For AI:Preparations"
    },
    "478": {
        "title": "Platform For AI:Workspace",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/workspace-management/",
        "content": "This Product\nPlatform For AI:Workspace"
    },
    "479": {
        "title": "Platform For AI:AI computing resources",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/ai-computing-resource-management/",
        "content": "This Product\nPlatform For AI:AI computing resources\nBefore you use Platform for AI (PAI), we recommend that you activate PAI and purchase resources for AI development and training. To use cloud-native resources, you must purchase the resources, create a resource quota, and associate the resource quota with a workspace. To use big data engine resources, you need only to purchase the resources and associate the resources with a workspace. This topic describes cloud-native resources and big data engine resources.\nCloud-native resources\nLingjun resources\nLingjun resources are computing resources provided by PAI for large-scale deep learning and integrated intelligent computing. Based on a seamless blend of software and hardware enhancements, Lingjun resources deliver the high-performance and heterogeneous computing power that is essential for high-performance computing. Lingjun resources provide core benefits such as high performance, high efficiency, and high resource utilization. You can use Lingjun resources for AI development, training, and inference in PAI.\nGeneral computing resources\nGeneral computing resources, such as Elastic Compute Service (ECS), Elastic Container Instance, and Elastic GPU Service (EGS) resources, provide flexible, stable, easy-to-use, and high-performance environments for training deep learning models. After you activate PAI, the system automatically creates a public quota for general computing resources. You can associate the resource quota with a workspace to use the resources.\nBig data engine resources\nMaxCompute resources\nMaxCompute is an enterprise-level cloud data warehouse that uses the software as a service (SaaS) model. MaxCompute is suitable for scenarios that involve data analytics. It provides a fast, fully managed online data warehousing service. MaxCompute eliminates the constraints of traditional data platforms in terms of resource extensibility and elasticity, minimizes O&M costs, and allows you to efficiently process and analyze large amounts of data at low costs. For more information about MaxCompute resources, see What is MaxCompute?\nFully managed Flink resources\nRealtime Compute for Apache Flink is a one-stop real-time big data analytics platform developed by Alibaba Cloud based on Apache Flink. Realtime Compute for Apache Flink supports end-to-end data analytics within subseconds. For more information, see What is Alibaba Cloud Realtime Compute for Apache Flink?\nLog on to the PAI console. In the left-side navigation pane, choose AI Computing Resources > Resource Pool. On the Resource Pool page, create resource groups of different types and purchase computing resources.\nFor more information about how to purchase and manage general computing resources, see Create and manage general computing resources.\nFor more information about how to purchase and manage Lingjun resources, see Use and manage Lingjun resources.\nLog on to the PAI console. In the left-side navigation pane, choose AI Computing Resources > Resource Quota. On the Resource Quota page, create resource quotas for different types of resources. You can associate the resource quotas with a workspace to perform AI development and training.\nCloud-native resource quotas\nAfter you purchase cloud-native resources on the Resource Pool page in the PAI console, you can allocate the computing resources in one or more resource groups to one or more resource quotas. You can create child-level resource quotas to generate a quota tree that enhances performance in queuing and scheduling.\nFor more information about how to create and use a resource quota for Lingjun resources, see Lingjun resource quotas.\nFor more information about how to create and use a resource quota for general computing resources, see General computing resource quotas.\nBig data resource quotas\nFor more information about how to activate MaxCompute, purchase MaxCompute resources, and create and use a resource quota for MaxCompute resources, see MaxCompute resources.\nFor more information about how to activate Realtime Compute for Apache Flink, purchase fully managed Flink resources, and create and use a resource quota for the resources, see Fully managed Flink resources."
    },
    "480": {
        "title": "Platform For AI:AI development",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/model-training-2/",
        "content": "This Product\nPlatform For AI:AI development"
    },
    "481": {
        "title": "Platform For AI:AI acceleration",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/ai-acceleration/",
        "content": "This Product\nPlatform For AI:AI acceleration\nPlatform for AI (PAI) provides AI accelerators for training acceleration and inference acceleration. AI accelerators can facilitate training and inference, and improve the speed and stability of AI training and inference by using various methods such as dataset acceleration and computing acceleration. You can use AI accelerators to improve the efficiency of AI computing. This topic describes the features of AI accelerators.\nThe following table describes the technical methods and features supported by AI accelerators.\nTechnical method\nFeature\nEPL (large-scale framework for distributed training)\nSupports data parallelism, operator splitting, and pipeline parallelism.\nSupports automatic parallelism for optimal distributed training performance.\nRapidformer (Transformer training acceleration)\nOptimizes the training of PyTorch Transformer models and incorporates multiple optimization technologies to seamlessly integrate with the Transformer model library.\nPAI-Blade (general inference optimization)\nSupports TensorFlow, PyTorch, and mainstream acceleration devices such as GPU, CPU, and end devices.\nSupports multiple optimization technologies, such as graph optimization, vendor-optimized libraries, AI compiler optimization, high-performance operator libraries, mixed precision, and automatic compression.\nProvides easy-to-use, standard SDK for Python for you to implement optimization.\nYou can refer to the following documents to quickly get started with AI accelerators.\nEPL (large-scale framework for distributed training)\nEPL is an efficient and easy-to-use framework for distributed model training. You can use EPL to implement high-performance distributed model training at a low cost. For more information about how to use EPL to accelerate training, see Use EPL to accelerate AI model training.\nRapidformer (Transformer training acceleration)\nRapidformer is a training optimization tool for PyTorch Transformer models. You can combine different optimization technologies to improve the speed and efficiency of model training. For more information, see Rapidformer overview.\nPAI-Blade (general inference optimization)\nPAI-Blade is a general-purpose inference optimization tool. PAI-Blade integrates with various optimization technologies. You can use PAI-Blade to optimize the inference performance of a trained model so that the model can run at optimal inference performance. For more information, see Blade overview."
    },
    "482": {
        "title": "Platform For AI:AI computing asset management",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/ai-computing-asset-management/",
        "content": "This Product\nPlatform For AI:AI computing asset management"
    },
    "483": {
        "title": "Platform For AI:Other general features",
        "url": "https://www.alibabacloud.com/help/en/pai/user-guide/untitled-document-1701746285230/",
        "content": "This Product\nPlatform For AI:Other general features"
    },
    "484": {
        "title": "Platform For AI:Overview",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/overview-7",
        "content": "This Product\nPlatform For AI:Overview\nThis topic provides the links to the best practices of Platform for AI (PAI).\nLLM\nDevelop Qwen models in PAI-Lingjun AI Computing Service\nQuickly deploy a Llama 3 model in EAS\nQuickly deploy open source LLMs in EAS\nQuickly deploy Tongyi Qianwen in EAS\nUse QuickStart to fine-tune and deploy Llama 2 models\nFine-tune a Llama3-8B model\nData Processing for LLM (Github Code)\nE2E Development and Usage of LLM: Data Processing + Model Training + Model Inference\nData processing for LLM (web text data from Wikipedia)\nData processing for LLM (thesis data from arXiv)\nData processing for LLM (SFT data from Alpaca-CoT)\nLLM Data Processing-Alpaca-Cot (SFT Data)-DLC\nData Processing for LLM (Github Code)-DLC\nE2E Development and Usage of LLM: Data Processing + Model Training + Model Inference\nImage-Text Filtering\nVideo data filtering and labeling\nRAG-based LLM chatbot\nAIGC\nDeploy an MLLM application in EAS\nGenerate a video\nDeploy a LoRA SD model by using Kohya_ss in EAS\nUse ComfyUI to deploy an AI video generation model service\nUse Stable Diffusion web UI to deploy an AI painting service\nRAG\nRAG-based LLM chatbot\nBuild an intelligent conversation system based on RAG and Elasticsearch in EAS\nUse FeatureStore to manage features in a recommendation system\nBest practices for using FeatureStore\nUse AutoFE in FeatureStore\nIntelligent risk control\nImplement public opinion risk control based on the reviews from a takeaway platform\nUse graph algorithms to manage financial risks\nPredict credit scores by using a scorecard model\nPredict system anomalies by monitoring system metrics\nMonitor user churn\nClassification\nAutomatically classify tags\nClassify news based on text analysis\nIntelligent recommendation\nCustomized recommendation solutions\nGeneral solutions\nVideo data filtering and labeling\nImplement consistent click-through rate prediction in batch and real-time modes\nPredict heart disease\nClassify news based on text analysis\nPredict the repayment ability of agricultural loan applicants based on linear regression\nUse the Binning component to implement the discretization of continuous features\nPredict the performance of students in examinations\nAutomatically classify tags\nBuild models to predict the hazy weather\nBuild a model to predict the output power of a power plant\nIdentify electricity theft and leakage\nOffline scheduling\nUse EasyVision to detect objects\nUse EasyTransfer to develop a text classification model\nUse EasyASR for speech recognition\nUse EasyASR for speech classification\nSubmit a standalone training job that uses PyTorch\nUse NAS to submit standalone PyTorch migration learning jobs\nUse PAIIO to read data from and write data to MaxCompute tables\nSubmit an MPIJob training job\nBest practice for running the K-means Clustering component\nUse the PS-SMART Binary Classification component based on MaxCompute resources\nBest practice for performing DLC MNIST training\nBest practice for LoRA training in DLC\nDeploy a Hugging Face model in EAS\nBest practices for accessing dedicated gateway across VPCs\nInference acceleration (PAI-Blade)\nUse PAI-Blade to optimize a RetinaNet mode in the Detectron2 framework\nUse PAI-Blade and TorchScript custom C++ operators to optimize a RetinaNet model\nUse PAI-Blade and TensorRT plug-ins to optimize a RetinaNet model\nUse PAI-Blade to optimize a TensorFlow ResNet50 model\nUse PAI-Blade to optimize a TensorFlow BERT model\nDataset Accelerator\nUse Dataset Accelerator\nUse PAI-Rapidformer to accelerate the training of transformers\nAccelerate the training of transformers\nPAI-TF\nUse PAI-TensorFlow to implement the distributed DeepFM algorithm\nFastNN"
    },
    "485": {
        "title": "Platform For AI:DeepSeek",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/deepseek-model-development-application-guide/",
        "content": "This Product\nPlatform For AI:DeepSeek\n\nHere are topics about the deployment, fine-tuning, and distillation of DeepSeek models in Model Gallery.\nOne-click deployment of DeepSeek-V3 and DeepSeek-R1 models\nOne-click fine-tuning of DeepSeek-R1 distill models\nLangStudio offers an interactive environment for rapid development of LLM applications based on DeepSeek. You can easily add and edit nodes, and with a single click, deploy them to the production environment.\nScenario\nReference\nDeepSeek + Web Search\nLangStudio: Networked Search: Chat With Web Search\nDeepSeek + Knowledge base\nLangStudio: Develop and deploy a RAG application flow\nDeepSeek + Knowledge base + Web Search\nLangStudio: Chatbot with RAG and Web Search\n"
    },
    "486": {
        "title": "Platform For AI:LLM",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/llm1/",
        "content": "This Product\nPlatform For AI:LLM\n\nThe Model Gallery offers a range of pre-trained large language models from the open-source community. It enables you to engage in model training (fine-tuning), distillation, compression, evaluation, and deployment without writing any code. The following are related tutorial practices:\nGetting Started: Fine-tuning, Evaluation, and Deployment of Qwen2.5 Series Models\nGetting Started: Training, Evaluation, Compression, and Deployment Practices of Qwen2.5-Coder Model\nGetting Started: Training, Evaluation, Compression, and Deployment of DistilQwen2 Distilled Small Model\nGetting Started: Deployment and Fine-tuning of Llama-3 Series Models\nGetting Started: Deployment and Fine-tuning of Qwen1.5 Series Models\nGetting Started: Deployment and Fine-tuning of Mixtral-8x7B MoE Model\nGetting Started: Deployment and Fine-tuning of Llama2 Series Models\nGetting Started: Continued Pre-training Solution for Large Models\nGetting Started: Data Augmentation and Model Distillation Solution for Large Language Models\nIf the Model Gallery does not include the model you require, or if the available training and deployment capabilities do not meet your needs, consider using visual modeling (DSW) and distributed training (DLC) for model fine-tuning and training. You can then deploy and run inferences on models using the online model service (EAS).\nDevelopment Stage\nTutorial Practices\nTraining Stage\nDSW: Fine-tuning Training of Llama3-8B\nPAI-ChatLearn: Alignment on DLC Best Practices\nDeployment Stage\nDeploy LLM Large Language Model Applications with One Click in 5 Minutes Using EAS\nOperate EAS to Deploy Tongyi Qianwen Model with One Click in 5 Minutes\nAlibaba Cloud PAI Lingjun AI Computing Service is an intelligent computing product tailored for large-scale deep learning scenarios. It offers a comprehensive heterogeneous computing resource and AI engineering platform. Get started with Lingjun AI Computing Service through the following tutorial practices:\nTongyi Qianwen Qwen Fully Managed Lingjun Best Practices\nIntent Detection Solution Based on LLM\n\n"
    },
    "487": {
        "title": "Platform For AI:AIGC",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/aigc-pai/",
        "content": "This Product\nPlatform For AI:AIGC"
    },
    "488": {
        "title": "Platform For AI:RAG",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/rag/",
        "content": "This Product\nPlatform For AI:RAG\nThis topic provides a guide to Retrieval-Augmented Generation (RAG)-related documents to help you quickly find the content that you require.\nDocument\nDescription\nRAG-based LLM chatbot\nThis topic describes how to use Elastic Algorithm Service (EAS) to deploy the RAG services. The RAG architecture is designed for retrieval and generation.\nRetrieval: EAS integrates a range of vector databases, including open source Faiss and Alibaba Cloud services such as Milvus, Elasticsearch, Hologres, OpenSearch, and AnalyticDB for PostgreSQL.\nGeneration: EAS supports various open source models such as Qwen, Meta Llama, Mistral, and Baichuan, and also integrates ChatGPT.\nAfter you deploy an RAG service, you can call the RAG service by using the web UI or API operations. The web UI provides various inference parameters and allows you to upload knowledge base files to develop personalized and precise large language models (LLMs).\nUse EAS and Elasticsearch to deploy a RAG-based LLM chatbot\nUse EAS and OpenSearch to deploy a RAG-based LLM chatbot\nUse EAS and ApsaraDB RDS for PostgreSQL to deploy a RAG-based LLM chatbot\nThese topics describe how to associate vector databases with RAG services when you use EAS to deploy the RAG services. This topic also describes the basic features of RAG chatbots and the features of corresponding vector databases."
    },
    "489": {
        "title": "Platform For AI:Intelligent recommendation",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/intelligent-recommendation-1/",
        "content": "This Product\nPlatform For AI:Intelligent recommendation"
    },
    "490": {
        "title": "Platform For AI:Intelligent risk control",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/intelligent-wind-control/",
        "content": "This Product\nPlatform For AI:Intelligent risk control"
    },
    "491": {
        "title": "Platform For AI:Use cases for FeatureStore",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/featurestore-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for FeatureStore"
    },
    "492": {
        "title": "Platform For AI:Use cases for Designer",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/designer-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for Designer"
    },
    "493": {
        "title": "Platform For AI:Use cases for DSW",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/dsw-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for DSW"
    },
    "494": {
        "title": "Platform For AI:Use cases for DLC",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/dlc-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for DLC"
    },
    "495": {
        "title": "Platform For AI:Use cases for AutoML",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/automl-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for AutoML"
    },
    "496": {
        "title": "Platform For AI:Use cases for EAS",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/eas-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for EAS"
    },
    "497": {
        "title": "Platform For AI:Use cases for AI acceleration",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/acceleration-use-cases/",
        "content": "This Product\nPlatform For AI:Use cases for AI acceleration"
    },
    "498": {
        "title": "Platform For AI:Responsible AI",
        "url": "https://www.alibabacloud.com/help/en/pai/use-cases/responsible-ai/",
        "content": "This Product\nPlatform For AI:Responsible AI"
    },
    "499": {
        "title": "Platform For AI:API Reference",
        "url": "https://www.alibabacloud.com/help/en/pai/developer-reference/api-reference-335103/",
        "content": "This Product\nPlatform For AI:API Reference"
    },
    "500": {
        "title": "Platform For AI:SDK Reference",
        "url": "https://www.alibabacloud.com/help/en/pai/developer-reference/sdk-reference/",
        "content": "This Product\nPlatform For AI:SDK Reference"
    },
    "501": {
        "title": "Platform For AI:CLI Tools",
        "url": "https://www.alibabacloud.com/help/en/pai/developer-reference/cli-tools/",
        "content": "This Product\nPlatform For AI:CLI Tools"
    },
    "502": {
        "title": "Platform For AI:Permission management",
        "url": "https://www.alibabacloud.com/help/en/pai/manage-asset-permissions/",
        "content": "This Product\nPlatform For AI:Permission management"
    },
    "503": {
        "title": "Platform For AI:Infrastructure security",
        "url": "https://www.alibabacloud.com/help/en/pai/infrastructure-security",
        "content": "This Product\nPlatform For AI:Infrastructure security\n\n\n\n\n\n\n\n\n\n\n\n\nPlatform for AI (PAI) divides a region into multiple zones. Each zone is an isolated area that has its own power supply and network.\nZones in the same region are connected by using a low-latency internal network. To ensure that incidents in one zone do not affect operations in another zone, fault isolation is enabled between zones.\nPAI provides AIMaster, which is an elastic fault-tolerant engine that facilitates execution of Deep Learning Container (DLC) jobs. When you use AIMaster for a DLC job, an AIMaster instance is launched to run concurrently with other job instances. The AIMaster instance monitors the job progress and manages fault tolerance and resource allocation.\nThe sanity check feature of DLC allows you to check the health status and performance of computing resources that are used to run DLC jobs. You can enable the sanity check feature when you create a DLC job. If you enable the sanity check feature, the system automatically examines the resources related to the job, isolates malfunctioning nodes, and triggers an automated O&M process in the background. The sanity check feature can reduce failures at an early stage and increase the success rate of a job. After a sanity check is complete, the system provides a test report on the computing power and communication performance of the related GPUs. You can use the report to identify potential risks that may impair the training performance, which improves troubleshooting efficiency. For more information, see Sanity check.\nYou can use CloudMonitor to build and reinforce your security defense system. CloudMonitor provides the following feature for PAI:\nInference monitoring for the Elastic Algorithm Service (EAS) module of PAI: For more information, see View ServiceInstance events in CloudMonitor."
    },
    "504": {
        "title": "Platform For AI:Data security",
        "url": "https://www.alibabacloud.com/help/en/pai/data-security",
        "content": "This Product\nPlatform For AI:Data security\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo enhance data transmission security for a model service that is deployed in Platform for AI (PAI), you can access the service over a virtual private cloud (VPC) by using the official SDK for Python or implementing custom logic. VPCs are isolated from each other, which ensures private high-speed access.\nFor more information about VPC security, see Security system overview.\nPAI provides a dataset management module that allows you to create datasets by using public datasets or data that is stored in Alibaba Cloud storage services. The module also allows you to scan Object Storage Service (OSS) folders to generate index datasets that you can use for intelligent labeling and model training.\nTo ensure the storage security of data files such as datasets and models, we recommend that you use the following Alibaba Cloud storage services:\nData storage service\nRelated topic\nOSS\nSecurity and compliance\nFile Storage NAS\nFunctions and features\nCloud disks\nDisks\nMaxCompute\nFAQ about security configurations\nPAI allows you to use images to back up and restore user environments and datasets. For example, you can create an image to save the data, engineering environments, and configurations of an instance. This way, you can deploy the image based on your business requirements, which provides a safeguard against data loss. When you use Alibaba Cloud storage services to store data or datasets, backup and restoration is guaranteed by the corresponding service.\nData storage service\nRelated topic\nOSS\nData backup and recovery\nFile Storage NAS\nBack up and restore files\nMaxCompute\nBackup and restoration\nWhen you use PyTorch to train a foundation model, you can use EasyCkpt to save and resume the model training progress to minimize data loss and waste of resources. EasyCkpt is a high-performance checkpoint framework provided by PAI and is compatible with Megatron and DeepSpeed, which are popular model training frameworks. For more information, see Use EasyCkpt to save and resume foundation model trainings."
    },
    "505": {
        "title": "Platform For AI:Monitoring and logging",
        "url": "https://www.alibabacloud.com/help/en/pai/monitoring-and-logging",
        "content": "This Product\nPlatform For AI:Monitoring and logging\n\n\nWe recommend that you keep track of the health status of your Alibaba Cloud resources. This way, you can handle exceptions at the earliest opportunity. For more information, visit Alibaba Cloud Health Status.\nOn the Alibaba Cloud Health Status page, you can check the health status of each service in different regions and subscribe to Really Simple Syndication (RSS) feeds about service exceptions.\n\nCloudMonitor Basic is a free service that can provide real-time monitoring capabilities for Platform for AI (PAI). CloudMonitor Basic allows you to track the operational status of cloud resources, resource usage in Elastic Compute Service (ECS), website performance, and disruptions in business operations.\nTo use the monitoring capabilities of CloudMonitor Basic, you must enable CloudMonitor Basic for PAI. For more information, see Cloud service monitoring.\n\nCloudMonitor Basic allows you to enable alerts for multiple critical PAI metrics at the same time and establish an alert system efficiently. This way, you can gain comprehensive insights into the usage of your cloud resources and the operational status of your business. For more information, see Enable the initiative alert feature.\nYou can create a custom dashboard to manage all metrics that you want to monitor on a single platform. For more information, see Manage the monitoring charts of a custom dashboard.\nYou can configure alert rules for each metric to receive important notifications by using multiple notification methods, including phone calls, text messages, emails, DingTalk chatbots, and the Alibaba Cloud app.\nYou can also create an alert blacklist to block alerts for specific metrics. For more information, see Manage blacklist policies.\nCloud Config is a free auditing service that helps you monitor the configuration changes  of all cloud resources and ensure the continuous compliance of your cloud infrastructure.\nCloud Config can audit the operations of your Alibaba Cloud account and Resource Access Management (RAM) users that are created by your Alibaba Cloud account. By default, configuration changes are recorded every 10 minutes.\nCloud Config uses rules that align with the Baseline for Multi-Level Protection Scheme (MLPS) 2.0 to evaluate the compliance of cloud resource configurations. You can enable the compliance pre-check for MLPS 2.0 with a few clicks. The system automatically and continuously checks your resources for compliance. You can also download the pre-check report and submit it to an inspection agency.\nYou can send the historical configuration changes and non-compliant events of your resources to a Logstore in Simple Log Service. This way, you can query and analyze audit data in a centralized manner. For more information, see Deliver resource data to a Logstore in Simple Log Service.\nYou can enable ActionTrail for PAI to monitor and record the operations of your Alibaba Cloud account in a centralized manner, including logon to the PAI console and access to cloud resources. This way, you can perform security analysis, intrusion detection, resource change tracking, and compliance auditing based on the records.\nActionTrail can generate logs for cloud service access by using the Alibaba Cloud Management Console, calling API operations, and using developer tools. For information about the audit events, see Audit events of ECS.\nBy default, ActionTrail tracks and retains the events of the previous 90 days. If you need to retain events for a longer period of time, create a trail that sends events to a Simple Log Service Logstore or an Object Storage Service (OSS) bucket. For more information, see Getting Started.\nAfter you create a trail to send events to a Simple Log Service Logstore or an OSS bucket, you can query or analyze the events in the Simple Log Service or OSS console. For more information, see Query events in the Simple Log Service or OSS console.\nIf you need to trace a historical event, submit a ticket to request the required permissions.\nPAI provides a notification mechanism for workspaces. You can create notification rules to monitor the status of Deep Learning Containers (DLC) jobs and pipeline jobs, or trigger related events based on the approval status of model versions. You can receive notifications through multiple notification methods, such as DingTalk, phone calls, and emails. For more information, see Workspace notification.\nYou can create a Tensorboard in Machine Learning Designer or for a DLC job to view the analytical reports of model training in a visualized manner. For more information, see the following topics:\nMachine Learning Designer: Use TensorBoard to visualize analytical reports.\nDLC: Tensorboard.\n"
    },
    "506": {
        "title": "Platform For AI:Security compliance qualifications",
        "url": "https://www.alibabacloud.com/help/en/pai/security-compliance-qualifications",
        "content": "This Product\nPlatform For AI:Security compliance qualifications\nTo ensure data security and regulatory compliance when you use Platform for AI (PAI), Alibaba Cloud adheres to the most stringent security compliance standards. This topic describes the security compliance qualifications that PAI acquired and their significance for the protection of your business and data.\n\nCompliance qualification\nScope\nDescription\nISO 27018\nInternational\nThis standard provides guidelines for cloud service providers on how to protect personal data in the cloud.\nISO 27701\nInternational\nThis standard is an extension of ISO 27001 and specifies the privacy information management requirements for all types and sizes of organizations.\nISO 27799\nInternational\nThis standard provides guidelines for healthcare providers on how to protect personal health information.\nISO 29151\nInternational\nThis standard provides guidelines on how to protect personally identifiable information (PII).\nISO 9001\nInternational\nThis standard specifies the quality management system requirements for all types and sizes of organizations to ensure the continuous improvement of product or service quality.\nISO 20000\nInternational\nThis standard helps organizations improve IT services to meet customer needs.\nISO 22301\nInternational\nThis standard specifies business continuity management requirements to help organizations recover from disruptive incidents.\nISO 27001\nInternational\nThis standard specifies information security management requirements to secure information assets.\nISO 27017\nInternational\nThis standard provides information security guidelines that are specific to cloud services.\nBS 10012\nInternational\nThis standard specifies requirements regarding data protection and processing for a personal information management system.\nCSA STAR\nInternational\nSecurity, Trust & Assurance Registry (STAR) is a program that is provided by the Cloud Security Alliance (CSA) to assess the security practices and privacy controls of cloud service providers.\nMLPS Level 3\nChina\nThe Multi-Level Protection Scheme (MLPS) Level 3 standard mandates stringent security measures for systems in which a data breach may harm societal order.\nSOC\nInternational\nService Organization Control (SOC) reports assess the data security and protection measures of an organization, such as a data center.\nPCI DSS\nInternational\nThe Payment Card Industry Data Security Standard (PCI DSS) is a set of security standards that ensure all entities that accept, process, store, or transmit credit card information maintain a secure environment."
    },
    "507": {
        "title": "Platform For AI:FAQ",
        "url": "https://www.alibabacloud.com/help/en/pai/support/faq/",
        "content": "This Product\nPlatform For AI:FAQ"
    },
    "508": {
        "title": "Platform For AI:Related downloads",
        "url": "https://www.alibabacloud.com/help/en/pai/support/download-tensorflow-resources",
        "content": "This Product\nPlatform For AI:Related downloads\nThis topic provides related downloads for TensorFlow, online prediction, PyTorch, and video classification.\nItem\nDescription\nURL\nMNIST database\nProvides the download URLs of the code, training data, and test data that are required when you use TensorFlow to train a model based on the Modified National Institute of Standards and Technology (MNIST) database.\nCode\nTraining data\nTest data\nAfter you download the code, training data, and test data, you must upload them to the same Object Storage Service (OSS) directory.\nTensorBoard\nProvides the download URL of the code that is related to TensorBoard.\nRelated code of TensorBoard\nLyric writing\nProvides the download URL of data and code that are required when you use TensorFlow to automatically write lyrics.\nCode and data\nModel training on multiple multi-GPU servers\nProvides the download URL of the code that is required when you use TensorFlow to train a model on multiple multi-GPU servers.\nCode\nFastNN\nProvides the download URLs of Fast Neural Networks (FastNN) code.\nFastNN code\nHyperparameter file\nRead/write operations on MaxCompute tables\nProvides the download URL of the code that is required when you use TensorFlow to read data from and write data to MaxCompute tables.\nCode\nProvides the download URL of resources that can be used for online prediction.\nPAI-online-service\nProvides the download URLs of the code that is required when you use PyTorch to train a model based on the MNIST database.\nMNIST training file\nMNIST test file\nCode that is required when you use PyTorch to train a model based on the MNIST database in a distributed manner\nProvides the download URLs of resources that can be used for video classification.\nModels:\nResNet 1\nResNet 2\nResNet 3\nVideo data\nConfiguration file\nLabel file"
    },
    "509": {
        "title": "Platform For AI:Service Agreements",
        "url": "https://www.alibabacloud.com/help/en/pai/support/legal-resources/",
        "content": "This Product\nPlatform For AI:Service Agreements"
    },
    "510": {
        "title": "Platform For AI:Announcements and Updates",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/announcements-and-updates",
        "content": "This Product\nPlatform For AI:Announcements and Updates"
    },
    "511": {
        "title": "Platform For AI:Get started with Designer",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/start-using-alibaba-cloud-machine-learning-platform-for-ai",
        "content": "This Product\nPlatform For AI:Get started with Designer\nMachine Learning Designer uses pipelines to build and debug models. Start by planning and creating a pipeline, then organize the various components according to your processing and scheduling logic. Machine Learning Designer offers multiple methods for pipeline creation, including demos to show you how to create a pipeline by using a template and how to create a custom pipeline.\nUse a preset template\nDesigner offers a variety of built-in templates tailored to different frameworks and the diverse needs of industry scenarios. You can use a preset template to create a pipeline, adjust the components or their configurations, and swiftly construct and deploy a model that aligns with your requirements. This demo shows how to create a pipeline using the heart disease prediction template, see Demo for creating a pipeline by using a template.\nCustom pipeline\nThis demo walks you through the creation of a blank pipeline for developing a binary classification model for heart disease prediction. Starting from scratch, you will engage in data preprocessing, model prediction, and evaluation, culminating in a fully visualized model building and deployment process. For more information, see Custom pipelines."
    },
    "512": {
        "title": "Platform For AI:FAQ about iTAG",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/pai-itag-faq",
        "content": "This Product\nPlatform For AI:FAQ about iTAG\nThis topic provides answers to some frequently asked questions about iTAG.\nWhat do I do if the system fails to load content in iTAG?\nWhat do I do If I am prompted that I do not have permissions to use iTAG?\nWhat do I do if the dataset format fails to be parsed when I create a labeling task?\nIf the system fails to load resources during the labeling process in iTAG, you must enable Cross-Origin Resource Sharing (CORS) for the Object Storage Service (OSS) buckets that are used as data sources. The following section describes how to enable CORS for an OSS bucket.\nGo to the details page of a bucket.\nLog on to the OSS console.\nIn the left-side navigation pane, click Buckets.\nOn the Buckets page, find the OSS bucket that you want to manage and click the bucket name.\nOn the details page of the bucket, choose Content Security > Cross-Origin Resource Sharing (CORS) in the left-side navigation pane.\nClick Create Rule. In the Create Rule panel, configure the parameters described in the following table.\nParameter\nRequired\nDescription\nSources\nYes\nThe sources of cross-region requests that you want to allow. Use the following address for this parameter:\nAllowed Methods\nYes\nThe methods that cross-origin requests are allowed to use. Select the following methods:\nAllowed Headers\nYes\nThe response headers for the allowed cross-region requests. Use the following header for this parameter:\nExposed Headers\nYes\nThe response headers that are exposed to your applications. Use the following headers for this parameter:\nCache Timeout (Seconds)\nNo\nThe timeout period of the response that is cached by the browser for an OPTIONS preflight request destined for specific resources.\nVary: Origin\nYes\nYou must select the check box next to Vary: Origin to return the Vary: Origin header.\nIf both CORS and non-CORS requests are sent at the same time, or if the Origin header has multiple possible values, you can select Vary: Origin to prevent errors in the local cache.\nClick OK.\n\nYou can add a Resource Access Management (RAM) user as a member of your workspace, and then grant the required permissions to the RAM user on the Users tab of the iTAG page. For more information, see Grant the permissions that are required to use iTAG.\n\nIf the The format of the dataset fails to be parsed. Select a dataset with a valid format error message is returned when you select a registered dataset for creating a labeling task on the iTAG page, perform one of the following steps:\nCreate a dataset in a valid format. Only datasets that match the formats of the labeled data of iTAG are supported. For more information, see Create a dataset for a labeling job.\nCheck whether the format of the registered dataset is valid. For more information, see \tOverview.\n\n"
    },
    "513": {
        "title": "Platform For AI:Overview",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/best-practices",
        "content": "This Product\nPlatform For AI:Overview\nThis topic provides the links to the best practices of Platform for AI (PAI).\nLLM\nDevelop Qwen models in PAI-Lingjun AI Computing Service\nQuickly deploy a Llama 3 model in EAS\nQuickly deploy open source LLMs in EAS\nQuickly deploy Tongyi Qianwen in EAS\nUse QuickStart to fine-tune and deploy Llama 2 models\nFine-tune a Llama3-8B model\nData Processing for LLM (Github Code)\nE2E Development and Usage of LLM: Data Processing + Model Training + Model Inference\nData processing for LLM (web text data from Wikipedia)\nData processing for LLM (thesis data from arXiv)\nData processing for LLM (SFT data from Alpaca-CoT)\nLLM Data Processing-Alpaca-Cot (SFT Data)-DLC\nData Processing for LLM (Github Code)-DLC\nE2E Development and Usage of LLM: Data Processing + Model Training + Model Inference\nImage-Text Filtering\nVideo data filtering and labeling\nRAG-based LLM chatbot\nAIGC\nDeploy an MLLM application in EAS\nGenerate a video\nDeploy a LoRA SD model by using Kohya_ss in EAS\nUse ComfyUI to deploy an AI video generation model service\nUse Stable Diffusion web UI to deploy an AI painting service\nRAG\nRAG-based LLM chatbot\nBuild an intelligent conversation system based on RAG and Elasticsearch in EAS\nUse FeatureStore to manage features in a recommendation system\nBest practices for using FeatureStore\nUse AutoFE in FeatureStore\nIntelligent risk control\nImplement public opinion risk control based on the reviews from a takeaway platform\nUse graph algorithms to manage financial risks\nPredict credit scores by using a scorecard model\nPredict system anomalies by monitoring system metrics\nMonitor user churn\nClassification\nAutomatically classify tags\nClassify news based on text analysis\nIntelligent recommendation\nCustomized recommendation solutions\nGeneral solutions\nVideo data filtering and labeling\nImplement consistent click-through rate prediction in batch and real-time modes\nPredict heart disease\nClassify news based on text analysis\nPredict the repayment ability of agricultural loan applicants based on linear regression\nUse the Binning component to implement the discretization of continuous features\nPredict the performance of students in examinations\nAutomatically classify tags\nBuild models to predict the hazy weather\nBuild a model to predict the output power of a power plant\nIdentify electricity theft and leakage\nOffline scheduling\nUse EasyVision to detect objects\nUse EasyTransfer to develop a text classification model\nUse EasyASR for speech recognition\nUse EasyASR for speech classification\nSubmit a standalone training job that uses PyTorch\nUse NAS to submit standalone PyTorch migration learning jobs\nUse PAIIO to read data from and write data to MaxCompute tables\nSubmit an MPIJob training job\nBest practice for running the K-means Clustering component\nUse the PS-SMART Binary Classification component based on MaxCompute resources\nBest practice for performing DLC MNIST training\nBest practice for LoRA training in DLC\nDeploy a Hugging Face model in EAS\nBest practices for accessing dedicated gateway across VPCs\nInference acceleration (PAI-Blade)\nUse PAI-Blade to optimize a RetinaNet mode in the Detectron2 framework\nUse PAI-Blade and TorchScript custom C++ operators to optimize a RetinaNet model\nUse PAI-Blade and TensorRT plug-ins to optimize a RetinaNet model\nUse PAI-Blade to optimize a TensorFlow ResNet50 model\nUse PAI-Blade to optimize a TensorFlow BERT model\nDataset Accelerator\nUse Dataset Accelerator\nUse PAI-Rapidformer to accelerate the training of transformers\nAccelerate the training of transformers\nPAI-TF\nUse PAI-TensorFlow to implement the distributed DeepFM algorithm\nFastNN"
    },
    "514": {
        "title": "Platform For AI:What is PAI?",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/what-is-machine-learning-pai",
        "content": "This Product\nPlatform For AI:What is PAI?\nAlibaba Cloud Platform for AI (PAI) is a one-stop machine learning platform that provides data labeling, model development, model training, and model deployment services. This topic describes what PAI is.\nPAI is a one-stop machine learning platform for developers. With its core modules, such as Machine Learning Designer, Data Science Workshop (DSW), Deep Learning Containers (DLC), and Elastic Algorithm Service (EAS), PAI provides an all-in-one solution for machine learning, covering data labeling, model development, model training, and model deployment. PAI supports multiple open-source frameworks and AI optimization capabilities. PAI is flexible and easy to use.\nFeatures\nBenefits\nBilling\nScenarios\nAI development phase\nRelated module\nDescription\nData preparation\nPAI-iTAG\nIn the data preparation phase, iTAG provides intelligent data labeling services. You can create data labeling tasks for the following data types: image, text, video, and audio. You can also create multimodal data labeling tasks. iTAG provides various content and question components for data labeling. You can use the preset templates provided by iTAG or custom data labeling templates based on your business requirements. iTAG also provides fully managed data labeling services that are outsourced.\n\nModel development\nPAI-Designer\nMachine Learning Designer provides more than 140 mature algorithms and allows you to develop AI models by performing visualized drag-and-drop operations in a low-code environment.\nPAI-DSW\nDSW allows you to develop models through interactive programming. DSW is a cloud integrated development environment (IDE) embedded with Notebook, VS Code, and Terminal. DSW also grants you sudo permissions for flexible management.\nModel training\nPAI-DLC\nYou can use general computing resources and Lingjun resources for model training based on scenarios and computing power types.\nGeneral computing resources: Alibaba Cloud general computing resources, such as Elastic Compute Service (ECS), Elastic Container Instance, and Elastic GPU Service (EGS). DLC supports multiple training frameworks such as Tensorflow, PyTorch, and MPI and provides flexible, stable, and easy-to-use model training services.\nLingjun intelligent computing resources: Based on the integrated optimization technology of software and hardware, DLC allows you to run ultra-large distributed deep learning jobs and provides benefits such as high performance, high efficiency, and high utilization. Both Lingjun AI Computing Service Serverless Edition on the Alibaba Cloud public cloud and Lingjun AI Computing Service Dedicated Edition for a single tenant are supported. An AI engineering end-to-end platform with software-hardware heterogeneously integrated computing power is provided.\n\nModel deployment\nPAI-EAS\nEAS allows you to deploy models as online inference services or AI-powered web applications. EAS is suitable for multiple scenarios, such as real-time inference, asynchronous inference, and offline inference.\nView more features\nEnd-to-end AI-powered R&D\nSupports data labeling, model development, model training, model optimization, model deployment, and AI O&M as a one-stop AI platform.\nProvides over 140 types of optimized built-in algorithm components.\nProvides core capabilities such as multiple modes, deep integration with big data engines, multi-framework compatibility, and custom images.\nProvides  cloud-native AI development, training, and deployment services.\nMultiple open-source frameworks\nSupports Flink, a stream computing framework.\nSupports TensorFlow, PyTorch, Megatron and DeepSpeed, which are optimized deep learning frameworks based on the related open-source frameworks.\nSupports Parameter Server, a computing framework that can process hundreds of billions of samples in parallel.\nSupports Spark, PySpark, MapReduce, and other mainstream open-source computing frameworks.\nIndustry-leading AI optimization\nSupports high-performance training framework, sparse training scenarios, billions to tens of billions of sparse features, tens to hundreds of billions of samples, and distributed incremental training of thousands of workers.\nSupports acceleration of mainstream framework models such as RestNet50 and Transformer language model (LM) by using PAI Blade.\nDiverse service modes\nSupports fully managed and semi-managed services for public cloud.\nProvides high-performance AI computing clusters and lightweight service modes.\nSupports periodical scheduling by using DataWorks. You can run scheduled tasks in the production or development environment. This enables data isolation.\n\nBilling method\nDescription\nInvolved module\nPay-as-you-go\nIf you use the pay-as-you-go billing method, you are charged based on the actual usage of each module.\nThe pay-as-you-go billing method is suitable for short-term or uncertain workloads. It allows you to pay for resources based on the actual amount of resources that you use. The pay-as-you-go billing method is suitable for test environments, development environments, unexpected requirements, or projects in the early phases.\nMachine Learning Designer, DSW, DLC, and EAS\nSubscription\nThe subscription billing method\nis suitable for long-term and stable workloads. You must pay in advance to use resources for a specific period of time, such as a month or a year. The subscription billing method is more cost-effective than the pay-as-you-go billing method for long-term use.\nDSW, DLC, and EAS\nResource plan\nResource plans refer to quota plans of specific resources that you can purchase in advance.\nResource plans are suitable for scenarios in which you want to use a large number of specific resources. You can purchase quota plans for specific resources at more favorable prices.\nDSW\nSavings plan\nYou can purchase savings plans in advance, which offer specific discounts or benefits.\nSavings plans provide discounted pay-as-you-go rates in exchange for committing to a specific spending amount within a specific period of time.\nDSW and EAS\nPay-by-inference-duration\nYou are charged based on the actual inference duration. The resource specifications support automatic scaling based on the number of service requests.\nThis billing method is suitable for inference tasks that require indefinite quantities and is appropriate for high-concurrent requests and dynamic loads.\nEAS\nView more information about billing\nScenario\nUse case\nLarge language model (LLM)\nQuickly deploy LLMs in EAS\nRetrieval-Augmented Generation (RAG)-based LLM chatbot\nRAG-based LLM chatbot\nAI painting\nUse Stable Diffusion web UI to deploy an AI painting service\nGenerate a video\nSubmit a standalone training job that uses PyTorch\nView more scenarios\nIf you use PAI for the first time, you must activate PAI and create a default workspace. For more information, see Activate PAI and create a default workspace."
    },
    "515": {
        "title": "Platform For AI:Service architecture",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/overview-72285",
        "content": "This Product\nPlatform For AI:Service architecture\nThis topic describes the architecture of Platform for AI (PAI).\n\nThe architecture of PAI consists of the following layers, as shown in the preceding figure:\nBasic resources layer (computing resources and infrastructure):\nInfrastructure: includes CPU, GPU, high-speed Remote Direct Memory Access (RDMA) network, and Container Service for Kubernetes (ACK) resources.\nComputing resources: include cloud-native resources (intelligent computing LINGJUN resources and general-purpose computing resources) and big data computing resources (MaxCompute and Flink resources).\nPlatform and framework layer (PAI-Lingjun AI Computing Service and AI frameworks):\nAI frameworks: include frameworks that can be used to run distributed computing tasks, such as Alink, TensorFlow, PyTorch, Megatron, DeepSpeed, and Reinforcement Learning from Human Feedback (RLHF).\nOptimization and acceleration frameworks: include DatasetAcc for dataset acceleration, TorchAcc for training acceleration, Easy Parallel Library (EPL) for parallel training acceleration, Blade for inference acceleration, AIMaster for automatic fault tolerance trainings, and EasyCkpt for second-level asynchronous training snapshots.\nPAI provides services for full-link machine learning development, including data preparation, model development and training, and model deployment.\nData preparation: iTAG allows you to label data and manage datasets in multiple scenarios.\nModel development and training: PAI provides various services to meet different modeling requirements. These services are Machine Learning Designer, Data Science Workshop (DSW), Deep Learning Containers (DLC), and FeatureStore. Machine Learning Designer is a visualized modeling service. DSW allows you to create models by using interactive programming. DLC is a cloud-native platform for training deep learning models. FeatureStore allows you to manage model features.\nModel deployment: You can use Elastic Algorithm Service (EAS) to deploy models as services.\nApplication layer (model services): model services, such as ModelScope community, PAI-DashScope, third-party MaaS platforms, and Alibaba Cloud Model Studio.\nBusiness layer (Scenario-based solutions): PAI is widely used in business scenarios, such as autonomous driving, scientific research, financial risk management, and AI recommendations. The search systems, recommendation systems, and financial service systems of Alibaba Group use PAI to mine data and make informed business decisions."
    },
    "516": {
        "title": "Platform For AI:Features",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/product-advantages",
        "content": "This Product\nPlatform For AI:Features\n\n\nModule\nFeature\nDescription\nReference\nAI computing resource management\nLingjun resources\nPAI provides Lingjun resources for large-scale and high-density computing. Lingjun resources provide heterogeneous computing power, which is required for high-performance AI training and computing. You can use Lingjun resources for trainings in PAI.\nLingjun resource quotas\nGeneral training resources\nGeneral training resources are deep learning training resources based on Container Service for Kubernetes (ACK). The resources provides scalable, stable, easy-to-use, and high-performance runtimes for training deep learning models.\nGeneral computing resource quotas\nOther big data computing resources\nBig data computing resources, such as MaxCompute and Realtime Compute for Apache Flink.\nOverview of AI computing resources\nWorkspaces\nResource management\nThe workspace administrator can associate the AI computing resources in the current Alibaba Cloud account with the workspace to allow workspace members to use the resources for development and training.\nManage workspaces\nWorkspace notification\nPAI provides a notification mechanism for workspaces. You can create a notification rule to track and monitor Deep Learning Containers (DLC) jobs or Machine Learning Designer pipelines. You can also use notification rules to trigger events when the status of the model version changes.\nCreate a notification rule\nWorkspace storage and SLS configuration\nThe workspace administrator can specify the default storage path for development training in the current workspace and the storage lifecycle of temporary tables.\nManage workspaces\nMember and permission management\nPAI uses role-based access control that provides multiple roles, such as labeling administrators, algorithm developers, and algorithm O&M, to facilitate efficient collaboration. You can manage the visibility scope of AI assets in a workspace and manage access permissions for different roles.\nManage members of a workspace\nQuickStart\nModel Hub\nPAI provides various pre-trained models from open-source communities, such as ModelScope and Hugging Face.\nDeploy and train models\nPre-trained model training\nYou can use the pre-trained models for training in PAI.\nDeploy and train models\nPre-trained model deployment\nYou can use the pre-trained models for deployment in PAI.\nDeploy and train models\nMachine Learning Designer\nPipeline building\nMachine Learning Designer allows you to build and debug models by using pipelines. You can drag components to the canvas to build a pipeline based on your business requirements.\nPipeline overview\nPipeline import and export\nYou can export a pipeline as a JSON file. You can also import a JSON file to a workspace to build a pipeline.\nExport and import pipelines\nPipeline scheduling\nYou can use DataWorks to periodically schedule pipelines in Machine Learning Designer.\nUse DataWorks tasks to schedule pipelines in Machine Learning Designer\nPreset pipeline templates\nPAI provides pipeline templates that for various industries, such as product recommendation, news classification, financial risk control, haze weather prediction, heart disease prediction, agricultural loan issuance, and population census. The templates are preset with complete datasets and documentation to facilitate usage.\nGeneral solutions that use Machine Learning Designer\nCustom pipeline templates\nYou can create a pipeline template based on algorithm workflows that you develop and share the template with your team. Your team member can directly perform modeling, deployment, and online verification based on the custom template.\nCreate a pipeline from a custom template\nDashboards\nMachine Learning Designer provides dashboards to help you visualize data analysis, model analysis, and model results.\nUse dashboards to view analytical reports\nPreset algorithm component library\nPAI provides hundreds of built-in algorithm components for various industries, such as data source, data preprocessing, feature engineering, statistical analysis, machine learning, time series, recommendation algorithms, anomaly detection, natural language processing, network analysis, finance, visual algorithms, speech algorithms, and custom algorithms.\nComponent reference: Overview of all components\nCustom algorithms\nYou can implement nodes by using multiple methods, such as SQL, Python, and PyAlink scripts.\nCustom algorithm components\nData Science Workshop (DSW)\nCloud-native development environment\nDSW provides a flexible, stable, easy-to-use, and high-performance environment for AI development and various CPU-accelerated and GPU-accelerated resources to facilitate training.\nWhat is DSW?\nDSW Gallery\nDSW Gallery provides easy-to-use cases from various industries and technical verticals to help improve development efficiency.\nNotebook Gallery\nJupyterLab\nDSW integrates open source JupyterLab and provides plug-ins for custom development. You can directly start Notebook to write, debug, and run Python code without O&M configurations.\nAccess a DSW instance\nWebIDE\nDSW provides WebIDE in which you can install open source plug-ins for modeling.\nAccess a DSW instance\nTerminal\nDSW supports character terminals to debug models.\nAccess a DSW instance\nPersistent instance environment\nYou can manage the lifecycle of the development environment, save the instance environment, mount and share data, and persist the environment image.\nMount datasets or OSS paths\nResource usage monitoring\nYou can view real-time resource usage in a visualized manner.\nAccess a DSW instance\nImage creation\nYou can create an image and save the image to Container Registry for subsequent distributed training or inference.\nManage DSW instances\nSSH remote connection\nDSW provides the following SSH connection methods: direct connection and proxy client connection. You can select a connection method based on the resource dependencies, usage methods, and limits of the connection methods to meet your business requirements.\nConnect to a DSW instance over SSH\nDeep Learning Containers (DLC)\nCloud-native distributed training environment\nDLC is a deep learning platform developed based on Container Service for Kubernetes (ACK) that provides stable, easy-to-use, scalable, and high-performance runtimes for training deep learning models.\nBefore you begin\nDataset mounting\nYou can mount multiple datasets, such as File Storage NAS or Object Storage Service (OSS) datasets, in DLC at the same time.\nBefore you begin\nPublic and dedicated resource groups\nDLC provides public and dedicated resource groups.\nBefore you begin\nOfficial and custom images\nDLC allows you to use official images or custom images to submit training jobs.\nBefore you begin\nDistributed trainings\nDLC provides a distributed deployment solution for implementing data parallelism, model parallelism, and hybrid parallelism.\nCreate a training job\nTraining job management\nDLC allows you to manage jobs during the entire lifecycle.\nManage training jobs\nElastic Algorithm Service (EAS)\nResource group management\nEAS provides resources in resource groups for isolation. When you create a model service, you can deploy the model service in the public resource group provided by the system or a dedicated resource group that you created.\nOverview of EAS resource groups\nService and application deployment\nYou can deploy models that you downloaded from the open source community or models that you trained as inference services or AI-powered web applications in EAS. EAS provides multiple methods that you can use to deploy models. You can use the PAI console to deploy models as API services.\nDeploy a model service in the PAI console\nService debugging and stress testing\nAfter you deploy the service, you can use the online debugging and stress testing feature to test whether the service runs as expected.\nService debugging and stress testing\nAuto scaling\nYou can configure automatic scaling, scheduled scaling, and elastic resource pools for EAS services.\nService Auto Scaling\nService calls\nEAS provides the following service call methods based on the network environment of the client: Internet access, VPC access, and VPC direct connection.\nService calls\nAsynchronous inference\nEAS provides the asynchronous inference feature, which allows you to obtain inference results by subscribing to requests or polling.\nAsynchronous inference services\nIntegrated resource group and service management capabilities\nEAS provides standard OpenAPI and SDKs that support integration.\nList of operations by function\nAI computing asset management\nDatasets\nPAI provides public datasets and supports dataset management during labeling and modeling. PAI also support OSS and NAS datasets and SDK calls.\nCreate and manage datasets\nModels\nPAI allows you to manage versions, lineages, evaluation metrics, and associated services of models in a centralized manner.\nRegister and manage models\nTasks\nPAI supports management of distributed training tasks and PAIFlow pipeline runs.\nJob management\nImages\nPAI provides official images and supports image management.\nView and add images\nCode builds\nYou can register code repositories to PAI to facilitate code version management in PAI modules.\nCode builds\nCustom components\nYou can create custom algorithm components based on your business requirements. You can use custom components together with preset components in Machine Learning Designer to manage pipelines in a flexible manner.\n-\nAutoML\nAutomatic hyperparameter optimization (HPO)\nHPO is used to automatically fine-tune model-related parameters and training parameters.\nHow AutoML works\nScenario-based solutions\nMultimedia analysis\nPAI provides ready-to-use image-related services such as image labeling, classification, and quality evaluation.\nOverview of multimedia analysis\nAI acceleration\nDataset Accelerator\nDatasetAcc is a PaaS service developed by Alibaba Cloud to accelerate AI and datasets in the cloud. DatasetAcc provides dataset acceleration solutions for various cloud-native training engines by pre-analyzing and preprocessing training datasets used in machine learning training. This helps improve the overall training efficiency.\n-\nEasy Parallel Library (EPL)\nEPL is an efficient and easy-to-use framework for distributed model training. EPL uses multiple training optimization technologies and provides easy-to-use API operations that allow you to use parallelism strategies. You can use EPL to reduce costs and improve the efficiency of distributed model training.\nUse EPL to accelerate AI model training\nPAI-Rapidformer\nPAI-Rapidformer applies various technologies to optimize the training of PyTorch transformers and provide optimal training performance.\nPai-Megatron-Patch overview\nBlade\nBlade integrates various optimization technologies. You can use PAI-Blade to optimize the inference performance of a trained model.\nOverview of Blade\nPAI-SDK\nDistributed model training\nPAI SDK for Python provides an easy-to-use HighLevel API that allows you to submit training jobs to PAI and run the jobs in the cloud.\nSubmit a training job\nService deployment\nPAI SDK for Python provides an easy-to-use HighLevel API that allows you to deploy models to PAI and create inference services.\nDeploy an inference service"
    },
    "517": {
        "title": "Platform For AI:Billing of Machine Learning Designer",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/pricing-and-billing-of-product-modules",
        "content": "This Product\nPlatform For AI:Billing of Machine Learning Designer\nThis topic describes the billing rules of Machine Learning Designer of Platform for AI (PAI).\nThe pricing information in this topic is only for reference. The actual prices in the billing statement shall prevail.\n\nBillable resource\nBillable item\nBilling method\nStop billing\nBilling rule\nGeneral algorithm components\nRuntime of the component\nPay-as-you-go\nStop the component.\nThe resources consumption of the components is calculated based on billable hours on a pay-as-you-go basis.\nWhen you use the algorithm components in Machine Learning Designer, the unit price of the component varies based on the type of the algorithm. The following section describes the billing method.\nBilling formula: Bill amount = Number of billable hours \u00d7 Unit price\nNumber of billable hours = Max (Number of vCPUs \u00d7 Billing duration (h), Memory size (GB) \u00d7 Billing duration/4).\nBilling duration: The billing starts when the component starts to run and ends when the component stops running.\nBilling example: The following formula shows how to calculate the number of billable hours if you use 2 vCPUs and 5 GB of memory of a data analysis component for 1 hour and 30 minutes: Number of billable hours: Max (2 \u00d7 (1 + 30/60), 5 \u00d7 (1 + 30/60)/4) = 3. The bill amount is calculated by using the following formula: Bill amount = 3 \u00d7 0.21 = USD 0.63. The following table describes the unit price of each type of algorithm components:\nAlgorithm\nUnit price (USD per billable hour)\nAlgorithm description\nData preprocessing (data_manipulation)\n0.16\nIncludes the following types of components: data preprocessing and feature engineering.\nData analysis (data_analysis)\n0.21\nIncludes the following types of components: statistical analysis, machine learning, time series, network analysis, and financial.\nText analysis (text_analysis)\n0.27\nIncludes components that use text analysis algorithms.\nDeep learning (deep_learning)\n0.16\nDeep learning tasks that consume only CPU, including EasyRec-based components and the CPU version of Tensorflow-based framework components.\nIf you activate MaxCompute when you activate PAI, you are charged for MaxCompute resources when you use the SQL Script, JOIN, UNION, and Filtering and Mapping components. For more information, see Billing of MaxCompute.\nIf you activate Realtime Compute for Apache Flink when you activate PAI, you are charged when you use the Alink components. For more information, see Billing of Flink.\nA pipeline in Machine Learning Designer consists of multiple algorithm components. An algorithm component is composed of multiple subtasks. To calculate the fees for a pipeline, you need to calculate the fees of the subtasks in each algorithm component and then add the fees of all components that are used in the pipeline.\nDetermine the category of an algorithm component.\nLog on to the PAI console.\nIn the upper-left corner, select a region based on your business requirements.\nIn the left-side navigation pane, click Workspaces. On the Workspaces page, click the name of the workspace that you want to use.\nIn the left-side navigation pane, choose Model Training > Visual Modeling (Designer).\nOn the Pipelines page, select a pipeline and click Open to go to the canvas.\nIn the component list, the PLDA component is in the Natural Language Processing folder. The price of the PLDA component is USD 0.27 per billable hour.\n\nView the resources consumed for the job.\nOn the canvas, right-click the PLDA component.\nIn the menu that appears, click View Log.\nOn the Log-PLDA tab, click a hyperlink. Each hyperlink corresponds to a subtask.\n\nOn the LogView page, click the SourceXML tab.\nIn the TaskPlan section, you can view the value of the CPU and Memory fields.\nThe number of used vCPUs is calculated by using the following formula: CPU field value/100. In this example, 1 vCPU is used for running the job.\nThe unit of the Memory field is MB. In this example, 1,024 MB of memory is used to run the job.\nOn the LogView page, click the Job Details tab.\nClick the task object on the AlgoTask_0_0 tab. In the section that appears, click the Terminated tab. The Latency field specifies the running duration of each job.\nIn this example, the subtask has 49 jobs, and each job runs for approximately 26 seconds.\nCalculate the fee of the subtask.\nNumber of billable hours used in the subtask = Max (Number of vCPUs \u00d7 Usage duration, Memory size \u00d7 Usage duration/4) = Max [49 \u00d7 1 \u00d7 (26/3,600), 49 \u00d7 1 \u00d7 26/3,600/4] \u2248 0.35 billable hours\nSubtask fee = Number of billable hours \u00d7 Unit price = 0.35 \u00d7 0.27 \u2248 USD 0.095\nCalculate and add the total fee of all running subtasks in the PLDA component.\nRepeat the preceding steps to calculate and add the fees of all components used in the pipeline.\n"
    },
    "518": {
        "title": "Platform For AI:Billing of DSW",
        "url": "https://www.alibabacloud.com/help/en/pai/product-overview/dsw-billing-description",
        "content": "This Product\nPlatform For AI:Billing of DSW\nThis topic describes the billing rules of Data Science Workshop (DSW) of Platform for AI (PAI).\nThe following figure shows the billable resources of DSW.\n\n\nThe following table describes the billing methods of DSW.\nBilling method\nBillable resource\nBillable item\nBilling rule\nStop billing\nPay-as-you-go\nPublic resources\nThe running duration of a DSW instance , which is the duration for which the public resource group is occupied.\nThe public resource group is billed based on the amount of time during which public resources are occupied by the DSW instance.\nStop the instance.\nDelete the instance.\nPay-as-you-go\nSystem disk\nThe capacity and running duration of the system disk.\nYou can expand the system disk capacity. The expanded capacity is billed based on the capacity and running duration.\nDelete the DSW instance.\nSubscription\nAI computing resources (general computing resources and Lingjun resources)\nFor more information, see Billing of AI computing resources.\nFor more information, see Billing of AI computing resources.\nN/A\nIf you want to use the pay-as-you-go billing method, you must use public resources to create a DSW instance.\nBillable resource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nPublic resources\n\nBill amount = (Price/60) \u00d7 Running duration. The running duration is measured in minutes.\nThe price of a DSW instance may vary based on the region. To view the actual price of an instance, go to the Create Instance page in the PAI console and set the Resource Quota parameter to Public Resource Group (Pay-as-you-go). For information about how to go to the Create Instance page, see Create a DSW instance.\nRunning duration of a DSW instance\nN/A\nN/A\nSystem disk\nBill amount = System disk capacity (GiB) \u00d7 Unit price \u00d7 Running duration (hours).\nFor information about pricing, visit the ECS pricing page. Choose Pricing > Storage and view the System Cloud Disk Fee.\nAfter you expand the system disk capacity, you are charged based on the capacity that exceeds the free quota and running duration.\nThe billing starts when the capacity is expanded.\nN/A\nAI computing resources include general computing resources and Lingjun resources. If you want to use the subscription billing method, you must purchase AI computing resource quotas and use the resource quotas to create DSW instances. For more information, see Billing of AI computing resources.\n\nThe following billing examples are only for reference. For the actual fees, go to the console or buy page of the service that you want to purchase.\nScenario\nFor example, you use public resources to create a DSW instance of the ecs.g6.13xlarge instance type that is deployed in the China (Shanghai) region. The instance runs for 1 minute and 15 seconds.\nFee calculation\nScenario\nFor example, you use dedicated resources to create two DSW instances of the ecs.g6.13xlarge-52c192g instance type that are deployed in the China (Shanghai) region. The subscription period is two months and the unit price is USD 980.57 per month.\nFee calculation"
    },
    "519": {
        "title": "Platform For AI:Billing of DLC",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/pai-dlc-billing",
        "content": "This Product\nPlatform For AI:Billing of DLC\nThis topic describes how you are billed for Deep Learning Containers (DLC) of Platform for AI (PAI).\nThe pricing information in this topic is only for reference. You can view the actual prices in your billing statements.\nThe following figure shows the billable resources of DLC.\n\nThe following table describes the billing methods of DLC.\nBilling method\nBillable resource\nBillable item\nBilling rule\nHow to stop billing\nPay-as-you-go\nPublic resources\nThe amount of time for which DLC jobs run by using public resources.\nIf you run DLC jobs by using public resources, you are charged based on the usage duration.\nBilling stops when DLC jobs are complete.\nBilling stops when you stop DLC jobs.\nSubscription\nAI computing resources (general computing resources and Lingjun resources)\nFor more information, see Billing of AI computing resources.\nFor more information, see Billing of AI computing resources.\nN/A\nTo use the pay-as-you-go billing method, you must use public resources to create DLC jobs.\nResource\nBilling formula\nUnit price\nBilling duration\nScaling\nUsage notes\nPublic resources\n\nBill amount = Number of nodes \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nThe unit prices may vary based on the instance type and region. To view the unit prices, go to the Create Job page in the PAI console. For more information, see Submit a job in the console. In the Resource Information section, set the Source parameter to Public Resources and select an instance type. You can view the unit price of the instance in the Current Price/Original Price ($/Hour) column.\nRunning duration of DLC jobs.\nN/A\nNone\nAI computing resources include general computing resources and Lingjun resources. AI computing resources support only the subscription billing method. You can add resource quotas for purchased AI computing resources and use the quotas to create DLC jobs. For more information, see Billing of AI computing resources.\nThe following example is only for reference. You can view the actual prices in the console or on the buy page.\nScenario\nYou purchase a pay-as-you-go ecs.g6.2xlarge instance in the China (Shanghai) region to create a training job. The job runs for 1 minute and 15 seconds.\nFee calculation\nFor billing examples of AI computing resources, see Billing of AI computing resources.\nThe following table describes some of the instance types that can be used to create DLC jobs in the public resource group. For a complete list of the supported instance types, go to the DLC page in the PAI console and click Create Job. You can view the supported instance types in the Resource Information section. For more information, see Submit a job in the console. The supported instance types may vary based on the region.\nInstance type\nSpecification\nGPU\necs.g6.xlarge\n4 vCPUs + 16 GB memory\nNone\necs.c6.large\n2 vCPUs + 4 GB memory\nNone\necs.g6.large\n2 vCPUs + 8 GB memory\nNone\necs.g6.2xlarge\n8 vCPUs + 32 GB memory\nNone\necs.g6.4xlarge\n16 vCPUs + 64 GB memory\nNone\necs.g6.8xlarge\n32 vCPUs + 128 GB memory\nNone\necs.r7.large\n2 vCPUs + 16 GB of memory\nNone\necs.r7.xlarge\n4 vCPUs + 32 GB memory\nNone\necs.r7.2xlarge\n8 vCPUs + 64 GB memory\nNone\necs.r7.4xlarge\n16 vCPUs + 128 GB memory\nNone\necs.r7.6xlarge\n24 vCPUs + 192 GB memory\nNone\necs.r7.8xlarge\n32 vCPUs + 256 GB memory\nNone\necs.r7.16xlarge\n64 vCPUs + 512 GB memory\nNone\necs.g5.xlarge\n4 vCPUs + 16 GB memory\nNone\necs.g7.xlarge\n4 vCPUs + 16 GB memory\nNone\necs.g7.2xlarge\n8 vCPUs + 32 GB memory\nNone\necs.g5.2xlarge\n8 vCPUs + 32 GB memory\nNone\necs.g6.3xlarge\n12 vCPUs + 48 GB memory\nNone\necs.g7.3xlarge\n12 vCPUs + 48 GB memory\nNone\necs.g7.4xlarge\n16 vCPUs + 64 GB memory\nNone\necs.r7.3xlarge\n12 vCPUs + 96 GB memory\nNone\necs.c6e.8xlarge\n32 vCPUs + 64 GB memory\nNone\necs.g6.6xlarge\n24 vCPUs + 96 GB memory\nNone\necs.g7.6xlarge\n24 vCPUs + 96 GB memory\nNone\necs.g5.4xlarge\n16 vCPUs + 64 GB memory\nNone\necs.hfc6.8xlarge\n32 vCPUs + 64 GB memory\nNone\necs.g7.8xlarge\n32 vCPUs + 128 GB memory\nNone\necs.hfc6.10xlarge\n40 vCPUs + 96 GB memory\nNone\necs.g6.13xlarge\n52 vCPUs + 192 GB memory\nNone\necs.g5.8xlarge\n32 vCPUs + 128 GB memory\nNone\necs.hfc6.16xlarge\n64 vCPUs + 128 GB memory\nNone\necs.g7.16xlarge\n64 vCPUs + 256 GB memory\nNone\necs.hfc6.20xlarge\n80 vCPUs + 192 GB memory\nNone\necs.g6.26xlarge\n104 vCPUs + 384 GB memory\nNone\necs.g5.16xlarge\n64 vCPUs + 256 GB memory\nNone\necs.r5.8xlarge\n32 vCPUs + 256 GB memory\nNone\necs.re6.13xlarge\n52 vCPUs + 768 GB memory\nNone\necs.re6.26xlarge\n104 vCPU + 1,536 GB memory\nNone\necs.re6.52xlarge\n208 vCPU + 3,072 GB memory\nNone\necs.g7.32xlarge\n128 vCPU + 512 GB memory\nNone\necs.gn7i-c8g1.2xlarge\n8 vCPUs + 30 GB memory\n1 \u00d7 NVIDIA A10\necs.gn6v-c8g1.2xlarge\n8 vCPUs + 32 GB memory\n1 \u00d7 NVIDIA V100\necs.gn6e-c12g1.24xlarge\n96 vCPUs + 736 GB memory\n8 \u00d7 NVIDIA V100\necs.gn6v-c8g1.16xlarge\n64 vCPUs + 256 GB memory\n8 \u00d7 NVIDIA V100\necs.gn6v-c10g1.20xlarge\n82 vCPUs + 336 GB memory\n8 \u00d7 NVIDIA V100\necs.gn6e-c12g1.12xlarge\n48 vCPUs + 338 GB memory\n4 \u00d7 NVIDIA V100\necs.gn6v-c8g1.8xlarge\n32 vCPUs + 128 GB memory\n4 \u00d7 NVIDIA V100\necs.gn6i-c24g1.24xlarge\n96 vCPUs + 372 GB memory\n4 \u00d7 NVIDIA T4\necs.gn5-c8g1.4xlarge\n16 vCPUs + 120 GB memory\n2 \u00d7 NVIDIA P100\necs.gn7i-c32g1.16xlarge\n64 vCPUs + 376 GB memory\n2 \u00d7 NVIDIA A10\necs.gn6i-c24g1.12xlarge\n48 vCPUs + 186 GB memory\n2 \u00d7 NVIDIA T4\necs.gn6e-c12g1.3xlarge\n12 vCPUs + 92 GB memory\n1 \u00d7 NVIDIA V100\necs.gn5-c4g1.xlarge\n4 vCPUs + 30 GB memory\n1 \u00d7 NVIDIA P100\necs.gn5-c8g1.2xlarge\n8 vCPUs + 60 GB memory\n1 \u00d7 NVIDIA P100\necs.gn5-c28g1.7xlarge\n28 vCPUs + 112 GB memory\n1 \u00d7 NVIDIA P100\necs.gn6i-c4g1.xlarge\n4 vCPUs + 15 GB memory\n1 \u00d7 NVIDIA T4\necs.gn6i-c8g1.2xlarge\n8 vCPUs + 31 GB memory\n1 \u00d7 NVIDIA T4\necs.gn6i-c16g1.4xlarge\n16 vCPUs + 62 GB memory\n1 \u00d7 NVIDIA T4\necs.gn6i-c24g1.6xlarge\n24 vCPUs + 93 GB memory\n1 \u00d7 NVIDIA T4\necs.gn7i-c32g1.8xlarge\n32 vCPUs + 188 GB memory\n1 \u00d7 NVIDIA A10\necs.gn7e-c16g1.4xlarge\n16 vCPUs + 125 GB memory\n1 \u00d7 GU50\necs.gn7-c12g1.3xlarge\n12 vCPUs + 95 GB memory\n1 \u00d7 GU50\necs.gn7i-c16g1.4xlarge\n16 vCPUs + 60 GB memory\n1 \u00d7 NVIDIA A10\necs.gn7-c13g1.26xlarge\n104 vCPUs + 760 GB memory\n8 \u00d7 GU50\necs.ebmgn7e.32xlarge\n128 vCPUs + 1,024 GB memory\n8 \u00d7 GU50\necs.gn7i-c32g1.32xlarge\n128 vCPUs + 752 GB memory\n4 \u00d7 NVIDIA A10\necs.gn7-c13g1.13xlarge\n52 vCPUs + 380 GB memory\n4 \u00d7 GU50\necs.gn7s-c32g1.32xlarge\n128 vCPUs + 1,000 GB memory\n4 \u00d7 NVIDIA A30\necs.gn7s-c56g1.14xlarge\n56 vCPUs + 440 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c48g1.12xlarge\n48 vCPUs + 380 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c16g1.4xlarge\n16 vCPUs + 120 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c8g1.2xlarge\n8 vCPUs + 60 GB memory\n1 \u00d7 NVIDIA A30\necs.gn7s-c32g1.8xlarge\n32 vCPUs + 250 GB memory\n1 \u00d7 NVIDIA A30"
    },
    "520": {
        "title": "Platform For AI:Billing of EAS",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/pai-eas-billing",
        "content": "This Product\nPlatform For AI:Billing of EAS\nThis topic describes the billable items and billing methods of Elastic Algorithm Service (EAS) of Platform for AI (PAI).\nThe pricing information in this topic is only for reference. The actual prices in the billing statement shall prevail.\nThe following figure shows the billable resources of EAS.\n\n\nThe following table describes the billing methods of EAS.\nBilling method\nBillable resource\nBillable item\nBilling rule\nStop billing\nPay-as-you-go\nPublic resource group\nThe amount of time for which a model service runs by using public resources.\nIf you use public resources to deploy a model service, you are charged based on the usage duration. Billing starts immediately after model services are deployed.\nStop model services.\nPay-as-you-go\nEAS resources (dedicated resource group)\nThe number of nodes and the usage duration.\nIf you use dedicated resources to deploy a model service, you are charged only for nodes in the dedicated resource group. Billing starts immediately after pay-as-you-go nodes are created in dedicated resource groups.\nDelete pay-as-you-go nodes from dedicated resource groups.\nSubscription\nThe number of nodes and the subscription duration.\nN/A\nPay-as-you-go\nSystem disk\nThe system disk capacity and the usage duration.\nBilling starts immediately after the system disk is created.\nDelete nodes from dedicated resource groups.\nDelete model services deployed in the public resource group.\nSubscription\nThe system disk capacity and the subscription duration.\nBilling starts immediately after the system disk is created.\nN/A\nSubscription\nAI computing resources (Lingjun resources)\nFor more information, see Billing of AI computing resources.\nFor more information, see Billing of AI computing resources.\nN/A\nPay-by-inference-duration\nService calls\nThe inference duration of the Serverless Edition service.\nYou are billed based on the inference duration of the Serverless Edition service.\nIf you do not use the service to perform inference, you are not charged.\nPay-as-you-go\nDedicated gateway\nThe number and usage duration of gateway nodes.\nYou are billed based on the number of gateway nodes you purchase and the usage duration of the nodes.\nDelete dedicated gateways.\nSubscription\nThe number and purchase duration of gateway nodes\nYou are billed based on the number of gateway nodes you purchase and the usage duration of the nodes.\nN/A\nThe public resource group supports only the pay-as-you-go billing method. When you deploy a model service in the public resource group, you can select an instance type that has predefined resources or specify resources based on your business requirements.Dedicated resource group (pay-as-you-go)\nResource type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nSpecified resources\nBill amount for each model service = Number of nodes \u00d7 [Number of vCPUs \u00d7 (Unit price of vCPUs/60) + Memory size \u00d7 (Unit price of memory/60)] \u00d7 Usage duration (minutes)\nFor the unit prices per hour of vCPUs and memory, see Table 1. Pricing for specified resources in this topic. Fees are billed per minute. You can calculate the unit prices per minute by dividing the prices listed in Table 1 by 60.\nBilling starts when a model service starts to run and consume resources.\nBilling ends when a model service stops running and releases resources.\nIf you scale out a model service, you are charged for new resources after the scale-out activity is complete.\nIf you scale in a model service, the released resources are no longer billed. You are charged only for the remaining resources.\nThe usage duration is measured in minutes.\nTo prevent unnecessary costs, we recommend that you stop model services that you no longer use.\nSpecified instance type\nBill amount for each model service = Number of nodes \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nUnit prices may vary based on the instance type and the region. To view the unit prices of nodes, go to the EAS page in the PAI console, click Deploy Service, and then click Custom Deployment. In the Resource Deployment Information section, set the Resource Group Type parameter to Public Resource Group and select the instance type that you want to use. The unit price of the instance is displayed. For more information, see Model service deployment by using the PAI console.\nFor information about the instance types supported by the public resource group, see Appendix: Public resource group instance types.\nBilling starts when a model service starts to run and consume resources.\nBilling ends when a model service stops running and releases resources.\nN/A\nThe usage duration is measured in minutes.\nTo prevent unnecessary costs, we recommend that you stop model services that you no longer use.\nSpecific resources may be unavailable in specific regions for a short period of time.\nTable 1. Resource-based configuration\nThe unit prices listed in the following table are only for reference. You can view the actual prices in the console or on the buy page of the service resource that you want to purchase.\nResource\nUnit price\nvCPU\nUSD 0.03 per vCPU-hour\nMemory\nUSD 0.004 per GB-hour\nEAS resources support the pay-as-you-go billing method.\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated resource group\nBill amount for each resource group = Number of nodes \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nFor information about the unit prices of pay-as-you-go nodes, go to the EAS post-payment for dedicated machine buy page.\nBilling starts immediately after a node is created in a dedicated resource group and enters the Running state.\nBilling ends when all resources in a dedicated resource group are released.\nIf you scale out a model service, you are charged for new resources after the scale-out activity is complete.\nIf you scale in a model service, the released resources are no longer billed. You are charged only for the remaining resources.\nThe usage duration is measured in minutes.\nSpecific instance types may become unavailable for short periods of time in specific regions. In this case, you can purchase instances in different regions.\nEAS resources also support the subscription billing method.\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated resource group\nBill amount for each resource group = Number of nodes \u00d7 Unit price \u00d7 Subscription duration (months)\nFor information about the unit prices of subscription nodes, go to the EAS pre-payment for dedicated machine buy page.\nBilling starts at 00:00:00 the next day after the purchase.\nBilling ends when the subscription expires.\nN/A\nSpecific instance types may become unavailable for short periods of time in specific regions. In this case, you can purchase instances in different regions.\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nSystem disk\nBill amount = Number of nodes \u00d7 System disk capacity (GiB) \u00d7 (Unit price/60) \u00d7 Usage duration (minutes)\nTo view the unit prices of system disks, go to the product overview page of Elastic Compute Service (ECS), click the Pricing tab, and then click Storage. The pricing information of Enhanced SSD PL1 is displayed in the System Cloud Disk Fee section.\nBilling starts immediately after a system disk is created.\nBilling ends when nodes are deleted from dedicated resource groups or when model services deployed in the public resource group are deleted.\nN/A\nN/A\nResource\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nSystem disk\nBill amount = Number of nodes \u00d7 System disk capacity (GiB) \u00d7 Unit price \u00d7 Subscription duration (months)\nTo view the unit prices of system disks, go to the product overview page of ECS, click the Pricing tab, and then click Storage. The pricing information of Enhanced SSD PL1 is displayed in the System Cloud Disk Fee section.\nBilling starts immediately after a system disk is created.\nBilling ends when the subscription expires.\nN/A\nNone\nLingjun resources support the subscription billing method. You can deploy model services in EAS by using Lingjun resource quotas. For more information, see Billing of AI computing resources.\nThe deployment of Serverless Edition services is free of charge. You are charged only if you call the services based on the inference duration. For example, if you click Generate on the web UI page to generate an image and the process requires 10 seconds, the billing duration is 10 seconds.\nTo view the pricing details, go to the Deploy Service page in the PAI console, click AI Painting - SD Web UI Deployment in the Scenario-based Deployment section, and then select Serverless Edition. The pricing information is displayed in the Total Configuration Fee section. For more information, see Use SD web UI to deploy an AI painting service.\nResource type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated gateway\nBill amount = (Unit price/60) \u00d7 Number of gateway nodes \u00d7 Usage duration (minutes)\nTo view the unit prices of dedicated gateways, go to the EAS Dedicated Gateway Postpay buy page.\nBilling starts immediately after a dedicated gateway is purchased.\nBilling ends when the dedicated gateway is deleted.\nN/A\nN/A\nResource type\nFee calculation\nUnit price\nBilling duration\nScaling description\nUsage notes\nDedicated gateway\nBill amount = Unit price \u00d7 Number of gateway nodes \u00d7 Usage duration (months)\nTo view the unit prices of dedicated gateways, go to the EAS Dedicated Gateway Prepay buy page.\nBilling starts immediately after a dedicated gateway is purchased.\nBilling ends when the dedicated gateway expires.\nN/A\nN/A\n\nThe following examples are for reference only. The actual prices listed on the EAS buy page of the PAI console shall prevail.\nScenario\nYou used the public resource group to deploy a model service in the China (Hangzhou) region. You specified the public resources used for model deployment based on your business requirements.\nThe model service occupied 2 vCPUs and 8 GB of memory and started to run at 09:00:00 (UTC+8) on June 3, 2019.\nYou scaled in the model service and reduced the occupied resources to 1 vCPU and 4 GB of memory at 10:00:00 (UTC+8) on June 3, 2019.\nYou scaled out the model service and increased the occupied resources to 4 vCPUs and 16 GB of memory at 11:00:00 (UTC+8) on June 3, 2019.\nThe model service stopped running at 12:00:00 (UTC+8) on June 3, 2019.\nFee calculation\nScenario\nYou subscribed to two NVIDIA T4 GPUs in the China (Hangzhou) region for three months. Each GPU provides 4 vCPUs and 15 GB of memory. The unit price of the GPU is USD 570 per month.\nFee calculation\nScenario\nYou purchased two pay-as-you-go ecs.g6.6xlarge instances in the China (Hangzhou) region and used the instances for 45 minutes. Each instance provides 24 vCPUs and 96 GB of memory. The unit price of the instance is USD 1.02 per hour.\nFee calculation\nScenario\nYou purchased two subscription instances in the China (Hangzhou) region for a dedicated resource group. Each instance provides a system disk capacity of 300 GiB (free storage: 200 GiB). The subscription duration is three months.\nFee calculation\nDedicated resource group\nScenario\nYou purchased two pay-as-you-go instances in the China (Hangzhou) region for a dedicated resource group and used them for 5 hours. Each instance provides a system disk capacity of 300 GiB (free storage: 200 GiB).\nFee calculation\nPublic resource group\nScenario\nYou purchased two pay-as-you-go instances in the public resource group and deployed them in the China (Hangzhou) region. You used the instances for 5 hours. Each instance provides a system disk capacity of 300 GiB (free storage: 30 GiB).\nFee calculation\nThe following table lists some of the instance types that can be used to deploy EAS services in the public resource group. For a complete list of supported instance types, go to the EAS page in the PAI console, click Deploy Service, and then click Custom Deployment. In the Resource Deployment Information section, you can view the supported instance types. For more information, see Model service deployment by using the PAI console. The supported instance types may vary based on the region.\nInstance type\nvCPU\nMemory (GiB)\necs.c7.large\n2\n4\necs.c7.xlarge\n4\n8\necs.c7.2xlarge\n8\n16\necs.c7.4xlarge\n16\n32\necs.c7.6xlarge\n24\n48\necs.c7.8xlarge\n32\n64\necs.c7.16xlarge\n64\n128\necs.r7.4xlarge\n16\n128\necs.r7.large\n2\n16\necs.r7.xlarge\n4\n32\necs.r7.2xlarge\n8\n64\necs.r7.6xlarge\n24\n192\necs.r7.8xlarge\n32\n256\necs.r7.16xlarge\n64\n512\necs.g7.large\n2\n8\necs.g7.xlarge\n4\n16\necs.g7.2xlarge\n8\n32\necs.g7.4xlarge\n16\n64\necs.g7.6xlarge\n24\n96\necs.g7.8xlarge\n32\n128\necs.g7.16xlarge\n64\n256\necs.g6.large\n2\n8\necs.g6.xlarge\n4\n16\necs.g6.2xlarge\n8\n32\necs.g6.4xlarge\n16\n64\necs.g6.6xlarge\n24\n96\necs.g6.8xlarge\n32\n128\necs.c6.large\n2\n4\necs.c6.xlarge\n4\n8\necs.c6.2xlarge\n8\n16\necs.c6.4xlarge\n16\n32\necs.c6.6xlarge\n24\n48\necs.c6.8xlarge\n32\n64\necs.r6.large\n2\n16\necs.r6.xlarge\n4\n32\necs.r6.2xlarge\n8\n64\necs.r6.4xlarge\n16\n128\necs.r6.6xlarge\n24\n192\necs.r6.8xlarge\n32\n256\necs.g5.6xlarge\n24\n96\necs.c5.6xlarge\n24\n48\necs.g8y.large\n2\n8\necs.g8y.xlarge\n4\n16\necs.g8y.2xlarge\n8\n32\necs.g8y.4xlarge\n16\n64\necs.g8y.8xlarge\n32\n128\necs.g8y.16xlarge\n64\n256\necs.c7a.large\n2\n4\necs.c7a.xlarge\n4\n8\necs.c7a.2xlarge\n8\n16\necs.c7a.4xlarge\n16\n32\necs.c7a.8xlarge\n32\n64\necs.c7a.16xlarge\n64\n128\necs.g7a.large\n2\n8\necs.g7a.xlarge\n4\n16\necs.g7a.2xlarge\n8\n32\necs.g7a.4xlarge\n16\n64\necs.g7a.8xlarge\n32\n128\necs.g7a.16xlarge\n64\n256\nInstance type\nvCPU\nMemory (GiB)\nGPU memory\nml.gu7i.c8m30.1-gu30\n8\n30\n1 * 24 GB\nml.gu7i.c16m60.1-gu30\n16\n60\n1 * 24 GB\nml.gu7i.c32m188.1-gu30\n32\n188\n1 * 24 GB\nml.gu7i.c64m376.2-gu30\n64\n376\n2 * 24 GB\nml.gu7i.c128m752.4-gu30\n80\n256\n4 * 24 GB\necs.gn5i-c4g1.xlarge\n4\n16\n1 * 8 GB\necs.gn5i-c8g1.2xlarge\n8\n32\n1 * 8 GB\necs.gn5-c4g1.xlarge\n4\n30\n1 * 16 GB\necs.gn5-c8g1.2xlarge\n8\n60\n1 * 16 GB\necs.gn5-c8g1.4xlarge\n16\n120\n2 * 16 GB\necs.gn5-c28g1.7xlarge\n28\n112\n1 * 16 GB\necs.vgn6i-m4-vws.xlarge\n4\n23\n1 * 4 GB\necs.vgn6i-m8-vws.2xlarge\n10\n46\n1 * 8 GB\necs.gn6i-c4g1.xlarge\n4\n15\n1 * 16 GB\necs.gn6i-c8g1.2xlarge\n8\n31\n1 * 16 GB\necs.gn6i-c16g1.4xlarge\n16\n62\n1 * 16 GB\necs.gn6i-c24g1.6xlarge\n24\n93\n1 * 16 GB\necs.gn6i-c24g1.12xlarge\n48\n186\n2 * 16 GB\necs.gn6i-c24g1.24xlarge\n96\n372\n4 * 16 GB\necs.gn7i-c8g1.2xlarge\n8\n30\n1 * 24 GB\necs.gn7i-c16g1.4xlarge\n16\n60\n1 * 24 GB\necs.gn7i-c32g1.8xlarge\n32\n188\n1 * 24 GB\necs.gn7i-c32g1.16xlarge\n64\n376\n2 * 24 GB\necs.gn7i-c32g1.32xlarge\n128\n752\n4 * 24 GB\necs.gn6v-c8g1.2xlarge\n8\n32\n1 * 16 GB\necs.gn6v-c8g1.4xlarge\n16\n64\n2 * 16 GB\necs.gn6v-c8g1.8xlarge\n32\n128\n4 * 16 GB\necs.gn6e-c12g1.3xlarge\n12\n92\n1 * 32 GB\necs.gn6e-c12g1.12xlarge\n48\n368\n4 * 32 GB\necs.gn6e-c12g1.24xlarge\n96\n736\n8 * 32 GB\necs.gn7-c12g1.3xlarge\n12\n94\n1 * 40 GB\necs.gn7-c13g1.13xlarge\n52\n378\n4 * 40 GB\necs.gn7-c13g1.26xlarge\n104\n756\n8 * 40 GB\necs.gn7-c13g1.6xlarge\n26\n189\n2 * 40 GB\necs.gn7e-c16g1.4xlarge\n16\n125\n1 * 80 GB\necs.gn7e-c16g1.8xlarge\n32\n250\n2 * 80 GB\necs.gn7e-c16g1.16xlarge\n64\n500\n4 * 80 GB\necs.gn7e-c16g1.32xlarge\n128\n1000\n8 * 80 GB"
    },
    "521": {
        "title": "Platform For AI:Scenario-based solution billing description",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/scenario-solution-billing-description",
        "content": "This Product\nPlatform For AI:Scenario-based solution billing description"
    },
    "522": {
        "title": "Platform For AI:Demo for creating a pipeline by using a template",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/get-started-quickly-in-10-minutes",
        "content": "This Product\nPlatform For AI:Demo for creating a pipeline by using a template\nMachine Learning Designer has dozens of preset templates that are developed based on different frameworks to meet the requirements of different industry scenarios. You can create a pipeline by using a preset template and modify the components or the component configurations to build a model based on your business requirements. In this topic, the Heart Disease Prediction template is used to describe how to build a model in a visualized manner.\nPlatform for AI (PAI) is activated and a default workspace is created. For more information, see Activate PAI and create a default workspace.\nMachine Learning Designer allows you to build models by using pipelines. To build a model, you must create a pipeline, add different components to the pipeline, and then arrange the components based on the logic of your model.\nLog on to the PAI console and go to the Visualized Modeling (Designer) page. On the Visualized Modeling (Designer) page, select a workspace and click Enter Visualized Modeling (Designer).\nOn the Pipelines tab of the Visualized Modeling (Designer) page, click the Preset Templates tab. On the Preset Templates tab, click Create in the Heart Disease Prediction template.\n\nIn the Create Pipeline dialog box, configure related parameters and click OK.\nParameter\nDescription\nPipeline Name\nSpecify a name for the pipeline that you want to create.\nData Storage\nThe path of the Object Storage Service (OSS) bucket that stores the temporary data and models generated during pipeline runtime. We recommend that you configure this parameter. If you leave this parameter empty, the default storage of the workspace is used.\nThe system automatically creates a temporary directory in the <Pipeline data path>/<Task ID>/<Node ID> format for each run. This saves you from creating an OSS directory for storing data of each component and allows you to manage data in a centralized manner.\nVisibility\nVisible to Me: A workflow is created in the My Pipelines folder and is visible only to you and the administrator in the workspace.\nVisible to Current Workspace: A pipeline is created in the Pipelines Visible to Workspaces folder and is visible to all members of the current workspace.\nFor more information about the configuration methods and the parameters, see Create a pipeline.\nOn the page that appears, click Open.\nThe following figure shows the model built by using the preset template.\n\nTo quickly build the model, the preset template contains pre-configured parameters for each component. You can click a component to view the related parameters. For more information, see Predict heart disease.\nIf you need to perform Step 4: Use the model for prediction, you must click the Logistic Regression for Binary Classification node and select Whether to Generate PMML on the right-side Fields Setting tab.\nIn the upper-left corner of the canvas, click the  icon to run the pipeline.\nView data and perform visual analysis\nAfter a component runs, you can right-click the component and select View Data to view the generated data.\nFor specific components such as the Confusion Matrix and Binary Classification Evaluation components, Machine Learning Designer allows you to convert data into graphs and charts to display complex data and analysis results in an intuitive and simple manner. This helps you quickly obtain key information and identify trends and patterns for more efficient analysis and decision-making. To analyze data in a visualized manner, you can right-click a component and select Visual Analysis or click the visualization icon in the upper part of the canvas. For more information, see Visualized analysis.\nView logs\nIf a component fails to run, you can right-click the component and select View Log to troubleshoot the issue.\nMachine Learning Designer is seamlessly integrated with Elastic Algorithm Service (EAS). After you train and evaluate a model in Machine Learning Designer offline, you can deploy the model to EAS as an online service.\nAfter you run the pipeline, click Models, select the model that you want to deploy, and then click Deploy in EAS.\n\nConfirm the parameter configurations. For more information, see Deploy a model as an online service.\nOn the Deploy Service page, the Model File and Processor Type parameters are automatically configured. You can modify other parameters based on your business requirements.\nClick Deploy.\nWhen the service status changes from Creating to Running, the model is deployed.\nIf you do not use the model temporarily, click Stop in the Actions column to avoid unnecessary charges.\nYou can build and debug a model in a pipeline. For more information, see Build and debug a model.\nYou can create a blank pipeline and arrange different components to handle scheduling logic from scratch based on your business requirements. For more information, see Custom pipelines.\nDataWorks allows you to schedule offline pipelines and periodically modify models. For more information, see Use DataWorks tasks to schedule pipelines in Machine Learning Designer.\nFor information about the billing of Machine Learning Designer, see Billing of Machine Learning Designer.\nFor information about components, see Component reference: Overview of all components.\nFor information about how to build a model in a visualized manner, see Use cases for Designer."
    },
    "523": {
        "title": "Platform For AI:Component reference: data source or destination",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/source-and-target-1",
        "content": "This Product\nPlatform For AI:Component reference: data source or destination"
    },
    "524": {
        "title": "Platform For AI:Component reference: Deep learning",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/deep-learning-framework-components",
        "content": "This Product\nPlatform For AI:Component reference: Deep learning"
    },
    "525": {
        "title": "Platform For AI:AutoML",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/use-automl-for-automatic-feature-engineering",
        "content": "This Product\nPlatform For AI:AutoML\nPlatform for AI (PAI) provides AutoML to help you search for optimal hyperparameter combinations based on specific policies. You can use AutoML to improve the efficiency of model tuning.\nHyperparameter: external parameters used to train models. You need to configure hyperparameters before you start to train a model. After you configure the hyperparameters of a model, the hyperparameters remain unchanged during model training. In contrast, the parameters of a model are constantly updated and optimized during the machine learning process.\nHyperparameter optimization (HPO): a process that allows for manual or automatic hyperparameter fine-tuning. In this topic, HPO refers to the service provided by AutoML that automatically searches and fine-tunes hyperparameters. HPO can help you obtain optimal hyperparameters and improve the model performance in an efficient manner. HPO also allows algorithm developers to focus on modeling.\nSearch space: a range of possible values of hyperparameter combinations. AutoML searches for the optimal hyperparameter combination within this range.\nExperiment: You can search for the optimal hyperparameter combination of a model in the search space by creating an experiment.\nTrial: Each trial involves model training, generation, and evaluation by using a specific hyperparameter combination. An experiment runs multiple trials and compares the results of the trials to find the optimal hyperparameter combination. For more information, see How AutoML works.\nJob type: the resources and environment that are used for training in a trial. Valid values: Deep Learning Containers (DLC) and MaxCompute.\nIn machine learning, hyperparameters are a set of parameters that are used to train models.\nHPO is the process of finding the optimal hyperparameters. If a model has multiple hyperparameters, such as a multi-dimensional vector, HPO finds the specific vector value that provides the optimal model performance across all the ranges of the vector values of this model.\nFor example, a model has two hyperparameters A and B. Possible values for A are a, b, and c, and possible values for B are d and e. In this case, the model has six hyperparameter combinations. For this model, HPO finds the specific combination of A and B that allows the model to outperform other models. To obtain the optimal hyperparameter combination, separately use the six combinations of A and B for model training on the same training dataset. Then, compare the model performance by using the same test dataset.\nHyperparameter fine-tuning is complex because the process involves a large amount of model hyperparameters and various data types and value ranges of hyperparameters. For example, a model has multiple hyperparameters, in which some hyperparameters are of the integer type and some parameters are of the floating-point type. In this case, manual hyperparameter tuning requires a large amount of computing resources. In this case, an automated system is required to complete the task. The HPO feature of AutoML can help you automatically fine-tune various hyperparameters.\nYou can use AutoML to fine-tune hyperparameters in a simple, efficient, and accurate manner. The following section describes the benefits of using AutoML:\nSimplified fine-tuning: AutoML greatly simplifies the process of hyperparameter fine-tuning and saves time by using automated tools.\nImproved model quality: AutoML integrates multiple algorithms of PAI to quickly find the optimal hyperparameter combination. This helps you train models in a more accurate and efficient manner.\nReduced computing resources: AutoML evaluates the model performance during the training to determine whether to terminate the current training and evaluate another hyperparameter combination. AutoML allows you to obtain the optimal hyperparameter combination without the need to evaluate all combinations. This helps you save computing resources.\nFlexible use of computing power: You can use DLC and MaxCompute resources in AutoML in a convenient and flexible manner.\nAutoML is suitable for all hyperparameter fine-tuning scenarios in machine learning training. The following section provides common scenarios in machine learning:\nBinary classification tasks, such as determining whether a user is a paying user.\nRegression tasks, such as estimating the payment amount a user makes within seven days.\nClustering tasks, such as determining the number of branches of a cosmetic brand in a city.\nRecommendation tasks, such as fine-tuning ranking and retrieval models, or improving the area under curve (AUC) metric.\nDeep learning tasks, such as improving the accuracy of image multi-classification and video multi-classification.\nHow AutoML works\n(Recommend.) This topic describes how AutoML works and the relationship between experiments, trials, and training tasks. This helps you become familiar with the concepts and facilitate configuration.\nCreate an experiment\nThis topic describes how to create an experiment in the PAI console and how to configure key parameters.\nAutoML use cases\nThis topic provides use cases of how to use AutoML to fine-tune hyperparameters."
    },
    "526": {
        "title": "Platform For AI:Create a DSW instance",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/purchase-notice",
        "content": "This Product\nPlatform For AI:Create a DSW instance\nData Science Workshop (DSW) is a cloud integrated development environment (IDE) that is provided by Platform for AI (PAI) for interactive programming of machine learning. Before you use DSW, you must create a DSW instance. This topic describes how to create a DSW instance.\nIf you use DSW to develop models, you can create and manage DSW instances in the PAI console.\nThe required permissions are granted.\nActivate PAI and create a workspace by using an Alibaba Cloud account. Log on to the PAI console, select a region where you want to activate PAI in the upper-left corner of the page, and then complete authentication, authorization, and service activation. For more information, see Activate PAI and create a default workspace.\nAuthorize the operation account. If you use an Alibaba Cloud account to manage DSW instances, skip this step. If you use a RAM account, you must authorize the operation account.\n(Optional) A dedicated resource group is prepared.\nAfter you complete configurations in Step 1, a public resource group is prepared. If you want to use a dedicated resource group, you must purchase dedicated resources and allocate resource quotas.\nIf you want to use a dedicated resource group of general computing resources, see Create a dedicated resource group and purchase general computing resources and General computing resource quotas.\nIf you want to use a dedicated resource group of Lingjun resources, see Create a resource group and purchase Lingjun resources and Lingjun resource quotas.\n(Optional) A dataset is prepared.\nThe default data storage size of public and dedicated resource groups is limited and does not support persistent storage. If you want to expand the storage space of an instance or persistently store data, you can mount a File Storage NAS (NAS) or Object Storage Service (OSS) dataset or an OSS path. For more information about how to create a dataset, see Create and manage datasets.\nIf you create a DSW instance by using the public resource group, data is stored in free disks with limited storage space. Data is cleared after the instance is deleted or stopped for more than 15 days.\nIf you create a DSW instance by using the dedicated resource group, data is stored in the system disk of the instance. Data in the temporary storage is cleared after the instance is deleted or stopped.\n(Optional) A custom image is used.\nDSW provides various types of preset official images, such as PyTorch, TensorFlow, and ModelScope. If you want to use a custom image to meet specific development requirements, see Custom images.\nEach Alibaba Cloud account can purchase up to two GPUs per region. If the resource usage exceeds the limit, an error may occur. If you want to increase the quota, submit a ticket.\nAfter you create an instance by using public resources, you are charged based on the subscription duration of the instance. The billing stops only after you stop or delete the instance. For more information about billing rules, see Billing of DSW.\nGo to the Interactive Modeling (DSW) page.\nLog on to the PAI console.\nOn the Overview page, select a region in the top navigation bar.\nIn the left-side navigation pane, click Workspaces. On the Workspaces page, click the name of the workspace that you want to manage.\nIn the left-side navigation pane, choose Model Development and Training > Interactive Modeling (DSW).\nClick Create Instance.\nOn the Create Instance page, configure the following key parameters.\nParameter\nDescription\nBasic Information\nInstance Name\nThe name of the DSW instance.\nTag\nThe instance tag. You can tag the instance based on your business requirements. This facilitates multi-dimensional resource searching, resource locating, batch operation, and cost allocation.\nResource Information\nResource Type\nValid values:\nPublic Resources: Only the pay-as-you-go billing method is supported. You cannot change the billing method from pay-as-you-go to subscription.\nResource Quota: You can select general computing resources or intelligent computing Lingjun resources. If resources you want to use are available, click Associate Resource Quota to configure the resources.\nThe parameters that you can configure vary based on the resource types.\nIf Resource Type is set to Public Resources, you must configure the following parameters:\nInstance Type: You can select the CPU, GPU, or free instance. For more information, see Overview of instance families.\n(Optional) Bidding Purchase: If you create a DSW instance by using the public resources, you can use preemptible instances. This reduces costs.\nThis parameter is available only in the China (Hangzhou), China (Shanghai), China (Beijing), China (Ulanqab), China (Shenzhen), China (Guangzhou), Japan (Tokyo), and Singapore regions.\nIf Resource Type is set to Resource Quota, you must configure the following parameters:\nResource Quota: You can select general computing resources or intelligent computing Lingjun resources.\nInstance Type: You can select the CPU, GPU, or free instance based on your business requirements.\nPriority: Valid values: 1 to 9. A large value indicates a high priority.\nCPU Affinity: If you enable CPU affinity, processes in containers or pods can be bound to specific CPU cores. This reduces CPU cache misses and context switches and increases CPU utilization and performance in scenarios that require high performance and low latency.\nThis parameter is available only in the China (Beijing) and China (Shenzhen) regions.\nEnvironment Information\nImage\nValid values:\nAlibaba Cloud Image: the preset official image. Python, TensorFlow, and PyTorch versions of images are supported.\nCustom Image: a custom image that you created. For more information about how to add a custom image, see Custom images.\nImage Address: You can use an image by entering a publicly accessible URL of the image. You can also enter the publicly accessible URL of the image in Container Registry Personal Edition in the current region. For more information, see Create a Container Registry Personal Edition instance.\nSystem Disk\nIf you set Resource Type to Public Resources or select subscription general computing resources that provide more than 2 CPU cores and more than 4 GB of memory or GPUs) for Resource Quota:\nEach instance is provided with 100 GiB of free system disk for persistent storage. If the instance is stopped for more than 15 days, the data in the disk will be cleared. The disk storage space can be expanded. For information about the disk storage expansion pricing, go to the PAI console.\nAfter the expansion, you cannot reduce the storage space. Proceed with caution.\nAfter the expansion, the disk is not cleared if the instance is stopped and not recovered for more than 15 days. However, you continue to be charged for data storage.\nIf you delete the instance, the system disk is also released and the data stored in the disk is deleted. Make sure that you have backed up your data before you delete the instance.\nIf you want to permanently store the data, you can configure Dataset Mounting  or enter an OSS path in the Mount Path field of Storage Path Mounting.\nDataset Mounting\nClick Custom Dataset to mount a custom dataset that has been created. OSS custom datasets support multiple mount modes and custom configurations. Public datasets support only the read-only mount mode.\nMount Path is the location where the dataset is mounted in the DSW instance. For example, the default mount path /mnt/data/ indicates that the dataset is mounted in the /mnt/data/ directory within the DSW instance.\nYou cannot mount multiple datasets to the same path.\nIf you use a Cloud Parallel File Storage (CPFS) dataset, specify a virtual private cloud (VPC) for the instance. The VPC must be the same as the VPC of the CPFS dataset. Otherwise, the DSW instance may fail to be created.\nIf you set the Resource Quota parameter to a dedicated resource group, the first dataset that you mount to the instance must be a NAS dataset. The dataset is simultaneously mounted to the path that you specify and the default working directory/mnt/workspace/.\nStorage Path Mounting\nClick OSS to mount an OSS path to DSW. OSS supports multiple mount modes and custom configurations.\nMount Path is the same as the Mount Path of Dataset Mounting.\nWorking Directory\nThe working directory is the startup directory of Notebook and WebIDE. The working directory is mounted to the /mnt/workspace directory.\nNetwork Information\nVPC\nThis parameter is available only if you set the Resource Type parameter to Public Resources.\nTo connect to a DSW instance over VPC, you must configure this parameter together with the vSwitch and Security Group parameters. For more information about configurations in different scenarios, see DSW network configuration.\nInternet Gateway\nYou can select one of the following options for Internet Gateway:\nPublic Gateway: The public bandwidth is shared by multiple DSW instances in the cluster. The download rate is slow in high concurrent scenarios.\nPrivate Gateway (recommended): The DSW instance uses dedicated bandwidth. You can configure the dedicated bandwidth based on your business requirements. If you select this option, you must create an Internet NAT gateway for the VPC that is associated with the DSW instance, associate an elastic IP address (EIP) with the DSW instance, and configure an SNAT entry. For more information, see Enable Internet access for a DSW instance by using a private Internet NAT gateway.\nYou need to configure the following parameters if you select a CPFS dataset for the Custom Dataset parameter:\nEnable All Options: By default, this option is not selected, which indicates that the system disables the VPCs that cannot connect to the CPFS dataset.\nIf you use a CPFS dataset, you must specify a VPC for the DSW instance, and the VPC must be the same as the VPC of the CPFS dataset.\nAccess Configuration\nEnable SSH\nYou can configure this parameter if you use a VPC.\nAfter you enable SSH, you can directly log on to the DSW instance by using SSH based on the selected VPC. If you configure a custom image, you must make sure that sshd is installed on the custom image.\nSSH Public Key\nYou can configure this parameter after you turn on Enable SSH.\nIf you want to enable VPC and Internet logon, you must add the public keys of multiple clients. Separate public keys by pressing the Enter key. You can add up to 10 public keys.\nSSH Access Method\nYou can configure this parameter after you turn on Enable SSH.\nAccess over VPC: the default access method. You can remotely connect to the DSW instance by using SSH from another terminal, such as an ECS instance in the VPC.\nAccess over Internet: After you select Access over Internet, the Internet access method is added. You can configure the following parameters and connect to the DSW instance over SSH by using an on-premises CLI or another terminal.\nNAT Gateway: Select the Internet NAT gateway that you created for the VPC.\nEIP: Select the EIP that you created on the Internet NAT gateway.\nCustom Services\nAllow external access to custom services running in the instance. For more information, see Custom services access configuration.\nCreate Private Zone in VPC\nCreate a private domain (Private Zone). You can use the Private Zone in this VPC to access the SSH service or other custom services of the current instance. This avoids the inconvenience caused by the changing IP address of the instance. Note that the Private Zone will incur fees. For more information, see Billing.\nAdvanced Information\nVisibility\nYou can select Visible to the Instance Owner or Visible to the Current Workspace.\nInstance Owner\nOnly the workspace administrator can change the instance owner.\nInstance RAM Role\nWhen you access other cloud resources from a DSW instance, you can associate a RAM role with the instance. This method allows you to use temporary Security Token Service (STS) tokens instead of AccessKey pairs to access the resources, which effectively reduces the risk of AccessKey pair leaks.\nYou can select one of the following options for this parameter:\nDefault Roles of PAI: The default roles of PAI have the permissions to access PAI services, MaxCompute, and OSS. If you use the temporary credentials issued by the default roles of PAI, you are granted the same permissions as the DSW instance owner when you access PAI services and MaxCompute tables. When you access OSS, you can access only the bucket that is configured as the default storage path for the current workspace.\nCustom Roles: If you want to perform customized or fine-grained permission control, you can configure custom roles.\nDoes Not Associate Role: If you want to directly access resources of other cloud services by using an AccessKey pair, you can choose not to associate a role with the instance.\nFor more information about how to configure an instance RAM role, see Configure RAM roles for a DSW instance.\nAfter you confirm the configurations, click Yes.\nAfter you create an instance, you can prepare the data files that are required for development. DSW supports multiple data sources, including OSS, NAS, and MaxCompute. For more information, see Read data from and write data to OSS and MaxCompute.\nYou can also use a DSW instance to upload and download small-sized data files.\u00a0For more information, see Upload or download data files.\nFor information about the features and workflow of DSW and how to get started with DSW, see DSW overview.\nFor information about the use cases of DSW, see DSW use cases.\nAfter creating an instance, you can save the environment of a current running DSW instance as a custom image for future use. For more information, see Create a DSW instance image.\n"
    },
    "527": {
        "title": "Platform For AI:Read data from and write data to OSS and MaxCompute",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/instructions-for-use",
        "content": "This Product\nPlatform For AI:Read data from and write data to OSS and MaxCompute"
    },
    "528": {
        "title": "Platform For AI:DSW use cases",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/dsw-use-case-summary",
        "content": "This Product\nPlatform For AI:DSW use cases\nThis topic describes the relevant topics of Data Science Workshop (DSW) use cases.\nCase\nDescription\nResponsible AI: Fairness analysis\nThis topic describes how to use responsible-ai-toolbox to perform fairness analysis on the model in DSW. In this topic, the fairness of a model that predicts whether the annual income exceeds 50K is evaluated in terms of gender and race.\nResponsible AI: error analysis\nThis topic describes how to use the responsible-ai-toolbox to perform error analysis on a model in DSW. In this topic, a model that predicts whether the annual income exceeds 50K is evaluated.\nUse EasyVision to detect objects\nThis topic describes how to use EasyVision in DSW to detect objects.\nUse EasyTransfer to develop a text classification model\nThis topic uses text classification as an example to describe how to use EasyTransfer to train and evaluate models, use models to make predictions, export model files, and deploy models in DSW.\nUse EasyASR for speech recognition\nThis topic describes how to use EasyASR for speech recognition in DSW.\nUse EasyASR for speech classification\nThis topic describes how to use EasyASR for speech classification in DSW."
    },
    "529": {
        "title": "Platform For AI:Submit training jobs",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/create-a-task",
        "content": "This Product\nPlatform For AI:Submit training jobs\nAfter you complete the preparations, you can submit Deep Learning Containers (DLC) jobs in the Platform for AI (PAI) console or by using SDK for Python or the command line. This topic describes how to submit a DLC job.\nThe required resources, images, datasets, and code builds are prepared. For more information, see Before you begin.\nEnvironment variables are configured for using the SDK for Python to submit a DLC job. For more information, see the \"Install the Credentials tool\" section in the Manage access credentials topic and the \"Step 2: Configure environment variables\" section in the Get started with Alibaba Cloud Darabonba SDK for Python topic.\nGo to the Create Job page.\nLog on to the PAI console. Select a region and a workspace. Then, click Enter Deep Learning Containers (DLC).\nOn the Deep Learning Containers (DLC) page, click Create Job.\nConfigure the parameters in the following sections.\nBasic Information\nIn this section, configure the Job Name and Tag parameters.\nEnvironment Information\nParameter\nDescription\nNode Image\nThe worker node image. You can select one of the following node images:\nAlibaba Cloud Image: an image provided by Alibaba Cloud PAI. Such images support different Python versions and deep learning frameworks, such as TensorFlow, PyTorch, Ray, and XGBoost. For more information, see Before you begin.\nCustom Image: a custom image that you uploaded to PAI. For more information about how to upload a custom image, see Custom images.\nIf you want to use Lingjun resources and custom images, install Remote Direct Memory Access (RDMA) network to use the high-performance RDMA network of Lingjun resources. For more information, see RDMA: high-performance networks for distributed training.\nYou need to set the image repository type to public or store the image in Alibaba Cloud Container Registry. This way, you can directly use the image.\nImage Address: a custom, community, or Alibaba Cloud image that can be accessed by using the image address. If you select Image Address, you must also specify the public URL of the Docker registry image that you want to access.\nIf you want to specify the private URL of an image, click enter the username and password and specify the Username and Password parameters to grant permissions on the private image repository.\nYou can also use an accelerated image to accelerate model training. For more information, see Use an accelerated image in PAI.\nData Set\nYou can select one of the following dataset types.\nCustom Dataset: Select a dataset that you prepared. If the dataset has multiple versions, you can click Versions in the Actions column to select the required version. For more information about how to prepare a dataset, see Step 3: Prepare a dataset.\nPublic Dataset: Select an existing public dataset provided by PAI. The mount option for the data is read-only.\nSet the Mount Path parameter to the specific path in the DLC training container, such as /mnt/data. DLC retrieves the required files based on the mount path you specified. For more information, see Use cloud storage for a DLC training job.\nIf you select an OSS dataset or an File Storage NAS (NAS) dataset, you must grant PAI the permissions to access OSS or NAS. Otherwise, PAI cannot read or write data. For more information, see the \"Grant PAI the permissions to access OSS and NAS\" section in the Grant the permissions that are required to use DLC topic.\nIf you select a Cloud Parallel File Storage (CPFS) dataset, you must configure a virtual private cloud (VPC). The VPC must be the same as the VPC configured for the CPFS dataset. Otherwise, the job may stay in the preparing environment state for a long time.\nDirectly Mount\nYou can click OSS, General purpose NAS, Extreme speed NAS, and BMCPFS to directly mount the related data sources to a DLC container. You must specify the data source parameters and the mount path.\nOnly jobs that use Lingjun resources support the BMCPFS data source.\nStartup Command\nThe command that the job runs. Shell commands are supported. For example, you can use the python -c \"print('Hello World')\" command to run Python.\nWhen you submit a job, PAI automatically injects multiple general environment variables. To obtain the values of specific environment variables, configure the $Environment Variable Name parameter. For more information about the general environment variables provided by DLC, see General environment variables.\nIf you configure a dataset, you can export the training results to the directory on which the dataset is mounted by using commands. This allows you to view the training results in the dataset.\nEnvironment Variable\nAdditional configuration information or parameters. The format is key:value. You can configure up to 20 environment variables.\nThird-party Libraries\nValid values:\nSelect from List: Enter the name of a third-party library in the field.\nDirectory of requirements.txt: Enter the path of the requirements.txt file in the field. You must upload the file to a DLC container by using code, datasets or direct mounting. Then, enter the path of file in the DLC container in the text field.\nCode Builds\nYou must upload the code build that is required for the training to a DLC container. Valid values:\nOnline Configuration\nSpecify the location of the repository that stores the code file. In this example, a code build that you prepared is selected. For information about how to create a code build, see the \"Step 4: Prepare a code build\" section in the Before you begin topic.\nDLC automatically downloads the code to the specified working path. Make sure that your account has permissions to access the repository.\nLocal Upload\nClick the  icon and follow the on-screen instructions to upload the code build. After the upload succeeds, set the Mount Path parameter to the specified path in the container, such as /mnt/data.\nResource Information\nParameter\nDescription\nInstance type\nThis parameter is available only if the workspace allows you to use Lingjun resources and general computing resources to submit jobs in DLC. Valid values:\nLingjun Resources\nLingjun resources are available only in the China (Ulanqab) and Singapore regions.\nGeneral Computing Resources\nSource\nPublic Resources, Resource Quota, and Preemptible Resources, are available. Resource Quota includes general computing resources and Lingjun resources.\nPublic resources can provide up to two GPUs and eight vCPUs. To increase the resource quota, contact your account manager.\nFor more information about the limitations and usage of preemptible resources, see Use a preemptible job.\nResource Quota\nThis parameter is required only if you set the Source parameter to Resource Quota. Select the resource quota that you prepared. For more information about how to prepare a resource quota, see Resource quota overview.\nPriority\nThis parameter is available only if you set the Source parameter to Resource Quota.\nSpecify the priority for running the job. Valid values: 1 to 9. A greater value indicates a higher priority.\nFramework\nSpecify the deep learning training framework and tool. The framework provides rich features and operations that you can use to build, train, and optimize deep learning models.\nTensorflow\nPyTorch\nElasticBatch\nXGBoost\nOneFlow\nMPIJob\nRay\nIf you set the Resource Quota parameter to Lingjun resources, you can submit only the following types of jobs: TensorFlow, PyTorch, ElasticBatch, MPIJob, and Ray.\nJob Resource\nConfigure the resources of the following nodes based on the framework you selected: worker nodes, parameter server (PS) nodes, chief nodes, evaluator nodes, and GraphLearn nodes.\nUse public resources\nConfigure the following parameters:\nNumber of Nodes: the number of nodes on which the DLC job runs.\nResource Type: Click the  icon to select an instance type. The prices of the specifications are displayed in the Instance Type panel. For information about the billing of resource specifications, see Billing of DLC.\nUse general computing resources or Lingjun resources\nConfigure the following parameters for the nodes: Number of Nodes, vCPUs, GPUs, Memory (GiB), and Shared Memory (GiB).\nUse preemptible resources\nConfigure the following parameters. For more information about preemptible resources, see Use a preemptible job.\nNumber of Nodes: the number of nodes on which the DLC job runs.\nResource Type: Click the  icon to select an instance type.\nBid Price: the maximum bid price to apply for the preemptible resources. You can click the  icon to switch the bidding method.\nBid Price (Discount): The maximum bid price ranges from 10% to 90% of the market price with a 10% interval. You can get the preemptible resources if your bid meets or exceeds the market price and inventory is available.\nBid Price ($/Minutes): The maximum bid price range is based on the market price range.\nNode-Specific Scheduling\nAfter you enable this feature, you can select nodes for scheduling.\nThis parameter is available only when you use resource quota.\nCPU Affinity\nEnabling CPU affinity allows processes in a container or Pod to be bound to specific CPU cores for execution. This approach can reduce CPU cache misses and context switching, improving CPU utilization and enhancing application performance. It is suitable for scenarios that are sensitive to performance and have high real-time requirements.\nMaximum Duration\nYou can specify the maximum duration for which a job runs. The job is automatically stopped when the uptime of the job exceeds the maximum duration. Default value: 30. Unit: hours.\nRetention Period\nSpecify the retention period of jobs after they completed or fail. During the retention period, the resources are occupied. After the retention period ends, the jobs are deleted.\nDLC jobs that are deleted cannot be restored. Exercise caution when you delete the jobs.\nVPC\nIf you do not configure a VPC, Internet connection is used. Due to the limited bandwidth of the Internet, the job may not progress or may not run as expected.\nTo ensure sufficient network bandwidth and stable performance, we recommend that you configure a VPC.\nSelect a VPC, a vSwitch, and a security group in the current region. When the configuration takes effect, the cluster on which the job runs directly accesses the services in the VPC and performs access control based on the selected security group.\nYou can also configure the Internet Gateway parameter.\nPrivate Gateway: You can select a dedicated bandwidth based on your business requirements. If you access the Internet by using a private gateway, you need to create an Internet NAT gateway, associate an elastic IP address (EIP) with a DSW instance and configure SNAT in the VPC that is associated with the DSW instance. For more information, see Enable Internet access for a DSW instance by using a private Internet NAT gateway.\nPublic Gateway: The shared public bandwidth is used. The download rate is slow in high concurrency scenarios.\nBefore you run a DLC job, make sure that instances in the resource group and the OSS bucket of the dataset reside in the VPCs of the same region, and that the VPCs are connected to the networks of the code repository.\nIf you select a CPFS dataset, you must configure a VPC. The VPC must be the same as the VPC configured for the CPFS dataset. Otherwise, the job may stay in the preparing environment state for a long time.\nIf you use Lingjun preemptible resources to submit a DLC job, you must configure a VPC.\nFault Tolerance and Diagnosis\nParameter\nDescription\nAutomatic Fault Tolerance\nAfter you turn on Automatic Fault Tolerance and configure the related parameters, the system checks the jobs to identify algorithmic errors of the jobs and improve GPU utilization. For more information, see AIMaster: elastic fault tolerance engine.\nAfter you enable Automatic Fault Tolerance, the system starts an AIMaster instance that runs together with the job instance and occupies the following resources:\nResource quota: one CPU core and 1 GB of memory.\nPublic resources: uses ecs.c6.large.\nSanity Check\nAfter you turn on Sanity Check, the system detects the resources that are used to run the jobs, isolates faulty nodes, and triggers automated O&M processes in the background. This prevents job failure in the early stage of training and improves the training success rate. For more information, see Sanity Check.\nYou can enable the sanity check feature only for PyTorch jobs that run on Lingjun resources and use GPU.\nRoles and Permissions\nThe following table describes how to configure the Instance RAM Role parameter. For more information, see Configure the DLC RAM role.\nInstance RAM Role\nDescription\nDefault Role of PAI\nThe default role of PAI is developed based on the AliyunPAIDLCDefaultRole role and has only the permissions to access MaxCompute and OSS. You can use this role to implement fine-grained permission management. The temporary credentials issued by the default role of PAI:\nYou are granted the same permissions as the owner of a DLC job when you access MaxCompute tables.\nWhen you access OSS, you can access only the bucket that is configured as the default storage path for the current workspace.\nCustom Roles\nSelect or create a custom Resource Access Management (RAM) role. You are granted the same permissions as the custom role you select when you call API operations of other Alibaba Cloud services by using Security Token Service (STS) temporary credentials.\nDoes Not Associate Role\nDo not associate a RAM role with the DLC job. By default, this option is selected.\nAfter you configure the parameters, click Confirm.\nInstall the workspace SDK.\nInstall the DLC SDK.\nIf you want to submit a job that runs on pay-as-you-go resources, you can use public resources. Training jobs that run on public resources may encounter queuing delays. We recommend that you use public resources in time-insensitive scenarios that involve a small number of tasks.\nIf you want to submit a job that runs on subscription resources, you can use AI computing resources, such as general computing resources or Lingjun resources. You can use AI computing resources to ensure resource availability in high workload scenarios.\nIf you want to reduce the resource cost for job execution, you can use preemptible resources. Preemptible resources offer a certain discount. However, preemptible resources may be preempted or released. For more information about the limitations and usage of preemptible resources, see Use a preemptible job.\nThe following sample code provides an example on how to create and submit a DLC job:\nLog on to the PAI console.\nFollow the instructions to obtain your workspace ID on the Workspaces page.\nFollow the instructions to obtain the resource quota ID of your dedicated resource group.\nThe following sample code provides an example on how to create and submit a job. For information about the available public images, see the \"Step 2: Prepare an image\" section in the Before you begin topic.\nDownload the DLC client for your operating system and verify your credentials. For more information, see Before you begin.\nLog on to the PAI console.\nFollow the instructions shown in the following figure to obtain your workspace ID on the Workspace page.\n\nFollow the instructions shown in the following figure to obtain the resource quota ID.\n\nCreate a parameter file named tfjob.params and copy the following content into the file. Change the parameter values based on your business requirements. For information about how to use the command line in the DLC client, see Supported commands.\nThe following sample code provides an example on how to specify the params_file parameter to submit a DLC job to the specified workspace and resource quota.\nThe following sample code provides an example on how to query the DLC jobs that you created.\nAfter you submit the job, you can perform the following operations:\nView the basic information, resource view, and operation logs of the job. For more information, see View training jobs.\nManage jobs, including cloning, stopping, and deleting jobs. For more information, see Manage training jobs.\nView the training results on TensorBoard. For more information, see Use TensorBoard to view training results in DLC.\nView the billing details when the job is completed. For more information, see Bill details.\nEnable the log forwarding feature to forward logs of DLC jobs from the current workspace to a specific Logstore for custom analysis. For more information, see Subscribe to job logs.\nCreate a notification rule for a PAI workspace to track and monitor the status of DLC jobs. For more information, see Notification rule.\nIf you have other questions about DLC jobs, see FAQ about DLC."
    },
    "530": {
        "title": "Platform For AI:Deep Learning Containers (DLC)",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/low-cost-running-tasks-use-spot-instances-preemptible-instances",
        "content": "This Product\nPlatform For AI:Deep Learning Containers (DLC)"
    },
    "531": {
        "title": "Platform For AI:DLC use cases",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/dlc-use-case-summary",
        "content": "This Product\nPlatform For AI:DLC use cases\nThis topic lists relevant topics of Deep Learning Containers (DLC) use cases.\nCase\nDescription\nSubmit a standalone training job that uses PyTorch\nThis topic describes how to use DLC to train transfer learning models based on the PyTorch framework.\nUse NAS to submit standalone PyTorch migration learning jobs\nThis topic describes how to use DLC and File Storage NAS (NAS) to perform PyTorch-based offline migration training.\nUse PAIIO to read data from and write data to MaxCompute tables\nThis topic describes how to use the PAIIO module to read data from and write data to MaxCompute tables.\nSubmit an MPIJob training job\nThis topic describes how to use mpirun and Deepspeed to submit distributed training jobs of the MPIJob type in DLC."
    },
    "532": {
        "title": "Platform For AI:Overview",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/model-service-deployment-and-management-110981",
        "content": "This Product\nPlatform For AI:Overview\nThe Elastic Algorithm Service (EAS) module of Platform for AI (PAI) provides multiple methods to help you deploy model services based on your business requirements.\nYou can deploy a model by using an image or a processor in EAS.\nIf you deploy a model by using an image, EAS pulls the image that contains the runtime environment from Container Registry (ACR) and mounts model files and code from storage services such as Object Storage Service (OSS) and File Storage NAS (NAS).\nThe following figure shows the workflow of deploying a model by using an image in EAS.\nTake note of the following items:\nYou can use one of the following methods when you deploy a model by using an image:\nDeploy Service by Using Image: You can call the service by using API operations after deployment.\nDeploy Web App by Using Image: You can access the web application by using a link after deployment.\nFor information about the differences between the two methods, see the \"Step 2: Deploy a model\" section of this topic.\nPAI provides multiple prebuilt images to accelerate model deployment. You can also create a custom image and upload the image to ACR.\nWe recommend that you upload the model files and the code files that contain the preprocessing or postprocessing logic to storage services. This way, you can mount the files to the runtime environment. Compared with packaging the files into a custom image, this method allows you to update the model in a convenient manner.\nWhen you deploy a model by using an image, we recommend that you build an HTTP server to receive requests that are forwarded by EAS. The HTTP server cannot receive requests on ports 8080 and 9090 because the EAS engine listens on these ports.\nIf you use a custom image, you must upload the image to ACR before you use the image during deployment. Otherwise, EAS may fail to pull the image. If you use Data Science Workshop (DSW) to develop a model, you must upload the image to ACR before you use the image in EAS.\nIf you want to reuse your custom images or warm-up data in other scenarios, you can manage the images or data in a centralized manner by using the AI Computing Asset Management module of PAI. EAS does not support mounting CPFS datasets from NAS.\nIf you deploy a model by using a processor, prepare the model files and processor files, upload the files to storage services such as OSS or NAS before deployment, and then mount the files to EAS during deployment.\nThe following figure shows the workflow of deploying a model by using a processor in EAS.\nTake note of the following items:\nPAI provides multiple prebuilt images to accelerate model deployment. You can also create a custom image based on your business requirements and upload the image to ACR.\nWe recommend that you develop and store the model file and the processor file separately. You can call the get_model_path() method in the processor file to obtain the path of the model file. This allows you to update the model in a convenient manner.\nWhen you deploy a model by using a processor, EAS automatically pulls an official image based on the inference framework of the model and deploys an HTTP server based on the processor file to receive service requests.\nWhen you deploy a model by using a processor, make sure that the inference framework of the model and the processor file meet the requirements of the development environment. This method is less flexible and efficient. We recommend that you deploy a model by using an image.\nThe following table describes the deployment tools.\nOperation\nGUI tools\nCLI tools\nDeploy services\nUse the PAI console or Machine Learning Designer to deploy a service with a few clicks. For more information, see Deploy a model service in the PAI console or Deploy a model service by using Machine Learning Designer.\nUse DSW or the EASCMD client to deploy a service. For more information, see Deploy model services by using EASCMD or DSW.\nManage services\nManage model services on the EAS-Online Model Services page. For more information, see Deploy a model service in the PAI console.\nThe following operations are supported:\nView invocation information.\nView logs, monitoring information, and service deployment information.\nScale, start, stop, and delete model services.\nUse the EASCMD client to manage model services. For more information, see Run commands to use the EASCMD client.\nIf you use a dedicated resource group to deploy a model service, you can mount the required data from storage services. For more information, see Mount storage to services.\nThe following table describes the deployment methods.\nDeployment method\nDescription\nReference\nDeploy Service by Using Image (recommended)\nScenario: Use an image to deploy a model service.\nBenefits:\nImages ensure consistency between the model development environment and the runtime environments.\nPrebuilt images for common scenarios allow you to complete deployment with a few clicks.\nCustom images can be used for deployment without the need for modification.\nDeployment methods\nDeploy a model service by using a custom image\nDeploy Web App by Using Image (recommended)\nScenario: Use an image to deploy a web application.\nBenefits:\nPrebuilt images for common scenarios, such as Stable-Diffusion-Webui and Chat-LLM-Webui, allow you to complete deployment with a few clicks. You can build an HTTP server by using frameworks such as Gradio, Flask, and FastAPI.\nCustom images can be used for deployment without the need for modification.\nDeploy Service by Using Model and Processor\nEAS provides prebuilt processors for common model frameworks, such as PMML and XGBOOST, to accelerate deployment.\nIf the prebuilt processors cannot meet your business requirements, you can build custom processors to obtain greater flexibility.\nUse a processor\nDeploy model services by using built-in processors\nDeploy services by using custom processors\nService groups\nEAS supports service groups, which you can use in scenarios that require traffic distribution across multiple services, such as canary releases. For more information, see Manage service groups.\nScheduled service deployment\nYou can use DataWorks to automatically deploy services on a regular basis. For more information, see Configure scheduled model deployment.\nInstance utilization\nEAS provides preemptible instances and allows you to select multiple instance types. This way, you can deploy services in a cost-effective manner. For more information, see Create and use preemptible instances and Specify multiple instance types.\nStorage integration\nEAS can mount data from multiple storage services, such as Object Storage Service (OSS), File Storage NAS (NAS), and Git repositories. For more information, see Mount storage to services.\nModel warm-up\nEAS provides the model warm-up feature to reduce the delay in processing the first request after deployment. This ensures that model services can work as expected immediately after they are published. For more information, see Warm up model services (advanced).\nYou can use multiple methods to call the service that you deployed. For more information, see Methods for calling services.\nYou can view the metrics related to service invocation and operational health on the Service Monitoring tab. For more information, see Service monitoring."
    },
    "533": {
        "title": ":Service debugging and stress testing",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/service-debugging-and-stress-testing",
        "content": "This Product\n:Service debugging and stress testing"
    },
    "534": {
        "title": "Platform For AI:Service calling and stress testing",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/model-service-call-110984",
        "content": "This Product\nPlatform For AI:Service calling and stress testing"
    },
    "535": {
        "title": "Platform For AI:Distributed deep learning framework Whale",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/quick-start-1",
        "content": "This Product\nPlatform For AI:Distributed deep learning framework Whale\nEasy Parallel Library (EPL) is an efficient and easy-to-use framework for distributed model training. EPL adopts multiple training optimization technologies and provides easy-to-use API operations that allow you to use parallelism strategies. You can use EPL to reduce costs and improve the efficiency of distributed model training. This topic describes how to use EPL to accelerate TensorFlow distributed model trainings in Deep Learning Containers (DLC).\nBefore you perform the operations described in this topic, make sure that the following requirements are met:\nThe required service-linked role is created for DLC. For more information, see Grant the permissions that are required to use DLC.\nThe official image or one of the following community images is prepared: NVIDIA TensorFlow 1.15 or TensorFlow-GPU 1.15.\nIf you use the official image, you can use EPL without the need to install it. For more information about official images, see Alibaba Cloud image.\nIf you use an open source image, you must first install EPL. For more information about community images, see Community image. For more information about how to install EPL, see Install EPL.\nIf you use DLC, we recommend that you select the community image tensorflow-training:1.15-gpu-py36-cu100-ubuntu18.04. You can run commands to install EPL in DLC.\nYou can use EPL to write code for TensorFlow-based distributed model training. For more information, see Quick Start.\nYou can also use the sample code provided by EPL to start the TensorFlow distributed model training. In this example, the training dataset ResNet50 is used to create a code build. You can use the code build to submit a TensorFlow training job. Each time model training is performed, the latest version is automatically cloned. To configure a code build, perform the following steps.\nGo to the code builds page.\nLog on to the PAI console.\nIn the left-side navigation pane, click Workspaces. On the Workspaces page, click the name of the workspace that you want to manage.\nIn the left-side navigation pane, choose AI Computing Asset Management > Source Code Repositories to go to the code builds page.\nOn the Code Configuration page, click Create Code Build.\nIn the Create Code Build panel, configure the parameters and click Submit.\nSet the Repository parameter to https://github.com/alibaba/EasyParallelLibrary.git and the Code branch parameter to main. For more information about other parameters, see Code builds.\nGo to the Create Job page.\nLog on to the PAI console. Select a region and a workspace. Then, click Enter Deep Learning Containers (DLC).\nOn the Deep Learning Containers (DLC) page, click Create Job.\nOn the Create Job page, configure the parameters in the Basic Information and Resource Configuration sections. For more information about other parameters, see Submit training jobs. Click Submit.\nThe following table describes the parameters in the Basic Information section.\nParameter\nExample\nResource Quota\nPublic resource group.\nJob Name\nSpecify a name for the training job.\nNode Image\nClick Community Image and select tensorflow-training:1.15-gpu-py36-cu100-ubuntu18.04 from the image list.\nFramework\nTensorFlow.\nCode Builds\nClick Online Configuration and select the dataset that you configured in step 1 from the drop-down list.\nCode Branch\nmain.\nJob Command\nThe following table describes the parameters in the Resource Configuration section.\nParameter\nExample\nNumber of Nodes\nSet the value to 2. You can change the value based on the requirements of the training job.\nNode Configuration\nOn the GPU Instance tab, select ecs.gn6v-c8g1.2xlarge.\nMaximum Duration\n2. Unit: hours.\nOn the Distributed Training Jobs page, click the name of the job that you want to manage and go to the job details page. View the running status of the job. For more information, see View training jobs.\nFor more information about EPL, see the EPL documentation.\nFor more information about DLC, see Before you begin."
    },
    "536": {
        "title": "Platform For AI:Pai-Megatron-Patch for accelerating the training of transformers",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/model-training-acceleration-rapidtransformer",
        "content": "This Product\nPlatform For AI:Pai-Megatron-Patch for accelerating the training of transformers\nPai-Megatron-Patch applies various technologies to optimize the training of PyTorch Transformers and deliver optimal training performance. This topic describes how Pai-Megatron-Patch works and how you can use it.\nPai-Megatron-Patch is a tool developed by Alibaba Cloud Platform for AI (PAI) team based on best practice solutions of foundation models in the intelligent computing LINGJUN platform. Pai-Megatron-Patch is used to facilitate foundation model developers throughout the whole foundation model development process, such as getting started with LINGJUN services and performing efficient distributed trainings on large language models (LLM), supervised fine-tuning (SFT), and offline model inference. Pai-Megatron-Patch provides a Megatron-LM-based training and offline inference verification process for mainstream open source foundation models in the industry, which helps you get started with foundation model training.\nPai-Megatron-Patch strengthens the Megatron-LM capabilities without source code modification by providing feature support through patches. This way, Pai-Megatron-Patch can build an independent LLM training process without modifying the core library of Megatron-LM and ensure compatibility with Megatron-LM updates without impairing user experience.\nPai-Megatron-Patch provides tools and features that include a model library, tokenizers, model transformation tools, reinforcement learning, offline text generation, and multiple usage examples and toolsets to help you quickly deploy foundation model training and inference.\nThe model library includes multiple popular foundation models, such as Baichuan, BLOOM, ChatGLM, Falcon, Galactica, GLM, Llama, Qwen, and StarCoder. In addition, the patch supports conversion between the Hugging Face model weights and Megatron model weights. This allows you to load Hugging Face model weights in the Megatron environment for pre-training or fine-tuning, or convert Megatron model weights to the Hugging Face model weights for evaluation and inference.\nIn terms of reinforcement learning, Pai-Megatron-Patch provides a Proximal Policy Optimization (PPO) training process that you can use to perform SFT and reward model (RM) trainings. The Pai-Megatron-Patch tools and usage examples provide you with a comprehensive solution for foundation model training and evaluation.\n\nPerform the following operations to use Pai-Megatron-Patch:\nInstall a Pai-Megatron-Patch image\nConfigure parameters\nAccelerate the training of transformers\nReferences: Benchmarks of training performance"
    },
    "537": {
        "title": "Platform For AI:Inference Acceleration (Blade)",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/pai-blade-and-inference-optimization-agile-edition",
        "content": "This Product\nPlatform For AI:Inference Acceleration (Blade)"
    },
    "538": {
        "title": "Platform For AI:Use Stable Diffusion web UI to deploy an AI painting service",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/eas-one-click-deployment-of-aigc-sdwebui-painting-best-practices",
        "content": "This Product\nPlatform For AI:Use Stable Diffusion web UI to deploy an AI painting service\nStable Diffusion is a stable and easy-to-use image generation model that can generate high-quality and high-resolution images. Open source Stable Diffusion WebUI is a browser interface for Stable Diffusion models developed based on the Gradio library and provides various image generation tools. Elastic Algorithm Service (EAS) of Platform for AI (PAI) provides a scenario-based deployment mode that allows you to deploy a model service based on Stable Diffusion WebUI by configuring several parameters. You can use the service that you deployed to perform model inference to generate images based on text prompts. This topic describes how to deploy and call the Stable Diffusion WebUI service. This topic also provides answers to some frequently asked questions about the service.\nThe deployment in EAS provides the following features and benefits:\nEase of use: You can quickly deploy a ready-to-use model service in EAS. EAS also allows you to dynamically switch underlying resources, such as GPUs based on your business requirements.\nEnterprise-level features: The individual mechanisms for frontend and backend services support multiple users for scheduling multi-GPUs, user isolation, and bill splitting.\nPlug-ins and optimization: PAI provides the open source edition of Stable Diffusion WebUI, the PAI-Blade tool, and the FileBrower and ModelZoo plugins. The PAI-Blade tool is used for performance optimization. The FileBrowser plug-in is used to upload models and images from or download models and images to on-premises clients.The self-developed ModelZoo plug-in is used to accelerate downloading of open source models.\nThe Stable Diffusion WebUI service provides the following editions: Standard Edition, API Edition, Cluster Edition WebUI, and Serverless Edition. The following table describes the differences among the editions.\n\nApplication scenario\nCalling method\nBilling\nStandard Edition\nSuitable for a single user who wants to call the service deployed on a single instance to perform test verification.\nWeb UI\nOnline debugging\nSynchronous API calling\nYou are billed based on your deployment configurations. For more information, see Billing of EAS.\nAPI Edition\nSuitable for high-concurrency scenarios. The system automatically deploys the service as an asynchronous service.\nSynchronous and asynchronous API calling\nCluster Edition WebUI\nSuitable for multiple users to call the service by using the web UI at the same time. For example, members of a design team in an enterprise call the service at the same time.\nWeb UI\nServerless Edition\nSuitable for fluctuating request scenarios. The system automatically scales the service based on your service requests.\nWeb UI\nThe deployment of a Serverless Edition service is provided free of charge. You are billed based on the duration of service calls.\nAPI Edition: The system automatically deploys the service as an asynchronous service. The system creates queue service instances. Therefore, additional CPU resources need to be allocated.\nCluster Edition WebUI: Each user has an independent backend environment and working directory, enabling efficient GPU sharing and file management.\nServerless Edition: available only in the China (Shanghai) and China (Hangzhou) regions.\nIf scenario-based deployment cannot meet your requirements, you can deploy Standard Edition, Cluster Edition, and API Edition by using custom deployment that support more service features. For more information, see Configure parameters for custom deployment.\nAn File Storage NAS (NAS) file system or Object Storage Service (OSS) bucket is created to store the model files and generated images.\nCreate a General-purpose NAS file system. For more information, see Create a NAS file system.\nCreate an OSS bucket. For more information, see Create a bucket.\nIf you call a service by using the API operations, you must configure environment variables. For more information, see Configure access credentials.\nThe following deployment methods are supported:\nThis method is applicable to Standard Edition, API Edition, Cluster Edition, and Serverless Edition. Perform the following steps:\nLog on to the PAI console. On the page that appears, select the desired workspace and click Enter Elastic Algorithm Service (EAS).\nOn the Elastic Algorithm Service (EAS) page, click Deploy Service. In the Scenario-based Model Deployment section, click AI Painting - SD Web UI Deployment.\nOn the AI Painting - SD Web UI Deployment page, configure the following parameters.\nParameter\nDescription\nBasic Information\nEdition\nFor information about deployment editions, see Deployment editions.\nModel Settings\nClick Add to configure storage for the model that is used to store model files and generated images. Valid values:\nOSS: Select an existing OSS bucket. Compared with NAS, OSS is more convenient for data upload and download and can generate an Internet access address for generated images. However, the speed of switching models and saving images is slower.\nNAS:  NAS supports faster model switching and image saving. This option is supported only for the following editions: Standard Edition, API Edition, and Cluster Edition WebUI.\nNAS Mount Target: Select an existing NAS file system and mount target.\nNAS Source Path: Set the value to /.\nIn this example, OSS is used.\nResource Configuration\nResource Configuration\nThis parameter is supported only for the following editions: Standard Edition, API Edition, and Cluster Edition WebUI.\nSelect GPU. In the Instance Type panel that appears, select an instance type. We recommend that you select ml.gu7i.c16m60.1-gu30 for cost efficiency.\nInference Acceleration\nThe inference acceleration feature. Valid values:\nPAI-Blade: PAI-Blade is a general-purpose inference optimization tool provided by PAI. You can use PAI-Blade to optimize a trained model for optimal inference performance.\nxFormers: xFormers is an open source acceleration tool based on Transformer that can effectively accelerate image generation.\nNot Accelerated: The inference acceleration feature is disabled.\nVPC Configuration (Optional)\nVPC\nIf you set Model Settings to Mount NAS, the system automatically selects the virtual private cloud (VPC) that is connected to the VPC in which the NAS file system resides.\nvSwitch\nSecurity Group Name\nAfter you configure the parameters, click Deploy.\nThis method is applicable to the following editions: Standard Edition, API Edition, and Cluster Edition WebUI. Perform the following steps:\nLog on to the PAI console. On the page that appears, select the desired workspace and click Enter Elastic Algorithm Service (EAS).\nOn the Model Online Service (EAS) page, click Deploy Service. In the Custom Model Deployment section, click Custom Deploy.\nOn the Custom Deployment page, configure the following parameters.\nParameter\nDescription\nEnvironment Information\nDeployment Mode\nTo deploy a Standard Edition or Cluster Edition WebUI service, select Image-based Deployment and Enable Web App.\nTo deploy an API Edition service, select Image-based Deployment and Asynchronous Services.\nImage Configuration\nSelect stable-diffusion-webui of the latest version in the Image Configuration panel.\nx.x-standard: Standard Edition\nx.x-api: API Edition\nx.x-cluster-webui: Cluster Edition WebUI\nThe image version is frequently updated. We recommend that you select the latest version.\nIf you want to allow multiple users to use a Stable Diffusion WebUI to generate images, select the x.x-cluster-webui version.\nFor information about deployment editions, see Deployment editions.\nModel Settings\nConfigure the location where you want to store the model file and the image that is generated by model inference. Valid values:\nOSS\nOSS: Select an existing OSS bucket.\nMount Path: Set the value to /code/stable-diffusion-webui/data.\nNAS\nSelect a file system: Select an existing NAS file system.\nMount Target: Select an existing mount target.\nFile System Path: Set the value to /.\nMount Path: Set the value to /code/stable-diffusion-webui/data.\nPAI Model\nPAI Model: Select a PAI model and a model version.\nMount Path: Set the value to /code/stable-diffusion-webui/data.\nIn this example, an OSS bucket is mounted.\nCommand to Run\nAfter you configure the image version, the system automatically specifies a command.\nAfter you configure the model settings, append the --data-dir /code/stable-diffusion-webui/data parameter to the command to mount data to the specific path.\nOptional. You can also append the --blade or --xformers parameter to the command to enable inference acceleration. For more information, see the \"What parameters can I configure when I create a service?\" section of this topic.\nResource Deployment\nDeployment Resources\nSelect GPU. In the Instance Type panel that appears, select an instance type. We recommend that you select ml.gu7i.c16m60.1-gu30 for cost efficiency.\nVPC\nVPC\nIf you set Model Settings to NAS, the system automatically selects the VPC that is connected to the VPC in which the NAS file system resides.\nvSwitch\nSecurity Group Name\nAfter you configure the parameters, click Deploy.\nYou can deploy a Stable Diffusion WebUI service by using a JSON script. The following section describes how to use JSON to deploy Standard Edition and API Edition services.\nLog on to the PAI console. On the page that appears, select the desired workspace and click Enter Elastic Algorithm Service (EAS).\nOn the Elastic Algorithm Service (EAS) page, click Deploy Service. In the Configuration Editor section, click JSON Deployment.\nOn the JSON Deployment page, configure the following content in the JSON format:\nThe following table describes the parameters in the preceding code.\nParameter\nRequired\nDescription\nmetadata.name\nYes\nThe name of the custom model service, which is unique in the same region.\ncontainers.image\nYes\nReplace <region> with the ID of the current region. For example, replace the variable with cn-shanghai if your service is deployed in the China (Shanghai) region. For more information about region IDs, see Regions and zones.\nstorage\nNo\nValid values:\noss: Compared with NAS, OSS is more convenient for data upload and download and can generate an Internet access address for generated images. However, the speed of switching models and saving images is slower. Set the storage.oss.path parameter to the path of the existing OSS bucket.\nnas: NAS supports faster model switching and image saving. Set the storage.nfs.server parameter to the existing NAS file system.\nIn this example, OSS is used.\ncloud.networking\nNo\nIf you set the storage parameter to nas, you must configure the VPC, including the ID of the VPC, vSwitch, and security group. The VPC must be the same as the VPC of the general-purpose NAS file system.\nThe following table describes only the parameters whose configuration are different from the Standard Edition service deployment.\nParameter\nDescription\nDelete the following parameters:\nmetadata.enable_webservice\nDelete this parameter to disable webserver.\ncontainers.script\nDelete the --filebrowser option that is specified in the containers.script parameter to accelerate the service startup.\nAdd the following parameters:\nmetadata.type\nSet the value to Async to enable the asynchronous service.\nmetadata.rpc.worker_threads\nSet the value to 1 to allow a single instance to process only one request at a time.\nqueue.max_delivery\nSet the value to 1 to disable retry after an error occurs.\ncontainers.script\nAdd the --nowebui and --time-log options in the containers.script parameter to accelerate the service startup and log the response time, respectively.\nFor more information about the parameters, see the \"Standard Edition\" section of this topic.\nClick Deploy.\nYou can use the web UI to call a service of the Standard Edition, Cluster Edition WebUI, and Serverless Edition. Perform the following steps:\nFind the service that you want to manage and click View Web App in the Service Type column.\nPerform model inference.\nOn the txt2img tab of the Stable Diffusion WebUI page, enter a prompt, such as cute dog, and then click Generate. The following figure provides an sample response.\n\nYou can use API operations to call services of Standard Edition or API Edition. API calls support synchronous and asynchronous service calls. The Standard Edition service supports only synchronous calls. The API Edition service supports synchronous and asynchronous service calls.\nSynchronous call: If you send a synchronous request, the client pauses execution and waits for the result to return.\nAsynchronous call: The client uses the queue service of EAS to send requests to the input queue and subscribes to the inference result in the output queue.\nAfter you deploy a Standard Edition or API Edition service, you can perform the following steps to send a synchronous request.\nObtain the call information.\nAfter you deploy a service, click the service name to go to the Service Details page.\nIn the Basic Information section, click View Endpoint Information.\nIn the Invocation Method dialog box, obtain the endpoint and token of the service.\nIf you deploy an API Edition service, obtain the endpoint and token of the service on the Public Endpoint tab of the Synchronous Call tab.\nIf you deploy a Standard Edition service, obtain the endpoint and token of the service on the Public Endpoint tab.\nTo send a synchronous request, use one of the following methods.\nSample file:\nModify the following parameters in the preceding code:\n<service_url>: Replace the value with the endpoint that you obtained in Step 1. Delete /at the end of the endpoint.\n<token>: Set this parameter to the token that you obtained in Step 1.\nAfter you run the command, the system returns the Base64-encoded image.\nFor information about how to send requests to the SD API, see the GitHub project wiki.\nExample 1 (recommended): We recommend that you mount an OSS bucket to the EAS service to save the generated images. In the following example, the OSS mount path is used in the request body to save the image to OSS, and the oss2 SDK is used to download the image from OSS to your on-premises device.\nThe following table describes the key parameters.\nParameter\nDescription\nurl\nReplace <service_url> with the endpoint that you obtained in Step 1. Delete / at the end of the endpoint.\nbucket\nTake note of the following parameters:\nReplace <endpoint> with the endpoint that is used to access OSS. For example, the http://oss-cn-shanghai.aliyuncs.com endpoint is used for the China (Shanghai) region. If your service is deployed in another region, specify your actual endpoint. For more information, see Regions and endpoints.\nReplace <examplebucket> with the name of the OSS bucket that you created.\n<token>\nSet this parameter to the token that you obtained in Step 1.\nmount_path\nThe OSS mount path that you configured when you deployed the service.\noss_url\nThe OSS storage path that you configured when you deployed the service.\nIf the code successfully runs, the following results are returned. You can go to the OSS console and view the generated image in the outputs directory which you mounted when you deployed the service.\nExample 2: Save an image to an on-premises path. Run the following Python code to obtain the Base64-encoded image and save the image file to an on-premises directory.\nTake note of the following parameters:\n<service_url>: Replace the value with the endpoint that you obtained in Step 1. Delete /at the end of the endpoint.\n<token>: Set this parameter to the token that you obtained in Step 1.\nYou can also use LoRA and ControlNet data in the request to enable a specific functionality.\nAdd <lora:yaeMikoRealistic_Genshin:1000> in the prompt parameter to use LoRA models. For more information, see LORA and alwayson_scripts example.\nSample request body:\nYou can add the controlnet parameter in the request to perform common operations on the generated image, such as keeping the image horizontal or vertical. For more information, see the \"Example: txt2img with ControlNet\" section of this topic.\nAfter you deploy an API Edition service, you can send an asynchronous request to the service. The client subscribes to the inference result in the output queue. Perform the following steps:\nObtain the invocation information.\nClick Invocation Method in the Service Type column of the service. On the Public Endpoint tab of the Asynchronous Call tab, view the service endpoint and token.\nSend asynchronous requests. You can use the SDK for Python or SDK for Java.\nThe queue service requires that input or output queues cannot exceed 8 KB in size. Take note of the following items:\nIf the request data contains an image, we recommend that you use a URL to pass the image data. SD WebUI automatically downloads and parses the image data.\nTo ensure that the response does not contain original image data, we recommend that you use the save_dir parameter to specify the path where the generated image is saved. For more information, see the \"What parameters can I configure for API operations?\" section of this topic.\nBy default, EAS cannot access the Internet. If you set the image_link parameter to an Internet URL, you must configure network connectivity and Internet access so that EAS can access the image.\n\nSample code:\nTake note of the following parameters:\n<service_url>: Replace the value with the endpoint that you obtained in Step 1. Delete / at the end of the endpoint.\n<token>: Replace the value with the token that you obtained in Step 1.\nYou can use SDK for Python to send POST requests to the API endpoints provided by SD WebUI. Select an endpoint based on your business requirements.\nIf you want to pass custom information to the service, specify a custom tag by using a URL parameter. For example, you can append ?task_id=task_abc to the request path to specify a tag named task_id. The tag information is included in the result specified by the tags parameter.\nIf the code successfully runs, the following result is returned. Your actual result may vary.\nMaven is used to manage Java projects. You must add EAS SDK for Java as a dependency in the pom.xml file. For more information, see SDK for Java.\nThe following sample code provides an example on how to send asynchronous requests.\nThe following table describes the key parameters.\nqueueEndpoint: Set the value to the endpoint that you obtained in Step 1. Refer to the sample code to configure this parameter.\nqueueToken: Set the value to the token that you obtained in Step 1.\n<service_name>: Set the value to the name of the asynchronous service that you deployed.\nIf you want to pass custom information to the service, specify a custom tag in the put function. You can refer to the sample code to configure custom tags. The tag information is included in the result within the tags parameter.\nIf the code successfully runs, the following result is returned. Your actual result may vary.\n\nSubscribe to the results of the asynchronous requests.\nAfter the server completes processing related requests, the server automatically pushes the results to the client for efficient asynchronous communication. You can use SDK for Python or SDK for Java to subscribe to the results.\nSample code:\nThe following table describes the key parameters.\nParameter\nDescription\nsink_queue\nReplace 139699392458****.cn-hangzhou.pai-eas.aliyuncs.com with the endpoint that you obtained in the preceding step in the format shown in the sample code.\nReplace sd_async with the name of the asynchronous service that you deployed in the format shown in the sample code.\n<token>\nSet the value to the service token that you obtained in Step 1.\noss_url\nSet the value to the OSS path that you specified when you deployed the service.\nbucket\nTake note of the following parameters:\nUse the endpoint that is used to access OSS. In this example, http://oss-cn-hangzhou.aliyuncs.com is used for the China (Hangzhou) region. If your service is deployed in another region, configure the parameter based on actual situation. For more information, see Regions and endpoints.\nReplace <examplebucket> with the name of the OSS bucket that you created.\nYou can manually commit the data or set the auto_commit parameter to true to automatically commit the data.\nIf the client of the queue service stops consuming data, we recommend that you close the client to release resources.\nYou can also run a cURL command or call an API operation to subscribe to the results. For more information, see Asynchronous inference and queue service.\nThe client continuously listens for results from the server by using the watcher.run() method. If the server returns no result, the client keeps waiting. If the server returns a result, the client prints the result. If the code successfully runs, the following result is returned. Your actual results may vary. You can go to the OSS console and view the generated images in the OSS path that you specified when you deployed the service.\nSample code:\nTake note of the following parameters:\nqueueEndpoint: Set the value to the endpoint that you obtained in Step 1. You can refer to the sample code to configure this parameter.\nqueueToken: Set the value to the token that you obtained in Step 1.\n<service_name>: Set the value to the name of the asynchronous service that you deployed.\nYou can manually commit the data or set the auto_commit parameter to true to automatically commit the data.\nIf the client of the queue service stops consuming data, we recommend that you close the client to release resources.\nYou can also run a cURL command or call an API operation to subscribe to the results. For more information, see Asynchronous inference and queue service.\nThe client continuously listens for results from the server by using the watcher.getDataFrame() method. If the server returns no result, the client keeps waiting. If the server returns a result, the client prints the result. If the code successfully runs, the following result is returned. Your actual results may vary. You can go to the OSS console and view the generated images in the OSS path that you specified when you deployed the service.\nAfter you send an asynchronous request and subscribe to the results, you can use search() methods to query the request status. For more information, see SDK for Python and SDK for Java.\nEAS provides additional parameters on top of the SD WebUI API. You can configure these parameters to use advanced features and meet custom business requirements. For more information, see the \"What parameters can I configure for API operations?\" section of this topic.\nYou can configure extensions for Stable Diffusion WebUI to enable various features. PAI provides various preset extensions, such as the BeautifulPrompt extension, which is used to expand and polish a prompt. The following section uses the BeautifulPrompt extension as an example to describe how to install and use the extension.\nYou can view and install the extension on the Extensions tab of the web UI page. Perform the following steps:\nFind the service that you want to manage and click View Web App in the Service Type column.\nOn the Extensions tab of the web UI page, check whether BeautifulPrompt is selected. If the extension is not selected, select the check box in front of BeautifulPrompt and click Apply and restart UI to load the BeautifulPrompt extension.\nWhen you install the extension, the web UI automatically restarts. After the extension is reloaded, you can perform model inference to check the effect.\nOn the BeautifulPrompt tab, enter a simple prompt in the field and click Generate to generate a detailed prompt.\nPAI provides multiple prompt generation models. The prompt generated by each model varies. Where:\npai-bloom-1b1-text2prompt-sd-v2: suitable for generating prompts in complex scenarios.\npai-bloom-1b1-text2prompt-sd: suitable for generating prompts that describe a single object.\nYou can select a model based on your business requirements.\nSelect the prompt that you want to use and click to txt2img next to the generated prompt.\nThe txt2img tab appears and the prompt that you selected is automatically specified.\nClick Generate to generate an image on the right side of the web UI page.\nBeautifulPrompt helps you improve the image quality and add more details to the image. The following table compares the effects before and after the BeautifulPrompt extension is used:\nPrompt that you enter\nWithout BeautifulPrompt\nWith BeautifulPrompt\na cat\n\n\na giant tiger\n\n\nAfter you deploy the service, the system automatically creates the following directory structure in the mounted OSS bucket or NAS file system:\nTake note of the following parameters:\nmodels: This directory is used to store model files.\nAfter you send an inference request, the system automatically generates the result file to this directory based on the preset configurations in the API code.\nTo load and use a new model, you can store a LoRA or Stable Diffusion model that you downloaded from the open source community or trained in the preceding specified directory. Perform the following steps:\nUpload the model file to the subdirectory of the models directory. For more information, see the \"Upload an object\" section in the Get started by using the OSS console topic.\nOn the Elastic Algorithm Service (EAS) page, find the service that you want to manage and click  /> Restart Service in the Actions column. After the service restarts, the configuration takes effect.\nOn the Stable Diffusion web UI page, switch the model and perform model inference.\n\nYou can reopen the Stable Diffusion web application page or restart the EAS service. Perform the following steps:\nFind the service that you want to manage and click View Web App in the Service Type column to reopen the web application page.\nClick  />Restart Service in the Actions column of the service to restart the EAS service.\nIf the issue persists, the service may need to download models or plug-ins from the Internet. By default, EAS is not connected to the Internet. You can load an image or mount a model offline. However, you may need Internet connection to download specific plug-ins. In this case, we recommend that you find the download path of the model or plug-in by viewing the service logs, download the model, and then upload and mount the model to OSS. For more information, see How do I use my model and output directory?. If you require Internet connection, you can configure network settings. For more information, see Configure network connectivity.\nOn the web UI page, click \u8bbe\u7f6e.\nIn the left-side navigation pane, click \u7528\u6237\u754c\u9762. In the lower part of the \u672c\u5730\u5316 page, select \u65e0.\nIn the upper part of the Stable Diffusion WebUI page, click \u4fdd\u5b58\u8bbe\u7f6e, and then click \u91cd\u8f7d\u524d\u7aef.\nRefresh the web application interface. The page is displayed in English.\nWhen you deploy a service of Standard Edition, API Edition, or Cluster Edition WebUI, the system automatically adds the --filebrowser parameter to the command. You can directly manage your file system by using the web UI. Perform the following steps:\nAfter the service is deployed, click View Web App in the Service Type column.\nOn the web UI page, click the FileBrowser tab. You can view the file system, upload on-premises files to the file system, or download files to your on-premises computer.\n\nCommon parameters\nParameter\nDescription\nUsage notes\n--blade\nEnables PAI-Blade to accelerate the image generation.\nWe recommend that you enable the feature.\n--filebrowser\nAllows you to upload and download models or images.\nBy default, this feature is enabled.\n--data-dir /code/stable-diffusion-webui/data-oss\nThe path used to mount the persistent storage.\n\nThe default path is /code/stable-diffusion-webui/. You can also use a relative path.\n--api\nThe API calling mode of the web UI.\nBy default, this feature is enabled.\n--enable-nsfw-censor\nBy default, this feature is disabled. If you require security compliance, you can enable the content moderation feature.\nEnable the feature based on your business requirements.\n--always-hide-tabs\nHide specific tabs.\nEnable the feature based on your business requirements.\n--min-ram-reserved 40 --sd-dynamic-cache\nCache the Stable Diffusion model to memory.\nN/A\nCluster Edition parameters\nThe ckpt and ControlNet models automatically load files in the public directory and the custom files.\nParameter\nDescription\nUsage notes\n--lora-dir\nSpecifies the public LoRA model directory. Example: --lora-dir /code/stable-diffusion-webui/data-oss/models/Lora.\nBy default, this parameter is not configured. All LoRA directories of the user are isolated and only LoRA models in the user folder are loaded. If you specify a directory, all users load the LoRA models in the public directory and the LoRA models in the user folder.\n--vae-dir\nSpecifies the public Variational Autoencoder (VAE) model directory. Example: --vae-dir /code/stable-diffusion-webui/data-oss/models/VAE.\nBy default, this parameter is not configured. All VAE directories of the user are isolated and only VAE models in the user folder are loaded. If you specify a directory, all users load the VAE models in the public directory.\n--gfpgan-dir\nSpecifies the public GFPGAN model directory. Example: --gfpgan-dir /code/stable-diffusion-webui/data-oss/models/GFPGAN.\nBy default, this parameter is not configured. All GFPGAN directories of the user are isolated and only GFPGAN models in the user folder are loaded. If you specify a directory, all users load the GFPGAN models in the public directory.\n--embeddings-dir\nSpecifies the public embeddings model directory. Example: --embeddings-dir /code/stable-diffusion-webui/data-oss/embeddings.\nBy default, this parameter is not configured. All embeddings directories of the user are isolated and only embedding models in the user folder are loaded. If you specify a directory, all users load the embedding models in the public directory.\n--hypernetwork-dir\nSpecify the public hypernetwork model directory. Example: --hypernetwork-dir /code/stable-diffusion-webui/data-oss/models/hypernetworks.\nBy default, this parameter is not configured. All hypernetwork directories of the user are isolated and only embedding models in the user folder are loaded. If you specify a directory, all users load the hypernetwork models in the public directory.\n--root-extensions\nUses the extension directory as a public directory. If you configure this parameter, all users can see the same extensions.\nIf you want to install or manage extensions in a centralized manner, use this parameter.\nEAS provides additional parameters on top of the SD WebUI API. You can configure these parameters to use advanced features and meet custom business requirements.\nConfigure the SD model, the VAE model, and the path to save the generated images.\nUse URL parameters to send requests, for which status codes are returned.\nAccess the generated images by using URLs, including the images that are processed by ControlNet.\nSample code:\nSample request body:\nParameters:\nsd_model_checkpoint: the SD model that you want to use. The SD model can automatically switch to a foundation model.\nsd_vae: the VAE model that you want to use.\nsave_dir: the path in which to save the generated images.\nSample synchronous request:\nSample response to a synchronous request:\nSample asynchronous request:\nSample request body:\nSample response:\nSample request body:\nSample response:\nYou can also use EAS to deploy the following items:\nYou can deploy an LLM application that can be called by using the web UI or API operations. After the LLM application is deployed, use the LangChain framework to integrate enterprise knowledge bases into the LLM application and implement intelligent Q&A and automation features. For more information, see Quickly deploy LLMs in EAS.\nYou can deploy an AI video generation model service by using ComfyUI and Stable Video Diffusion models. This helps you complete tasks such as short video generation and animation on social media platforms. For more information, see Use ComfyUI to deploy an AI video generation model service.\nYou can deploy a Retrieval-Augmented Generation (RAG)-based LLM chatbot that is suitable for Q&A, summarization, and other natural language processing (NLP) tasks that rely on specific knowledge bases. For more information, see RAG-based LLM chatbot deployment.\nIn AI painting scenarios, you can use a trained LoRA model in an SD service as an auxiliary model to improve the painting performance. For more information, see Deploy a LoRA SD model by using Kohya_ss in EAS.\nFor more information about the SDKs that you can use to call services, see SDKs.\nFor more information about billing rules of EAS, see Billing of EAS."
    },
    "539": {
        "title": "Platform For AI:Intelligent risk control",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/intelligent-wind-control",
        "content": "This Product\nPlatform For AI:Intelligent risk control"
    },
    "540": {
        "title": "Platform For AI:General recommendation solutions",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/intelligent-recommendation-solution",
        "content": "This Product\nPlatform For AI:General recommendation solutions"
    },
    "541": {
        "title": "Platform For AI:FAQ",
        "url": "https://www.alibabacloud.com/help/en/machine-learning-platform-for-ai/latest/machine-learning-platform-for-ai-faq",
        "content": "This Product\nPlatform For AI:FAQ"
    },
    "542": {
        "title": "MaxCompute:Product Introduction",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/product-overview/product-introduction/",
        "content": "This Product\nMaxCompute:Product Introduction"
    },
    "543": {
        "title": "MaxCompute:Pricing",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/product-overview/pricing/",
        "content": "This Product\nMaxCompute:Pricing"
    },
    "544": {
        "title": "MaxCompute:Announcements and Updates",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/product-overview/announcements-and-updates/",
        "content": "This Product\nMaxCompute:Announcements and Updates"
    },
    "545": {
        "title": "MaxCompute:Prepare",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/getting-started/prepare/",
        "content": "This Product\nMaxCompute:Prepare"
    },
    "546": {
        "title": "MaxCompute:Getting Started",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/getting-started/getting-started-5/",
        "content": "This Product\nMaxCompute:Getting Started"
    },
    "547": {
        "title": "MaxCompute:Tutorials",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/getting-started/tutorials/",
        "content": "This Product\nMaxCompute:Tutorials"
    },
    "548": {
        "title": "MaxCompute:Public Datasets",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/getting-started/public-datasets/",
        "content": "This Product\nMaxCompute:Public Datasets"
    },
    "549": {
        "title": "MaxCompute:TPC-DS performance testing",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/getting-started/tpc-ds-performance-test",
        "content": "This Product\nMaxCompute:TPC-DS performance testing\nMaxCompute has high performance advantages in the industry and is suitable for queries of terabytes, petabytes, or even exabytes of data. This topic describes how to perform a big data benchmark TPC-DS test based on the public datasets and test tools that are provided by MaxCompute to verify the performance of MaxCompute.\nPrepare an environment.\nBefore you perform a TPC-DS test, activate MaxCompute and create a project. For more information, see Create a project.\nActivate MaxCompute Query Acceleration (MCQA) for a subscription MaxCompute project. For more information, see MaxCompute Query Acceleration.\nPrepare a test tool.\nMaxCompute provides a TPC-DS automated performance test tool to help you quickly complete a TPC-DS test and automatically generate test results.\nThe test tool can be used only in Linux in which a Java Development Kit (JDK) of 1.7 or later is installed.\nYou can click mc_tpcds_benchmark to download the package of the test tool and run the following command on the Linux server to decompress the package:\nThe following code shows the directory structure of the decompressed file.\nObtain a test dataset.\nMaxCompute provides public datasets. You do not need to prepare test data. All test data is stored in the public project BIGDATA_PUBLIC_DATASET of MaxCompute. For more information, see Overview.\nTPC-DS test datasets are divided into 10 GB, 100 GB, 1 TB, and 10 TB datasets based on the data size. The following table describes the datasets.\nType\nDescription\nDataset name\nSchema name\nTPC-DS\nTPC-DS is a decision support benchmark that models several generally applicable aspects of a decision support system, including queries and data maintenance. TPC-DS enables emerging technologies, such as big data systems, to perform benchmark tests.\nTPC-DS 10-GB performance test dataset\nTPC-DS 100-GB performance test dataset\nTPC-DS 1-TB performance test dataset\nTPC-DS 10-TB performance test dataset\ntpcds_10g\ntpcds_100g\ntpcds_1t\ntpcds_10t\nGo to the mc_tpcds_benchmark directory of the decompressed package of the test tool and modify the config file. The following table describes the configuration items that you need to modify.\nConfiguration item\nDescription\nValue\nODPS_CLT_CMD\nThe absolute path of the executable file of the MaxCompute client.\nThe client that is provided in the package is odps_clt in the working directory. You can modify the related configuration. For more information, see Install and configure the MaxCompute client.\nExample: /xxxxx/mc_tpcds_benchmark/odps_clt/bin/odpscmd.\nPROJECT\nThe MaxCompute project that is used for the test.\nExample: tpcds_test.\nSF\nThe data size of the TPC-DS test.\nUnit: GB. 1 indicates 1 GB. 1000 indicates 1 TB. You can change the value based on your test requirements.\nDefault value: 1000\nSQL_FLAGS\nThe built-in flag parameters of MaxCompute. You do not need to modify the configuration of these parameters.\nset odps.sql.session.result.cache.enable=false: Disable the result cache feature for a MaxCompute project in MCQA mode. This ensures that each query can be independently executed.\nset odps.sql.allow.cartesian=true: Allow SQL to support Cartesian product calculation.\nset odps.sql.session.query.timeout=600: Specify the timeout period of a Fuxi job for a MaxCompute project in MCQA mode.\nRun the following command in the mc_tpcds_benchmark directory to start the TPC-DS test:\nIf the test is successful, a pt.log file is generated in the mc_tpcds_benchmark directory. You can run the following command to view the logs of the job:\nYou can view the execution information about a job on the Jobs page in the MaxCompute console. For more information, see Manage jobs.\nIf the execution is successful, a test result file named console_test_result.csv is generated in the mc_tpcds_benchmark directory. You can view test results in the file, including the total test duration, the execution time of each query, and the related LogView information."
    },
    "550": {
        "title": "MaxCompute:Connect to Maxcompute",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/connect-to-maxcompute/",
        "content": "This Product\nMaxCompute:Connect to Maxcompute"
    },
    "551": {
        "title": "MaxCompute:SQL",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/sql-3/",
        "content": "This Product\nMaxCompute:SQL"
    },
    "552": {
        "title": "MaxCompute:Engines",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/engines/",
        "content": "This Product\nMaxCompute:Engines"
    },
    "553": {
        "title": "MaxCompute:Storage API",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/development-reference-open-storage/",
        "content": "This Product\nMaxCompute:Storage API"
    },
    "554": {
        "title": "MaxCompute:Data + AI and data science",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/data-science-computing-overview/",
        "content": "This Product\nMaxCompute:Data + AI and data science\nMaxFrame is a distributed science computing framework that is developed by Alibaba Cloud. In MaxCompute, MaxFrame is an evolution from PyODPS and Mars, and provides a set of APIs that are fully compatible with Pandas interfaces to allow you to use MaxCompute in the same manner that you use Python. This topic describes the background information and development history of the Python development ecosystem that is provided by MaxCompute.\nAs the mainstream programming language for machine learning and AI model development, Python provides rich science computing and visualization libraries such as NumPy, SciPy, scikit-learn, and Matplotlib for data science and data analytics. Python also supports a wide range of training frameworks such as TensorFlow, PyTorch, XGBoost, and LightGBM.\nNumPy: a library used for multidimensional array operations.\nPandas: a data analytics library that contains DataFrame.\nMatplotlib: a two-dimensional drawing library for creating graphs.\nscikit-learn: a library that provides algorithms for data analytics and data mining.\nMaxCompute provides a Python development ecosystem to meet the requirements for processing, analytics, mining, and model training of large amounts of data. You can use centralized Python APIs to perform data processing and mining in a comprehensive and efficient manner.\nThe following figure shows the development history of the Python development ecosystem that is provided by MaxCompute.\nPyODPS was officially released in 2015 and works as MaxCompute SDK for Python. You can use Python interfaces to perform operations on data in MaxCompute. After the iterative development of multiple versions, PyODPS supports DataFrame. PyODPS also provides Pandas-like syntax and built-in operators for data aggregation, sorting, and deduplication.\nCore features of PyODPS:\nSupport for basic operations on MaxCompute objects (in 2015):\nPyODPS supports access to MaxCompute objects, such as tables, resources, and functions.\nPyODPS allows you to submit SQL requests by using the run_sql or execute_sql method.\nPyODPS allows you to run Platform for AI (PAI) commands to run machine learning tasks by using the run_xflow or execute_xflow method.\nPyODPS allows you to use the open_write, open_reader, or cloud-native Tunnel API operations to upload and download data.\nSupport for DataFrame APIs and Pandas-like interfaces to fully utilize the computing capabilities of MaxCompute for DataFrame computing (from 2016 to 2022):\nPyODPS DataFrame allows you to use Python to perform data operations. This way, you can easily leverage the language features of Python.\nPyODPS DataFrame provides a large number of Pandas-like interfaces that have extended syntax. For example, MapReduce APIs are added to adapt to the big data environment.\nPyODPS DataFrame provides built-in functions for common operations such as data aggregation, data sorting, data deduplication, data sampling, and visual drawing.\nThe Python ecosystem contains rich science computing libraries, such as NumPy, Pandas, and scikit-learn. The libraries provide convenient data analytics and mining operators. However, most of the libraries are restricted by standalone resources. Mars is a tensor-based centralized distributed computing framework that implements approximately 70% of the interfaces of NumPy in a distributed manner. Mars significantly reduces the difficulty in writing distributed science computing code and improves performance.\nCore features of Mars:\nCompatibility and distributed capability: Mars was officially open sourced in January 2019. Mars enables NumPy, Pandas, scikit-learn, and Python functions to be executed in a distributed manner and is compatible with most interfaces.\nMars and PyODPS are suitable for different scenarios. For example, users who are familiar with Pandas and want to run NumPy or scikit-learn in a parallel and distributed manner are more suitable to use Mars. Users who are familiar with DataFrame and have high requirements for stability and data amount (terabytes-level or higher) are suitable to use PyODPS. However, the complexity of the architecture also brings difficulties to users.\nMaxFrame is a distributed science computing framework that is developed by Alibaba Cloud based on PyODPS and Mars. MaxFrame provides a set of APIs that are fully compatible with Pandas interfaces. MaxFrame provides higher interface compatibility than Mars and allows you to use MaxCompute in the same manner that you use Python. MaxFrame automatically submits jobs to the optimal underlying engine based on the use scenarios. The underlying engines include the SQL engine, single Python engine, and Mars engine. You do not need to select an execution engine. You need to only focus on the process from data development and analytics to AI training and inference. The following figure shows the architecture.\nCore features of MaxFrame:\nMore familiar development habits\nMaxFrame is compatible with the Python development ecosystem and provides unified development interfaces for the Python ecosystem of MaxCompute. You can use the same Python code to implement a complete data and AI development process.\nMaxFrame can directly reference third-party libraries such as NumPy, SciPy, Pandas, and Matplotlib to perform operations such as scientific computing, data analysis, and visualization. This reduces the operation costs of users.\nHigher processing performance\nMaxFrame allows you to directly access MaxCompute data. When you run MaxFrame, you do not need to pull data to your on-premises machine. This eliminates the need for data transfers and improves execution efficiency.\nMaxFrame can directly use huge amounts of elastic computing resources in MaxCompute. MaxFrame supports automatic distribution and parallel processing. This significantly reduces the data processing time.\nMore convenient development experience\nMaxFrame is integrated with MaxCompute Notebook and DataWorks. You can directly use MaxFrame in MaxCompute Notebook or DataWorks without the need to configure the environment. You can also install and use MaxFrame on your on-premises environment.\nMaxFrame allows you to directly reference built-in images and custom images in MaxCompute. This reduces the time to prepare for a development environment and prevents conflicts between environment versions.\nImproved operator support\nMaxFrame is fully compatible with Pandas interfaces and automatically performs distributed processing. This ensures powerful data processing capabilities and significantly improves data processing and computing efficiency."
    },
    "555": {
        "title": "MaxCompute:Data lakehouse",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/data-lake-integration/",
        "content": "This Product\nMaxCompute:Data lakehouse"
    },
    "556": {
        "title": "MaxCompute:Near real-time data warehouse",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/near-real-time-bin/",
        "content": "This Product\nMaxCompute:Near real-time data warehouse"
    },
    "557": {
        "title": "MaxCompute:Data Migration",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/data-migration-1/",
        "content": "This Product\nMaxCompute:Data Migration"
    },
    "558": {
        "title": "MaxCompute:Development",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/development/",
        "content": "This Product\nMaxCompute:Development"
    },
    "559": {
        "title": "MaxCompute:BI Tools",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/bi-tools/",
        "content": "This Product\nMaxCompute:BI Tools"
    },
    "560": {
        "title": "MaxCompute:Permission Management",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/permission-management-1/",
        "content": "This Product\nMaxCompute:Permission Management"
    },
    "561": {
        "title": "MaxCompute:Maintenance Management",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/maintenance-management/",
        "content": "This Product\nMaxCompute:Maintenance Management"
    },
    "562": {
        "title": "MaxCompute:SDK Reference",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/sdk-reference/",
        "content": "This Product\nMaxCompute:SDK Reference"
    },
    "563": {
        "title": "MaxCompute:API Reference",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/api-reference/",
        "content": "This Product\nMaxCompute:API Reference"
    },
    "564": {
        "title": "MaxCompute:CLI integration example",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/cli-integration-example",
        "content": "This Product\nMaxCompute:CLI integration example\nThis topic describes how to use Alibaba Cloud Command Line Interface (CLI) to call the MaxCompute OpenAPI, demonstrated through the example of invoking the ListProjects API to fetch a list of MaxCompute projects.\nAlibaba Cloud CLI is a command line tool based on OpenAPI. It allows for the automation of management and maintenance tasks for MaxCompute. For more information, see What is Alibaba Cloud CLI?\nFirst, choose the appropriate installation package for your operating system.\nWindows: Install Alibaba Cloud CLI on Windows\nLinux: Install Alibaba Cloud CLI on Linux\nmacOS: Install Alibaba Cloud CLI on macOS\nCloud Shell is pre-installed with Alibaba Cloud CLI and automatically configures your identity credentials, simplifying the setup process. You can test Alibaba Cloud CLI commands in Cloud Shell. For more information, see What is Cloud Shell?\nFor security reasons, we recommend that you create a Resource Access Management (RAM) user and assign permissions based on the principle of least privilege when accessing OpenAPI. For more information about the policies supported by MaxCompute, see Identity-based policies.\nAlibaba Cloud CLI supports various credential types. For more information, see Credential types. You can use the AccessKey of a RAM user to configure its identity credentials. Follow these steps to set up AK-type credentials:\nCreate a RAM user and an AccessKey pair to configure the identity credentials. For more information, see Create a RAM user and Create an AccessKey pair.\nGrant the RAM user permissions. In this example, assign the RAM user read-only access to MaxCompute by using the AliyunMaxComputeReadOnlyAccess policy. For more information, see Grant permissions to a RAM user.\nGet the region ID for your operations. Alibaba Cloud CLI uses the specified region ID to initiate API calls. For available regions for MaxCompute, see Endpoints.\nWhen using Alibaba Cloud CLI, you can use the --region option and its parameter region to specify a region. After you specify a valid region, Alibaba Cloud CLI ignores the region in the default identity credential and environment variable configurations and uses the region that you specify to run commands. For more information, see Command line options for API calls.\nConfigure AK-type credentials by using the AccessKey of the RAM user and name the configuration file AkProfile. For more information, see Configuration examples.\nVisit the  or ListProjects debugging address.\n\nInput the request parameters in the Parameters section and click the CLI Example tab to see the generated CLI command.\nCopy the CLI command or execute it quickly in Cloud Shell:\nClick the Run Command button to open Cloud Shell and complete command debugging.\nClick the Copy button to copy the CLI command to your clipboard. You can then paste it into your local shell to run or modify it for automated command line scripts.\nWhen pasting the CLI command into your local shell for testing, ensure that the parameter formats are correct. For details on parameter formats in Alibaba Cloud CLI commands, see Parameter formats.\nThe OpenAPI portal automatically includes the --region option in the generated command. When executing the command locally, Alibaba Cloud CLI prioritizes the specified region over the default identity credential configuration and environment variable settings. You may choose to keep or remove this option as needed.\nThe following example demonstrates how to use the --help option to retrieve a list of MaxCompute OpenAPI operations that are supported by Alibaba Cloud CLI. For more information, see List of operations by function.\nExecute the following command:\nExpected output:\n\nThe following example demonstrates how to use Alibaba Cloud CLI to call the MaxCompute ListProjects API to filter and retrieve a list of MaxCompute projects based on input parameters. For the details of the API, see ListProjects.\nExecute the following command:\nExpected output:\nIf an error occurs after calling the MaxCompute OpenAPI, verify the request parameters and their values against the returned error code.\nYou can record the RequestID from the call or the error message from the SDK. For self-service diagnostics, use the  or Alibaba Cloud OpenAPI Diagnostics Platform."
    },
    "565": {
        "title": "MaxCompute:Common Reference",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/user-guide/common-reference/",
        "content": "This Product\nMaxCompute:Common Reference"
    },
    "566": {
        "title": "MaxCompute:Best Practices",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/use-cases/best-practices/",
        "content": "This Product\nMaxCompute:Best Practices"
    },
    "567": {
        "title": "MaxCompute:MaxCompute security white paper",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/security-and-compliance/maxcompute-security-white-paper",
        "content": "This Product\nMaxCompute:MaxCompute security white paper\nAlibaba Cloud reminds you to carefully read and fully understand the terms and conditions of this legal disclaimer before you read or use this document. If you have read or used this document, it shall be deemed as your total acceptance of this legal disclaimer.\nYou shall download and obtain this document from the Alibaba Cloud website or other channels that are authorized by Alibaba Cloud, and use this document for your own legal business activities only. The content of this document is considered confidential information of Alibaba Cloud. You shall strictly abide by the confidentiality obligations. No part of this document shall be disclosed or provided to any third party for use without the prior written consent of Alibaba Cloud.\nNo part of this document shall be excerpted, translated, reproduced, transmitted, or disseminated by any organization, company, or individual in any form or by any means without the prior written consent of Alibaba Cloud.\nThe content of this document may be changed due to product version upgrades, adjustments, or other reasons. Alibaba Cloud reserves the right to modify the content of this document without notice. The updated versions of this document will be occasionally released through channels that are authorized by Alibaba Cloud. You shall pay attention to the version changes of this document as they occur and download and obtain the most up-to-date version of this document from channels that are authorized by Alibaba Cloud.\nThis document serves only as a reference guide for your use of Alibaba Cloud products and services. Alibaba Cloud provides the document in the context that Alibaba Cloud products and services are provided on an as is, with all faults, and as available basis. Alibaba Cloud makes every effort to provide relevant operational guidance based on existing technologies. However, Alibaba Cloud hereby makes a clear statement that it in no way guarantees the accuracy, integrity, applicability, and reliability of the content of this document, either explicitly or implicitly. Alibaba Cloud shall not bear any liability for any errors or financial losses incurred by any organizations, companies, or individuals arising from their download, use, or trust in this document. Alibaba Cloud shall not, under any circumstances, bear responsibility for any indirect, consequential, exemplary, incidental, special, or punitive damages, including lost profits arising from the use or trust in this document, even if Alibaba Cloud has been notified of the possibility of such a loss.\nBy law, all the content of the Alibaba Cloud website, including but not limited to works, products, images, archives, information, materials, website architecture, website architecture, website graphic layout, and webpage design, are intellectual property of Alibaba Cloud and/or its affiliates. This intellectual property includes, but is not limited to, trademark rights, patent rights, copyrights, and trade secrets. No part of the Alibaba Cloud website, product programs, or content shall be used, modified, reproduced, publicly transmitted, changed, disseminated, distributed, or published without the prior written consent of Alibaba Cloud and/or its affiliates. The names owned by Alibaba Cloud include, but are not limited to, Alibaba Cloud, Aliyun, HiChina, and other brands of Alibaba Cloud and/or its affiliates, which appear separately or in combination, as well as the auxiliary signs and patterns of the preceding brands, or anything similar to the company names, trade names, trademarks, product or service names, domain names, patterns, logos, marks, signs, or special descriptions that third parties identify as Alibaba Cloud and/or its affiliates.\nPlease contact Alibaba Cloud directly if you discover any errors in this document.\nMaxCompute builds a comprehensive data security system based on confidentiality, integrity, and availability, and provides comprehensive data access control capabilities and a secure and trusted computing environment. The cluster high availability and disaster recovery solutions are provided to ensure business continuity. MaxCompute records detailed user operation logs and task runtime logs for in-process O&M monitoring and post-event security auditing. MaxCompute is built on top of Alibaba Cloud Infrastructure as a service (IaaS) and leverages the security capabilities of the cloud infrastructure. MaxCompute is linked with the security products of the cloud platform, such as Resource Access Management (RAM), Security Center of DataWorks, and Data Security Guard of DataWorks, to implement more security control scenarios.\n\nMaxCompute provides an audit report of the principle compliance description about security, availability, and confidentiality in trusted Alibaba Cloud services in accordance with the relevant standards of the American Institute of Certified Public Accountants (AICPA). This audit report is issued by an independent third-party audit firm. For more information about the audit report, see SOC 3 Report.\nMaxCompute supports the following user identities: Alibaba Cloud accounts, RAM users, and RAM roles. MaxCompute also supports authentication based on an AccessKey pair, multi-factor authentication (MFA), and Security Token Service (STS) authorization.\nYou can create an AccessKey pair in the RAM console. An AccessKey pair consists of an AccessKey ID and an AccessKey secret. The AccessKey ID is public and uniquely identifies a user, whereas the AccessKey secret is private and used to authenticate a user. Before a client sends a request to MaxCompute, the client generates a string to be signed in the format that is required by MaxCompute and then generates a signature for the request by using the AccessKey secret. After MaxCompute receives the request, MaxCompute finds the AccessKey secret based on the AccessKey ID and then generates a signature. If the signature is the same as the signature that is sent by the client, the request is valid. Otherwise, MaxCompute rejects the request and returns an HTTP 403 error.\nFor more information, see User authentication.\nMaxCompute provides the following access control mechanisms to perform fine-grained access control: access control list (ACL)-based access control, policy-based access control, download control, LabelSecurity, and row-level permissions. Authorization objects include projects, quotas, network connections, tables, functions, resources, instances, external tables, and external volumes.\nMaxCompute supports RAM-based authorization to grant access and management permissions on MaxCompute resources of your Alibaba Cloud account to RAM users and RAM roles. This way, you can assign minimum permissions to users based on your business requirements. This reduces information security risks for enterprises. For more information, see RAM permissions.\nAn ACL is used to implement object-based authorization. An ACL specifies permissions on an object and is considered as a subresource of the object. An ACL takes effect only if the object exists. If the object is deleted, the ACL of the object is also deleted. ACL-based access control is similar to the authorization mechanism that is implemented by using the GRANT and REVOKE statements defined in SQL-92. You can execute these statements to grant or revoke permissions on an object. To manage permissions, you must specify the effect (grant or revoke), object (such as a table or resource), subject (user or role), and action (such as read, write, or delete). For more information, see ACL-based access control.\nA policy is used to define role permissions. After you assign a role to a user, the permissions of the role take effect on the user. Compared with ACL-based access control, policy-based access control supports not only the whitelist mechanism but also the blacklist mechanism. When you perform policy-based access control, you can specify a policy to allow a role to perform specified operations on specified objects or deny a role from performing specified operations on specified objects. If both the whitelist and blacklist mechanisms are used for the same object, the blacklist mechanism takes precedence. For more information, see Policy-based access control.\nLabelSecurity allows you to flexibly control user access to column-level sensitive data by using data sensitivity level labels. Data in tables or columns needs to be classified based on data sensitivity levels and users need to be classified based on data access levels. You can set the sensitivity level to 0 to 9 to adapt to different data classification standards. The following security policies are supported:\nNo-ReadUp: Users cannot read data that has a higher data sensitivity level than their data access level, unless the users are explicitly granted permissions.\nTrusted-User: Users are allowed to write data of all sensitivity levels. The default sensitivity level of newly written data is 0.\nFor more information, see Label-based access control.\nMaxCompute provides multiple endpoint-based access modes, including the Internet, virtual private cloud (VPC), and PrivateLink. You can enable endpoints for network isolation based on your business requirements. You can configure an IP address whitelist for each endpoint to limit connections from clients.\nMaxCompute provides secure computing containers and Java and Python sandboxes to isolate task processes and prevent malicious code from affecting cluster computing tasks.\nMaxCompute provides hybrid computing modes based on the considerations of computing flexibility and extensibility. MaxCompute supports user-defined functions (UDFs) in SQL engines and third-party computing frameworks such as Spark and Python in compute engines. However, these features may cause untrusted code, which can trigger unintended system damage and malicious code attacks. MaxCompute uses lightweight secure computing containers and language-level sandboxes to run untrusted code in secure computing containers to achieve process-level security isolation.\nMaxCompute provides security assurance to meet the network communication requirements of internal data synchronization and external data access in computing tasks. MaxCompute builds an overlay virtual network for each computing task among its running security containers to achieve security isolation from the host network. This ensures that all nodes in the task can communicate by using private IP addresses but cannot access the host network. If a computing task needs to access the data service API over the Internet or in a VPC, MaxCompute supports task-level networking by using network connections. You must declare the destination network that you want to access and meet the permission check requirements when you start a job. For more information, see Network connection process.\nThe code runtime environment provided by MaxCompute belongs to users. Any legal liability arising from code execution shall be borne by users.\nMaxCompute provides data security measures for the storage, computing, and transmission status of data.\nMaxCompute integrates Key Management Service (KMS) and Bring Your Own Key (BYOK) to automatically encrypt and decrypt data files in storage media. Applications can meet data ciphertext storage requirements without modification, and can use keys to encrypt or decrypt persistent data files of tables and partitions. Encryption algorithms such as AES256 are supported. Automatic key rotation is supported. If the customer disables the key service, the encrypted data cannot be decrypted and accessed. This meets the requirements of data confidentiality and regulatory compliance. For more information, see Storage encryption.\nMaxCompute supports column-level content encryption for sensitive data, such as personally identifiable information (PII), financial information, accounts, and passwords. Applications can call encryption functions to encrypt sensitive data before writing data and decrypt the data during data reading. This prevents sensitive data leaks caused by attacks, such as SQL injection or data breach. MaxCompute can be connected to KMS to encrypt data by using keysets that contain multiple keys. MaxCompute supports the following encryption algorithms: AES-GCM-256, AES-SIV-CMAC-128, and AES-SIV-CMAC-256. These encryption algorithms provide higher encryption reliability to prevent data cracking. For more information, see Encryption and decryption functions.\nMaxCompute supports the dynamic data masking feature to protect sensitive data such as PII during business development and testing, data sharing, and O&M. Data masking policies include masking, hashing, character replacement, numeric value rounding, and date rounding. Data masking policies can be used together with the data classification feature of Data Security Guard to meet your masking requirements for sensitive data, such as identity information, bank card numbers, addresses, and phone numbers. Data masking of MaxCompute is implemented in the link that is closest to data reading from storage. This ensures that data is de-sensitive during query, download, association, and UDF computing to avoid sensitive data breach. For more information, see Dynamic data masking.\nWhen you connect to MaxCompute by using the MaxCompute client, SDK, or API, the HTTPS TLS v1.2 encryption protocol is used. This prevents data from being intercepted or tampered with during transmission.\nMaxCompute allows you to specify a data retention period. After you specify a data retention period, MaxCompute automatically cleans up expired data to reduce data leak risks and storage costs. You can specify the lifecycle of a table based on your business requirements and data usage frequency. MaxCompute determines whether the interval between the latest update time (LastModifiedTime) of each table or partition and the current time exceeds the lifecycle. If the interval exceeds the lifecycle, MaxCompute performs the reclaim operation. For more information, see Lifecycle management operations.\nMaxCompute also supports tiered storage for cold and hot data. Infrequent Access (IA) storage and long-term storage can help you limit the access frequency of historical data and reduce storage costs. For more information, see Configure storage tiers for storage resources.\nMaxCompute provides data integrity protection measures during data processing.\nMaxCompute supports atomicity, consistency, isolation, durability (ACID) for large-scale data processing jobs. Delta tables use the multiversion concurrency control (MVCC) model to ensure read/write snapshot isolation and optimistic concurrency control (OCC) to control transaction concurrency. Row-level or file-level transaction concurrency control is not supported. Instead, each batch data processing operation is managed as a separate transaction. The transaction conflict logic of some frequently performed operations is optimized based on the semantics of the operations to better support concurrency control while ensuring correctness. MaxCompute uses cyclic redundancy check (CRC) codes to verify data integrity during data storage and transmission. For more information, see ACID semantics.\nMaxCompute uses a distributed file system to automatically create multiple replicas for stored data. By default, three replicas are created. The replicas are distributed across different physical machines and racks to prevent data loss caused by single points of failures (SPOFs) and ensure data durability and integrity.\nMaxCompute stores data in the Apsara Distributed File System. The system provides a flat linear storage space and slices linear addresses. Each shard is called a chunk. Each chunk has three replicas and stores the replicas on different nodes in the cluster based on specific policies. This prevents data unavailability due to the failure of one chunk server or one rack. The operations of adding, modifying, and deleting data are synchronized to the three replicas to ensure data integrity and consistency. The file system reclaims the storage space that is released after data is deleted, prohibits other users from accessing the storage space, and erases data to ensure that the deleted data cannot be restored.\nThe task scheduling system of MaxCompute has high fault tolerance and provides the task retry mechanism. When an SQL job runs, the system builds a directed acyclic graph (DAG) to allocate appropriate computing resource nodes for the job and optimizes the execution process. This eliminates unnecessary shuffles and network jitters and prevents the overall job from being affected by partial node faults. This ensures the accuracy of the execution result and execution efficiency.\nMaxCompute Tunnel supports resumable transmission for batch data uploads and downloads. MaxCompute Tunnel also allows you to specify the number of data rows that can contain errors and adjust the buffer size. This ensures data integrity for data processing.\nBy default, the backup and restoration feature is enabled for MaxCompute tables. This feature effectively prevents data loss caused by misoperations. MaxCompute automatically backs up historical versions of data each time data is modified or deleted, or a table is deleted. Historical versions of data are retained for up to 30 days. You can quickly restore data based on the data version number.\nDelta tables support time travel queries. You can query data snapshots of a delta table at any time in the previous seven days. You can also query incremental data within a specified time range or version range.\nFor more information, see Backup and restoration.\nMaxCompute provides security measures to ensure data availability.\nMaxCompute provides the package-based access control mechanism for cross-project data sharing scenarios. This mechanism can package the data resources and related permissions of a project. After the package is installed for a third-party project, the third-party project can access the authorized data resources of the project. After the package-based access control mechanism is used, the administrator of Project A can create a package and authorize Project B to install the package. After the administrator of Project B installs the package, you can manage whether the package needs to be further authorized to users in your own project. For more information, see Cross-project resource access based on packages.\nMaxCompute provides project protection mechanism for scenarios where data is only imported but not exported. For example, users who have access permissions on multiple projects can transfer data between different projects. If data in a project is sensitive and cannot be exported to other projects, the administrator can use the project protection mechanism to protect the data. This mechanism requires that data be written to the project but not read from the project. For more information, see Project data protection.\nMaxCompute supports zone-disaster recovery and cross-region disaster recovery to provide disaster recovery capabilities for customers.\nZone-disaster recovery of MaxCompute extends data storage and computing services to three zones in the same city to improve the resilience of your business. Zone-disaster recovery is suitable for industries such as finance and critical infrastructure. This feature ensures that services of business systems do not stop due to the failure of a single data center. This feature can provide data redundancy backup to reduce business downtime and meet industry compliance requirements for better customer experience on upper-layer applications.\nThis feature allows you to extend the availability of project-level data from a single zone to three zones in the same city. The three zones are physically isolated, but the network connection has low latency. This implements fault isolation and real-time data synchronization across data centers to ensure data integrity and availability if a disaster occurs.\nCross-region disaster recovery of MaxCompute allows you to select a region that is more than 1,000 kilometers away from the current region as a data disaster backup cluster to establish a complete geo-redundancy for the project-level data of customers and protect the data from regional natural disasters.\nMaxCompute provides in-process monitoring and post-audit capabilities for data authorization and data usage.\nMaxCompute provides detailed ActionTrail logs, which record information about operations related to jobs (instances), tables, users, roles, and permissions. ActionTrail logs can meet the compliance requirements for log retention and security management requirements such as real-time monitoring and backtracking analysis.\nMaxCompute records all operations triggered by users. You can view and retrieve user behavior logs in ActionTrail logs and store the logs in Simple Log Service projects or specified OSS buckets for a long period of time. For more information, see Audit logging.\nMaxCompute allows you to query the project metadata and job running history. MaxCompute also allows you to analyze data in real time and periodically export user information, role information, table partition authorization information, historical job records of the previous14 days, and batch upload and download task records for security audit based on the ANSI SQL-92 Information Schema. For more information, see Information schema."
    },
    "568": {
        "title": "MaxCompute:RAM-based access control",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/security-and-compliance/use-ram-for-access-control/",
        "content": "This Product\nMaxCompute:RAM-based access control"
    },
    "569": {
        "title": "MaxCompute:Project security configuration",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/security-and-compliance/project-security-configuration/",
        "content": "This Product\nMaxCompute:Project security configuration"
    },
    "570": {
        "title": "MaxCompute:Data security configuration",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/security-and-compliance/data-security-configuration/",
        "content": "This Product\nMaxCompute:Data security configuration"
    },
    "571": {
        "title": "MaxCompute:FAQ about security configurations",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/security-and-compliance/faq-about-security-configurations",
        "content": "This Product\nMaxCompute:FAQ about security configurations\nThis topic provides answers to some frequently asked questions about security configurations of MaxCompute.\nCategory\nFAQ\nData security\nHow does MaxCompute ensure data security?\nIs data in MaxCompute reliable?\nCan I add CIDR blocks to an IP address whitelist of a VPC?\nProject security\nWhat do I do if the error message \"AllMachineInBlackList\" appears when I run a job?\nWhen data protection is enabled for a MaxCompute project, I cannot export data from the MaxCompute project to a MySQL database. What do I do?\nHow do I restore data of deleted tables?\nMaxCompute provides comprehensive measures to ensure data security.\nIn multi-user scenarios, unauthorized users, except project owners or administrators, cannot access MaxCompute projects.\nMaxCompute provides multiple authorization methods to ensure that only authorized users can access MaxCompute projects.\nMaxCompute provides sandboxes to effectively prevent malicious users from performing unauthorized operations. For more information about sandboxes, see Java sandbox.\nAn AccessKey pair is used to verify the identity of a user. If user information leaks, you can immediately disable the AccessKey pair without affecting the use of other AccessKey pairs.\nIf an urgent data security risk occurs in a project, you can run the set ProjectProtection=true; command to enable data protection for the project. This prohibits users from exporting data from the project and prevents data leaks.\nMaxCompute uses the triplicate storage mode to ensure data reliability.\nIf you configure lifecycle rules for a table in MaxCompute, MaxCompute automatically deletes the table when the rules are met. If you do not configure lifecycle rules for a table, the table is permanently stored.\nYes, you can add CIDR blocks to an IP address whitelist of a virtual private cloud (VPC). For more information, see Manage IP address whitelists.\nProblem description\nWhen a job is run in MaxCompute, the following error message appears:\nCause\nSecurity hardening is performed on MaxCompute.\nSolution\nFill in an application form to join the MaxCompute DingTalk group for technical support.\nThe project owner or administrator can run the set projectProtection=false; command to disable data protection for the project. The project owner or administrator can also configure exception policies to allow you to export data. For more information about project data protection, see Project data protection.\nYou can use the backup and restoration feature that is provided by MaxCompute to restore data of deleted tables. For more information about the backup and restoration feature, see Backup and restoration."
    },
    "572": {
        "title": "MaxCompute:FAQ",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/support/faq-4",
        "content": "This Product\nMaxCompute:FAQ\nThis topic provides answers to some frequently asked questions about MaxCompute.\nCategory\nReferences\nResource packages\nFAQ about resource packages\nPreparations\nFAQ\nConnection to MaxCompute\nFAQ about SDK for Java\nData migration\nFAQ about Tunnel commands\nFAQ about Tunnel SDK\nDevelopment\nSQL: FAQ about DDL operations\nBuilt-in functions: FAQ about built-in functions\nUser-defined functions (UDFs): FAQ about MaxCompute Java UDFs and FAQ about MaxCompute Python UDFs\nPyODPS: FAQ about PyODPS\nMapReduce: FAQ about MaxCompute MapReduce\nWhy does a job slowly run and how do I resolve this issue?\nSecurity management\nFAQ about permission management\nFAQ about security configurations\nO&M management\nFAQ about Information Schema\nFAQ about other O&M issues"
    },
    "573": {
        "title": "MaxCompute:Legal Resources",
        "url": "https://www.alibabacloud.com/help/en/maxcompute/support/legal-resources/",
        "content": "This Product\nMaxCompute:Legal Resources"
    }
}